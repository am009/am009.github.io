<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>一句话的问题</title>
    <url>/%E4%B8%80%E5%8F%A5%E8%AF%9D/</url>
    <content><![CDATA[<h1 id="一句话的问题">一句话的问题</h1>
<p>很多问题的解决方案，虽然非常有用，但是概括起来不需要多少字，都汇总在这里。</p>
<span id="more"></span>
<p>[toc]</p>
<h2
id="使用draw.io-diagrams.net-给paper画图camera-ready提交时提示使用了type-3字体">使用Draw.io
diagrams.net 给paper画图，Camera Ready提交时提示使用了Type 3字体</h2>
<p>2024年9月2日 发现使用了特殊字符时会出现Type
3字体。比如emoji，特殊的图形或者数字字符。使用Adobe
Acrobat打开PDF在属性-字体里也可以看到有Type 3字体。</p>
<p>使用Adobe Illustrator 打开PDF的图然后直接另存为，就可以消除这些Type
3字体。</p>
<p>使用matplotlib的时候进行下面的设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib</span><br><span class="line">matplotlib.rcParams[&#x27;pdf.fonttype&#x27;] = 42</span><br><span class="line">matplotlib.rcParams[&#x27;ps.fonttype&#x27;] = 42</span><br></pre></td></tr></table></figure>
<h2 id="windows-11-远程桌面无法保存密钥">Windows 11
远程桌面无法保存密钥</h2>
<p>Windows 11 远程桌面无法保存密钥，报错"Windows Defender Credential
Guard does not allow using saved credentials"</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cmdkey /generic:TERMSRV/&lt;targetNameOrIp&gt; /user:&lt;username&gt; /pass:&lt;password&gt;</span><br></pre></td></tr></table></figure>
<p>来自：<a
href="https://superuser.com/questions/1756354/windows-defender-credential-guard-does-not-allow-using-saved-credentials-for-r">remote
desktop - "Windows Defender Credential Guard does not allow using saved
credentials" for RDP connections? - Super User</a></p>
<h2
id="调试docker构建过程-docker-image-build-debug-dockerfile">调试docker构建过程
docker image build debug dockerfile</h2>
<p>首先，在docker file里需要调试的地方增加
<code>RUN sleep infinity</code>
然后使用<code>ps -aux | grep sleep</code>找到sleep的uid，并使用
<code>sudo nsenter -a -t $PID_OF_SLEEP sh</code> 进入构建过程调试。</p>
<p>来自：
https://github.com/moby/buildkit/issues/1053#issuecomment-564340155</p>
<h2
id="docker修改现有容器的参数环境变量等">docker修改现有容器的参数，环境变量等</h2>
<ul>
<li>停止docker daemon</li>
<li>修改配置文件
<ul>
<li>每个容器的json配置文件在<code>/var/lib/docker/containers/&#123;&#123;.Id&#125;&#125;/config.v2.json</code>。</li>
</ul></li>
<li>启动docker daemon</li>
</ul>
<h2 id="ssh密钥管理">SSH密钥管理</h2>
<p>建议SSH密钥按照设备命名和管理。</p>
<ul>
<li>公钥并不是什么秘密，没必要一个设备创建多个公钥</li>
<li>泄露风险也是按设备的，单个设备被控制，所有该设备上的私钥都会泄露。</li>
</ul>
<p>按照这个思路，windows下wsl可以和本机用同一个密钥。</p>
<p>我现在就是这样，每个设备就用单独一个默认的id_ed25519，从来也不需要加选项单独指定私钥。</p>
<h2 id="github下载单个文件夹">Github下载单个文件夹</h2>
<p><a
href="https://stackoverflow.com/questions/7106012/download-a-single-folder-or-directory-from-a-github-repo">git
- Download a single folder or directory from a GitHub repo - Stack
Overflow</a></p>
<ul>
<li>可以使用svn export
（不进行版本管理）而不是checkout（同时下载了<code>.svn</code>文件夹）</li>
<li><code>--depth=files</code>
可以仅下载这个文件夹下面的文件，不深入下载</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">svn export --depth=files https://github.com/JordanSamhi/JuCify/trunk/benchApps &quot;$SCRIPTPATH/jucifybench&quot;</span><br></pre></td></tr></table></figure>
<h2
id="linux下限制进程cpu和内存使用率">Linux下限制进程CPU和内存使用率</h2>
<ul>
<li><code>CPUQuota=100%</code>:
强制限制CPU使用，100%表示单核的100%，即上限不是100%，比如我有256核，则上限是25600%</li>
<li><code>CPUWeight=idle</code> 或<code>CPUWeight=1</code>
仅使用空闲的CPU。</li>
<li><code>MemoryMax=32G</code> 限制最大内存占用</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemd-run --scope --same-dir --collect -p MemoryMax=32G -p CPUQuota=100% bash -c <span class="string">&quot;xxx&quot;</span> <span class="comment"># 限制内存和强制单核</span></span><br><span class="line">systemd-run --scope --same-dir -p CPUWeight=idle bash -c <span class="string">&quot;xxx&quot;</span></span><br></pre></td></tr></table></figure>
<p>默认需要root权限，加上<code>--user</code>
则不需要root权限了。但是现在好像有点问题，限制不住CPU和内存。</p>
<p>https://github.com/systemd/systemd/issues/10581</p>
<p>测试是否支持user模式：运行这个</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemd-run --user --scope --same-dir -p CPUQuota=50% bash -c <span class="string">&#x27;python -c &quot;while True: i=1&quot;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>然后用htop观察CPU占用，看是否生效：看CPU占用是100还是50</p>
<p>进一步调试：https://github.com/systemd/systemd/issues/9502</p>
<p><strong>相关系统配置：</strong>（仅使用的话不用管这一部分）</p>
<p>https://unix.stackexchange.com/questions/624428/cgroups-v2-cgroup-controllers-not-delegated-to-non-privileged-users-on-centos-s
（里面的EOF应该不用写进文件）</p>
<h2 id="windows下稳定的挂起执行">Windows下稳定的挂起执行</h2>
<p>https://github.com/winsw/winsw 不得不说比windows自带的task
scheduler（任务计划程序）好太多。下面盘点一下task scheduler的坑点</p>
<ol type="1">
<li><p>启动失败后多久重新启动任务的选项，对于启动失败的定义完全不是返回值是否不为零，而是他有没有正常启动你的程序。也就是说完全不管你的返回值的。</p></li>
<li><p>从某个时间点后周期性重复的触发器，如果你设置无限重复，但是开始时间是过去，即使你选了那个错过了时间立刻启动也不管用。可以看到下次执行时间是几分钟后，但是几分钟后就是不给你执行。必须要把开始时间设置在几分钟后，正常触发一次。</p>
<p>https://superuser.com/questions/1676539/scheduled-task-does-not-run-after-being-re-enabled-again</p></li>
</ol>
<h2 id="ddns">DDNS</h2>
<p>参见上一条，随便自己写个python脚本，然后用<code>winsw</code>挂起来。python里面直接写死循环即可。比计划任务稳定多了。不得不说Windows计划任务真是垃圾。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">do_once</span>():</span><br><span class="line">    <span class="comment"># ... do real thing</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 负责失败后短时间内重试</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_retry</span>():</span><br><span class="line">    ret = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> ret != <span class="number">0</span>:</span><br><span class="line">        ret = do_once()</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        time.sleep(<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        do_retry()</span><br><span class="line">        time.sleep(<span class="number">7200</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="稳定的给自己的推送接口">稳定的给自己的推送接口</h2>
<p>通过qq邮箱SMTP，发给自己（同一个邮箱），通过qq的QQ邮箱提醒接收</p>
<h2 id="方便地换硬盘重装系统">方便地换硬盘重装系统</h2>
<p>2022年9月13日
直接用DiskGenius的系统迁移功能，直接下免费版也能用。体验下来比<code>备份与恢复（win7）</code>好很多。但是<code>备份与恢复（win7）</code>用来给电脑做全盘备份还是不错的。</p>
<p><del>利用win10自带的 <code>备份与恢复（win7）</code>
借来一个大容量移动硬盘先备份，换硬盘之后恢复。</del></p>
<p>2021年12月19日 这个<code>备份与恢复（win7）</code>
其实还是有很多槽点的。一旦你用usb安装盘进入恢复过程，它给你报个错，你就完全没有任何办法。。。之前成功过两次，但也遇到了几次没办法的情况。今天尝试DiskGenius的系统迁移功能，新硬盘通过硬盘盒，usb连接电脑，然后热迁移过去。</p>
<h2
id="将旧电脑系统连带硬盘迁移到新电脑">将旧电脑系统连带硬盘迁移到新电脑</h2>
<p>首先关bitLocker。其次是WSL导出并unregister。</p>
<p>使用下面命令准备系统：然后直接移动硬盘过去。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="variable">%windir%</span>\system32\sysprep\sysprep.exe /generalize /oobe /shutdown</span><br></pre></td></tr></table></figure>
<p>出现问题：</p>
<ol type="1">
<li>为单个用户安装的appx会造成问题，先卸载。用dism++</li>
<li>千万要先把微软账户退出改用本地账号啊！！！不然被微软联网登录卡得进不去账号</li>
<li>电脑真的第一次开机要保证不能换任何配件！才能激活。激活之后再换硬盘。</li>
</ol>
<h2 id="ida出现import-site-failed">ida出现import site failed</h2>
<p>清空自己的PYTHONHOME才行 或者通过bat启动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set PYTHONHOME=</span><br><span class="line">set PYTHONPATH=</span><br><span class="line">start C:\Users\warren\my_programs\IDA_Pro_v7.0_Portable\ida.exe</span><br></pre></td></tr></table></figure>
<h2 id="sd卡作为内部存储">SD卡作为内部存储</h2>
<p><a
href="https://stackoverflow.com/questions/38044532/how-to-turn-a-portable-sd-card-into-internal-storage-via-adb-command">stackoverflow</a></p>
<p>不需要改initrd，或者什么vold.fstab了。现在的安卓系统内置支持了。害的我还折腾，root手机。
<code>sm set-force-adoptable true</code>大法，
<code>sm partition disk:179,64 mixed 60</code>表示留下60%的空间，将SD卡40%的空间用作内部存储。<code>sm partition disk:179,64 private</code>表示将整个SD卡用作内部存储。</p>
<h2 id="magisk的通用安装方法">Magisk的通用安装方法</h2>
<p><code>system as root</code>可能指没有boot分区，直接将system作为根目录。而不是像通常的boot目录作为initramfs只读启动，再挂载system分区。这种情况要patch
recovery分区，开机的时候用进入recovery的方式开机。</p>
<p>找到当前手机rom刷机包，提取boot.img打patch，解锁手机后fastboot刷入。</p>
<p>红米6这样操作后似乎没了基带。注意考虑基带问题。</p>
<p>三星手机似乎非常复杂。</p>
<h2 id="git从commit中提取patch">git从commit中提取patch</h2>
<p><a
href="https://stackoverflow.com/questions/6658313/how-to-generate-a-git-patch-for-a-specific-commit">这里</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git format-patch -1 HEAD</span><br></pre></td></tr></table></figure>
<p>想要把多个commit放到一个patch里，就先check
out新branch，然后squash成一个，最后提取patch。</p>
<h2 id="screen让ssh退出还能运行命令">screen让ssh退出还能运行命令</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">screen</span><br></pre></td></tr></table></figure>
<p>启动screen然后运行自己的命令，然后Ctrl-a,
d就可以detach，安全离开ssh</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">screen -r</span><br></pre></td></tr></table></figure>
<p>恢复之前的screen</p>
<p>如果报错<code>Cannot make directory '/run/screen': Permission denied</code>执行<code>sudo /etc/init.d/screen-cleanup start</code>
。</p>
<h2 id="移动硬盘被占用">移动硬盘被占用</h2>
<ol type="1">
<li>任务管理器-资源监视器-CPU-句柄-搜索盘符</li>
<li>弹出失败时去事件查看器<code>eventvwr.msc</code>找Windows日志-系统-来源是Kernel-PnP的事件，会显示哪个进程拒绝了弹出</li>
</ol>
<h2 id="cmd启动uwp程序">cmd启动UWP程序</h2>
<p>例如<code>Microsoft.WindowsTerminal_8wekyb3d8bbwe!App</code></p>
<p>用管理员cmd，cd到<code>C:\ProgramData\Microsoft\Windows\AppRepository\Packages</code>
然后dir看目录名字就可以了。或者everything搜。或者先pin到开始菜单再拖到桌面得到快捷方式，在看属性。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">explorer shell:appsFolder\Microsoft.WindowsTerminal_8wekyb3d8bbwe!App</span><br></pre></td></tr></table></figure>
<h2 id="diff导出单个文件的patch">diff导出单个文件的patch</h2>
<p><a
href="https://unix.stackexchange.com/questions/162131/is-this-a-good-way-to-create-a-patch">单个文件或文件夹</a></p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">&quot;diff.exe&quot; -Naru --strip-trailing-cr orig-file-<span class="built_in">path</span> new-file-<span class="built_in">path</span> &gt; result.patch</span><br></pre></td></tr></table></figure>
<h2 id="visual-studio-字符集-character-set">Visual Studio 字符集
Character Set</h2>
<p>https://stackoverflow.com/questions/9349342/about-the-character-set-option-in-visual-studio</p>
<p>https://stackoverflow.com/questions/3298569/difference-between-mbcs-and-utf-8-on-windows</p>
<p>听说tchar不太好，Multi byte在GBK环境下可能不是指utf-8.
推荐处理windows API时全用wchar的版本。</p>
<p>输出方面，直接使用wchar版本输出函数，可能导致每个字符带一个空字符。使用
<code>setmode(_fileno(stdout), _O_U16TEXT);</code> 启用UTF-16输出。</p>
<p><code>system("chcp 65001")</code>
可以配合在不带L的字符串常量，使用不带w的输出函数输出中文正常。（这可能和源代码的编码有关？）</p>
<p>猜测：codepage决定了multibyte的解码。</p>
<p>TODO: locale和chcp 、code page和setmode什么关系。</p>
<p>：涉及 <code>setlocale(LC_ALL, "chinese");</code>
<code>_setmode(_fileno(stdout), _O_U16TEXT);</code> 等操作</p>
<p>https://stackoverflow.com/questions/2492077/output-unicode-strings-in-windows-console-app</p>
<h2
id="gdb如何断点自动执行命令并继续">gdb如何断点自动执行命令并继续？</h2>
<p>在使用hook-stop里使用continue会出现问题。但是使用<a
href="https://sourceware.org/gdb/current/onlinedocs/gdb/Break-Commands.html"><code>break command</code></a>就可以了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def hook-stop</span><br><span class="line">end</span><br><span class="line">b usb_packet_copy</span><br><span class="line">commands</span><br><span class="line">  print $rdx</span><br><span class="line">  continue</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<h2 id="linux-目录的可执行权限">Linux 目录的可执行权限</h2>
<p>https://unix.stackexchange.com/questions/21251/execute-vs-read-bit-how-do-directory-permissions-in-linux-work</p>
<p>有点复杂，有机会再总结吧。</p>
<h2 id="life-tips">Life Tips</h2>
<ol type="1">
<li>熬夜后头痛很可能是缺钾，可以通过香蕉和土豆补充。</li>
<li>刷牙重在时长，不需要追求刷得特别干净。因为主要是氟元素的化学反应。所以不如刷着牙做点别的。另外晚上睡前刷牙最重要。</li>
<li>和近视相关度最大的是自然光时间。多晒晒太阳吧。</li>
<li>合理的饮食应当以淀粉为主，淀粉在肚子里慢慢水解，为身体提供持续的能量。</li>
<li>剧烈运动能促进肠胃活动。如果肠胃有溃疡，应当尽早除幽门螺杆菌，虽然不会治疗溃疡，但是会没那么难受一些。</li>
<li>便秘考虑吃些纤维素补充剂。似乎木耳主要成分都是纤维素？但是木耳含水有90%，吃起来效率太低。</li>
</ol>
<h2 id="chroot-环境下debug">chroot 环境下Debug</h2>
<p>主要问题是在chroot的环境下debug，没有proc文件系统。网上下了一个静态编译的gdb放进去。结果启动gdb
的时候出现了unable to disable address ramdonmization和不能跟随fork，set
folllow-fork-mode
child解决。gdb最开始调的时候还没有符号信息，好像是开了PIE而不能读取到mapping，关闭PIE好像就行了。。。。</p>
<p>最后发现是DNS的问题。。。在chroot的文件夹里新建etc，里面新建resolv.conf，里面写nameserver
8.8.8.8就可以了。</p>
<p>以后考虑看看chroot环境下能不能搞出procfs，这样可能就方便很多。</p>
<p>https://superuser.com/questions/165116/mount-dev-proc-sys-in-a-chroot-environment</p>
<h2 id="影响程序堆布局的因素">影响程序堆布局的因素</h2>
<ol type="1">
<li>程序自身的输入，如标准输入，打开的socket等等。</li>
<li>程序文件名，参数，<strong>环境变量</strong>。</li>
</ol>
<h2 id="如何带库移植elf文件">如何带库移植ELF文件</h2>
<ol type="1">
<li><p>ldd copy dependencies脚本复制所有用到的依赖</p></li>
<li><p>patchelf修改rpath</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> ./*; <span class="keyword">do</span></span><br><span class="line">	patchelf --set-rpath /home/wjk/raw/reallib2 <span class="variable">$f</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>比较坑的一点是，<code>patchelf $f --set-rpath /home/wjk/raw/reallib2</code>这样不行，文件一定要放到set-rpath后面。。。有时间去patchelf看看是不是确实有这个问题，提个PR。</p></li>
<li><p>拿出<code>libc</code>，<code>ld</code>，<code>libpthread</code>
<code>librt.so</code>，<code>libdl</code>。不要忘了<code>libdl</code>。这次就是因为没有使用系统的<code>libdl</code>而执行<code>dlopen</code>函数的时候崩了。这些库都用目标系统的。如果还是崩就用下面这条检查检查文件访问，看看缺了什么文件，用gdb
debug看看是不是加载什么库的时候崩的。</p></li>
</ol>
<h2 id="如何strace脚本的文件访问">如何strace脚本的文件访问</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">strace -f bash ./run.sh 2&gt;&amp;1 | grep bios</span><br></pre></td></tr></table></figure>
<p>strace 的<code>-f</code>能够trace
fork。一般访问文件的时候是<code>openat</code>系统调用，或者<code>access</code>。</p>
<h2 id="codimd-slide放映模式-调整格式">Codimd slide放映模式
调整格式</h2>
<p>图片：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;https://xxx.png&quot;</span> <span class="attr">style</span>=<span class="string">&quot;height: 60%; width: 60%&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>其他： 注意在列表和html标签前后留空行</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;font-size: 80%&quot;</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">- A</span><br><span class="line">- B</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>换行使用<code>&lt;br&gt;</code>。</p>
<h2 id="快速解决编译的exe的闪退问题">快速解决编译的exe的闪退问题</h2>
<p>首先按住alt，拖动exe到当前目录，从而创建快捷方式。</p>
<p>然后编辑快捷方式的目标，在前面加上<code>cmd[空格]/k[空格]</code>
执行完exe就会回到cmd了，不会闪退了。</p>
<h2 id="在ubuntu中找到文件属于什么包">在Ubuntu中找到文件属于什么包</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">dpkg -S &quot;*/libclangBasic.a&quot;</span><br></pre></td></tr></table></figure>
<h2 id="手机电脑传文件">手机电脑传文件</h2>
<p>MT管理器的远程管理可以选择目录（局域网FTP）。</p>
<p>电脑可以开启一个https://github.com/filebrowser/filebrowser</p>
<h2 id="linux-进程池时间内存消耗超时">Linux
进程池，时间内存消耗，超时</h2>
<p>进程池：xargs：<a href="http://coldattic.info/post/7/">Easy
parallelization with Bash in Linux - A Foo walks into a Bar... - blog by
Paul Shved - coldattic.info</a></p>
<p>时间内存消耗：time：<a
href="https://stackoverflow.com/questions/774556/peak-memory-usage-of-a-linux-unix-process">command
line - Peak memory usage of a linux/unix process - Stack
Overflow</a></p>
<p>超时：timeout</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>K210开发板相关外设学习</title>
    <url>/2020/K210%E5%BC%80%E5%8F%91%E6%9D%BF%E7%9B%B8%E5%85%B3%E5%A4%96%E8%AE%BE%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="k210开发板相关外设学习">K210开发板相关外设学习</h1>
<p>这篇文章是我买了<code>Widora AIRV R3</code>这个<code>K210</code>芯片的开发板。这时候刚好看了一些Python内部实现的书，并且Maixpy（一个移植Micropython到K210开发板上的项目）对这块开发版支持还不完善，于是就克隆下来，试图修改移植。</p>
<span id="more"></span>
<p>这只是最初的想法，希望能做成一个项目。虽然确实群里很多人也都需要这样的固件，但是一方面群主不太待见这种使用python的行为，另一方面，我发现我做的一些工作都是非常浅层的，真的就是修改一下引脚号，而且随着Maixpy的发展，现在已经支持配置文件修改引脚号了，导致完全不需要代码上的修改就可以适配这个开发板。</p>
<p>中间曾经出现了python导致摄像头刷新率太低的问题，rebase到最新的Maixpy就解决了。</p>
<h2 id="前言">前言</h2>
<p>看到推荐就买了, 毕竟板载的传感器太全了, 一个小板子就什么都有了,
而且便宜. 导致我走上了这条路. 希望能静下心来. 学到什么.
我经常为了像这样做到些什么而学习, 但往往走偏, 后期只想着想要做到的事情,
完全抛弃了学习, 瞎试, 就是不去继续学.</p>
<h2 id="spi总线">spi总线</h2>
<p>maixpy支持其他板子, 经测试, 无法驱动本板子屏幕. 怀疑是接线有问题.
找来板子的接线图, 和各种硬件资料.</p>
<p>中景园1.14寸屏幕用的是TODO的芯片. 支持各种SPI通讯方式.
主要看屏幕控制芯片的手册.</p>
<p>SPI总线可以只靠一条线(3线接口), 或者控制/数据的电平信号线 +
真正的数据线(4线接口).
控制/数据的电平信号线为(高/低)的时候表示发送的这个字节是命令,
否则表示是数据(命令的参数). 另外, 这些传输都有时钟信号的同步.</p>
<p>片选信号变低, 选择芯片, 芯片准备接受数据.
不带(控制/数据的电平信号线)的时候传输9个bit,
第一个bit表示是控制还是数据. 带的时候连续传输8个bit,
传输第8个bit结束的时候对控制/数据信号进行采样, 判断是控制还是数据.</p>
<p>k210芯片带有fpio,
能够软件控制输出引脚和对应芯片内真正引脚的映射关系!! 可能类似fpga,
这个功能真是绝了, 可能是我见识太浅. 接spi线的时候,
一般spi接口的数据线还是直连, 其他复位, 控制/数据选择,
片选都可以直接在GPIO或者高速GPIO里面随便选一个.
因此不同板子要调整这些映射.</p>
<p>SPI总线也可以多条线, 4条,8条甚至16条等并行连接, 这个屏幕是典型的4线.
该板子可以外接的另外那个大屏幕似乎就是8数据线的spi.</p>
<p>4-line serial interface Ⅱ</p>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr>
<th>Pin Name</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>CSX/CS</td>
<td>Chip selection signal</td>
</tr>
<tr>
<td>SCL</td>
<td>Clock signal</td>
</tr>
<tr>
<td>SDA</td>
<td>Serial data input data</td>
</tr>
<tr>
<td>WRX/RS</td>
<td>Data is regarded as a command when WRX is low. Data is regarded as a
parameter or data when WRX is high</td>
</tr>
<tr>
<td>DCX</td>
<td>Clock signal</td>
</tr>
<tr>
<td>SDO</td>
<td>serial output data</td>
</tr>
</tbody>
</table>
<p>3 line interface Ⅰ spi 只有片选CSX, DCX时钟, SDA 输入输出 3 line
interface Ⅱ 多了 SDO, 输入和输出引脚分开了. 4 line interface Ⅰ
只有片选CSX, WRX控制/数据(参数)选择, DCX时钟, SDA 输入输出 . 4 line
interface Ⅱ同理.</p>
<p>DCX有时说是WRX一样的控制/数据选择.
可能是叫法的问题还是理解的问题???TODO</p>
<p>SCL --&gt; LCD_WR WRX/RS --&gt; LCD_DC</p>
<p>LCD_WR是时钟 GPIOHS30在maixpy代表LCD复位
GPIOHS31代表控制/数据选择</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fm.unregister(36, fm.fpioa.SPI0_SS3)</span><br><span class="line">fm.register(37, fm.fpioa.SPI0_SS3)</span><br><span class="line"></span><br><span class="line">fm.unregister(37, fm.fpioa.SPI0_SCLK)</span><br><span class="line">fm.register(39, fm.fpioa.SPI0_SCLK)</span><br><span class="line"></span><br><span class="line">fm.unregister(38, fm.fpioa.GPIOHS30)</span><br><span class="line">fm.unregister(39, fm.fpioa.GPIOHS31)</span><br><span class="line">fm.register(38, fm.fpioa.GPIOHS31)</span><br></pre></td></tr></table></figure>
<p>LCD是片选3 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+----------|-----------------------+</span><br><span class="line">|   36     |     LCD_CS            |</span><br><span class="line">+----------|-----------------------+</span><br><span class="line">|   37     |     LCD_RST           |</span><br><span class="line">+----------|-----------------------+</span><br><span class="line">|   38     |     LCD_DC            |</span><br><span class="line">+----------|-----------------------+</span><br><span class="line">|   39     |     LCD_WR            |</span><br><span class="line">+----------|-----------------------+</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fm.unregister(36, fm.fpioa.SPI0_SS3)</span><br><span class="line">fm.unregister(37, fm.fpioa.SPI0_SCLK)</span><br><span class="line"></span><br><span class="line">fm.register(37, fm.fpioa.SPI0_SS3)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fpioa_set_function(37, FUNC_GPIOHS0 + RST_GPIONUM);</span><br><span class="line">fpioa_set_function(38, FUNC_GPIOHS0 + DCX_GPIONUM);</span><br><span class="line">fpioa_set_function(36, FUNC_SPI0_SS0+LCD_SPI_SLAVE_SELECT);</span><br><span class="line">fpioa_set_function(39, FUNC_SPI0_SCLK);</span><br></pre></td></tr></table></figure>
<p>SPI_FF_STANDARD： 标准 ​ SPI_FF_DUAL： 双线 ​ SPI_FF_QUAD： 四线 ​
SPI_FF_OCTAL： 八线（SPI3 不支持）</p>
<h2 id="屏幕控制芯片todo">屏幕控制芯片TODO</h2>
<p>和芯片的交互基于SPI之后, 就是发送各种控制和数据.
芯片一般有nt35310和我现在的这个st7789. 首先是各种初始化的命令,
后面就是发送数据了. 显示的数据是一个个像素传送的,
有RGB565和SUV等颜色模式.</p>
<p>初始化首先发送SOFTWARE_RESET -(睡100ms 后面同理)-&gt; SLEEP_OFF
--&gt; PIXEL_FORMAT_SET= 0x55 (表示是TODO模式) --&gt; DISPALY_ON</p>
<h2 id="屏幕定位">屏幕定位</h2>
<p>横着是x, 竖着是y方向</p>
<p>控制芯片的大小是<code>320x240</code>, 当设置屏幕大小是这个值的时候.
屏幕的大小是<code>240x135</code>, 刚好在中间. 左右空出40,
上下空出53/52左右 左上角大概在(40, 52), 右下角在(280, 187)左右.
发现代码中可以设置偏移, 把偏移设置成50 40(横屏模式), 和 40 52(竖屏模式)
就好了. 基本完美. 而且反色了... 和代码中写的颜色是反的,
代码中初始化是背景色红色, 白色的字. 不知道是不是有意为之,
或者有的屏幕就是这样. 反色之后的背景白里透蓝, 黑色的字.
那我就默认反色吧, 就和代码里的颜色一致了.</p>
<p>可以设置默认的屏幕大小. 按照保证允许软件传参更改的同时,
设置好能用的默认值的这个方针.</p>
<h2 id="摄像头">摄像头</h2>
<p>引脚接的都是对的. 可以直接用, 但是不稳. 不知道为什么例程很稳,
而当前的maixpy经常会报错</p>
<h2 id="ov2640-摄像头模块">ov2640 摄像头模块</h2>
<p>关键在于学习如何操作寄存器 k210的dvp datasheet:</p>
<blockquote>
<p>3.9 数字视频接口(DVP) DVP 是摄像头接口模块，特性如下： *
支持DVP接口的摄像头 * 支持SCCB协议配置摄像头寄存器 * 最大支持640X480
及以下分辨率，每帧大小可配置 * 支持YUV422 和RGB565 格式的图像输入 *
支持图像同时输出到KPU和显示屏: * 输出到KPU
的格式可选RGB888，或YUV422输入时的Y分量 * 输出到显示屏的格式为RGB565 *
检测到一帧开始或一帧图像传输完成时可向CPU发送中断</p>
</blockquote>
<h3 id="接口">接口</h3>
<p>PCLK,即像素时钟,一个PCLK时钟,输出一个(或半个)像素。</p>
<p>VSYNC,即帧同步信号。</p>
<p>HREF/ HSYNC,即行同步信号。</p>
<h3 id="颜色格式-rgb-yuv-ycbcr">颜色格式 RGB, YUV, YCbCr</h3>
<h4 id="sccb">sccb</h4>
<p>SCCB 特性都与 I2C 无区别, 可以直接用I2C控制器去通信</p>
<h3 id="dvp">dvp</h3>
<p>各种大大小小的时钟, 最终形成了同步的信号.
一个帧同步信号的有效时间内有很多个行同步信号,
每个行同步信号的有效时间内有很多像素时钟.</p>
<h3 id="输出格式">输出格式</h3>
<p>SVGA: 800 x 600 摄像头也可以配置缩放. 没写怎么配置的缩放的.</p>
<h3 id="图形翻转">图形翻转</h3>
<p>0xFF=1的时候, 04寄存器最高两位分别是水平镜像和垂直翻转.
widora的ov2640例程中, 注释了airv r3 back的地方是 d8 也就是这两位都有.
maixpy则是只有水平镜像(0xa8). 在去掉水平镜像之后,
也就是两个bit都不设置的时候(0x28), 后置摄像头显示刚好正常.
(怀疑是)两边lcd的方向设置不一致, maixpy暂时调整摄像头这边.</p>
<h3 id="代码对比阅读">代码对比阅读</h3>
<p>linux的ov2640代码可能是发源地, 也是最完善的吧. 接着是openmv的代码,
比maixpy的整齐很多, 不乱. 接着就是kendryte的代码,
也许是参照openmv的,对比一下widora的例程. 最后是maixpy的代码.</p>
<h3 id="widora对比kentryte">widora对比kentryte</h3>
<p>代码的对比最好先format后diff. 这样即使widora他们声明数组是好几个一行,
也能迅速展平方便对比</p>
<p>经过对比发现, 除了多设置了一个翻转bit之外, 只有这两个不同. 官方是
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;0x5a, 0xc8&#125;,</span><br><span class="line">&#123;0x5b, 0x96&#125;,</span><br></pre></td></tr></table></figure> widora是 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;0x5a, 0x50&#125;,</span><br><span class="line">&#123;0x5b, 0x3C&#125;,</span><br></pre></td></tr></table></figure> 搜索ov2640和zmow,
找到了Android的相关驱动代码!!! Android它们相关驱动可能比linux还完善.</p>
<p>#define ZMOW 0x5A /* Zoom: Out Width OUTW[7:0] (real/4) <em>/ #define
ZMOW_OUTW_SET(x) VAL_SET(x, 0xFF, 2, 0) #define ZMOH 0x5B /</em> Zoom:
Out Height OUTH[7:0] (real/4) */</p>
<p>这样看的话, widora是: 320*240分辨率. 官方是800*600,
修改这里确实说得过去, 不过也不注释一下...</p>
<p>没想到这样的例程都用到了ai加速器? <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 设置允许导流到AI模型</span></span><br><span class="line">dvp_set_output_enable(<span class="number">0</span>, <span class="number">1</span>);    <span class="comment">//enable to ai</span></span><br><span class="line"><span class="comment">// DVP不直接导流到LCD</span></span><br><span class="line">dvp_set_output_enable(<span class="number">1</span>, <span class="number">1</span>);    <span class="comment">//disable to lcd</span></span><br></pre></td></tr></table></figure> dvp_set_ai_addr设置AI
存放图像的地址，供AI 模块进行算法处理。 void
dvp_set_ai_addr(uint32_tr_addr, uint32_tg_addr,
uint32_tb_addr)设置采集图像在内存中的存放地址，可以用来显示。
dvp_clear_interrupt(DVP_STS_FRAME_START | DVP_STS_FRAME_FINISH);
一般表示当前的这种中断处理完了, 可以来新的中断了.
算是是中断的pending位?. dvp_config_interrupt(DVP_CFG_START_INT_ENABLE |
DVP_CFG_FINISH_INT_ENABLE, 1); 打开中断开关 dvp_start_convert()
在开始采集图像的时候调用 表示开始采集图像 dvp_disable_auto()
禁用自动接收图像模式。</p>
<p>总结起来, 就是开启dvp中断.
k210的dvp会提供开始采集和停止采集的两种中断. 开始采集的时候,
在中断处理中调用start_convert. 结束采集的时候, 设置标志位.
当中断退出的时候, 忙等的处理器就会注意到标志位,
清零并设置切换buffer的标志, 向屏幕发送数据.
另外就是中断处理的时候根据buffer标志设置buffer.
根据需要切换buffer是在结束采集的时候?? 不应该啊,
切换buffer不是为了让采集和输出不在同一个buffer吗.</p>
<p>根据LCD的需求来切换dvp数据放到哪个缓存，目的是保证把图像传给LCD的时候,
dvp不是正好输出到这个buf。</p>
<p>buf大小上, ai为什么要给三个RGB的buf?
我修改了zoom出来的大小是否相关的buf大小也需要变化?
查看发现widora和官方的main函数一直, buf大小相同. RGB565是2字节一个像素.
这里是320*240*2 = 38400个uint32 (widora的dvp buffer大小.)
而AI的buffer大小是3*12c00 = 38400 这是怎么回事? RGB怎么可能均分呢?
这可是RGB565.</p>
<p>set_framesize在设置QVGA的时候不仅设置了dvp_set_image_size,
也设置了摄像头那边的zoom寄存器.</p>
<h3 id="ov2640-帧率">ov2640 帧率</h3>
<p>分析software application notes的帧率设置案例.
下面的寄存器都在0xff=1的情况下 首先是0x11寄存器, 最低4位为clock dividor.
寄存器的值高帧率的时候为0, 低的时候为1, 可能divide了就帧率减半吗?
0x12寄存器的(低到高)第三位, zoom mode. svga的时候设为1, uxga的时候为0
0x2a寄存器, 大家都设置为0 line interval adjust value的高四位, Hsync
start/end point adjustment MSB. 0x2b也为0, line interval adjust
value的低8位. 帧率会被这个12bit的值微调. 0x46为低位, 0x47为高位,
组成了frame length adjustment. 这个值每多1,
就在帧中增加了1个水平线的时间. 0x47大家也都设置为0.
这个值是调整帧率的关键. 0x3d寄存器很神秘, 在手册的保留寄存器的范围内.
svga设置为了0x38, uxga设置成了0x34</p>
<p>SVGA 800×600来看的话, 高度是600. frame length
adjustment为0时的刷新率是30fps. 而增加了clock dividor,
帧率减半得到15fps. 如果只frame length adjustment设置为了0x87=135,
那么帧率就乘上了缩放倍数(600/600+135), 得到25fps.</p>
<p>总之关键在于寄存器0x11和寄存器0x46 0x47.</p>
<table>
<thead>
<tr>
<th>type</th>
<th>clock dividor</th>
<th>frame length adjustment</th>
</tr>
</thead>
<tbody>
<tr>
<td>widora/kendryte</td>
<td>0</td>
<td>0x22</td>
</tr>
<tr>
<td>maixpy</td>
<td>0</td>
<td>0x22</td>
</tr>
</tbody>
</table>
<p>当前maixpy的帧率, 30fps * (600/600+34) = 28.4帧...
为什么是这种奇怪的帧数? 难道是我哪里理解错了? 或者为了凑什么倍数??</p>
<h3 id="ov2460-颜色">ov2460 颜色</h3>
<p>0xff= CTRL0 = 0xC2寄存器 最低四位由低到高依次为RAW_EN, RGB_EN,
YUV_EN, YUV422. 默认和maixpy的配置都是0x0C=1100
0xDA寄存器的名字是IMAGE_MODE, bit0 byte swap for DVP(low/high byte
first), bit[3:2] 00-&gt;yuv422, 01-&gt;raw10, 10-&gt; RGB565,
11-&gt;Reserved kendryte是0x08, 也就是RGB565, maixpy是0x01,
也就是YUV422+byte swap</p>
<p>这边寄存器的设置要和那边dvp的接收设置匹配起来.
而调用picformat只是设置dvp的接收的格式.</p>
<h3 id="maixpy和openmv的代码解析">maixpy和openmv的代码解析</h3>
<p>openmv的代码更大型一些, 功能更多. 对摄像头相关的寄存器使用得更灵活.
前面的配置一般还是svga, 但是最后zoom出来分辨率不会那么大.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import sensor    </span><br><span class="line">import lcd</span><br><span class="line"></span><br><span class="line">lcd.init()</span><br><span class="line"></span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.run(1)</span><br><span class="line"></span><br><span class="line">while True:</span><br><span class="line">    img = sensor.snapshot()</span><br><span class="line">    lcd.display(img)</span><br></pre></td></tr></table></figure>
<p>先在这个典型的例程里, 依次分析一下各个函数. 代码结构依次是py_sensor.c
-&gt; sensor.c -&gt; ov2460.c 首先是探测过程, 读取厂家和型号id.
ov2460_init函数会填写sensor结构体, 暴露出内部函数. 设置frame_size的时候,
也会设置摄像头的zoom相关寄存器. set_pixformat似乎没有用了,
而且似乎是yuv. 设置成其他的格式会花屏. 也许是方便直接输入模型吧.
set_framerate也无法设置, ov2460.c中直接返回-1了.</p>
<p>sensor和lcd没有直接的关联或者相互调用, snapshot函数则是传过去的关键.
snapshot函数甚至还对buf做了什么jpeg压缩处理, 考虑了连接ide的情况.</p>
<p>超时不一定是摄像头配置问题. 也可能是中断处理问题.
试了下去掉双buf选项编译还是不行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    #ifdef CONFIG_BOARD_AIRVR3</span><br><span class="line">	&#123;0x5a, 0x50&#125;,</span><br><span class="line">	&#123;0x5b, 0x3c&#125;,</span><br><span class="line">    #else</span><br><span class="line">	&#123;0x5a, 0xc8&#125;,</span><br><span class="line">	&#123;0x5b, 0x96&#125;,</span><br><span class="line">    #endif</span><br><span class="line">	&#123;0x5c, 0x00&#125;,</span><br><span class="line">	&#123;0xc3, 0xed&#125;,</span><br><span class="line">	&#123;0x7f, 0x00&#125;,</span><br><span class="line">	&#123;0xe5, 0x1f&#125;,</span><br><span class="line">	&#123;0xdd, 0x7f&#125;,</span><br><span class="line">	&#123;0x05, 0x00&#125;,</span><br><span class="line">#if 1	//color bar</span><br><span class="line">	&#123;0xff, 0x01&#125;,</span><br><span class="line">	&#123;0x12, 0x02&#125;,</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>
<h3 id="尝试log">尝试log</h3>
<p>reduced the clock to 11MHz, 似乎能提高帧率</p>
<p>图像格式的问题, 搞清楚是怎么设置的. 八成不是中断的问题...
把RGB关掉试试, 用YUV也是好的</p>
<p>测试情况: 使用airv配置 不注释svga, 有时花屏有时正常显示,
图像也上下左右反了 使用maixpy配置有时无法显示, 有时正常</p>
<p>不会显示异常的关键是选对dvp的颜色格式和摄像头配置的颜色格式</p>
<p>maixpy的摄像头相关还是不太行, 可能有bug.
这里如果不设置framesize就直接snapshot, 会报错Not init.
之后居然就崩了...</p>
<p>这就是软件工程的困境吗?</p>
<p>等一波新版本发布, github watch了</p>
<p>不会是供电问题吧... 只有程序小的时候才能正常显示</p>
<h3 id="总结">总结</h3>
<p>今天添加散热片发现, k210在dvp2lcd的时候发热还是非常大的.
而当我把k210吹冷了之后, 摄像头就又能用了. 可能摄像头本身就是好的吧,
一个是摄像头的参数不如官方的例程调教得好, 有一些彩色条纹.
看电脑屏幕有波纹(可能是正常现象.) 另外就是Back的时候,
需要额外设置hmirror(1)的时候才是正确的, 之后可以把这个设置搞成默认.</p>
<p>也可能是摄像头发热严重(更可能了, 因为我CPU降频了还是不太稳.)
这个还不好贴散热片 降频试试, 改代码增加了个clock devidor, 帧率减半,
看看会不会好一点</p>
<p>最后发现帧率减半确实稳定了一些,
没有显示的时候手动按下reset也容易来显示. 另外修改main.py,
利用time的计时器, 计算了一下调用sensor.snapshot和lcd.display消耗的时间
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while True:</span><br><span class="line">    img=sensor.snapshot()</span><br><span class="line">    print(&#x27;sensor time consume:&#x27;)</span><br><span class="line">    print(time.ticks_diff(time.ticks_us(), last))</span><br><span class="line">    last = time.ticks_us()</span><br><span class="line">    lcd.display(img)</span><br><span class="line">    print(&#x27;display time consume:&#x27;)</span><br><span class="line">    print(time.ticks_diff(time.ticks_us(), last))</span><br><span class="line">    last = time.ticks_us()</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sensor time consume:</span><br><span class="line">64081</span><br><span class="line">display time consume:</span><br><span class="line">158648</span><br><span class="line">sensor time consume:</span><br><span class="line">64122</span><br><span class="line">display time consume:</span><br><span class="line">158715</span><br><span class="line">sensor time consume:</span><br><span class="line">64022</span><br><span class="line">display time consume:</span><br><span class="line">158769</span><br><span class="line">sensor time consume:</span><br><span class="line">63994</span><br><span class="line">display time consume:</span><br><span class="line">158708</span><br><span class="line">sensor time consume:</span><br><span class="line">64098</span><br><span class="line">display time consume:</span><br><span class="line">158698</span><br></pre></td></tr></table></figure> 可能拖后腿的还是这个小屏吧?
毕竟只有一根线的spi? 或者说是maixpy的display太消耗时间了?</p>
<p>看了看那边widora例程的频率确实高一些,
设置<code>lcd.freq(20000000)</code>和那边相同之后帧率感觉高了一些,
不知道是不是错觉 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sensor time consume:</span><br><span class="line">73897</span><br><span class="line">display time consume:</span><br><span class="line">148786</span><br><span class="line">sensor time consume:</span><br><span class="line">74002</span><br><span class="line">display time consume:</span><br><span class="line">148886</span><br><span class="line">sensor time consume:</span><br><span class="line">73860</span><br><span class="line">display time consume:</span><br><span class="line">148909</span><br><span class="line">sensor time consume:</span><br><span class="line">73860</span><br><span class="line">display time consume:</span><br><span class="line">148867</span><br></pre></td></tr></table></figure> 把这个帧率也搞成默认吧.
直接在makefile里面设置就可以. 帧率就先不考虑, 主要考虑摄像头的稳定性,
不会重启用不了就好</p>
<p>我以为freq.conf是自己改的, 没想到是设置之后自动保存的,
我们不用改...</p>
<p>希望maixpy越来越好.</p>
<h2 id="i2s学习与maixpy麦克风">i2s学习与maixpy麦克风</h2>
<p>看怎么用上面的麦克风.</p>
<p>https://www.allaboutcircuits.com/technical-articles/introduction-to-the-i2s-interface/</p>
<p>https://hackaday.com/2019/04/18/all-you-need-to-know-about-i2s/</p>
<p>https://www.jianshu.com/p/e4f07bcd9df4</p>
<p>https://www.cnblogs.com/schips/p/12305649.html</p>
<table>
<thead>
<tr>
<th>引脚</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>SCK/BLCK/SLCK</td>
<td>clock</td>
</tr>
<tr>
<td>WS/LRCK</td>
<td>word select</td>
</tr>
<tr>
<td>SD/SDATA</td>
<td>data</td>
</tr>
<tr>
<td>NC</td>
<td>(悬空)</td>
</tr>
<tr>
<td>EN</td>
<td>片选/启用? 直接接到了3v3</td>
</tr>
<tr>
<td>LR</td>
<td>左右选择</td>
</tr>
</tbody>
</table>
<p>I2S就是被设计来传送音频数据的, 其他的数据都是之后的hacky玩法.
它用一条线区分左右声道, 一条时钟线同步信号, 和一条真正的线传送数据.
在我们板子的receiver=master的情况下, 时钟和WS是接收方发送给麦克风的,
发送方通过SD发送数据给接收方.</p>
<p>I2S允许两个声道的数据在一条线上传送. 因此有了左右声道的选择线.
采样的时候要交替左右轮流读一个字, 导致这个选择线的信号也类似于时钟.
麦克风的规格书里推荐的就是两个麦克风的三条I2S线相连, 一个L/R接地,
一个L/R接电源, 这样就成为了一个立体麦克风.</p>
<p>板子的L/R是接地的, 因此音频要在左声道接受,
需要给出WS为低的时候才有数据, 否则为0. 这是使用的左对齐标准,
24bit的采样数据包装在32位中. 最右边8bit固定为0.
Phillips标准则在WS高的时候发送左声道数据.</p>
<p>MSB优先发送. 变化WS之后要等一个时钟周期再开始接受数据.
SCLK的频率=2×采样频率×采样位数, LRCK的频率等于采样频率,
这样就刚好能完整收集左右声道的采样数据了.</p>
<p>下面这段来自麦克风的规格书 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">I²S DATA INTERFACE</span><br><span class="line">  The serial data is in slave mode I²S format, which has 24‐bit depth in a 32 bit word. In a stereo frame there are 64 SCK cycles, or 32 SCK cycles per data‐word. When L/R=0, the output data in the left channel, while L/R=Vdd, data in the right channel. The output data pin (SD) is tristated after the LSB is output so that another microphone can drive the common data line.</span><br><span class="line">Data Word Length</span><br><span class="line">  The output data‐word length is 24 bits per channel. The Mic must always have 64 clock cycles for every stereo data‐word (fSCK = 64 × fWS).</span><br><span class="line">Data‐Word Format</span><br><span class="line">  The default data format is I²S, MSB‐first. In this format, the MSB of each word is delayed by one SCK cycle from the start of each half‐frame.</span><br></pre></td></tr></table></figure></p>
<h2 id="k210的i2s">k210的I2S</h2>
<p>k210有3个I2S, 因此说它能接6麦克风阵列.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">其中I²S0 支持可配置连接语音处理模块，实现语音增强和声源定向的功能。</span><br><span class="line">• 总线宽度可配置为8，16，和32 位</span><br><span class="line">• 每个接口最多支持4个立体声通道</span><br><span class="line">• 由于发送器和接收器的独立性，所以支持全双工通讯</span><br><span class="line">• APB 总线和I²S SCLK 的异步时钟</span><br><span class="line">• 音频数据分辨率为12,16,20,24 和32 位</span><br><span class="line">• I²S0 发送FIFO 深度为64 字节, 接收为8 字节，I²S1 和I²S2 的发送和接收FIFO 深度都为8字节</span><br><span class="line">• 支持DMA 传输</span><br><span class="line">• 可编程FIFO 阈值</span><br></pre></td></tr></table></figure>
<p>k210使用的是4通道的I2S.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[MAIXPY]: numchannels = 2</span><br><span class="line">[MAIXPY]: samplerate = 22050</span><br><span class="line">[MAIXPY]: byterate = 88200</span><br><span class="line">[MAIXPY]: blockalign = 4</span><br><span class="line">[MAIXPY]: bitspersample = 16</span><br></pre></td></tr></table></figure>
<p>目前还是没声音, 需要学习I2S的FIFO是什么意思. 深度是什么意思,
然后就是怎么处理ws的, 为什么每个I2S有4个输入,4个输出引脚,
采样率怎么设置</p>
<p>4个输入和4个输出应该是对应4个channel, 可能方便切换吧??
接受数据的时候, 一个每次传送数据的cycle. 每次传送的数据的bit数</p>
<table>
<colgroup>
<col style="width: 42%" />
<col style="width: 57%" />
</colgroup>
<thead>
<tr>
<th>参数</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>word_length/RESOLUTION</td>
<td>每个word的长度. 12/16/20/24/32选24</td>
</tr>
<tr>
<td>word_select_size/SCLK_CYCLES</td>
<td>16/24/32选32. 大概是指在WS不变化的时候的cycle数,
也就是WS周期的一半.</td>
</tr>
<tr>
<td>word_mode</td>
<td>选左对齐.</td>
</tr>
</tbody>
</table>
<p>有声音了, 关键是上面列举的参数选择. I2S学习先告一段落.</p>
<p>i2s_set_dma_divide_16 函数能设置让DMA的时候自动把32 比特INT32
数据分成两个16 比特的左右声道数据。 那么这32bit的数据从哪来的?</p>
<p>I2S要不要设置时钟周期??</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Embedded</tag>
      </tags>
  </entry>
  <entry>
    <title>COM与RPC</title>
    <url>/2020/COM%E4%B8%8ERPC/</url>
    <content><![CDATA[<h1 id="com与rpc">COM与RPC</h1>
<p>研究windows安全的过程中对COM非常不熟。于是找资料学习了一会。</p>
<span id="more"></span>
<h2 id="概述">概述</h2>
<p>COM，组件对象模型，它解决的问题是二进制间兼容性问题，并在此基础上实现了RPC。</p>
<p>主要学习资料： <a
href="https://zhuanlan.zhihu.com/c_1234485736897552384">COM编程攻略</a></p>
<p>它的兼容思想是通过只暴露接口，不得出现跨边界的编译器相关行为，从而实现二进制的兼容。即不依赖结构体的布局，不依赖类型转换和new、delete的实现。</p>
<p>AddRef()：返回之后的引用计数。</p>
<p>Release()：一旦引用计数为0，实现者必须要释放此对象。</p>
<p>QueryInterface()</p>
<h2 id="接口转换的实现原则">接口转换的实现原则</h2>
<p><code>HRESULT QueryInterface(REFIID iid, void** ppvObject);</code></p>
<p>1、如果可以成功拿出接口，返回S_OK。如果ppvObject为空，返回E_POINTER。如果不能拿出接口，那么返回E_NOINTERFACE。</p>
<p>2、QueryInterface(下面简称QI)是静态的，不是动态的。这说明，一个对象QI能否成功，和时间没有关系。如果某个特定的类的实例QI(A)-&gt;B（执行QueryInterface拿到B），那么任何时候都应该能拿到B。</p>
<p>3、QI是自反的（如果QI(A)-&gt;B，那么QI(B)-&gt;A。</p>
<p>4、QI是对称的。</p>
<p>5、QI是可传递的。</p>
<p>6、如果需要取的是IUnknown(IID_IUnknown)，那么必须要返回相同的指针。</p>
<h2 id="iunknown-继承模型-聚合模型">IUnknown 继承模型 聚合模型</h2>
<p>继承模型：一个接口继承IUnknown，要用的时候转换成自己。</p>
<p>聚合模型：实现IUnknown的是套壳接口，QI的时候返回不同的接口。</p>
<p>结合聚合模型的特点和接口转换的实现原则，进行推理：用不同的地址代表不同接口的具体实现：</p>
<ol type="1">
<li>根据自反性，必须能够一次任意转换。因此所有的聚合在同一个套壳接口的类型调用QI的时候必须调用套壳接口的QI。</li>
<li>根据</li>
</ol>
<h2 id="atl实现的三层模型">ATL实现的三层模型</h2>
<p><code>Wrapper -&gt; YourClass -&gt; Internal</code></p>
<figure>
<img src="COM.jpg" alt="COM" />
<figcaption aria-hidden="true">COM</figcaption>
</figure>
<p><code>CComObject</code> 对应继承模型，如下</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">Base</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CComObject</span> : </span><br><span class="line">	<span class="keyword">public</span> Base</span><br></pre></td></tr></table></figure>
<p><code>CComAggObject</code> 则对应的是聚合模型，不再直接继承。</p>
<p>YourClass需要继承internal和各种需要的interface，并用宏指明转换规则。从而创建<code>_QueryInterface</code>
函数和静态与 <code>_GetEntries</code> 的Entries。由
<code>InternalQueryInterface</code>
来调用API遍历这个表。YourClass不只是一个分发器，而是把接口的实现都作为自己的成员函数。</p>
<p>Interface是带有很多虚函数的基类罢了。虚函数是父类声明时，用来告知编译器，希望即使把子类作为父类，调用同名方法的时候要调用子类的方法。</p>
<ol type="1">
<li>调用QI（wrapper的）会调用到内部的YourClass分发器的QI。</li>
<li>成功分发，转换类型后，再调用QI得调用回Wrapper的QI。</li>
</ol>
<p><code>CComObjectRootBase</code>
类型自身就有m_pOuterUnknown成员，和<code>OuterAddRef</code> 、
<code>OuterRelease</code>
函数，用来对聚合模型实现支持。它的QI就是总的QI，之后转换出去的COM接口都要调用回来这里的QI。</p>
<p>其实是COM手动实现了对与Interface类型的转换？YourClass注册Interface的时候，通过一个方法的静态数组成员来记录每个IID和对应的指针相对于this的偏移，转换的时候用到。但实际上，外围的CComAggObject持有的是通过模板生成的CComContainedObject。它通过模板继承上面写的类，重写了QueryInterface。通过CComAggObject拿到的都是继承自己的类之后的CComContainedObject了，此时构建的时候传入了原来的IUnokown的指针，通过继承和重新实现QI，把QI导向到了总的QI。导向方法是转调OuterQueryInterface，它调用了CComObjectRootBase的m_pOuterUnknown-&gt;QueryInterface</p>
<p>由于拿到的总是被<code>CComContainedObject</code>
包围的QI，这里是调用<code>CComContainedObject</code>
的QI。此时则调用的之前保存的OuterUnknown的QI。</p>
<p>QI，的时候，是把</p>
<h2 id="example">Example</h2>
<ol type="1">
<li><p>首先vs2019选ATL项目模板，创建ATLMessageBox项目，选择服务exe</p>
<p>此时的解决方案里面有ATLMessgaeBox和ATLMessageBoxPS项目，后者是ProxyStub代理桩，给享受服务的客户端用的，客户端调用对应服务的时候由它来处理序列化，通讯等事情。</p></li>
<li><p><strong>uuidgen /i /ohello.idl</strong>
创建带有UUID的IDL文件</p></li>
<li><p>IDL 文件描述接口，填写创建</p></li>
<li><p>rgs注册表消息，填写创建</p></li>
<li><p>创建MessageBox.cpp MessageBox.h</p></li>
<li><p>注册：C:.exe /RegServer</p></li>
</ol>
<h2 id="rpc">RPC</h2>
<p><a
href="https://docs.microsoft.com/en-us/windows/win32/rpc/rpc-start-page">Remote
Procedure Call</a></p>
<p>主要分析的是 <a
href="https://github.com/microsoft/Windows-classic-samples/blob/master/Samples/Win7Samples/netds/rpc/hello/Hellop.c">这个微软的例子RPCHello</a></p>
<p>TODO rpc的跨平台，是否支持linux或者Unix / Apple</p>
<p>RPC的环境内置在windows中，而RPC的开发环境在windows sdk中。</p>
<p>Microsoft Interface Definition Language
MIDL，用来描述调用的接口。</p>
<p>客户端程序调用的服务端的函数，实际上不是真正的实现函数，而是一个stub函数，负责把参数转换成标准的NDR格式，通过网络传输请求。</p>
<p>服务器的运行时函数接受请求，转换参数，最后再调用服务端的stub函数，返回值数据的时候也是类似的方法传输回去。</p>
<p>RPC有如下组件：MIDL编译器，运行时的lib和头文件，Name service
provider和Endpoint mapper。还有uuidgen工具。</p>
<p>承载RPC的dll有通过命名管道的、tcp/ip、NetBIOS、SPX、IPX、UDP的等等。</p>
<p>开发的过程包括：开发接口-&gt;开发服务端-&gt;开发客户端。</p>
<p>接口的定义主要包括的是IDL文件和ACF文件。编写后用MIDL编译器得到服务端和客户端的stub。VS1029中idl文件属于源文件，而acf文件属于资源文件。编译时的选项在项目的属性中多出来的MIDL项里面配置。</p>
<ul>
<li><p>Hello_c.c 客户端stub</p></li>
<li><p>Hello.h 两边都包括的头文件</p></li>
<li><p>Hello_s.c 服务端的stub</p></li>
</ul>
<p>Hellop.c
这个文件不是生成的，（example里面的）包含对server的procedure的实现。</p>
<p>Hellos.c和Helloc.c里面就是真正的RPC代码了。这一块才是重点关注的部分。</p>
<h3 id="midl">MIDL</h3>
<p>服务端和客户端代码容易混在一起，在同一个项目里建立两个文件夹。</p>
<p>默认情况下，客户端和服务端的stub函数名字相同，导致不能同时链接服务端和客户端的stub，编译的时候加上
<code>/prefix</code> 参数可以避免这种情况。</p>
<p>如果编译的时候不加上 <a
href="https://docs.microsoft.com/en-us/windows/win32/midl/-osf"><code>/osf</code></a>
(Open Software Foundation compatibility
mode)，就需要提供一个函数分配和回收内存。开启这个模式会失去很多功能特性。</p>
<h3 id="server">server</h3>
<p>API调用序列大致如下</p>
<p>RpcServerUseProtseqEp</p>
<p>RpcServerRegisterAuthInfo (增加安全机制)</p>
<p>RpcServerRegisterIfEx</p>
<p>RpcServerListen</p>
<p>RpcMgmtWaitServerListen 循环等待</p>
<p>RpcMgmtStopServerListening</p>
<p>RpcServerUnregisterIf</p>
<p>applications must specify a string that represents a combination
of</p>
<ol type="1">
<li><p>an RPC protocol,</p>
<ol type="1">
<li>Network Computing Architecture connection-oriented protocol
(NCACN)</li>
<li>Network Computing Architecture datagram protocol (NCADG)</li>
<li>Network Computing Architecture local remote procedure call
(NCALRPC)</li>
</ol>
<p>一般都选这个NCALRPC ？</p></li>
<li><p>a transport protocol and a network protocol. TCP/IP. IPX/SPX,
NetBIOS, AppleTalk DSP什么的。肯定选tcp/ip</p></li>
</ol>
<p><strong>ncalrpc</strong> for local communications and
<strong>ncacn_ip_tcp</strong> or <strong>ncacn_http</strong> for remote
communications are recommended</p>
<p>选好了就可以通过the <a
href="https://docs.microsoft.com/en-us/windows/desktop/api/Rpcdce/nf-rpcdce-rpcstringbindingcompose"><strong>RpcStringBindingCompose</strong></a>
and <a
href="https://docs.microsoft.com/en-us/windows/desktop/api/Rpcdce/nf-rpcdce-rpcbindingfromstringbinding"><strong>RpcBindingFromStringBinding</strong></a>
functions创建binding的handle了。</p>
<p>另外需要实现 the <a
href="https://docs.microsoft.com/en-us/windows/desktop/Rpc/the-midl-user-allocate-function"><strong>midl_user_allocate</strong></a>
and <a
href="https://docs.microsoft.com/en-us/windows/desktop/Rpc/the-midl-user-free-function"><strong>midl_user_free</strong></a>
这两个函数。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> __RPC_FAR * __RPC_USER <span class="title function_">midl_user_allocate</span><span class="params">(<span class="type">size_t</span> len)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span>(<span class="built_in">malloc</span>(len));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> __RPC_USER <span class="title function_">midl_user_free</span><span class="params">(<span class="type">void</span> __RPC_FAR * ptr)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">free</span>(ptr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="client">client</h3>
<p>源文件添加上生成的
_c.c后缀的文件。此外要加上任何可能需要的lib文件</p>
<p>API调用序列如下</p>
<p>RpcStringBindingCompose</p>
<p>RpcBindingFromStringBinding</p>
<p>RpcBindingSetAuthInfoEx (增加安全机制)</p>
<p>HelloProc</p>
<p>RpcStringFree</p>
<p>RpcBindingFree</p>
<h4 id="spn">spn</h4>
<p><em>Service Principal Name</em> is a concept from Kerberos</p>
<p>实现安全机制的时候用的，所以目前可以暂时不管。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>堆复习</title>
    <url>/2020/heap/</url>
    <content><![CDATA[<h1 id="堆复习">堆复习</h1>
<p>64位时, 默认开启的fastbin范围(chunk总大小)是0x20 - 0x80 32位TODO</p>
<p>tcache是64个单向链表，最多7个节点(chunk)，chunk的大小在32bit上是8到512（8byte递增）；在64bits上是16到1024（16bytes递增）。
fastbin只有10个链表, 范围肯定很小, 而和smallbins有62个,
大小基本重合.</p>
<p>当某一个tcache链表满了7个，再有对应的chunk（不属于fastbin的）被free，就直接进入了unsortedbin中。
tcache_perthread_struct结构，一般是在heapbase+0x10（0x8）的位置。对应tcache的数目是char类型。</p>
<span id="more"></span>
<h2 id="堆块结构">堆块结构</h2>
<p>堆块大小计算: 使用者视角,
两个指针的大小的整数倍(不包括下一个块的prevsize),
或者指针大小的奇数倍(包括下一个块的prevsize). 采用后一种说法</p>
<p>管理者视角, 每个堆块前面有size和prevsize, 其中prevsize属于前一个堆块,
当前一个堆块是空闲的时候, 会放上前一个堆块的大小. (有没有标志位?? TODO).
管理者视角来说的话, 堆块的大小为: (n * 两个指针的大小) +
指针大小(prevsize) + 指针大小(size). 也就是n+1倍的两个指针大小.
size域保存的就是这种大小.
因此谈到各种bin的时候也是指包括size域的大小.</p>
<p>chunk指针一般指向prev_size域的开始处.</p>
<p>堆块siza域最低位是AMP. (32位的时候只有3bit,
但是64位的时候就有4bit没有用了. 但还是只用3bit)</p>
<p>总结NON_MAIN_ARENA块和mmapped块与其他正常块的区别.
在libc_malloc调用int_malloc返回的时候,
会检测得到的堆块是不是当前arena的. ?? TODO</p>
<p>mmapped的块指一页内存大小的整数倍的分配来的内存. 其他两个bit会被忽略,
因为它是单独的一块, 不会和其他空闲块相邻, 也不会在任何arena里.
回收的时候会直接调用munmap</p>
<h2 id="malloc_state">malloc_state</h2>
<p>malloc_state描述arena的结构体. 主线程的arena是全局变量,
其他的arena在堆上(TODO). non_main_arena 可以有多个"堆"(heap_info).
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">malloc_state</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="comment">/* Serialize access.  */</span></span><br><span class="line">  __libc_lock_define (, mutex);</span><br><span class="line">  <span class="comment">/* Flags (formerly in max_fast).  */</span></span><br><span class="line">  <span class="type">int</span> flags;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Fastbins */</span></span><br><span class="line">  mfastbinptr fastbinsY[NFASTBINS];</span><br><span class="line">  <span class="comment">/* Base of the topmost chunk 不在其他任何bin里 */</span></span><br><span class="line">  mchunkptr top;</span><br><span class="line">  <span class="comment">/* The remainder from the most recent split of a small request */</span></span><br><span class="line">  mchunkptr last_remainder;</span><br><span class="line">  <span class="comment">/* Unsorted, small and large bins */</span></span><br><span class="line">  mchunkptr bins[NBINS * <span class="number">2</span> - <span class="number">2</span>];</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Bitmap of bins 表示某个bin空 */</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span> binmap[BINMAPSIZE];</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Linked list, 组织各个arena */</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">malloc_state</span> *<span class="title">next</span>;</span></span><br><span class="line">  <span class="comment">/* Linked list for free arenas.  Access to this field is serialized</span></span><br><span class="line"><span class="comment">     by free_list_lock in arena.c.  */</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">malloc_state</span> *<span class="title">next_free</span>;</span></span><br><span class="line">  <span class="comment">/* Number of threads attached to this arena.  0 if the arena is on</span></span><br><span class="line"><span class="comment">     the free list.  Access to this field is serialized by</span></span><br><span class="line"><span class="comment">     free_list_lock in arena.c.  */</span></span><br><span class="line"></span><br><span class="line">  INTERNAL_SIZE_T attached_threads;</span><br><span class="line">  <span class="comment">/* Memory allocated from the system in this arena.  */</span></span><br><span class="line">  INTERNAL_SIZE_T system_mem;</span><br><span class="line">  INTERNAL_SIZE_T max_system_mem;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">malloc_state</span> *<span class="title">mstate</span>;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="bins">bins</h2>
<p>fastbin有10个,位于fastbinsY, 单链表, 栈式后进先出, 大小是
<code>(1 * 两个指针的大小) + 2 * 指针大小</code> 到
<code>(10 * 两个指针的大小) + 2 * 指针大小</code>.
内部的堆块标记为使用中, 不前后合并</p>
<p>其他的bin都是双链表.<code>mchunkptr bins[NBINS * 2 - 2];</code>中,
两个指针是一个bin. 下标为0的bin没有被使用, 下标为1的是unsorted bin.
下标2-63的是small bin. 下标64-126的是large bin.</p>
<p>small bins 有 62个. 列表式的先进后出. 范围是16=0x10 ---
504=0x1f8大小.(含header) 64位是32=0x20 - 1008=0x3f0大小</p>
<p>large bins 有63个. 前32个, 每个bin管理64大小, 后16个,
每个bin管理512字节的范围, 8个4096, 2个262144, 1个剩下的任何大小.</p>
<p>top chunk是最底下的chunk, 使用sbrk的时候扩大的就是这个chunk.
它的prev_inuse位总是在的, 因为相邻的free
chunk在free的时候总会被合并.</p>
<p>last remainder chunk 上一个被分隔的chunk</p>
<h2 id="bins的循环">bins的循环</h2>
<p>综述: free的bins首先放到unsorted里,
malloc遍历unsorted的时候顺便整理放到各个bins里</p>
<h3 id="malloc_init_state">malloc_init_state</h3>
<p>对非fastbin, 创建头节点指向尾节点的循环
设置mstate的flags中的FASTCHUNKS_BIT. 初始化top chunk为第一个unsorted
bin中的chunk.</p>
<h3 id="int_malloc">_int_malloc</h3>
<p>__libc_malloc获取了arena后调用该函数. 如果大小在fastbin中.
去fastbin中找, 没有则到下一步, 有则检查得到的块, 检查通过后返回.
大小在small bin的时候, 去small bin中找, 如果对应的bin为空, 则下一步.
有则从末尾取一个, 检查一下另外一个方向的链表是否正常.
然后设置内存相邻的下一个chunk的prev_inuse, 最后返回 大小在large bin的,
也到large bin里找. 找完后调用malloc_consolidate
(如果arena有FASTCHUNKS_BIT). 如果都没找到就遍历unsorted bin,
(只有这时候才会把chunk放到bins里面) 从尾部遍历, 遍历的时候插入large
bin的时候会总是插入第二个位置. 当1. 申请的chunk是small bin大小. 2.
当前的chunk是last remainder. 3. 这个chunk的大小大于请求的大小,
则将这个chunk分割, 剩下的部分还放回unsorted bin. 还没找到的话,
如果是large bin, 就遍历每个更大的large bin,
找到小的但大于要求大小的large bin. 能分隔则分隔,
不能分隔(剩下的空间小于最小chunk大小)则不分隔返回.
分隔出来的chunk插入到unsorted bin 末尾. 如果是small bin,
开始考虑更大small bin的分割. 同样找到最小的但大于要求大小的chunk分隔.
如果都不能满足, 则使用top chunk. 剩下的成为新的top chunk 如果还不能满足,
调用sysmalloc用mmap分配内存.</p>
<h2 id="int_free">_int_free</h2>
<p>如果在fastbin 区间内, 插入人fastbin 再前后合并, 注意和top
chunk的合并, 检查unsorted bin 并插入头节点.</p>
<h3 id="malloc_consolidate">malloc_consolidate</h3>
<p>遍历每个fastbin, 前后如果有free chunk先调用unlink后合并, 放到unsorted
bin 头部里面去. 如果是top chunk当然和top chunk 合并</p>
<h2 id="层次化描述malloc">层次化描述malloc</h2>
<p>malloc和free这内存管理的逻辑过于复杂, 而且很多逻辑耦合比较紧密,
不好拆开分块理解. 导致了学习的难度. 这里试图采取迭代的思想,
毕竟大型项目都是从简单到复杂的迭代出来的.</p>
<h3 id="small-binlarge-bin模型">small bin+large bin模型</h3>
<p>该模型中只有small bin和large bin. 堆块的分配, 第一阶段是精确查找.
无法在对应的bin中找到时进入第二阶段是best fit查找,
找到满足要求的最小的堆块, 分隔或者不分割得到最终的堆块.
free的时候也前后合并, 合并了再放到bin里. 该模型还包含了top chunk.
free的时候如果和top chunk 相邻, 则和top chunk合并. 当small/large
bin中任何chunk都无法满足的时候, 首先看top chunk, 然后使用mmap去满足.
包含了binmap的数据结构, 方便跳过空的bins. binmap中标记为空的bin一定为空,
但是标记为有的bin则不一定必须有chunk, 也可以为空.</p>
<p>(精确查找阶段对于large bin是只要求处于相同bin内还是必须相同大小??
TODO 怀疑是后者)</p>
<h3 id="slsmall-large-unsorted-bin模型">sl(small large) + unsorted
bin模型</h3>
<p>该模型加入了unsorted bin. free的时候直接放入unsorted bin开头,
而malloc的时候, 在精确查找和best fit查找之间插入unsorted bin查找,
在末尾一边找一边处理unsorted bin. 当unsorted
bin碰到大小合适的bin的时候直接返回,
否则就一直查找处理(把遍历过的chunk插入合适的small/large bin中).</p>
<p>为了使unsorted bin处理的时间更加均匀, 处理unsorted
bin中的chunk最多处理MAX_ITER个.</p>
<h3 id="改进1-减少多次分割时的开销.">改进1 减少多次分割时的开销.</h3>
<p>经常会碰到小bin完全空, 分配时总是去某个large bin中分割的情况.
这种情况每次分配小块的时候都需要遍历一次很多small bin和large bin.
可以做出改进. 当每次有split的时候, 将剩下的chunk作为last remainder
chunk单独指针保存, 并且插入unsorted bin的末尾. 当遍历unsorted bin的时候,
如果是小chunk(在small bin范围内), 当前指向的chunk是last remainder chunk,
并且大小大于要求的大小, 则优先分隔该chunk直接返回.</p>
<h3 id="slu-fast-bin模型">slu + fast bin模型</h3>
<p>增加10个fast bin 作为上述模型的外包层. free的时候, 如果是fast
bin范围内的直接放入fast bin(因为fast bin无限容量.233 这也说明unsorted
bin不会有fast bin范围的chunk?? TODO) malloc的时候的精确查找阶段先去fast
bin里面找(fast bin范围内), 没有再去small/large bin里找.</p>
<p>引入 malloc_consolidate函数, 用于把fast bin中的chunk清理到small bin
中去. 引入flags中的 FASTCHUNKS_BIT 指示当前的arena有没有fast bin.</p>
<p>best fit阶段也不能满足, 找到了topchunk. 如果top chunk也不能满足要求,
就先清理掉fast bin再去mmap. 调用malloc_consolidate,
然后再去重新遍历unsorted bin, 把所有的chunk都清理了. 之后再回到这里,
发现没有fast bin的时候再通过mmap满足要求.</p>
<p>当分配large bin而精确查找阶段也满足了的时候也调用
malloc_consolidate.</p>
<h2 id="sluf-tcache模型">sluf + tcache模型</h2>
<p>在fast bin之前增加tcache.
(在__libc_malloc()调用_int_malloc()之前)在获取arena之前, 就先看tcache,
有则直接返回. free的时候优先放到tcache, 满了才继续放到别处.</p>
<p>tcache是很多个链表, 保存大小相同的chunk.
tcache是直接指向下一个的tcache_next, 而不是指向堆块头部. 直接形成链表
tcache_perthread_struct用于维护各个tcache内空闲堆块的数量,
和索引各个tcache. 第一次malloc的时候,
会malloc一块区域保存tcache_perthread_struct.</p>
<h2 id="与其他部分的关系">与其他部分的关系</h2>
<p>glibc2.26 开始有了tcache, 并默认开启. tcache比small bin还多一点.
内存释放的时候, tcache没满优先放到tcache. 分配的时候,
调用malloc之前看看tcache有没有. 申请fastbin大小的内存的时候,
找到fastbin内如果找到, 把fastbin上其他块填入tcache中. smallbin同理.
处理unsorted bin的时候, 即使找到大小合适的块, 也不直接返回, 而是</p>
<h2 id="查阅的资料">查阅的资料</h2>
<p>64位时, 默认开启的fastbin范围(chunk总大小)是0x20 - 0x80 32位TODO</p>
<p>tcache是64个单向链表，最多7个节点(chunk)，chunk的大小在32bit上是8到512（8byte递增）；在64bits上是16到1024（16bytes递增）。
fastbin只有10个链表, 范围肯定很小, 而和smallbins有62个,
大小基本重合.</p>
<p>当某一个tcache链表满了7个，再有对应的chunk（不属于fastbin的）被free，就直接进入了unsortedbin中。
tcache_perthread_struct结构，一般是在heapbase+0x10（0x8）的位置。对应tcache的数目是char类型。</p>
<h2 id="待整理">待整理</h2>
<blockquote>
<p>绕过tcache使得堆块free后进入unsorted bin的方式通常有两种：</p>
</blockquote>
<blockquote>
<p>每个tcache链上默认最多包含7个块，再次free这个大小的堆块将会进入其他bin中，例如tcache_attack/libc-leak
默认情况下，tcache中的单链表个数是64个，64位下可容纳的最大内存块大小是1032（0x408），故只要申请一个size大于0x408的堆块，然后free即可</p>
</blockquote>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>CTF</tag>
      </tags>
  </entry>
  <entry>
    <title>rcore学习笔记</title>
    <url>/2020/rcore%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="rcore学习笔记">rcore学习笔记</h1>
<p>这是我这几天学习rcore-Tutorial第三版时的笔记, 汇总到了一起. <a
href="#lab1中断">lab1</a> 学习了不少RISC-V的中断相关的基础知识,
之后补的中断相关的知识也补在这里了 <a href="#lab3虚拟内存管理">lab3</a>,
<a href="#lab4线程与调度">lab4</a> 对实现细节写得详细一些,
稍微看懂一点代码就写上去了, 很多函数的实现细节都写下来了.</p>
<p>有的地方还留下了一些疑问没有解决, 自己也查了资料但没有找到答案,
如果去掉感觉有可能产生误导, 所以就留着了.</p>
<span id="more"></span>
<h2 id="lab1中断">lab1中断</h2>
<p>回顾ucore, ucore的lab1也主要讲了中断, lab2讲分页
ucore的进程管理分了好几个lab, 内核进程, 用户进程, 进程调度.</p>
<p>添加了interrupt/context.rs, 文件也是一个mod,
interrupt文件夹也是一个新的mod, 现在rust2018,
既可以采用src/interrupt/mod.rs,
也可以用src/interrupt.rs来代表整个文件夹作为mod.</p>
<p>由于中断说起来比较顺口,
因此下文中部分地方说中断这个词的时候其实既包括中断又包括异常,
也就是包括那些会跳转到trap vector的事件.</p>
<h3 id="csr-是什么">CSR 是什么</h3>
<p>Control and status registers, 大部分是处理特权相关的寄存器.
为操作系统程序提供特权, 方便管理用户态程序.</p>
<p>操作这相关的寄存器的包装, riscv这个crate, 这是相关的文档.
https://docs.rs/riscv/0.6.0/riscv/register/index.html
dependencies里写的居然是rcore自己的fork, 而且比官方的多了特别多的commit,
太神奇了. 因此可能有我们rcore自己的fork实现的东西, 而文档里没有.</p>
<h3 id="risc-v中断">RISC-V中断</h3>
<p>比较关键的一点是sbi做什么, 而操作系统做什么
https://github.com/riscv/riscv-sbi-doc/blob/master/riscv-sbi.adoc
可以看看上面这个文档.
一个稍微比较重要的理念是supervisor态和user态都可能是虚拟化的,
只有m态不是虚拟化的. 因此一些对虚拟化有用的操作都不能直接从s态掌控.
包括时钟和ipc. 硬件线程间的通信.</p>
<h4 id="异常中断委托">异常/中断委托</h4>
<p>委托机制的使用: 默认是所有中断和异常都转到m模式的mtvec,
通过设置mideleg/medeleg寄存器可以设置把哪些中断和异常委托给s模式.</p>
<p>下面这段话是privileged isa手册中说的 &gt; Some exceptions cannot
occur at less privileged modes, and corresponding x edeleg bits should
be hardwired to zero. In particular, <code>medeleg[11]</code> and
<code>sedeleg[11:9]</code> are all hardwired to zero.</p>
<p>最后一句的意思是m模式产生的ecall异常无法被委托,
s模式下的ecall和m模式下的ecall在sedeleg中无法被委托给user模式.</p>
<p>所以在tutorial中具体哪些中断被委派了?
启动的时候opensbi会打印委派寄存器的值如下. MIDELEG : 0x0000000000000222
MEDELEG : 0x000000000000b109 mideleg的bit为分布和mip和mie相同,
medeleg的bit分布对应那张异常的编号的表. 分析一下得知: 地址对齐异常,
断点异常, 用户模式的ecall, 三种页异常(读写和指令) 被委派. 中断有:
s态软件中断, s态时间中断, s态外部中断 被委派</p>
<p>TODO 为什么user态的三个中断没有被委派??
user态中断是m态先处理还是s态先处理??</p>
<h4 id="中断的屏蔽">中断的屏蔽</h4>
<p>sstatus的SIE位是总开关, 每个单独的中断也可以针对性地屏蔽,
在sie寄存器有对应的屏蔽位. sie和sip这两个寄存器中,
只有被m态委派的对应位能够修改.</p>
<h4 id="中断向量">中断向量</h4>
<p>中断寄存器stvec指向的是中断的入口. 不像x86有一长条的中断向量表.
有两种模式, 向量模式和直接模式, 直接模式用一个地址处理所有中断和异常,
向量模式则会让不同中断跳转到不同的位置,
在基地址的基础上加上一定的偏移量, 而异常还是直接跳转到基地址. mtvec<a
href="vec寄存器的指令对齐使得最低位无效">0</a>设置为1可启用向量模式中断,
根据中断原因x将PC设置为(base + 4x), 也就是跳转到不同的地址.</p>
<p>产生中断时各种中断相关的位会被放到对应的previous位中,
之前的权限模式被放到sstatus的SPP.</p>
<p>执行相关的sRet指令的时候, 类似于产生异常的逆过程.
1是会把sepc恢复到pc, 2是sstatus中各种previous位都恢复到原来的位置. mret,
uret类似.</p>
<h3 id="中断过程梳理">中断过程梳理</h3>
<p>之前lab0完成了最小的启动, 通过sbi接口打印字符
本次lab1的代码主要完成的是中断相关. 接到控制权后转到了entry.asm
将bss段作为栈, 然后调用rust_main.</p>
<h4 id="中断准备">中断准备</h4>
<p>正是因为rust_main被汇编调用, 因此声明的时候要加上extern
"C"从而使用C的abi. rust_main 作为初始化代码, 刚启动就执行的代码,
自然是调用各种初始化函数. 这里调用中断初始化,
这部分代码单独放到一个mod内了, 也就是interrupt文件夹.</p>
<p>具体来说, 使用global_asm宏引入了interrupt.asm, 在要用到的地方用extern
"C" 声明函数,
最后使用write写入__interrupt地址到stvec.这里把写入stvec寄存器也放到unsafe内的原因是这个函数声明的作用域仅限unsafe作用域内.</p>
<p>main函数中调用interrupt模块的初始化, 完成中断的准备.
中断的初始化主要做两件事, 把准备好的中断处理函数加载到trap
vector寄存器stvec, 和打开中断总开关和对应的分开关.</p>
<p>进入interrupt模块的初始化函数,
分别是handler的初始化和timer的初始化.handler的初始化函数设置了stvec寄存器为interrupt.asm中符号<code>__interrupt</code>的地址,
同时开启sie寄存器中s态外部中断的开关 TODO 外部中断有哪些??.
timer的初始化函数则打开了sie中的s态时钟中断, 和中断的总开关,
并且设置了第一次时钟中断.</p>
<p>那Sstatus寄存器的SIE位负责的是中断总开关, 而类似ebreak这样的是异常,
所以不设置这个位也能进入trap处理.
当lab1后半部分用到时钟中断的时候就要设置SIE位打开总开关了.</p>
<h4 id="中断发生">中断发生</h4>
<p>中断随时可能来, 发生的时候, 可能程序执行到一半,
即使是一些临时寄存器也可能正在使用. 因此不能破坏任何现场.</p>
<p>断点异常和S态时钟中断都被opensbi在deleg系列寄存器中委托过了,
因此这两个中断产生时就会转到我们S态的中断向量处.</p>
<p>当有中断或者异常发生的时候就会跳转到之前设置好的<code>__interrupt</code>处,
硬件只是会修改sepc, scause, stval等寄存器的值,
而不像x86会直接保存到栈上. 保存到栈上全靠我们操作系统的指令.
而<code>__interrupt</code>主要做的就是保存现场并恢复.
首先是把各个寄存器压栈形成Context, Context的结构并不复杂,
32个通用寄存器, 加上sstatus, sepc. (riscv的pc不在32个通用寄存器里)
然后将栈上的Context地址放到a0, 把scause放到a1, 把stval放到a2,
最后jal(jump and link) 实现跳转. 因为函数调用约定就是用的jal调用函数,
ret返回. link代表把下一个指令的地址放到link寄存器中.
当handle_interrupt函数返回的时候, 就回到了汇编代码interrupt.asm中,
到了__restore这个部分, 自动开始了恢复中断的过程.</p>
<p>sscratch是一个单纯用来存数据的寄存器, 在tutorial中,
sscratch在用户态用来保存内核栈的地址, 内核态是0,
因为进入内核态(进入中断)的时候os把它清零. 之后为了支持用户态程序,
就需要用到sscratch, 先切换栈再保存Context, 而我们lab1还是一直内核态,
内核态发生中断, 就可以直接保存各种寄存器在当前栈上,
取出栈上的指针作为Context结构体的借用传入interrupt_handler.
sstatus里的带P(previous)的位会被设置好, 因此需要保存sstatus.
而scause和stval就直接看作局部于这次中断处理的临时变量(handle_interrupt的参数),
不保存, 在中断处理的过程中用寄存器传递.</p>
<p>os/src/interrupt.asm 内含中断保存现场__interrupt, 和恢复现场__restore
首先sp减34*8开辟空间,
保存时使用以sp为基地址的栈上偏移量寻址Context成员(类似栈上临时变量),
为了sp(x2)保持不变, 首先保存x1, 然后利用空闲出来的x1去计算原来的sp,
也就是把sp加34*8保存到x1, 再保存x1(作为sp(x2)), 再依次保存各种寄存器.
恢复的时候最后恢复sp即可.</p>
<p>handle_interrupt函数直接根据cause来调用不同的函数处理.
如果是断点异常, 就打印出来, 将PC加2(看来使用了C拓展减少了指令长度),
时钟中断就调用tick函数,
默认就调用fault函数panic并且打印未解决的异常.</p>
<h4 id="时钟中断">时钟中断</h4>
<p>现在RISC-V的timer一般都是内置在cpu内的,
不像x86是通过外部芯片产生时钟中断.</p>
<p>每次时钟中断的时候, 都会从中断处理程序那走一遭,
然后调用tick函数计数并继续设置下一次时钟. 目前设置的是每10
0000条指令产生一次时钟中断</p>
<blockquote>
<p>S模式不直接控制 时钟中断 和软件中断，而是使用 ecall指令请求
M模式设置定时器或代表它发送处理器间中断。该软件约定是监管者二进制接口
(Supervisor Binary Interface)的一部分。</p>
</blockquote>
<p>上面这句话来自那本中文的《riscv手册》. 虽然时钟的设置是通过sbi接口,
也就是ecall指令去使用m态程序(opensbi)提供的服务, 但时间到了的通知,
还是通过S态时钟中断. (猜测是opensbi设置时钟,
得到m态的时钟中断信号的时候, 传递下来, 产生S态的时钟中断信号.)</p>
<p>由于没有一个接口来设置固定重复的时间中断间隔，因此我们需要在每一次时钟中断时，设置再下一次的时钟中断.</p>
<h4 id="断点异常">断点异常</h4>
<p>ebreak指令会产生断点异常. 无论是ebreak还是ecall,
产生异常时的sepc都是指向该指令, 而不是下一条指令.</p>
<p>??那其他异常呢? 是下一条指令吗?? TODO</p>
<h4 id="中断结束">中断结束</h4>
<p>当handle_interrupt函数返回的时候,
返回到调用它的interrupt.asm中的jal指令之后, 开始恢复之前保存的现场.
直接把各个保存的寄存器恢复, 这样寄存器的状态就是发生中断时的状态.
恢复现场后, sstatus和sepc也恢复了, sret, 返回的时候将pc设置为sepc.
并且恢复sstatus寄存器, 把里面的previous位都还原.
如果中断之前是打开中断的状态, sret后也会回到打开中断状态.
最终恢复到中断前被打断的位置继续执行。</p>
<h3 id="interrupt-pending-寄存器">interrupt pending 寄存器</h3>
<p>machine/supervisor/user interrupt
pending寄存器是提供有关正在等待的中断的信息.</p>
<p>这里我也没有彻底学懂, 不过rcore-tutorial没怎么用到.</p>
<h4 id="背景">背景</h4>
<p>当多个中断发生的时候, riscv首先处理特权级最高的, 特权级相同的时候按照
外部-&gt;软件-&gt;时钟的顺序处理(使得最差情况时的处理时间最小).
因此当很多中断同时发生的时候, 或者ISA中断服务例程执行的时候,
其他中断却来了, 此时产生了中断pending.
让当前的中断例程能感知到新中断的存在有一定的作用, 我临时搜索了一下发现,
在arm架构中好像就有相关的应用.
看到一个是应用是省略相继产生的中断间的重新弹栈压栈, 提升性能.</p>
<h4 id="作用">作用</h4>
<p>当从mip(xip)寄存器中获取值的时候,
得到的是对应寄存器和对应中断产生信号的OR之后的值.
也就是如果这个中断真正在等待, 对应的pending位就为1.</p>
<p>高特权级如果设置了低特权级的对应中断的pending位,
(不知道是回到对应特权级的时候还是立刻?)就会产生对应的中断. 如,
m态的程序就可以通过设置mip对应的supervisor的中断pending位,
从而让低特权级的程序产生中断.
各种m态的中断的pending位在mip寄存器中是只读的,
mip中对应低特权级的pending位则既可读, 也可以写触发上述效果. S态软件中断,
U态软件中断(基本上)靠这种方式产生.</p>
<h2 id="lab2内存管理">lab2内存管理</h2>
<p>包括临时堆内存管理, 物理内存管理.</p>
<h3 id="临时堆内存管理">临时堆内存管理</h3>
<p>ucore中是先实现按页的物理内存管理, 再实现的任意大小的管理的.
而这里完全不一样, 先是bss段留了8M空间作为堆, 给操作系统动态内存分配用,
再去单独实现按页的物理内存管理.</p>
<p>这里我暂时使用临时堆内存管理这个新词,
表示为了使用rust提供的一些需要使用堆内存的数据结构而在bss段上划分出一块空间作为堆.
rcore-tutorial这里我们直接使用现有的buddy system内存分配算法,
在代码中开辟8M大小的bss段空间(u8数组), 作为被分配的空间.</p>
<p>我们分配算法和rust的对接主要在于Trait GlobalAlloc, 实例化之后用
<code>#[global_allocator]</code>标记就可以使用动态内存分配了(可以使用一些需要动态内存分配的内置数据结构,
如Box, Vec等). 接口也是和C语言中malloc/free类似的接口:
alloc和dealloc.</p>
<h4 id="bssbuddy-system实现细节">bss+buddy system实现细节</h4>
<p>直接分配u8 static数组,数组名字指向的就是对应的空间. 添加buddy
system这个包. spin和lazy_static也顺便加上. 创建memory文件夹作为新的mod,
创建init函数被main调用. 创建一个HEAP全局变量作为分配器,
并在init函数里面把那个数组的内存初始化给它. 想把数组的名字作为指针,
只需要调用.as_str()然后as转换为usize就可以了. 这样,
main函数调用完heap的init之后就可以分配堆空间了.</p>
<h4 id="使用自己的堆分配算法">使用自己的堆分配算法</h4>
<p>也可以不使用buddy_system, 答案中的heap2使用自己的algorithm
crate的bitmap_vector_allocator提供分配算法支持,
这里自己实现分配算法也可以很简单, 代码量挺少的.</p>
<p>堆分配算法和其他代码的接口一个是<code>#[global_allocator]</code>标注,
一个是init函数. 这里使用的是bitmap标记空闲, 以字节为单位,
查找时按照对齐要求的倍数顺序查找(作为内存的开头), 直到遇到了空闲处.
只标记4096字节, 最多只能管理4K的内存.
这里的实现也是对给定内存范围的对应内存的index(偏移)做分配,
每次分配得到的只是一个偏移, 需要去找到对应的内存地址.</p>
<p>不像buddy_system实现好了GlobalAlloc,
为了global_allocator要实现alloc::alloc::GlobalAlloc这个trait.
需要实现分配和回收两个函数, 传入的是core::alloc::Layout,
并且需要处理指针类型 *mut u8. 直接整个实现都是unsafe的.
Heap全局变量也不再是简单的直接是一个实例,
而是在VectorAllocatorImpl的基础上包了一层Option, 再包UnsafeCell.
UnsafeCell取内部的值需要get再as_mut, Option就直接unwarp,
就可以得到内部的VectorAllocatorImpl调用alloc/dealloc函数.</p>
<p>包一层Option有一个好处就是可以提供默认值. 初始化之前, Option里是None,
初始化函数使用replace函数替换成实例之后才能分配,
否则会在unwrap的时候panic</p>
<p>完成之后,
将main函数堆测试代码的两个循环数量从10000减少到100才能正常通过测试.
这个自己实现的算法毕竟管理的内存比较少.</p>
<h3 id="按页的物理内存管理">按页的物理内存管理</h3>
<p>物理内存管理不像临时堆内存管理只是为了让我们操作系统自己用,
它是虚拟内存管理的基础.
否则的话只要直接把buddy_system的LockedHeap的init函数中传入的内存改成我们可用的所有内存范围,
就能让我们操作系统自己用上这些内存了.</p>
<h4 id="封装地址类型与frame-tracker">封装地址类型与frame tracker</h4>
<p>内存地址空间确实是非常常用的东西. 无论是分页内存管理还是mmio,
之后肯定会大量用到内存地址的. 因此这里封装出了地址类型. 1.
封装地址类和页号类 1. 抽象实现From trait在地址和页号间相互转换 1.
抽象实现地址转页号的向上/下取整 1. 抽象实现和usize的加减输出操作.</p>
<p>还要在memory中新建mod range. 提供对内存地址range的支持.
它在基础的core::ops::range基础上增加相互转换, 和len函数, 和迭代,
重叠检测, 虚拟物理相互转换, 取下标, 包含检测的功能.</p>
<p>frame tracker 作为物理页面的智能指针, 继承PhysicalPageNumber,
实现Drop. frame模块除了frame_tracker的实现, 同时承载分配相关的实现:
allocator.rs 对分配算法进行包装, 对接frame tracker和分配.
分配算法实现Allocator trait(一次分配回收一个元素的index),
包装后提供初始化创建(起始物理页号和页数量), 分配一个页(frame tracker),
frame tracker析构的时候自动调用回收. 由于是简单的一次分配一个元素,
而且可以是离散的, 简单地使用一个栈进行分配. 创建StackedAllocator,
在allocator.rs中作为AllocImpl, 就会使用这个算法了.</p>
<p>frame tracker创建的时候不会自动申请页面, 因此想要获得frame
tracker需要通过allocator分配, 不能自己构造.</p>
<h4 id="分配哪些内存">分配哪些内存</h4>
<p>可以直接根据qemu内存映射,
riscv从0x8000_0000开始到0x8800_0000这128M初始内存, 直接硬编码拿来.
硬编码在 MEMORY_END_ADDRESS, 另外还要设置这些全局变量KERNEL_END_ADDRESS,
MEMORY_START_ADDRESS, KERNEL_HEAP_SIZE.</p>
<p>在ucore中, 一般以函数指针结构体作为接口,
让不同的分配算法提供相同的接口. 而且还花大量精力, 使用Page结构体,
链表组织空闲页面.(物理内存管理), 而我们这里实现的就简单得多,
对物理页的下标直接管理.</p>
<h4 id="frameallocator">FrameAllocator</h4>
<p>实现单页单页的物理内存的分配和回收. 内部使用的算法是StackedAllocator,
非常简单, 一个Vec, 新建的时候把一段物理内存范围输入,
每次分配取栈顶的一页, 每次回收页就压入栈中.
按照单页的分配和回收使得实现起来非常简单, 时间空间复杂度也会很低.
接着在StackedAllocator基础上包装出FrameAllocator,
把对下标的分配转化成真正的内存地址, 并且返回时返回Frame Tracker.</p>
<p>物理内存的分配器目前只实现的单页单页的分配和回收,
这一点我之前其实觉得挺合理的, 因为现在离散式虚拟内存技术已经非常成熟,
我们操作系统用到的现在全都是虚拟地址,
需要"连续的内存"时也一般是需要连续的虚拟地址空间,
因此物理地址的分配完全可以是这样一页一页离散的. 但是之后的lab可以看到,
DMA确实出现了需要连续的物理内存空间这种需求,
看来这里的实现确实值得改进...</p>
<h3 id="用到的其他小知识点">用到的其他小知识点</h3>
<p>pub(super) 指只对父模块是public的
https://doc.rust-lang.org/reference/visibility-and-privacy.html</p>
<p>KERNEL_END_ADDRESS是lazy_static, 因为不用会报错"pointer-to-integer
cast" needs an rfc before being allowed inside constants</p>
<p>下面这个impl代表某种类型, 而且最终会被确定下来
https://doc.rust-lang.org/std/keyword.impl.html <figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">iter</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="keyword">impl</span> <span class="title class_">Iterator</span>&lt;Item = T&gt; &#123;</span><br><span class="line">    (<span class="keyword">self</span>.start.<span class="title function_ invoke__">into</span>()..<span class="keyword">self</span>.end.<span class="title function_ invoke__">into</span>()).<span class="title function_ invoke__">map</span>(T::from)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>下面这句话的下划线似乎代表让编译器推断类型 <figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">offset</span> = ptr <span class="keyword">as</span> <span class="type">usize</span> - &amp;HEAP_SPACE <span class="keyword">as</span> *<span class="keyword">const</span> _ <span class="keyword">as</span> <span class="type">usize</span>;</span><br></pre></td></tr></table></figure></p>
<h2 id="lab3虚拟内存管理">lab3虚拟内存管理</h2>
<h3 id="sv39页内存管理">Sv39页内存管理</h3>
<p>Sv39最大支持512G地址空间, 分为3级页表. 每级页表大小都是一页, 因为8B *
512 = 4K. 最高级的页表, 每一项表示1G的地址空间,
第二级页表每项表示2M地址空间, 最低级的页表每一项表示4K地址空间.
虚拟地址空间64位只有低39位有效, 63-39 位的值必须等于第 38 位的值.
也就是说, 根据最高位是不是1, 512G地址空间被分为低256G(高位都是0),
和高256G(高位都是F).</p>
<p>39位的划分: 页内12位 + 9 + 9 + 9 对应的内存大小: 每页4K,
---(512页)---&gt; 2M -(512)-&gt; 1G -&gt; 512G 十六进制表示: 0x1000
-&gt; 0x20 0000 -&gt; 0x4000 0000 -&gt; 0x80 0000 0000
现在架构中最大可寻址的物理地址有56位. 也就是有56-12=44位标识页
而页表项中<code>[53-10]</code>这44位用来标识一个物理页.
也就是物理地址的过高位和低12位去掉之后还要右移两位才可以对应上页表项中.
页表项内低10位自然就是标志位. 页表项最低位(Valid位),
为0则表示该页表项无效.</p>
<p>然而三级和二级页表项不一定要指向下一级页表, 可以作为大页...
如果RWX位全0才是指向下一级页表, 否则作为大页, 项中指向映射的开始页,
向后自动映射2M/1G内存. 这方法厉害啊,
可以在线性映射的时候节约不少内存空间. 另外,
大页也需要按照自己的大小对齐.</p>
<p>satp寄存器指向页表. 要在修改 satp 的指令后面马上使用 sfence.vma
指令刷新整个
TLB。手动修改一个页表项之后可以通过在sfence.vma后面加上一个虚拟地址来刷新单独的页表项中这个虚拟地址的映射.</p>
<h4 id="页表工作方式">页表工作方式</h4>
<ol type="1">
<li>首先从 <code>satp</code> 中获取页表根节点的页号，找到根页表</li>
<li>对于虚拟地址中每一级 VPN（9
位），在对应的页表中找到对应的页表项</li>
<li>如果对应项 Valid 位为 0，则发生 Page Fault</li>
<li>如果对应项 Readable / Writable 位为 1，则表示这是一个叶子节点。
页表项中的值便是虚拟地址对应的物理页号
如果此时还没有达到最低级的页表，说明这是一个大页</li>
<li>将页表项中的页号作为下一级查询目标，查询直到达到最低级的页表，最终得到页号</li>
</ol>
<h3 id="内核启动">内核启动</h3>
<h4 id="内核地址空间的变化">内核地址空间的变化</h4>
<p>内核的地址空间要抬高, 在512G虚拟地址中不是平移256G.
数据段起始地址变成0xffff ffff 8020 0000, 在Sv39看来是0x7f_8020_0000
而原来是0x00 8020 0000, 多了0x7f 0000 0000, 也就是平移了508G.</p>
<p>另外观察到: 0x80200000 = 2G + 2M</p>
<h4 id="启动过程">启动过程</h4>
<ol type="1">
<li>0x80200000处(entry.asm)使用汇编开启分页模式</li>
<li>开启分页模式的一瞬间, 当前的PC还在原来的位置,
因此需要映射0x80200000附近的位置, 同时需要映射0xffffffff80200000
附近的位置 直接使用大页映射, 4K空间作为最高级页表, 映射两个1g,
简单方便省内存. (这里之后的lab会为了访问磁盘设备需要再映射1g的页).</li>
<li>跳转到rust内(rust_main)</li>
</ol>
<h3 id="代码变化梳理">代码变化梳理</h3>
<p>内核启动之后, rust_main在之前的初始化的基础上,
我们还会新建一个kernel的MemorySet内存地址映射, 并激活它.
这里的MemorySet更多主要是为了之后的进程的地址空间映射准备的.
之后lab的main函数在初始化的时候就不会再激活这样的映射了.</p>
<p>需要修改的地方有: 1. ld脚本需要修改链接的基址, 这个比较简单 2.
启动的asm文件, 需要加上临时页表, 和装载临时页表的语句 3.
加入虚拟地址结构体, 实现一些相关trait,
增加一个偏移量常量KERNEL_MAP_OFFSET</p>
<p>修改完这几个, 内核依然能够正常运行进入rust_main. 接着修改,
下面这前两步的工作量最大 1. 封装页表项, 页表等 1. 实现MemorySet,
和内部的Mapping和Segment 2. main函数中新建kernel类型的映射并激活</p>
<h4 id="entry.asm">entry.asm</h4>
<p>这里只说说这个页表项 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.quad (0x80000 &lt;&lt; 10) | 0xcf</span><br></pre></td></tr></table></figure> 由于取页号放到第10位开始的位置,
也就相当于0x8000 0000 &gt;&gt;12 &lt;&lt;10, 0xcf表示
VRWXAD这几个标志位均为 1, 表示这个页具有RWX属性.</p>
<h4 id="虚拟地址的封装-memoryaddress.rs">虚拟地址的封装
memory/address.rs</h4>
<p>完善之前物理地址的封装, 加上虚拟地址 1. 指针转换为虚拟地址,
实现这个trait, 这样任何指针类型都可以直接转虚拟地址类型 2.
deref_kernel和deref可以用地址类型转换成任意类型的指针,
而且生命周期是static的.
pageNumber类型的deref使得可以直接获得页表大小的u8数组. 3.
对VirtualPageNumber类型实现levels函数, 获得三级页号. 4.
也为address类型实现page_offset函数, 取得页内偏移.</p>
<h4 id="实现页表-memorymapping">实现页表 memory/mapping</h4>
<p>不仅封装了页表, 页表项, 还封装了mapping结构, 类似ucore的vma 1.
page_table_entry.rs 封装页表项. 实现了Flags类,
表示每个entry低8bit的标志位. 用implement_flags宏抽象标志位的读的实现.
提供了address函数, page_number函数用来找到页表项指向的页面,
实现了flags函数获取flags, 还有is_empty函数, has_next_level函数,
最后实现了Debug trait的打印 2. page_table.rs 封装了页表(页表项数组).
这里还需要把之前的frame_tracker增加了derefMut到u8数组的trait.
封装了PageTableTracker作为PageTable的智能指针. 内部包含一个FrameTracker,
实现自动释放内存的功能. 和PageTable只有一个Deref的距离.
创建页表时要申请物理页将FrameTracker包装为PageTable的智能指针类型再使用.
FrameTracker管理一个页, 并且能转换为任何类型, 作为任何类型的智能指针.
而包装了FrameTracker的PageTableTracker则更加具体,
仅仅作为页表的智能指针. 3. segment.rs 封装了线性映射类型,
实现了遍历某个映射中每个页的功能. 映射有两种类型,
操作系统使用的线性映射, 和按帧分配的离散映射. 后者只能遍历虚拟页,
前者可以直接使用虚拟转物理的转换trait遍历物理页. 4. mapping.rs
负责管理各种页表. 使用vec保存PageTableTracker这个智能指针,
同时另外保存根页表的物理页号(对应页表寄存器).
实现了激活该页表activate函数, new函数新建页表同时分配根目录表,
map函数映射一个segment, map_one函数映射一页, unmap移除映射,
会创建页表的find_entry函数(和ucore中那个函数类似),
虚拟地址查找物理地址的lookup函数. 5. memorySet总览全局,
包含了Mapping结构体和Segment数组, 实现添加和删除映射的总接口,
调用下部的mapping的添加和删除映射的接口.
另外还实现了让main函数调用的new_kernel新建memorySet和各种映射的函数,
之后的lab里还要实现读取ELF创建映射的函数</p>
<h3 id="实现细节">实现细节</h3>
<h4 id="mapping">Mapping</h4>
<p>mapping负责管理页表, 整个文件100多行, 非常重要. 1. map_one函数,
映射一个页, 调用find_entry找到对应的entry, 为空则新建并填入Page:
<code>*entry = PageTableEntry::new(ppn, flags);</code>由于page_table就是page_table_entry数组,
因此直接赋值由于实现了Copy, 就导致页表项写入. 2. lookup函数,
这个函数是静态的!! 首先拿出当前的页表寄存器内的值, 找到页目录表.
把参数的虚拟地址转为页号调用levels函数方便获取每级下标.
然后先取好最高级页表的下标, 再在循环中如果有下一级页表, 不断取下标,
直到页表项为空(判断valid???), 或者不再有下一level,
此时的entry就保存了base地址,
加上虚拟地址低位的offset(不一定只有12位)得到真正的地址. 3.
find_entry函数, 这个函数和lookup有些类似,
但是是从自己的mapping实例的页表物理页号中找到页表,
找的过程中如果页表不存在就直接分配新的页作为页表, 总是能找到页表项,
而且找的总是代表4k一页大小的第三级页表项. 4. unmap函数,
调用find_entry函数并调用clear 5. map函数, map一整个segment.
如果是线性映射, 则遍历虚拟地址不断调用map_one填页表项, 有数据复制数据,
最重要的特点是不用分配物理页面. 如果是离散映射,
则遍历虚拟地址不断分配页面, 把分配到的页面填充0.
拷贝数据的时候映射还没建立,
需要从物理地址加offset这个通用的访问物理内存的映射来复制,
还要考虑区间与整页不对齐的情况, start变量指从页开头开始的偏移,
指向需要复制数据的开始位置. stop变量也是偏移. 每次循环只处理一页.
当开始位置大于当前页的起始位置, 说明是第一页,
需要从开始位置而不是页开头进行复制. 否则就从开始位置复制.
当结束位置减去页起始位置, 小于页的大小的时候, 就说明是最后一页,
需要复制到结束位置为止, 而不是页结束位置.</p>
<h4 id="memoryset">MemorySet</h4>
<p>MemorySet 就是一个进程的所有内存空间管理的信息了. 内部包含Mapping,
负责管理页表,
用一个数组保存PageTableTracker(自己管理页表占用的物理页面),
并且另外保存页目录表. 包含segment数组, 内含每个映射,
和allocated_pairs数组,
保存虚拟页号到物理页智能指针(FrameTracker)的二元组, 拿着分配的物理页.
简而言之, MemorySet包含1页表2映射3物理页</p>
<p>添加新的映射的时候, 一方面要添加到页表里去, 一方面要加入映射vec保存,
如果申请了物理页要放到物理页vec中. 还检查是否和当前内存空间重叠.</p>
<p>由于内核换了位置(使用了虚拟地址), 需要在memory/config中加入MMIO
设备段内存区域起始地址: DEVICE_START_ADDRESS, 和DEVICE_END_ADDRESS,
另外还要将kernel_end_address 改成虚拟地址,
config里的部分高位地址都要改改. (MMIO表示memory mapped io.
访问这里的地址就是直接与外设交互)</p>
<h2 id="lab4线程与调度">lab4线程与调度</h2>
<p>这个lab工作量非常大.</p>
<h3 id="总览">总览</h3>
<p>ucore中把初始化的执行包装成idleproc,
调用创建内核线程的函数创建init_main线程.
不过idleproc除了初始化外没有执行任何实质性的任务, 不存在也没有关系.
我们在rcore-tutorial中则直接切换到新来的线程.
而且切换后甚至原本我们使用的栈 bootstack也可以被回收.</p>
<p>当前的内核由于只用一个单核cpu, 只有一个内核栈, 并且不支持中断的嵌套.
而且现在中断的时候无论是内核态还是用户态都会交换sp和sscratch,
这就导致如果嵌套会导致交换两次出现问题. 需要改进为用户态切换栈,
内核态不切换栈才能为支持嵌套中断打基础.</p>
<p>进程和线程辨析: 线程是运行和调度的单位. 进程则包含了地址空间,
同一个进程的不同线程的地址空间是共享的.(意味着高位地址处会映射多块栈给不同的线程)
新建线程和Context都需要传入process结构体</p>
<p>切换则直接通过保存当前中断栈上的Context,
把下一个要执行的线程的Context放到栈顶实现.</p>
<h3 id="代码变化梳理-1">代码变化梳理</h3>
<ol type="1">
<li>interrupt/context.rs 完善之前的Context实现. Context结构体不变,
为Context实现了Default, 使用全零作为Default. 实现了获取/设置
栈指针/返回地址的四个简单函数.
实现了按照调用规则把参数写入Context内对应寄存器的函数, 和传入函数地址,
参数, process结构体新建Context的函数.</li>
<li>新建process文件夹作为mod</li>
<li>增加全局Processor用到的Lock, 原本使用的是unsafeWrapper,
在algorithm目录内.
<ol type="1">
<li>config.rs 包含了每个线程的运行栈大小, 和共用的内核栈大小,
目前都是512K</li>
<li>process.rs process结构体当前只有is_user标志位和memory_set内存空间.
有三个函数, 新建内核进程的new_kernel,
从elf创建进程的from_elf函数(之后的lab才会添加),
映射新的虚拟地址的alloc_page_range函数(类似mmap)</li>
<li>kernel_stack.rs 内核栈也就是作为一个大小为KERNEL_STACK_SIZE的u8数组.
此外实现了push_context函数,
能在栈顶减去Context大小的位置强转为Context指针, 然后赋值写进去,
最后把这个指针返回. 同时暴露出全局变量作为共用的全局内核栈.</li>
<li>thread.rs Thread结构体包含id, 栈(虚拟地址range),
所属进程(arc+读写锁包装的Process结构体),
和inner(用一个mutex包装一些可变数据结构).
inner包含context和是否进入休眠的sleeping标志. 实现了Hash Eq这两个trait,
Debug打印的trait. prepare函数用于准备执行该线程, 会激活页表,
清空并返回Context, park函数会暂停线程, 保存传入的Context.
新建线程的new函数需要传入Process, 要执行的entry_point, 和参数,
该函数会新分配一段空间(alloc_page_range)作为栈, 并构建新的Context,
最后打包新建thread并返回</li>
<li>processor.rs 包装调度器算法, 包装进程状态转移的操作.</li>
</ol></li>
<li>增加新的调度算法: 使用hrrn高响应比优先的调度算法,
放到process文件夹内. hrrnThread结构体对线程再次包装,
增加birth_time和service_count两个字段.
调度结构体HrrnScheduler则包含linkedList保存的hrrnThread和currenttime的二元组.</li>
<li>修改interrupt.asm支持切换线程, 加入交换sscratch的代码,
修改保存sp为保存sscratch. 恢复时保存弹出Context之后的栈到sscratch.
把a1放到sp使得<code>__restore</code>有返回值和参数这两种新的调用方法,
从而执行不同的线程.</li>
<li>修改interrupt_handler (init函数里面的增加各种中断使能的操作先不做,
后面的lab需要键盘输入的时候再加上), 修改时钟中断处,
tick之后调用保存当前进程和准备下一个进程的函数, timer模块不变.</li>
<li>在interrupt/mod.rs中增加一个wait_for_interrupt函数.
给processor.rs中函数调用</li>
<li>修改timer模块init, 删除<code>sstatus::set_sie();</code>
这样main函数就不开中断, 执行内核线程的时候再接受中断</li>
<li>修改main.rs启动线程 main函数首先对各种东西进行初始化,
然后对线程的实现进行测试.</li>
</ol>
<h3 id="实现细节-1">实现细节</h3>
<h4 id="interruptcontext.rs">interrupt/context.rs</h4>
<p>这里新建的时候Context中返回值寄存器设置为-1, 如果执行的函数返回了,
就会报错. 之后新版的代码似乎修改了这里, 能正常返回.</p>
<h4 id="processprocess.rs">process/process.rs</h4>
<p>process结构体也算是MemorySet的封装了, 新建的时候会新建MemorySet,
函数也是调用MemorySet的接口.</p>
<p>alloc_page_range函数类似于mmap吧, 基于memory_set提供的接口操作,
传入一个size, 返回分配好的地址范围. 首先把size向上取整到页倍数,
再用while循环从0x100_0000开始不断步进查找可用内存空间(memory_set的overlap_with),
可用则调用memory_set.add_segment增加映射.</p>
<h4 id="kernel_stack.rs">kernel_stack.rs</h4>
<p>因为线程都有自己的栈映射在低地址区了, 函数调用关系的维护不靠内核栈,
内核栈只处理中断, 而且中断不会嵌套. 如果中断不嵌套,
那么Context总是在公用内核栈最顶上.
因此切换内核线程前可直接将Context放到栈顶上假装是正常的中断返回.</p>
<h4 id="thread.rs">thread.rs</h4>
<p>prepare函数, 1激活了新线程的页表, 2把Context放到了公共内核栈的栈顶.
切换线程的时候都是这样假装是中断返回.
此时大概调用了park函数保存好了中断进入时那个线程的Context.</p>
<p>重点关注新建线程的函数. 1. 新建线程的时候用的栈, 是新映射分配的!! 2.
新建的Context, 在切换的过程中还不会打开中断, 直到sret的时候中断才会打开.
3. 是否是用户线程取决于Process的is_user. 4. 返回的时候,
is_sleeping是false. 这意味着一创建就开始执行? 不,
这只说明不是放到sleeping的队列而是放到scheduler的队列里</p>
<h4 id="processor.rs">processor.rs</h4>
<p>processor 主要是包装一下进程的状态转换操作,
调度靠每次prepare_next_thread中询问调度算法的操作,
主要靠timer_interrupt的时候的park+prepare组合拳.
当线程出现问题调用fault函数的时候, 就会调用kill/prepare组合拳</p>
<p>在这样单核的环境, 确实可以说调度器是局部于处理器的.</p>
<p>线程的组织上, 使用了hashbrown这个crate保存sleeping的thread,
需要调度的线程让调度算法去用自己的数据结构保存.</p>
<p>add thread会检查是否当前线程为None, 是则放入. 主要还是加入scheduler.
只有刚启动的时候, 和kill线程的时候会take当前的Option-thread 为none</p>
<p>确实, __restore作为函数调用只出现在processor的run里面,
run函数只出现在rust_main里面. 只有刚开始的时候会刻意去调用__restore
毕竟,初始化的时候并不是调用的interrupt_handler, 不会返回到__restore.
而且使用的是boot_stack</p>
<p>执行的函数组合可以为 parl/kill [sleep] prepare_next_thread</p>
<h4 id="interrupt.rs">interrupt.rs</h4>
<p>外部中断如果是键盘输入, 就会把字符push到STDIN里(fs/stdin.rs)TODO</p>
<h4 id="unsafewrapper">unsafeWrapper</h4>
<p>unsafe包装后能增加多少灵活性? 这里的unsafe一方面实现了&amp;self
转mut, 使得可以同时持有多个可变借用. 并且实现了(标记了)sync Trait,
使得可以多线程共享.</p>
<p>static unsafe wrapper 还增加了Phantom data成员,
表明该结构体确实拥有T类型的值的所有权, 让wrapper被drop的时候也能drop
T.</p>
<h4 id="hrrn_scheduler.rs">hrrn_scheduler.rs</h4>
<p>alloc::collections::LinkedList组织内部线程
对线程再增加了一层包装HrrnThread, 增加相关数据结构.
真正关键的只是一个.max_by()</p>
<h4 id="interrupt.asm">interrupt.asm</h4>
<p>原来是直接把sp保存不切换栈, 现在是先交换sscratch再保存,
而且保存的时候是保存的原来的sp, 所以恢复的时候直接正常恢复就好.
只要把当前的栈放好到sscratch就行.</p>
<p>无论如何, 发生了中断就交换栈为sscratch. sscratch的值可能是什么??
如果是单线程不嵌套中断的话, 一定是公共栈顶上?? 恐怕是的</p>
<p>riscv调用约定中, a0, a1既是第一个参数, 又是返回地址. 这设计强!!
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">__restore:</span><br><span class="line">    mv      sp, a0  # 加入这一行</span><br></pre></td></tr></table></figure> 这样一方面可以调用__restore(context),
一方面也可以让interrupt_handler返回context指针. 也就是中断返回的时候,
如果不切换进程, 就返回当前的进程的context,
否则返回切换到的进程的context. 其次, 把第一个参数作为sp,
而sp不仅是当前Context的位置, 还是之后保存到sscratch的位置!!!
因此这个参数/返回值一定要放在作为栈的内存顶上</p>
<h4 id="interrupthandler.rs">interrupt/handler.rs</h4>
<p>这里打开了一些神奇的中断.
<code>sie::set_sext();</code>这个应该只是使能sie寄存器的某个中断,
中断的总开关还是没有打开的.
在某些特殊地址写入数字就能在OpenSBI中打开中断?? 为什么??</p>
<p>handle_interrupt函数中, 每个单独的处理函数确实应该返回应该Result类型,
是错误则调用fault.</p>
<p>fault函数现在出现异常的时候会杀死当前的线程了, 传入的参数也变了
最重要的当然还是timer的时候调度一下</p>
<h4 id="lock.rs">lock.rs</h4>
<p>为Mutex增加关中断的功能得到Lock类型. 则当获取其中内容的时候,
既关+保存了中断, 又独占了资源.</p>
<p>具体实现上, 上锁是在get函数中, 释放是在Drop的trait中.</p>
<p>同时实现了deref和deref mut, 可作为被包裹对象的智能指针使用.</p>
<p>另外实现了一个不上锁不关中断, 直接获得内部对象的unsafe_get函数,
用于PROCESSOR::run()的时候因为不会返回, 导致不会调用对应的析构函数</p>
<h3 id="线程的结束">线程的结束</h3>
<p>目前, 内核线程的结束是靠设置自己线程的isDead变量,
然后触发中断的时候检查时结束的.
也就是说设置了这个变量后即使不使用ebreak,
用其他方式触发中断也会被结束.</p>
<h3 id="线程进程的保存与组织">线程/进程的保存与组织</h3>
<p>线程的组织上, 使用了hashbrown这个crate保存sleeping的thread,
需要调度的线程让调度算法去用自己的数据结构保存.</p>
<p>Arc RwLock包着进程, 创建新线程的时候会把Arc
RwLock-进程的所有权要过来, 用clone可以多处持有.
似乎没有单独组织进程的地方, 父进程子进程之类的关系链接也似乎没有</p>
<h2 id="lab5-设备驱动与文件系统">lab5 设备驱动与文件系统</h2>
<h3 id="综述">综述</h3>
<ol type="1">
<li>提供对ELF文件用户程序的解析</li>
<li>提供对磁盘映像的支持</li>
<li>实现系统调用支持</li>
<li>支持文件描述符</li>
</ol>
<h3 id="相关修改">相关修改</h3>
<ol start="0" type="1">
<li>entry.asm 增加映射低位页表</li>
<li>main函数增加参数, 调用drivers的初始化函数</li>
<li>新建drivers文件夹, 在mod.rs中增加init函数,
调用设备树子模块的init函数</li>
<li>drivers/device_tree.rs 增加对device_tree这个库的依赖.
init函数调用dtb遍历库, walk函数负责遍历生成的树.</li>
<li>修改makefile, 增加qemu的启动参数
增加TEST_IMG变量指向之后的磁盘镜像</li>
<li>增加drivers/bus文件夹并增加子模块virtio_mmio.</li>
</ol>
<h4 id="entry.asm-1">entry.asm</h4>
<p>这里没想到增加了新的页表. 花了我差不多一个小时的时间去debug 当parse
dtb, 得到磁盘的Header的时候, 这个header的位置在0x1000_8000, 位于低地址,
而我们此时还处于初始化的状态, 映射还是巨页映射, 只映射了0x8000
0000开头的1GB, (1GB是0x4000 0000). 更加恐怖的是, 此时的sscratch都没有值,
中断都无法正常进行. 当前的设计是中断一定切换栈,
每次中断的时候都是先交换sscratch和sp, 然后保存真正的原来的sp到栈上.
离开的时候先把sp弹出后的位置放到sscratch.
而第一次放入sscratch就是运行线程时假装中断返回的时候. 因此,
我在debug的时候, 第一次页访问异常, 进入中断的时候,
从sscratch中取来了(似乎是-1)未知的值, 作为内核栈放到sp,
然后在保存第一个寄存器的时候发生了第二次页访问异常.
这时又把sscratch和sp交换, 得到了正常的sp值, 反而正常处理了,
但是报错的地址好像是0xffff_ffff_ffff_ffec. 我在main函数加入了把kernel
stack放到sscratch的汇编才正常得到了中断发生错误的地址.</p>
<h4 id="drivers模块">drivers模块</h4>
<p>driver模块目前主要负责文件系统的driver.
对外暴露的接口是driver模块中的driver trait,
和DRIVERS这个组织各种驱动的数据结构.</p>
<p>模块的初始化函数在mod.rs中, 参数传入dtb地址,
负责调用解析设备树的device_tree::init, device_tree的walk函数则一边遍历,
一边判断是不是想要的设备, 这里单指对应磁盘的块设备,
找到则把这个节点传给对应的总线协议驱动程序, 这里是bus/virtio_mmio.
本次实验中找到块设备的节点后, 把节点里reg字段拿出,
转换为virtio_drivers(库)::VirtIOHeader类型,
就传给驱动程序的包装virtio_blk,
virtio_blk::VirtIOBlkDriver内部包装的是mutex包装的virtio_drivers(库)::VirtIOBlk,
对外实现了driver的trait.</p>
<p>之后在fs中才会用到BlockDevice, 它包装driver,
实现rcore_fs的BlockDevice trait从而传入给SimpleFileSystem::open函数</p>
<p>层次关系: virtio_drivers(库)::VirtIOBlk --包装--&gt;
VirtIOBlkDriver(实现Driver) --包装--&gt;
BlockDevice(实现rcore_fs的BlockDevice)</p>
<h4 id="driver.rs">driver.rs</h4>
<p>这个模块包含了驱动接口driver trait, 描述驱动类型的DeviceType,
和lazy_static的DRIVERS.</p>
<p>Driver 这个trait, 使用时根据device_type返回的DeviceType,
来调用对应的方法, 现在这个trait中只有块设备相关的方法,
提供了用unimplemented宏表明没有实现这个方法的默认实现.
实现新的设备驱动的时候, 只需要加入新的方法即可.</p>
<p>DRIVERS保存所有驱动的数据结构, 方便获取驱动. 驱动是dyn Driver类型,
首先用Arc实现共享, 再通过Vec保存, 再加上读写锁保证多线程安全.</p>
<h4 id="device_tree.rs">device_tree.rs</h4>
<p>device tree blob 确实是个标准. 其中头部的字段其实很多,
包括了dtb的版本等等. 我们现在只读取了前两个字段.
第二个字段size确实是包含整个dtb的大小的, 包括头部.
https://www.devicetree.org/specifications/</p>
<p>这里init函数首先校验头部, 得到size,
再把整个dtb作为u8数组传入DeviceTree的crate中,
并且让遍历的walk函数递归遍历.
而walk函数则只是搜索compatiable字段为virtio,mmio的节点,
把节点传入virtio_probe进行初始化</p>
<h4 id="busvirtio_mmio.rs">bus/virtio_mmio.rs</h4>
<p>将传入的dtb节点的reg字段转为VirtIOHeader传入驱动程序进行初始化.</p>
<p>这里会遇到不少verify不对的设备,
因此如果verify函数调用失败或者没有reg字段就直接返回.
这里verify的时候就会访问1000_xxxx开头的低地址.</p>
<p>此外, 暴露了virtio_dma_dealloc, virtio_phys_to_virt,
virtio_virt_to_phys这三个extern "C"且no_mangle的函数.
而且没有在我们代码中其他地方被调用.
这说明是库函数在C语言中或者汇编中调用了这两个函数.
根据名字看可能是virtio库.</p>
<h4 id="block模块和-blockvirtio_blk.rs">block模块和
block/virtio_blk.rs</h4>
<p>block模块的mod.rs里提供了对接驱动与文件系统的VirtIOBlkDriver包装.
而模块内部则是保存的块设备的Driver实现.</p>
<p>BlockDevice的实现主要是将Driver的返回bool值的read_block/write_block
函数转换成返回Result&lt;()&gt;的read_at/write_at函数,
另外实现假的sync函数</p>
<p>VirtIOBlkDriver的实现就是调用内部的Driver的read_block/write_block函数,
把返回的Result再用is_ok转成bool.</p>
<p>VirtIOBlkDriver则需要实现read_block/write_block的Driver接口,
另外给解析Node的virtio_mmio.rs:virtio_probe函数一个创建设备的add_driver函数.
add_driver函数把header传给VirtIOBlk::new得到包装的内部驱动,
再把驱动包装上刚刚实现的VirtIOBlkDriver加入DRIVERS列表.</p>
<h3 id="fs模块">fs模块</h3>
<p>模块的mod.rs 提供了lazy_static的全局变量ROOT_INODE,
初始化的时候获取第一个Block类型的driver,
用BlockDevice包装后传入SimpleFileSystem::open()函数,
返回值赋给ROOT_INODE. 也许是SimpleFileSystem实现了对INode的deref,
在ROOT_INODE上可以调用到inode_ext拓展INode实现的方法</p>
<p>还有init函数, 负责作为测试,
main函数初始化的时候使用ls方法测试我们文件系统的功能.</p>
<h4 id="inode_ext.rs">inode_ext.rs</h4>
<p>impl INodeExt for dyn INode 通过这种方法为已有的Inode类型增加功能.
额外实现了 ls这个直接打印而不返回值的函数, 和readall函数,
把所有内容读到<code>Vec&lt;u8&gt;</code>并返回.</p>
<h3 id="elf相关代码">elf相关代码</h3>
<p>ELF文件也可以看作是一个地址空间. 因为它定义了各个段的映射关系.
MemorySet中增加根据ELF文件创建的from_elf函数, 它遍历elf文件的每个段,
根据大小和权限映射每个段.</p>
<p>首先在program_header中对每个为load类型的段,
读取开始地址和大小和数据和权限之后进行映射</p>
<p>process中也加入from_elf函数, 主要是调用MemorySet中的from_elf函数.</p>
<h3 id="sfs文件系统中的指向关系">sfs文件系统中的指向关系</h3>
<p>文件夹inode -&gt; 文件entry -&gt; 文件inode -&gt; 文件数据</p>
<h2 id="lab6-用户程序-系统调用-文件描述符">lab6 用户程序, 系统调用,
文件描述符</h2>
<h3 id="步骤">步骤</h3>
<ol type="1">
<li>完全构建新的crate作为user程序的框架, 这里也要新建Makefile文件,
并且可以单独build</li>
<li>在外面新建makefile文件, 依次make两个子目录</li>
<li>中断处理中, 初始化时开启外部中断,
用户态的ecall异常时调用kernel模块的syscall_handler,
增加外部中断处理键盘输入</li>
<li>为线程增加打开的文件descriptor数组, 初始化创建的时候就放入STDIN,
STDOUT.</li>
<li>fs中增加stdin和stdout全局变量</li>
<li>增加mod kernel
<ol type="1">
<li>condvar.rs 利用线程的睡眠实现条件变量</li>
<li>syscall.rs 系统调用的总入口.</li>
<li>process.rs 处理线程退出的系统调用</li>
<li>fs.rs 处理文件读取相关的系统调用</li>
</ol></li>
</ol>
<h3 id="用户进程">用户进程</h3>
<p>类似于自己做一些rust标准库的事情.
首先是实现了ecall的包装,从而实现了sys_read, sys_write, sys_exit.
利用sys_write实现了print, println宏.
实现了对用户程序的输入输出的支持.</p>
<p>hello_world主要使用了输出. nodebook可以把输入的字符回显.</p>
<h4 id="fsstdout.rs-stdin.rs">fs/stdout.rs stdin.rs</h4>
<p>让标准输入和输出实现和文件一样的接口(INode)进行读写.</p>
<p>stdout没想到就是一个空结构体 <figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Stdout</span>;</span><br></pre></td></tr></table></figure> 然后直接实现INode的方法,
read和poll都返回不支持的错误, write不允许offset为非0.</p>
<p>标准输入stdin同理, 只允许offset为0, buf中没有值则等待一次条件变量,
否则进入读过程, 要么是stdin的buffer空了, 要么是buf不够长, 返回.</p>
<h4 id="系统调用的实现">系统调用的实现</h4>
<p>syscall_handler函数根据传入的系统调用号调用各个子函数,
重要的是子函数的返回值还代表了对当前进程的处理方式.</p>
<p>write: 根据fd在进程的descriptor内获取inode, 调用inode的write_at,
直接返回Proceed和返回值.</p>
<p>read: 调用inode的read_at, 然后根据返回值包装一下.
和write不同的地方在于, 如果返回值为0则park当前线程(阻塞),
此时已经在read_at内部等待了condvar,
调用等待时会把当前线程放入等待队列并sleep_current_thread.
之后syscall_handler在处理返回值的时候发现是Park类型会再切换线程.
直到之后external
interrupt键盘输入-&gt;push到stdin中-&gt;条件变量notify-&gt;进程恢复调度.</p>
<h4 id="condvar">condvar</h4>
<p>这里的条件变量利用的是线程的休眠,
等待条件变量时进入条件变量内部的队列, 线程休眠. 当notify时则唤醒进程.
只在fs/stdin.rs中被实例化并使用.</p>
<p>如果有多个线程同时等待标准输入?
因为现在的线程的标准输入标准输出都是公用的, 没有不同的tty终端的概念,
如果等待输入的线程去sleep了, 那新执行的线程如果还想读取输入的话,
那就会产生冲突了, 两个线程读取一个标准输入. 如果引入了不同的终端的概念,
能有多个标准输入相互区分开就不会冲突. 目前看来还是阻塞,
另外加入新的把线程放到后台的按键, 这样比较好.</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>rcore</tag>
      </tags>
  </entry>
  <entry>
    <title>main函数启动与POSIX-ABI</title>
    <url>/2020/main%E5%87%BD%E6%95%B0%E5%90%AF%E5%8A%A8%E4%B8%8EPOSIX-ABI/</url>
    <content><![CDATA[<h1 id="main函数启动与posix-abi">main函数启动与POSIX-ABI</h1>
<span id="more"></span>
<p>https://0xax.gitbooks.io/linux-insides/content/Misc/linux-misc-4.html
这篇文章不错</p>
<p>https://embeddedartistry.com/blog/2019/04/08/a-general-overview-of-what-happens-before-main/
这篇文章的拓展阅读不少好东西： https://lwn.net/Articles/631631/ ##
初始时的栈布局 https://luomuxiaoxiao.com/?p=516 这篇文章也不错</p>
<blockquote>
<p>3.2.1 首先，_start是如何启动的？
当你执行一个程序的时候，shell或者GUI会调用execve()，它会执行linux系统调用execve()。如果你想了解关于execve()函数，你可以简单的在shell中输入man
execve。这些帮助来自于man手册（包含了所有系统调用）的第二节。简而言之，系统会为你设置栈，并且将argc，argv和envp压入栈中。文件描述符0，1和2（stdin,
stdout和stderr）保留shell之前的设置。加载器会帮你完成重定位，调用你设置的预初始化函数。当所有搞定之后，控制权会传递给_start()，下面是使用objdump
-d prog1输出的_start函数的内容：</p>
</blockquote>
<p>所以程序的运行过程就是，系统把elf的规定好的几个段加载进去，然后从_start(entry_point)运行。但是这时候，难道栈上什么都没有吗？
为了探究在进入entry_point时候的栈上的数据，看x86-64-ps-ABI.pdf。 在Low
Level Interface &gt; Process Initialization &gt; Initial Stack and
Register State这里的图3-9就表示了初始化时的栈布局：
这里先提一下寄存器的布局，除了rsp和rdx其他的寄存器的内容都是未定义的。其中rbp被点明需要清零，rdx是需要注册到退出前的函数的（application
should register it with
atexit）(BA_OS).这里观察到是_dl_fini。r13寄存器的值观察到和rsp一样，r12和rip一样。r9指向0x400000,rsi指向一个ld.so的数据段下方的无名地址。rax我还以为是execve的系统调用号，很可惜不是，而是0x1c。由于最先接管程序的反而是ld.so，所以这里的数据是什么在于它最后做了什么。而且栈的低地址方向上还有不少各种各样的数据，估计也是它的。有大概0xd10
3344字节的脏数据。。。 <img src="../imgs/psABIstack.png"
alt="stack layout" />
总之栈初始时是有东西的，而且还不少！随便找一个64位的程序用gdb打开，start自动停在入口点，就可以看到：
从低地址到高地址，首先rsp指向的是 argument
count，接下来是对应数量的参数指针，接着是参数和环境变量之间的8字节空白分隔，
接下来是环境变量的指针数组，libc的全局变量environ就是指向这里。key和value没有分开，在同一个字符串里面用等于号连接。这样每一个指针就指向一个带等于号的字符串。然后又是一个8字节的0分隔。（可想而知如果程序简单，main函数的栈只有几十字节大小，环境变量数组很容易就被溢出了，导致调用system失败。。。）
接下来是一些不明意义的数据，叫做Auxiliary vector
entries，每个16字节，前8字节是类型，后8字节是内容。这里接下来好像是0x18字节的分隔？
https://lwn.net/Articles/519085/
可以通过getauxval()这个libc的函数调用获得
我对照着表把这次运行的flag都标注了一下 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">24:0120│          0x7fffffffe380 ◂— 0x21 /* &#x27;!&#x27; */ AT_SYSINFO_EHDR？</span><br><span class="line">25:0128│          0x7fffffffe388 —▸ 0x7ffff7ffa000 ◂— jg     0x7ffff7ffa047 # vdso 的地址。 link：https://www.jianshu.com/p/071358f497ea</span><br><span class="line">26:0130│          0x7fffffffe390 ◂— 0x10 AT_HWCAP</span><br><span class="line">27:0138│          0x7fffffffe398 ◂— 0x78bfbff  an bitmask of CPU features. It mask to the value returned by CPUID 1.EDX.</span><br><span class="line">28:0140│          0x7fffffffe3a0 ◂— 0x6 AT_PAGESZ</span><br><span class="line">29:0148│          0x7fffffffe3a8 ◂— 0x1000 in bytes. 这就是为什么加载时最后三位都是0吧</span><br><span class="line">2a:0150│          0x7fffffffe3b0 ◂— 0x11 AT_CLKTCK</span><br><span class="line">2b:0158│          0x7fffffffe3b8 ◂— 0x64 /* &#x27;d&#x27; */  contains the frequency at which times() increments.</span><br><span class="line">2c:0160│          0x7fffffffe3c0 ◂— 0x3 AT_PHDR</span><br><span class="line">2d:0168│          0x7fffffffe3c8 —▸ 0x400040 ◂— 0x500000006 给脚本文件开头的#!/bin/bash之类的用的， tells the interpreter where to find the program header table in the memory image.</span><br><span class="line">2e:0170│          0x7fffffffe3d0 ◂— 0x4 AT_PHENT </span><br><span class="line">2f:0178│          0x7fffffffe3d8 ◂— 0x38 /* &#x27;8&#x27; */  the size, in bytes, of one entry in the program header table to which the AT_PHDR entry points.</span><br><span class="line">30:0180│          0x7fffffffe3e0 ◂— 0x5 AT_PHNUM</span><br><span class="line">31:0188│          0x7fffffffe3e8 ◂— 9 /* &#x27;\t&#x27; */ the number of entries in the program header table to which the AT_PHDR entry points.</span><br><span class="line">32:0190│          0x7fffffffe3f0 ◂— 0x7 AT_BASE</span><br><span class="line">33:0198│          0x7fffffffe3f8 —▸ 0x7ffff7dd5000 ◂— jg     0x7ffff7dd5047 holds the base address at which the interpreter program was loaded into memory. 这里是ld.so的地址</span><br><span class="line">34:01a0│          0x7fffffffe400 ◂— 0x8 AT_FLAGS</span><br><span class="line">35:01a8│          0x7fffffffe408 ◂— 0x0 一些flag位，但暂时没有用？？</span><br><span class="line">36:01b0│          0x7fffffffe410 ◂— 9 /* &#x27;\t&#x27; */ AT_ENTRY</span><br><span class="line">37:01b8│          0x7fffffffe418 —▸ 0x400470 (_start) ◂— xor    ebp, ebp # the entry point of the application program to which the interpreter program should transfer control.这就是entry_point的地址 </span><br><span class="line">38:01c0│          0x7fffffffe420 ◂— 0xb /* &#x27;\x0b&#x27; */ AT_UID </span><br><span class="line">39:01c8│          0x7fffffffe428 ◂— 0x3e8 the real user id of the process.</span><br><span class="line">3a:01d0│          0x7fffffffe430 ◂— 0xc /* &#x27;\x0c&#x27; */ AT_EUID</span><br><span class="line">3b:01d8│          0x7fffffffe438 ◂— 0x3e8 the effective user id of the process.</span><br><span class="line">3c:01e0│          0x7fffffffe440 ◂— 0xd /* &#x27;\r&#x27; */ AT_GID</span><br><span class="line">3d:01e8│          0x7fffffffe448 ◂— 0x3e8</span><br><span class="line">3e:01f0│          0x7fffffffe450 ◂— 0xe AT_EGID</span><br><span class="line">3f:01f8│          0x7fffffffe458 ◂— 0x3e8</span><br><span class="line">40:0200│          0x7fffffffe460 ◂— 0x17 AT_SECURE </span><br><span class="line">41:0208│          0x7fffffffe468 ◂— 0x0 if the program is in secure mode (for example started with suid). Otherwise zero.</span><br><span class="line">42:0210│          0x7fffffffe470 ◂— 0x19 AT_RANDOM</span><br><span class="line">43:0218│          0x7fffffffe478 —▸ 0x7fffffffe4c9 ◂— 0x3f2d4c26e658aa6f # 16 securely generated</span><br><span class="line">random bytes.</span><br><span class="line">44:0220│          0x7fffffffe480 ◂— 0x1a AT_HWCAP2</span><br><span class="line">45:0228│          0x7fffffffe488 ◂— 0x0 contains the extended hardware feature mask. Currently it is 0, but may contain additional feature bits in the future.</span><br><span class="line">46:0230│          0x7fffffffe490 ◂— 0x1f AT_EXECFN</span><br><span class="line">47:0238│          0x7fffffffe498 —▸ 0x7fffffffefbe ◂— 0x6667682f746e6d2f (&#x27;/mnt/hgf&#x27;) a pointer to the file name of the executed program.</span><br><span class="line">48:0240│          0x7fffffffe4a0 ◂— 0xf AT_PLATFORM</span><br><span class="line">49:0248│          0x7fffffffe4a8 —▸ 0x7fffffffe4d9 ◂— 0x34365f363878 /* &#x27;x86_64&#x27; */ a string containing the platform name.</span><br></pre></td></tr></table></figure>
再往下就是一些数据了。比如保存环境变量的字符串，这里我居然看到了一个环境变量是SHELL=/bin/bash，如果能泄露到这个变量，那连输入/bin/sh也不用愁了，不知道部署到服务器会怎么样。可能到docker里环境变量就全没了吧
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pwndbg&gt; find 0x7fffffffe260, 0x7ffffffff000-1, &quot;sh&quot;</span><br><span class="line">0x7fffffffeda6</span><br><span class="line">1 pattern found.</span><br></pre></td></tr></table></figure> 我随便打开了一个程序，初始时的栈离底部是3488字节。</p>
<h2 id="sysdepsx86_64start.s函数">sysdeps/x86_64/start.S函数</h2>
<p>32位： 首先清空ebp
再调用__libc_start_main，然后就是hlt这个指令，opcode是f4。。。这个难道不是让cpu停止工作的指令吗。。。
_start的函数代码在sysdeps/x86_64/start.S 这个hlt处的代码的注释写道：/*
Crash if somehow `exit' does return. */
也就是说libc_start_main是不会返回的。因为它调用了exit <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">STATIC int</span><br><span class="line">LIBC_START_MAIN (int (*main) (int, char **, char ** MAIN_AUXVEC_DECL),</span><br><span class="line">		 int argc, char **argv,</span><br><span class="line">#ifdef LIBC_START_MAIN_AUXVEC_ARG</span><br><span class="line">		 ElfW(auxv_t) *auxvec,</span><br><span class="line">#endif</span><br><span class="line">		 __typeof (main) init,</span><br><span class="line">		 void (*fini) (void),</span><br><span class="line">		 void (*rtld_fini) (void), void *stack_end)</span><br></pre></td></tr></table></figure>
参数有main函数，argc，argv，[辅助向量数组]，init函数
finit函数，rtld_finit函数，栈末尾指针
所以，当我们在rop中违法调用_start的时候，栈上的第一个数当成了argc，argv也错位了，剩下的参数还好
## csu/libc-start.c __libc_start_main的主要功能：
处理关于setuid、setgid程序的安全问题 启动线程
把fini函数和rtld_fini函数作为参数传递给at_exit调用，使它们在at_exit里被调用，从而完成用户程序和加载器的调用结束之后的清理工作
调用其init参数 调用main函数，并把argc和argv参数、环境变量传递给它
调用exit函数，并将main函数的返回值传递给它</p>
<p>但是这里发现_start函数有一个很诡异的动作就是push rax push
rsp。不知道是不是有意为之。总之栈上在argc上面就多了这两个数据。
其实是因为之前栈进行了对齐，这里push的rax是没有用的数据。而push的rsp是第七个参数stack_end指针，它要被放在栈上。rax就是为了保证对齐的。
接下来call __libc_start_main
栈上多了第一个返回地址。在argc上面一点点的__start+41这样的地址就是第一个返回地址。然而其实它并不会返回。</p>
<p>接下来则是dl去延迟绑定__libc_start_main。这里push了序号2和linkmap。之后进入_dl_runtime_resolve_xsavec它建立起了第一个栈。也就是说，这里保存了一个为0的rbp。所以按照栈帧回溯，最终是要回溯到0的。。。</p>
<p>我调试时发现源码上方写道忽略了fini参数，让fini参数在__cxa_atexit注册</p>
<h2 id="csuelf-init.c-libc_csu_init">csu/elf-init.c (libc_csu_init)</h2>
<p>libc_start_main函数的init参数被设置成了csu_init函数。csu函数先是调用了_init函数，再是循环调用init_array的函数指针，传入的参数和main函数一样
这里的init函数也在程序中 <img src="../imgs/startmaincallgraph.png"
alt="start main call graph" /></p>
<p>在我的ida中，它也叫init_proc。程序极其短，就算是汇编也没有几行。调用完gmon函数就完了，所以它也就是一个设置profiling的函数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sub     rsp, 8          ; _init</span><br><span class="line">mov     rax, cs:__gmon_start___ptr</span><br><span class="line">test    rax, rax</span><br><span class="line">jz      short loc_592</span><br><span class="line">call    rax ; __gmon_start__</span><br><span class="line"></span><br><span class="line">loc_592:</span><br><span class="line">add     rsp, 8</span><br><span class="line">retn</span><br></pre></td></tr></table></figure>
<blockquote>
<p>gmon_start函数。如果它是空的，我们跳过它，不调用它。否则，调用它来设置profiling。该函数调用一个例程开始profiling，并且调用at_exit去调用另一个程序运行,并且在运行结束的时候生成gmon.out。</p>
</blockquote>
<p>回到csu_init，看来还是靠csu，它去调用每个init array <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">push    r15</span><br><span class="line">push    r14</span><br><span class="line">mov     r15, rdx</span><br><span class="line">push    r13</span><br><span class="line">push    r12</span><br><span class="line">lea     r12, __frame_dummy_init_array_entry # init array</span><br><span class="line">push    rbp</span><br><span class="line">lea     rbp, __do_global_dtors_aux_fini_array_entry # finit array的开始地址就是init array 的结束地址！</span><br><span class="line">push    rbx</span><br><span class="line">mov     r13d, edi</span><br><span class="line">mov     r14, rsi</span><br><span class="line">sub     rbp, r12 把init array的结束地址减去开始地址再除以8得到数组大小</span><br><span class="line">sub     rsp, 8</span><br><span class="line">sar     rbp, 3</span><br><span class="line">call    _init_proc # 调用init</span><br><span class="line">test    rbp, rbp</span><br><span class="line">jz      short loc_7B6 # 如果数组大小是0就提前跳转结束</span><br></pre></td></tr></table></figure>
也就是csu_init 就是负责调用每一个init数组的。
那init数组里到底有什么？一般是frame_dummy 为什么csu结尾有那么多的pop?
这是为什么? 难道csu是用汇编写的?? 其实不是, csu的源码如下 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span></span><br><span class="line">__libc_csu_init (<span class="type">int</span> argc, <span class="type">char</span> **argv, <span class="type">char</span> **envp)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">/* For dynamically linked executables the preinit array is executed by</span></span><br><span class="line"><span class="comment">     the dynamic linker (before initializing any shared object).  */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> LIBC_NONSHARED</span></span><br><span class="line">  <span class="comment">/* For static executables, preinit happens right before init.  */</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> size = __preinit_array_end - __preinit_array_start;</span><br><span class="line">    <span class="type">size_t</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">      (*__preinit_array_start [i]) (argc, argv, envp);</span><br><span class="line">  &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> NO_INITFINI</span></span><br><span class="line">  _init ();</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">size_t</span> size = __init_array_end - __init_array_start;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">      (*__init_array_start [i]) (argc, argv, envp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
有pop可能只是编译器用到了太多寄存器去实现这个函数,
所以先保存在栈上吧....</p>
<p>在x86-64-psABI.pdf的Program Loading and Dynamic Linking里面的Dynamic
Linking的最后部分： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">5.2.2 Initialization and Termination Functions</span><br><span class="line">The implementation is responsible for executing the initialization functions specified</span><br><span class="line">by DT_INIT, DT_INIT_ARRAY, and DT_PREINIT_ARRAY entries in</span><br><span class="line">the executable file and shared object files for a process, and the termination (or</span><br><span class="line">finalization) functions specified by DT_FINI and DT_FINI_ARRAY, as specified</span><br><span class="line">by the System V ABI. The user program plays no further part in executing the</span><br><span class="line">initialization and termination functions specified by these dynamic tags.</span><br></pre></td></tr></table></figure> ## frame_dummy &gt;
接下来frame_dummy函数会被调用。其目的是调用__register_frame_info函数，但是，调用frame_dummy是为了给上述函数设置参数。这么做的目的是为了在出错时设置unwinding
stack frames。 但是在我这ida里，它调用的是register_tm_clones
https://stackoverflow.com/questions/41274482/why-does-register-tm-clones-and-deregister-tm-clones-reference-an-address-past-t
原来这两个函数是gcc的函数，其实不是libc的，
https://stackoverflow.com/questions/34966097/what-functions-does-gcc-add-to-the-linux-elf</p>
<p>总之它们是为了提供多线程的原子类操作transaction
memory的，在这里其实就是什么也不干，不会调用_ITM_registerTMCloneTable</p>
<h2 id="返回">返回</h2>
<p>csu_init结束返回</p>
<h2 id="exit函数">exit函数</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Functions that were registered with the atexit or on_exit functions are called in the reverse order of their registration. This mechanism allows your application to specify its own “cleanup” actions to be performed at program termination. Typically, this is used to do things like saving program state information in a file, or unlocking locks in shared data bases.</span><br><span class="line"></span><br><span class="line">All open streams are closed, writing out any buffered output data. See Closing Streams. In addition, temporary files opened with the tmpfile function are removed; see Temporary Files.</span><br><span class="line"></span><br><span class="line">_exit is called, terminating the program. See Termination Internals.</span><br></pre></td></tr></table></figure>
<p>把fini函数和rtld_fini函数作为参数传递给at_exit调用，使它们在at_exit里被调用</p>
<h2 id="其他栈调用规范">其他：栈调用规范</h2>
<p>这个规范里面有关函数调用的部分值得好好读读，下面是之前探究system函数rop调用失败的情况。有机会再补充。</p>
<p>The x86-64 System V ABI guarantees 16-byte stack alignment before a
call, so libc system is allowed to take advantage of that for 16-byte
aligned loads/stores.</p>
<p>找这个标准
https://stackoverflow.com/questions/18133812/where-is-the-x86-64-system-v-abi-documented
找到了 https://github.com/hjl-tools/x86-psABI/tree/hjl/master</p>
<p>下载下来看第18页，里面的图显示了需要在调用函数时对齐16字节。
也就是call的时候的push
rip占了8字节，然后函数开头保存ebp占用8字节，刚好16字节。
所以只要遵循了这个函数调用就可以正常使用system函数了.</p>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>CTF</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>设置最新版本的windows10能够访问的samba服务器</title>
    <url>/2020/samba/</url>
    <content><![CDATA[<h1
id="设置最新版本的windows10能够访问的samba服务器">设置最新版本的windows10能够访问的samba服务器</h1>
<p>目标：需要有只读的公共访问和可读可写的非公共访问</p>
<p>注意的地方是, 第一次访问可能会询问用户名密码, 不代表guest配置失败,
乱输用户名即可通过<code>map to guest = bad user</code>
作为guest。坑惨我了</p>
<span id="more"></span>
<p>现在回头看，总感觉微软只关注了那种公司内使用了域控服务器管理了大量主机，从而可以相互认证的情况，而不关心我们这种笔记本用户的“孤岛”情况，导致<code>"默认"</code>并不是无密码，而是当前用户的账号密码。无密码访问挺不容易的。</p>
<h2 id="关键配置1-加密和签名">关键配置1 加密和签名</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">	server signing = mandatory</span><br><span class="line">#	smb encrypt = mandatory</span><br></pre></td></tr></table></figure>
<p>查看日志发现,
新版本的win10(还是samba服务器??)对没有加密也没有签名的连接会拒绝.
所以需要这两个选项.</p>
<p>加密必须要用户名和密码, 因为加密的会话密钥就是和用户名关联的.
因此为了guest用户, 需要注释掉加密的选项.</p>
<p>来自<a
href="https://serverfault.com/questions/874423/how-to-enable-samba-encryption-and-do-not-require-user-authentication">How
to enable SAMBA encryption and do not require user
authentication</a></p>
<h2 id="关键配置2">关键配置2</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#	min protocol = SMB2</span><br></pre></td></tr></table></figure>
<p>自从win10开始, 默认使用的就是SMB3_11了, 在
<code>启用或关闭windows功能</code> 里开启SMB1/CIFS,
访问时就可能会使用SMB2. 这里调试的时候可以考虑强制改成SMB3.
发现关键问题之后为了兼容性注释掉了</p>
<h2 id="关键配置3">关键配置3</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">guest account = guest</span><br><span class="line">null passwords = yes</span><br></pre></td></tr></table></figure>
<p>默认是<code>guest account = nobody</code>. #TODO 第二个参数
<code>null passwords</code> 不加上, 使用空密码登录的时候就会被拒绝.</p>
<h2 id="关键配置4-ntlm-auth">关键配置4 ntlm auth</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ntlm auth = ntlmv1-permitted</span><br><span class="line">lanman auth = yes</span><br><span class="line">raw NTLMv2 auth = yes</span><br></pre></td></tr></table></figure>
<p>win10可能会使用ntlmv1, 而经过永恒之蓝事件之后samba默认只接受ntlmv2了.
关键的只是第一条, 后面的两条是逛的时候发现的, 加了可以增加兼容性.</p>
<p><a
href="https://bgstack15.wordpress.com/2017/10/01/samba-and-ntlm-for-windows-clients/">Samba
and ntlm for Windows clients</a></p>
<p><a
href="https://www.samba.org/samba/docs/current/man-html/smb.conf.5.html#NTLMAUTH">samba
config ntlmauth</a></p>
<h2 id="关键配置5-passdb-backend">关键配置5 passdb backend</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">passdb backend = smbpasswd:/etc/samba/smbpasswd</span><br><span class="line">smb passwd file = /etc/samba/smbpasswd</span><br></pre></td></tr></table></figure>
<p>新版本默认使用的不是smbpasswd, 默认的数据库位置更不是
<code>/etc/samba/smbpasswd</code>. 新版本似乎用的是
<code>pdbedit</code>?</p>
<p>指定数据库文件位置似乎是用第一行的方式了, 第二行似乎没有效果了?</p>
<h2 id="关键配置6-force-user">关键配置6 force user</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">force user = pi</span><br></pre></td></tr></table></figure>
<p>强制用户了之后上传的文件的所有者就都是一样的了</p>
<h2 id="总体配置">总体配置:</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">    map to guest = Bad User</span><br><span class="line">	server signing = mandatory</span><br><span class="line">#	smb encrypt = mandatory</span><br><span class="line">#	min protocol = SMB2</span><br><span class="line">	passdb backend = smbpasswd:/etc/samba/smbpasswd</span><br><span class="line">	smb passwd file = /etc/samba/smbpasswd</span><br><span class="line">	guest account = guest</span><br><span class="line">	null passwords = yes</span><br><span class="line">	security=user</span><br><span class="line">	ntlm auth = ntlmv1-permitted</span><br><span class="line">	lanman auth = yes</span><br><span class="line">	raw NTLMv2 auth = yes</span><br><span class="line"></span><br><span class="line">[ro]</span><br><span class="line">        # This share allows anonymous (guest) access</span><br><span class="line">        # without authentication!</span><br><span class="line">        path = /home/pi/</span><br><span class="line">#	force user = pi</span><br><span class="line">        read only = yes</span><br><span class="line">        guest ok = yes</span><br><span class="line">#        guest only = yes</span><br><span class="line"></span><br><span class="line">[rw]</span><br><span class="line">	path = /home/pi/</span><br><span class="line">	read only = no</span><br><span class="line">	valid users = pi</span><br><span class="line">	force user = pi</span><br></pre></td></tr></table></figure>
<h2 id="debug方法">debug方法</h2>
<p>windows 清除登录密码首先要凭据管理器删除
接着我任务管理器关闭explorer再启动, 没有用, 只有重启</p>
<p>debug samba 的方法 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service smbd stop</span><br><span class="line">sudo smbd -F -S -d=10</span><br></pre></td></tr></table></figure> 此时再连接, 就可以看到debug信息了.
-d指定的loglevel从1到10. <code>-d=5</code>的时候的log就已经很多了,
<code>-d=3</code> 的时候log不是很多.平时一般先使用 <code>-d=3</code></p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>ucore lab2</title>
    <url>/2020/ucore%20lab2/</url>
    <content><![CDATA[<h1 id="ucore-lab2">ucore lab2</h1>
<p>继续看Intel 80386 Programmer's Reference Manual, 1987 (HTML)
http://www.logix.cz/michal/doc/i386/ 再看Intel® 64 and IA-32
Architectures Software Developer Manuals
https://software.intel.com/en-us/articles/intel-sdm</p>
<span id="more"></span>
<h3 id="内存管理">内存管理</h3>
<p>分段机制启动、分页机制未启动：逻辑地址---&gt;段机制处理---&gt;线性地址=物理地址
分段机制和分页机制都启动：逻辑地址---&gt;段机制处理---&gt;线性地址---&gt;页机制处理---&gt;物理地址</p>
<p>2^32 = 2^10 * 2^10 * 4k
段机制的时候，limit域长20bit，如果以4k为单位，那么就是最大4g
页机制，一个页4k字节，4字节一个页，一个页可以放1k个页表，那就是1k × 4k =
4M的内存，页表目录则是保存1k个页表，正好4M × 1000 = 4G</p>
<p>内存分配有几个阶段
https://chyyuu.gitbooks.io/ucore_os_docs/content/lab2/lab2_3_3_5_4_maping_relations.html</p>
<h3 id="lab2-宏观内存分配">lab2 宏观内存分配</h3>
<p><img src="https://segmentfault.com/img/remote/1460000009450843" />
图片来自https://segmentfault.com/a/1190000009450840 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">memory: 0009fc00, [00000000, 0009fbff], type = 1.</span><br><span class="line">memory: 00000400, [0009fc00, 0009ffff], type = 2.</span><br><span class="line">memory: 00010000, [000f0000, 000fffff], type = 2.</span><br><span class="line">memory: 07ee0000, [00100000, 07fdffff], type = 1.</span><br><span class="line">memory: 00020000, [07fe0000, 07ffffff], type = 2.</span><br><span class="line">memory: 00040000, [fffc0000, ffffffff], type = 2.</span><br></pre></td></tr></table></figure>
可用内存有两块，一个是从00000000 --&gt; 0009fc00 约1M字节
5个十六进制位是20bit，2^10 是1KB,那么2^20就是1M</p>
<p>bios加载bootloader bootblock占512字节 = 0x200.占0x7c00 ---&gt; 0x
7dff bootloader探测的内存信息位于0x8000</p>
<p>内核加载到100000，恰好是第二块可用内存的起始地址
第二块内存有07ee0000，大概126MB多一点 在memlayout.h <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define KMEMSIZE            0x38000000                  // the maximum amount of physical memory</span><br></pre></td></tr></table></figure>
这里限制的物理内存接近1g</p>
<p>然后就是kernel的ELF一路加载下来
其中data段有页目录表（约0x0010b000）和第一个页表
映射0~4MB的首个页表已经填充好。</p>
<p>0x10e000之后就是Page结构体，有32736个，每一个管理4K内存，和内存总量相符。
每一个Page有20字节，所以Pages占了654720字节 =
0x9fd80。占了640K...比想象中大好多
page管理物理内存，数量固定，页表数量可能变化，按需创建。
0x1add80之后就是用来分配的内存了，我们的kernel总共用了0xadd80=712KB。</p>
<p>如果内存再大的话，如果想对应上整个4g空间，那么Page占的空间还可以大32倍。</p>
<h3 id="diff-lab2-with-lab1">diff lab2 with lab1</h3>
<p>https://chyyuu.gitbooks.io/ucore_os_docs/content/lab2/lab2_3_2_2_phymemlab_files.html
简单来说变化不大，变化的部分除了一些不重要的库（cprintf，什么console的命令解析）其他的基本上都要在写lab2的时候碰到，指导书也讲得很详细。
可以先git commit lab1_result 之后再把lab2 覆盖进去看看变化。</p>
<h3 id="内存探测">内存探测</h3>
<p>bootasm.S 添加了有关内存分布的汇编代码
https://chyyuu.gitbooks.io/ucore_os_docs/content/lab2/lab2_3_5_probe_phymem_methods.html</p>
<h3 id="do-while0">do while(0)</h3>
<p>kern/sync/sync.h https://www.jianshu.com/p/99efda8dfec9</p>
<h3 id="kern_entry">kern_entry</h3>
<p>https://segmentfault.com/a/1190000009450840
https://chyyuu.gitbooks.io/ucore_os_docs/content/lab2/lab2_3_3_5_4_maping_relations.html</p>
<h3 id="gdb打印变量不对">gdb打印变量不对</h3>
<p>https://blog.csdn.net/jeff_/article/details/53333154
http://gcc.gnu.org/onlinedocs/gcc/Debugging-Options.html CFLAGS :=
-march=i686 -fno-builtin -fno-PIC -Wall -ggdb -m32 -gstabs -nostdinc
$(DEFS) 修改成 CFLAGS := -march=i686 -fno-builtin -fno-PIC -Wall -ggdb
-m32 -gdwarf-4 -nostdinc $(DEFS) 目测没有什么其他问题 然而
造成了print_stackframe()不能打印出行数了</p>
<h3 id="页表映射到自己">页表映射到自己</h3>
<p>页目录表地址意义：
这个地址开头的线性地址，管理它的页表在哪一个内存页（物理地址）？
页表地址意义：
你这个4M的地址范围空间，里面的这个地址页在哪个物理内存页？</p>
<p>如果把页目录表项当成页表项，也就是说，里面的每一个页，都是一个页表。
把0xFAC（10 bit）映射到自己，也就是说在0xFAC（10
bit），这4M的虚拟地址，之后加上10bit的页表的虚拟地址前10bit作为index，就可以直接访问到页表了。
这就相当于必须要解两次地址，消耗了一次，这样就可以达到只取一次地址的效果了。</p>
<h3 id="invlpg">invlpg</h3>
<p>https://blog.csdn.net/cinmyheart/article/details/39994769 TLB
页表缓冲，我还以为只是页目录表缓冲。。。</p>
<p>问： TLB里面有页目录表吗？
暂时答：因为缓冲一次就缓冲了整个页表，是否命中的判断就是根据对应的页目录表项对不对，所以可能命中缓冲时完全不需要访问页目录表。。。</p>
<blockquote>
<p>5.2.5 Page Translation Cache For greatest efficiency in address
translation, the processor stores the most recently used page-table data
in an on-chip cache. Only if the necessary paging information is not in
the cache must both levels of page tables be referenced.</p>
<p>The existence of the page-translation cache is invisible to
applications programmers but not to systems programmers;
operating-system programmers must flush the cache whenever the page
tables are changed. The page-translation cache can be flushed by either
of two methods:</p>
<ol type="1">
<li><p>By reloading CR3 with a MOV instruction; for example:</p>
<p>MOV CR3, EAX</p></li>
<li><p>By performing a task switch to a TSS that has a different CR3
image than the current TSS. (Refer to Chapter 7 for more information on
task switching.)</p></li>
</ol>
</blockquote>
<p>When to do or not do INVLPG, MOV to CR3 to minimize TLB flushing
https://www.e-learn.cn/content/wangluowenzhang/626493 TLB的那些事儿
https://blog.csdn.net/omnispace/article/details/61415935</p>
<h2 id="缺页">缺页？</h2>
<p>问题：
现在管理的只是物理内存，那谁管理页表的映设关系？如果某虚拟地址没有对应的页怎么办？
还是说lab2其实就没有管这一块？
暂时答：似乎确实不管这回事？虽然有一些维护页表项的函数，但是没怎么被调用。
先写写lab3吧。</p>
<h3 id="mark-收藏夹">mark-收藏夹</h3>
<p>https://www.jianshu.com/p/abbe81dfe016
https://blog.csdn.net/hezxyz/article/details/95764158</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>ucore</tag>
      </tags>
  </entry>
  <entry>
    <title>UAC-bypass 笔记</title>
    <url>/2020/UAC-bypass%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="uac-bypass-笔记">UAC-bypass 笔记</h1>
<p>这是之前课程中调研UAC bypass时自己一些零散的记录。</p>
<span id="more"></span>
<p>[toc]</p>
<h3 id="uac的防御">UAC的防御</h3>
<p>越考虑UAC如何防御，越感觉应该直接把UAC slide拉到最上面</p>
<p>但是确实有几个能绕过Always Notify的方法，这方面确实要防御防御</p>
<ol type="1">
<li>做攻击demo绕WD, 但是我们能检测</li>
<li>dismcore.dll 劫持，直接利用win defender</li>
<li>做一些定向的提前防御手段。做成一个程序。这样反而不用监测了。</li>
</ol>
<p>能讲的：</p>
<ol type="1">
<li><p>比Windows Defender能做得更好的地方。因为讲Win
Defender的也就那一篇文章，研究防御的人还是少的，而我们就是研究了Windows
defender的检测的人。搞搞花式绕过。目前有注册表跟随符号链接和.local的DLL劫持方面能检测绕过WD的攻击。</p></li>
<li><p>FIleless attack 只留在注册表的那个攻击。 这就可能会避开windows
defender的扫描</p>
<p>https://github.com/bytecode77/living-off-the-land</p>
<p>https://enigma0x3.net/2016/08/15/fileless-uac-bypass-using-eventvwr-exe-and-registry-hijacking/</p>
<p>https://www.cybereason.com/blog/fileless-malware
现在的不少最新恶意软件在用</p></li>
<li><p>Living off the land 相关攻击</p></li>
<li><p>搞一些新的攻击检测，Process reimage attack？</p></li>
<li><p>锁屏界面下的键盘启动cmd的后门的检测 <a
href="https://github.com/hak5darren/USB-Rubber-Ducky/wiki/Attacking-Windows-At-The-Logon-Screen,---Gaining-Access-To-CMD-With-System-Privileges.">here</a></p></li>
</ol>
<p>有些部分windows用这种方法修复了，但类似的部分却没修复。</p>
<h3 id="值得讲的大块内容">值得讲的大块内容：</h3>
<p>注册表劫持的提权攻击-一系列。</p>
<p>COM组件提权 新博客内容。 COM组件提权的历史与修复</p>
<p>winsxs和.local机制
https://www.kernelmode.info/forum/viewtopicb857.html?t=3643&amp;start=90#p28579
，高权限移动文件的基础方法，sysprep.exe系列的dll劫持，UAC攻击的起源</p>
<p>wow64log机制, .net的profiling dll</p>
<p>UIAccess的消息注入</p>
<p>Manifest的路径漏洞</p>
<h3 id="资源">资源</h3>
<p>https://www.kernelmode.info/forum/viewtopice732.html?f=11&amp;t=3643
能补充UACMe</p>
<h3 id="uac-绕过的历史">UAC 绕过的历史</h3>
<p>2014年12月：有63种UAC绕过的方法。20%的方法是其他方法的结合。<strong>Win32</strong>/<strong>Simda</strong>.
B 这个之前广泛传播的木马，它利用的<strong>ISecurityEditor</strong>
这个方法让微软限制它只能用于文件后，不仅原来的方法失效了，<em>Application
Verifier</em> dll planting（later this method was also used in some ITW
malware）相关的方法也受到了影响。</p>
<p>微软只在有很大负面新闻的时候和大版本更新的时候才搞搞UAC。</p>
<p><em>Sysprep.exe</em>、<em>inetmgr.exe</em> 通过Manifest
的<strong><em>loadFrom</em></strong> 加固，unfortunately this was
incomplete fix and it took them few more years to finally harden sysprep
from dll hijacking。这里面的故事可以讲讲 TODO</p>
<p>*<strong>Software</strong> 被动了，WD就会报警</p>
<p><em>sdclt.exe</em> *<strong>/kickoffelev*</strong> 的报警</p>
<h3 id="uac-原理">UAC 原理</h3>
<p><a
href="https://docs.microsoft.com/en-us/previous-versions/technet-magazine/dd822916(v=msdn.10)">微软找借口文章1-</a></p>
<p><a
href="https://docs.microsoft.com/en-us/previous-versions/bb757008(v=msdn.10)">How
UAC Works</a></p>
<p><a
href="https://docs.microsoft.com/en-us/previous-versions/bb756945(v=msdn.10)">UAC
Architecture</a></p>
<p>在启动新进程的时候，通过一系列的流程决定是给程序受限令牌还是完整令牌。</p>
<p>通过安全桌面询问用户。</p>
<p>UAC slide UAC提醒级别控制条。AlwaysNotify</p>
<p>默认的级别运行可以看到，允许部分系统设置更改的时候提醒。</p>
<h3 id="uac自动提升总结">UAC自动提升总结</h3>
<p>Security through obscurity？</p>
<p>RPC call is made to AIS 。appinfo.dll逆向得到<a
href="https://medium.com/tenable-techblog/uac-bypass-by-mocking-trusted-directories-24a96675f6e">自动提取的规则</a></p>
<p>阶段1：Manifest内的AutoElevate/<strong>g_lpAutoApproveEXEList</strong></p>
<p>阶段2 微软签名</p>
<p>阶段3 受信任的目录下 C: 、Program Files等</p>
<p>不能把微软的不提权程序通过修改Manifest成为提权程序，因为
如果自己去更改Manifest，会破坏签名</p>
<p>Manifest中的自动提升
https://technet.microsoft.com/en-us/magazine/2009.07.uac.aspx</p>
<ol type="1">
<li>被（微软）签名</li>
<li>位于如 C: 的安全目录<strong>g_lpIncludePFDirs</strong> 中</li>
</ol>
<p><strong>g_lpAutoApproveEXEList</strong> 内部的approve表，直接提权</p>
<p><strong>g_lpIncludePFDirs</strong> 内部的可信文件夹列表</p>
<p>COM Approval List <a
href="https://docs.microsoft.com/en-us/windows/win32/com/the-com-elevation-moniker">elevated
com moniker</a> https://swapcontext.blogspot.com/</p>
<ol type="1">
<li><p>需要首先在HKEY_CLASSES_ROOT {CLSID} = 1 这里启用</p></li>
<li><p>（RS1）HKEY_LOCAL_MACHINENT里面也有。这次更新打掉了不少的Bypass的</p></li>
</ol>
<h2 id="基本操作--explorer-ifileoperation">基本操作- Explorer +
IFileOperation</h2>
<p>注入到Explorer.exe然后使用IFileOperation移动文件。</p>
<p>拓展：<a
href="https://github.com/AV1080p/Mottoin-SecPaper/blob/master/UAC%E6%94%BB%E5%87%BB%E5%89%96%E6%9E%90.md#0x03-%E6%8F%90%E6%9D%83%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C">伪装成explorer.EXE</a></p>
<h2 id="dll劫持">DLL劫持</h2>
<p>https://www.freebuf.com/articles/system/83369.html</p>
<p>程序可以通过DLL实现拓展功能。由于DLL的灵活性，程序可以动态判断是否有某个DLL，如果有则加载，并使用相关的功能，没有则不加载，从而实现插件等功能。但这也为DLL劫持留下了机会。</p>
<p>可能是debug用途的劫持，可能是搜索路径靠前的劫持。</p>
<p>大多数的DLL劫持的方法需要高权限移动文件。这是第一道防线</p>
<p>接下来需要防住劫持的点，这是第二道防线。</p>
<p>最后是一些通用的劫持防御，比如system32文件夹下的可执行文件增加的检测，system32文件夹下的.local劫持检测，这是第三道防线。</p>
<p>通常情况下是不会有这些文件的，而且也不可能有。</p>
<p>然而sysmon只支持检测文件的创建：</p>
<ol type="1">
<li>检测创建文件时的路径里是否含有.exe.local<br />
</li>
<li>ImageLoad里面增加Include，判断路径里是否含.exe.local<br />
</li>
</ol>
<p>缺点：文件剪切粘贴会被绕过、无法检测文件夹创建</p>
<p>winsxs的dot-local为DLL劫持提供了更多的机会</p>
<p><a
href="https://docs.microsoft.com/en-us/windows/win32/dlls/dynamic-link-library-search-order">DLL搜索路径</a></p>
<p>一些可劫持的exe和dll组合的统计：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\windows\System32\sysprep\sysprep.exe</span><br><span class="line">C:\Windows\System32\Sysprep\SHCORE.dll</span><br><span class="line">C:\Windows\System32\Sysprep\OLEACC.DLL</span><br><span class="line"></span><br><span class="line">C:\windows\System32\cliconfg.exe</span><br><span class="line">C:\Windows\System32\NTWDBLIB.DLL</span><br><span class="line"></span><br><span class="line">C:\windows\System32\pwcreator.exe</span><br><span class="line">C:\Windows\System32\vds.exe</span><br><span class="line">C:\Program Files\Common Files\microsoft shared\ink\CRYPTBASE.dll</span><br><span class="line">C:\Program Files\Common Files\microsoft shared\ink\CRYPTSP.dll</span><br><span class="line">C:\Program Files\Common Files\microsoft shared\ink\dwmapi.dll</span><br><span class="line">C:\Program Files\Common Files\microsoft shared\ink\USERENV.dll</span><br><span class="line">C:\Program Files\Common Files\microsoft shared\ink\OLEACC.dll</span><br><span class="line"></span><br><span class="line">C:\windows\System32\cliconfg.exe</span><br><span class="line">C:\Windows\System32\NTWDBLIB.DLL</span><br><span class="line"></span><br><span class="line">C:\windows\System32\pwcreator.exe</span><br><span class="line">C:\Windows\System32\vds.exe</span><br><span class="line">C:\Windows\System32\UReFS.DLL</span><br><span class="line"></span><br><span class="line">C:\windows\ehome\Mcx2Prov.exe</span><br><span class="line">C:\Windows\ehome\CRYPTBASE.dll</span><br><span class="line"></span><br><span class="line">C:\windows\System32\sysprep\sysprep.exe</span><br><span class="line">C:\Windows\System32\sysprep\CRYPTSP.dll</span><br><span class="line">C:\windows\System32\sysprep\CRYPTBASE.dll</span><br><span class="line">C:\Windows\System32\sysprep\RpcRtRemote.dll</span><br><span class="line">C:\Windows\System32\sysprep\UxTheme.dll</span><br><span class="line"></span><br><span class="line">C:\windows\System32\cliconfg.exe</span><br><span class="line">C:\Windows\System32\NTWDBLIB.DLL</span><br></pre></td></tr></table></figure>
<p>首先第一层防线是防止高权限移动文件。</p>
<p>dll劫持一方面攻击者可能发现各种各样的新dll可以劫持，拦截特定路径下的特定dll不太好</p>
<p>需要更好的办法</p>
<h2 id="winsxs">winsxs</h2>
<p>https://www.kernelmode.info/forum/viewtopic2782.html?t=3643&amp;start=110#p28833</p>
<p>https://docs.microsoft.com/zh-cn/archive/blogs/junfeng/dotlocal-local-dll-redirection</p>
<p>http://www.hexacorn.com/blog/2015/01/09/beyond-good-ol-run-key-part-23/</p>
<p>没有manifest就会启用.local，这样的程序不算多</p>
<p>设置注册表可以全局启用</p>
<p>当前目录下的exe名字+.local文件夹会优先成为dll搜索路径</p>
<p>dccw.exe屏幕校准和consent.exe，GoogleUpdate.exe没有menifest会找.local</p>
<h3 id="setprocessmitigationpolicy">SetProcessMitigationPolicy</h3>
<p><a
href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-setprocessmitigationpolicy">API文档</a></p>
<p>ProcessSignaturePolicy 防止加载非微软签名的dll。相关的论文不少。</p>
<p>怎样让系统exe能启动的时候调用？内核态驱动层设置？</p>
<h3 id="已经收集的攻击方法分类">已经收集的攻击方法分类</h3>
<table>
<thead>
<tr>
<th>类型</th>
<th>未修复的攻击</th>
<th>已修复</th>
</tr>
</thead>
<tbody>
<tr>
<td>注册表劫持</td>
<td>#33 #62 #53 #56 #61</td>
<td>#29 #25 #31</td>
</tr>
<tr>
<td>DLL劫持</td>
<td>#22 #23 #30 #37 #39</td>
<td>#18 #26</td>
</tr>
<tr>
<td>COM组件</td>
<td>#38 #59 #41 #43</td>
<td></td>
</tr>
<tr>
<td>UIAccess</td>
<td>#32 #55</td>
<td></td>
</tr>
<tr>
<td>其他</td>
<td>#36 #35 #52 #63</td>
<td></td>
</tr>
<tr>
<td>环境变量</td>
<td>#34 #58</td>
<td></td>
</tr>
</tbody>
</table>
<p>其中也有UAC提醒等级为Always Notify下可以绕过的方法: #26 #34</p>
<h3 id="windows-中的动词机制">Windows 中的动词机制</h3>
<p>https://docs.microsoft.com/en-us/windows/win32/shell/fa-verbs</p>
<p><strong>eg : Print</strong>, <strong>Edit</strong> and <strong>Open
with</strong>.
这个动词对应的恰好是ShellExecute的lpOperation参数。系统拿着动词去注册表找。</p>
<p>HKEY_CLASSES_ROOT
是*HKEY_LOCAL_MACHINE的链接。内保存了各种不同类型的文件拓展对应的打开方式。如HKCR\.py\@
保存的是Python.File。而HKCR\Python.File就保存了打开python文件的命令行。</p>
<p>但是HKEY_LOCAL_MACHINE是系统的总体打开方式。每个用户也有自己的HKEY_Current_User。</p>
<p>用户自己设置的打开方式理论上是覆盖系统的打开方式，就像局部变量的名字覆盖全局变量一样。</p>
<p>一般HKCU里面查不到是正常的，在HKLM里有，但是会去HKCU里面找。</p>
<h2 id="eventvwr.exe的注册表劫持---失效">#25 EventVwr.exe的注册表劫持 -
失效</h2>
<p>发现者：enigma0x3，时间：20160815。https://enigma0x3.net/2016/08/15/fileless-uac-bypass-using-eventvwr-exe-and-registry-hijacking/</p>
<p>sdclt.exe /KickOffElev</p>
<p>**HKCR*</p>
<p>EventVwr.exe redesigned, CompMgmtLauncher.exe autoelevation
removed</p>
<p>https://github.com/turbo/zero2hero</p>
<ul>
<li>Works from: Windows 7 (7600)</li>
<li>Fixed in: Windows 10 RS2 (15031)
<ul>
<li>How: EventVwr.exe redesigned, CompMgmtLauncher.exe autoelevation
removed</li>
</ul></li>
</ul>
<h2 id="sdclt.exe-apppathmethod---fixed">#29 sdclt.exe AppPathMethod -
fixed</h2>
<p>发现者：enigma0x3，时间：20170314。链接：https://enigma0x3.net/2017/03/14/bypassing-uac-using-app-paths/</p>
<p>sdclt.exe（打开跳到控制面板的backup）通过查看低权限的注册表<strong>HKCU:Paths.exe</strong>
启动控制面板。</p>
<ul>
<li>Works from: Windows 10 TH1 (10240)</li>
<li>Fixed in: Windows 10 RS3 (16215)
<ul>
<li>How: Shell API update</li>
</ul></li>
</ul>
<h2 id="sdclt.exe-isolatedcommandmethod---fixed">#31 sdclt.exe
IsolatedCommandMethod - fixed</h2>
<p>发现者：enigma0x3，时间：20170317。https://enigma0x3.net/2017/03/17/fileless-uac-bypass-using-sdclt-exe/</p>
<p>sdclt.exe /KickOffElev</p>
<ul>
<li>Works from: Windows 10 TH1 (10240)</li>
<li>Fixed in: Windows 10 RS4 (17025)
<ul>
<li>How: Shell API / Windows components update</li>
</ul></li>
</ul>
<h2 id="注册表劫持">#33（#62） 注册表劫持</h2>
<p>有点像infamous Enigma0x3 "<strong><em>mscfile fileless</em></strong>"
bypass，但利用的是不同的注册表和不同的程序。widely used ITW by
malware。</p>
<p>https://cqureacademy.com/cqure-labs/cqlabs-how-uac-bypass-methods-really-work-by-adrian-denkiewicz</p>
<p>fodhelper.exe computerdefaults.exe 加载注册表中的 exe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">New-Item &quot;HKCU:\Software\Classes\ms-settings\Shell\Open\command&quot; -Force</span><br><span class="line">New-ItemProperty -Path &quot;HKCU:\Software\Classes\ms-settings\Shell\Open\command&quot; -Name &quot;DelegateExecute&quot; -Value &quot;&quot; -Force</span><br><span class="line">Set-ItemProperty -Path &quot;HKCU:\Software\Classes\ms-settings\Shell\Open\command&quot; -Name &quot;(default)&quot; -Value cmd.exe -Force</span><br><span class="line">Start-Process &quot;C:\Windows\System32\fodhelper.exe&quot;</span><br><span class="line">Remove-Item &quot;HKCU:\Software\Classes\ms-settings\&quot; -Recurse -Force</span><br></pre></td></tr></table></figure>
<p>https://devblogs.microsoft.com/oldnewthing/?p=14623</p>
<p>其中#62就只是computerdefaults.exe触发</p>
<p>WD的检测与绕过：</p>
<ul>
<li>符号链接写入</li>
</ul>
<h2 id="注册表劫持-1">#53 注册表劫持</h2>
<p>Target key here is
<strong><em>HKCU</em></strong>\<strong><em>Software\</em></strong> <span
class="citation" data-cites="*Default">@*Default</span>* value
(+<em>DeletegateExecute</em> as usual) and trigger is
<em>sdclt.exe</em>。</p>
<p>WD会检测。修改那个@default就会触发。</p>
<p>绕过方法同上。</p>
<h2 id="注册表劫持-2">#56 注册表劫持</h2>
<p>Target key here is
<em><strong>HKCU82a6gwre4fdg3bt635tn5ctqjf8msdd2</strong> <span
class="citation" data-cites="*Default">@*Default</span></em> value
(+<em>DeletegateExecute</em> as usual) and trigger is
<em>wsreset.exe</em></p>
<p>WD会检测。修改那个@default就会触发。</p>
<p>绕过方法：准备好注册表相关的结构，再重命名过去。</p>
<h2 id="注册表劫持-3">#61 注册表劫持</h2>
<p>Target key here is
<strong><em>HKCU*</em>Launcher.SystemSettings</strong> <span
class="citation" data-cites="*Default">@*Default</span>* value
(+<em>DeletegateExecute</em> as usual) and trigger is <em>slui.exe</em>
which is started with <em><strong>runas*</strong> verb</em>.*</p>
<p>WD会检测。修改那个@default就会触发。</p>
<h2 id="com组件的环境变量劫持-alwaysnofity-ok">#58 COM组件的环境变量劫持
AlwaysNofity ok</h2>
<p><strong>EditionUpgradeManager</strong>
这个提权的接口里的<em>AcquireModernLicenseWithPreviousId</em>
函数会通过%windir%去组合路径调用<em>Clipup.exe</em>。设置windir环境变量去劫持。</p>
<p>Cheap and easy fix - get rid of environment variables from Win95 era
and build a proper path to <em>clipup.exe</em> by using, surprise -
surprise! <strong><em>GetSystemDirectory</em></strong>.</p>
<h2 id="diskcleanup计划任务---unfixed---alwaysnofity-ok">#34
DiskCleanup计划任务 - unfixed - AlwaysNofity ok</h2>
<p>20170515 <a href="https://twitter.com/tiraniddo">James Forshaw</a>
https://www.tiraniddo.dev/2017/05/exploiting-environment-variables-in.html</p>
<p>https://cqureacademy.com/cqure-labs/cqlabs-how-uac-bypass-methods-really-work-by-adrian-denkiewicz</p>
<p>*Microsoft会启动 %windir%.exe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">New-ItemProperty &quot;HKCU:\Environment&quot; -Name &quot;windir&quot; -Value &quot;cmd.exe /k cmd.exe&quot; -PropertyType String -Force</span><br><span class="line">schtasks.exe /Run /TN \Microsoft\Windows\DiskCleanup\SilentCleanup /I</span><br></pre></td></tr></table></figure>
<p>WD的检测：<em>schtaks.exe</em> 的命令行是否包含“Microsoft”，有则警报
（<strong>Behavior:Win32/SilentCleanupUACBypass</strong>）</p>
<p>检查<strong>* 子串（</strong><em>PossibleSchedTasksUACBypass</em>**
）</p>
<p>绕过：不用schtaks，用<strong><em>ITaskService</em></strong>,
<strong><em>ITaskFolder</em></strong> and
<strong><em>IRegisteredTask</em></strong> 接口自己去启动</p>
<p>真正应该：检测windir 环境变量改变。</p>
<p>windows中的环境变量直接反映在注册表里。</p>
<h2 id="method-18--fixed">Method #18 -fixed</h2>
<p>参考资料：</p>
<p>https://www.reddit.com/r/lowlevel/comments/4lktyw/sxs_backdoor_and_story_of_windows_uac_ridiculous/</p>
<p>https://www.kernelmode.info/forum/viewtopicb857.html?t=3643&amp;start=90#p28579</p>
<p>背景，自从SxS+sysprep.exe的劫持，已经烂大街，微软拿出了自己的后门进行修复：</p>
<p><strong>malware</strong>
friendly的微软对应用的垃圾Manifest文件的undocumented 项</p>
<p><code>&lt;file loadFrom="%systemroot%\system32\NAME.dll" name="NAME.dll" /&gt;</code></p>
<p>只要找到没有manifest的文件，通过外置manifest文件的方法，<code>ExeName.exe.manifest</code>
通过cryptbase.dll依然在sysprep文件夹内做dll劫持。</p>
<p><code>&lt;file loadFrom="%systemroot%\system32\sysprep\cryptbase.DLL" name="cryptbase.DLL"      /&gt;</code></p>
<p>当前该方法已经失效，因为外置manifest文件不再支持这个项了。</p>
<h2 id="section">#22</h2>
<p><em>comctrl32.dll</em> 植入到system32 （利用.local?）
劫持<em>consent.exe</em> 。</p>
<p>WD只检测了子文件夹创建，和文件移动到对应的文件夹内（移动？）。不移动，直接写入文件夹可以绕过？</p>
<p>首先通过<strong><em>IFileOperation</em></strong> with
<strong>ISecurityEditor</strong> 创建文件夹并降权？</p>
<p>创建好对应名字的文件再降权再写入。</p>
<p>创建好其他名字的文件后再降权？再重命名，写入</p>
<p>微软应该这样修复： process mitigation policy 的
<strong>ProcessSignaturePolicy</strong> 设置为只有微软签名的</p>
<p>ProcessSignaturePolicy restrict image loading to those images that
are either signed by Microsoft, by the Windows Store, or by Microsoft,
the Windows Store and the Windows Hardware Quality Labs</p>
<h2 id="pkgmgr-dism劫持">#23 PkgMgr-Dism劫持</h2>
<p>https://cqureacademy.com/cqure-labs/cqlabs-how-uac-bypass-methods-really-work-by-adrian-denkiewicz</p>
<p>+博客https://swapcontext.blogspot.com/</p>
<p><em>PkgMgr</em>
被放弃支持了，但还在自动提权的exe列表（g_lpAutoApproveEXEList）里，是dism的启动器。</p>
<p>dism搜索<strong><em>dismcore.dll</em></strong>
的时候会先搜索system32文件夹，再搜索当前路径，然后找到。</p>
<ol type="1">
<li><p>创建<em>oemsetup.xml</em>文件，用来调用pkgmgr程序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;</span><br><span class="line">&lt;unattend xmlns=&quot;urn:schemas-microsoft-com:unattend&quot;&gt;</span><br><span class="line">&lt;servicing&gt;</span><br><span class="line">&lt;package action=&quot;install&quot;&gt;</span><br><span class="line">&lt;assemblyIdentity name=&quot;Package_1_for_KB929761&quot; version=&quot;6.0.1.1&quot; language=&quot;neutral&quot; processorArchitecture=&quot;x86&quot; publicKeyToken=&quot;31bf3856ad364e35&quot;/&gt;</span><br><span class="line">&lt;source location=&quot;%configsetroot%\Windows6.0-KB929761-x86.CAB&quot; /&gt;</span><br><span class="line">&lt;/package&gt;</span><br><span class="line">&lt;/servicing&gt;</span><br><span class="line">&lt;/unattend&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>IFileOperation 移动DismCore.dll到<em>C:</em>.</p></li>
<li><p><code>"C:\WINDOWS\system32\pkgmgr.exe" /n:C:\Users\&lt;user&gt;\AppData\Local\Temp\oemsetup.xml</code></p>
<p>随后pkgmgr调用<code>"C:\WINDOWS\system32\dism.exe" /online /norestart /apply-unattend:"C:\Users\&lt;user&gt;\AppData\Local\Temp\oemsetup.xml"</code></p></li>
</ol>
<p>WD叫<strong><em>Win32/Disemer</em></strong>，首先会检测system32下的
DismCore.dll（平常系统不可能发生），其次会检测<em>pkgmgr.exe</em>
的参数里特定的Token</p>
<p>绕过方法：通过其他的dll去劫持。pkgmgr的参数（xml文件）也不用加什么？？因为没有意义。</p>
<h2 id="wow64-subsystem-logger-dll">#30 Wow64 subsystem logger dll</h2>
<p>subsystem logger dll是无文档内部的debug工具，十年前<a
href="https://lhc645.wordpress.com/tag/wow64log-dll/">lhc645</a>就发现了。wow64log.dll
源码骨架都有。</p>
<p>每个wow64 application（32位）启动的时候都会加载它（64位），</p>
<p>This method has a lot of disadvantages and not that much room to
maneuver in case of active counteraction from WD.</p>
<p>UACMe首先移植非native的wow64log.dll到system32，之后相关程序启动之后就会崩溃，然后启动<em>WerFault</em>
实例，此时wow64log.dll才执行payload。</p>
<p>最好能默认关闭这个debug功能。</p>
<h2 id="dismhost.exe劫持---fixed">#26 dismhost.exe劫持 - fixed</h2>
<p>发现者：enigma0x3，时间：20160722。https://enigma0x3.net/2016/07/22/bypassing-uac-on-windows-10-using-disk-cleanup/</p>
<p>cleanmgr.exe
系统的计划任务中的磁盘清理程序，是提权的计划任务。它运行的时候会把dismhost.exe和一些其他dll拷到%temp%.exe再运行。通过复制LogProvider.dll劫持。需要一直监控着temp文件夹然后在他们运行之前拷好。有点算条件竞争吧。</p>
<ul>
<li><p>Works from: Windows 10 TH1 (10240)</p></li>
<li><p>AlwaysNotify compatible</p></li>
<li><p>Fixed in: Windows 10 RS2 (15031)</p>
<ul>
<li>How: File security permissions altered</li>
</ul></li>
</ul>
<h2 id="section-1">#36</h2>
<p>infamous <em>SandboxEscaper</em>
利用Wusa在当前盘符根目录下创建的临时目录的安全性不对，利用NTFS reparse
point feature。条件竞争设置reparse
point到那个目录上就可以重定向写入到其他地方。</p>
<h2 id="section-2">#37</h2>
<p>使用#35去高权限移动文件。</p>
<p>使用GdiPlus with target set to <em>DCCW.exe</em>
进行dotLocal的dll劫持。</p>
<p>dccw.exe.local的防御</p>
<h2 id="没看懂">#38 没看懂</h2>
<p>This method uses <em>appinfo</em> command line parsing spoofing. This
requires talking to <em>appinfo</em> via <em>RPC</em> as Windows Shell
always build correct command line request when used
<em>ShellExecute(Ex)</em>. This can be achieved through
<strong><em>AicLaunchAdminProcess</em></strong> hook or by direct
<em>RPC</em> call. You have to prepare your <em>MMC</em> snap-in and
embed in it <em>Shockwave Flash Object</em> which will execute supplied
<em>HTML</em> script located somewhere on disk. This <em>HTML</em> code
will eventually run your payload through <em>ExecuteShellCommand</em>
method.</p>
<h2 id="section-3">#59</h2>
<p><em>appinfo</em> direct talking 的debug
object去提权，非常复杂。和#38利用的原理不同</p>
<h2 id="c-profile---unfixed">#39 C# profile - unfixed</h2>
<p>https://www.freebuf.com/vuls/183914.html</p>
<p>https://offsec.almond.consulting/UAC-bypass-dotnet.html</p>
<p>https://3gstudent.github.io/3gstudent.github.io/Use-CLR-to-bypass-UAC/</p>
<p>双击任一msc文件，通过Procmon监控发现最终运行的都是mmc.exe文件</p>
<p>CLR(Common Language
Runtime)，是微软为他们的.NET的虚拟机所选用的名称</p>
<p>CLR会先检查环境变量中COR_ENABLE_PROFILING是否为1，若检查通过，则根据.NET版本不同，查找DLL位置的方法也不同，对于低于4.0的则去注册表中查找CLSID或ProgID项，找到其指定的dll文件路径。从.NET4.0版本开始则先查找环境变量COR_PROFILER_PATH是否指定dll文件路径，没有再去注册表中查找对应的CLSID项。所以这里我们就不设置COR_PROFILER_PATH了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">COR_ENABLE_PROFILING = 1</span><br><span class="line"></span><br><span class="line">COR_PROFILER=&#123;CLSIDor ProgID&#125;</span><br></pre></td></tr></table></figure>
<p>找到HKEY_CURRENT_USER，分别添加以下新项：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;11111111-1111-1111-1111-111111111111&#125;和InprocServer32</span><br></pre></td></tr></table></figure>
<p>该dll中只负责运行cmd.exe，并退出主进程：现在我们尝试运行gpedit.msc，看能否运行管理员权限的cmd程序：</p>
<p>WD：无法检测</p>
<p>检测方法：检测环境变量。</p>
<p>真正的修复：mmc.exe在高权限允许时应该不允许加载非微软签名的程序。</p>
<h2 id="icmluautil">#41 ICMLuaUtil</h2>
<p>应该直接从COMAutoApprovalList移除。</p>
<h2 id="icolordataproxy">#43 IColorDataProxy</h2>
<p>先用#41的任意注册表写，写入<strong>HKLMNT* <span class="citation"
data-cites="*DisplayCalibrator">@*DisplayCalibrator</span>* 然后调用
</strong>IColorDataProxy** 通过高完整度<strong>ShellExecuteEx</strong>
运行指定的程序。</p>
<h2 id="appinfo里利用getlongpathname缺陷">#52
appinfo里利用GetLongPathName缺陷</h2>
<p>恶意软件非常喜欢的方法。简单。Win32 API path conversion</p>
<p>特殊方法创建一个后面带空格的"C:"目录，然后在appinfo.dll里面UAC检查的时候经过*<strong>GetLongPathName*</strong>
这个API会自作主张修复这个不合法的路径，导致之后比对的时候成为可信路径。</p>
<p>然后从system32里面拷可信exe出来做dll劫持。</p>
<p>UACME的作者改进了，增加了reparse points。</p>
<h2 id="osk的劫持uiaccess消息注入">#32 osk的劫持+UIAccess消息注入</h2>
<p>复制osk.exe到<code>%ProgramFiles%\Windows Media Player</code>
文件夹，然后通过该文件夹下的<em>duser.dll</em> or
<em>osksupport.dll</em>
进行劫持，最终得到Medium+的带UIAccess的权限。可以通过MessageHook注入高权限进程。UacMe注入了<em>eventvwr.exe</em>
。</p>
<p>微软应该：</p>
<ol type="1">
<li>加固Manifest的LoadFrom项</li>
<li>禁止<em>UIAccess</em> 权限的进程从Medium+注入到High</li>
</ol>
<h2 id="method-55">Method #55</h2>
<p>有意思的攻击，虽然是自动化的，但是涉及到了UI的操作，会被用户看到。</p>
<blockquote>
<p>参考资料：</p>
<p>https://github.com/rootm0s/UUB</p>
<p>https://swapcontext.blogspot.com/</p>
<p>https://cqureacademy.com/cqure-labs/cqlabs-how-uac-bypass-methods-really-work-by-adrian-denkiewicz</p>
</blockquote>
<p>获取UIAccess权限 -&gt; 利用它提权。</p>
<h4 id="阶段一-uipi-token窃取">阶段一 UIPI token窃取</h4>
<p>从msra.exe/osk.exe(on-screen keyboard)
窃取有UIAccess标志的令牌，然后修改完整度从Medium+到Medium，再启动自己的程序，这样就能操作高完整度的UI窗口了。</p>
<h4 id="阶段二-gui操作">阶段二 GUI操作</h4>
<p>启动msconfig打开cmd，cmd输入命令任意执行。</p>
<h2 id="section-4">#63</h2>
<p>相对较新的方法。dll injection to the Windows <em>Native Image Cache
(NIC)</em></p>
<h2 id="always-notify下可以绕过的方法">Always
Notify下可以绕过的方法</h2>
<h2 id="结语">结语</h2>
<p>While maybe not that sophisticated and complicated UAC is still part
of Windows and integrated to the system. It is not about OpenDialog. The
better you understand Windows internals the better you understand how
UAC works and it weakness (and the more you laugh at yet another idiot
with OpenDialog). Aside of this some of these bypasses are usually
accompaned by various different mechanics, algorithms and internals that
need to be researched.</p>
<p>There is a still a lot of possible real UAC bypasses undiscovered
since this system mechanics is entirely broken in many ways and these
methods are just waiting to be exploited.</p>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows权限与UAC</title>
    <url>/2020/windows%E6%9D%83%E9%99%90/</url>
    <content><![CDATA[<h1 id="windows权限与uac">Windows权限与UAC</h1>
<p>这篇文章是课程中被逼无奈（被一门2学分的课的老师疯狂压榨时间）调研Windows相关的攻击，UAC绕过中总结的一些笔记</p>
<span id="more"></span>
<h2 id="综述">综述</h2>
<p>在windows中有两种访问控制，首先是强制完整性控制，它蕴含在SACL中。其次是自主访问控制DACL。</p>
<p>SACL原本的用途是类似自主访问控制一样自主控制系统日志，但完整性控制加入到了它的范围内。</p>
<p>UAC提权不仅完整性从medium到了high，而且多了特权。特权是另外的资源。</p>
<p>UAC绕过的例外方法：提升的COM名字对象，UIAccess</p>
<p>从admin到system的方法：令牌窃取。</p>
<h3 id="强制完整性控制mic">强制完整性控制（MIC）</h3>
<p>windows 首先是自主访问控制, 只有很简单的强制访问控制,
在原本只是打印日志的SACL的完整性字段里. 实现的方式是"可上读, 可下写".
为了保证完整性, 只需要严格控制写权限. TODO: 能不能下读.</p>
<p>保护完整性的强制访问控制:
低级的不可以（发送消息）影响高级的程序。</p>
<p>与之对应的是保护机密性的强制访问控制：低级的可以发消息给高级程序，而高级程序无法发消息给低级程序（泄露机密。）</p>
<p>windows中的完整性等级：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SeUntrustedMandatorySid</span><br><span class="line">SeLowMandatorySid</span><br><span class="line">SeMediumMandatorySid</span><br><span class="line">SeHighMandatorySid</span><br><span class="line">SeSystemMandatorySid</span><br></pre></td></tr></table></figure>
<p>主体的缺省完整性级别是SeUntrustedMandatorySid，而客体的缺省完整性级别是SeMediumMandatorySid</p>
<blockquote>
<p>进程完整性级别是为了保证不同标签的进程（TOKEN)
和对象（SACL)之间的访问安全
https://zh.wikipedia.org/wiki/%E5%BC%BA%E5%88%B6%E5%AE%8C%E6%95%B4%E6%80%A7%E6%8E%A7%E5%88%B6</p>
<p><a
href="https://en.wikipedia.org/wiki/Security_Identifier">SID</a></p>
<p>可以看到标准用户和经过权限提升的UAC用户信息的差别。用户名项中组信息和sid均相同，区别就是UAC用户是经过权限提升的，最终体现在权限上的不同如下：</p>
<p>1.组信息项中主要是Integrity levels
(IL)【进程完整性级别不同】。标准用户是Medium Mandatory
Level，UAC用户是High Mandatory Level,它包括Untrust， Low， Medium，
Hight， System等，
级别越低，权限也就越低。我们可以通过GetTokenInformation的TokenIntegrityLevel来进行查询。
2.体现在Privilege中的就是UAC用户拥有很多Privilege，比如最常用的SeDebugPrivilege
。 注释： 进程完整性级别是为了保证不同标签的进程（TOKEN)
和对象（SACL)之间的访问安全，如果当前进程的TOKEN 是Low Mandatory Level，
它就不能修改具有Medium Mandatory
Level的对象，即使我们对象的DACL赋予完全读写的权限。当每个进程打开对象，
我们会进行SACL和DACL检查，这个检查通过核心态函数 SeAccessCheck .
只有当前进程TOKEN的　完整性标签　高于或者等于　对象的完整性标，　我们才会进一步进行
DACL 检查。如果完整性标签验证通不过。
即使DACL给予再高权限都无济于事。</p>
</blockquote>
<h3 id="dacl-自主访问控制列表">DACL 自主访问控制列表</h3>
<p>文件/注册表方面自然是还有自主访问控制. 进程没想到!!和文件一样的,
有安全描述符 主体是访问令牌. 每个进程都有一个基本令牌 (Primary
Token)，可以被进程中的每个线程所共享, 后面线程可以获得其他令牌.
令牌里有用户sid, 组sid, 受限sid, 特权, 身份模拟级别, 完整度级别.
客体是对象: 文件/注册表/进程. 客体关联了安全描述符,
安全描述符包括所有者SID, 组SID, DACL, SACL(日志)</p>
<p>“属性” =&gt; “安全”,
“权限”选项卡就是DACL，”审核”选项卡是SACL，“所有者”是Owner、Group。</p>
<p>每个DACL内有很多ACE, 访问控制表项, 可以接受也可以拒绝, 先找到的生效.
因此(有时?)一般拒绝的放在接受的前面.</p>
<p>impersonation 身份模拟 传输层, 被rpc使用的,
服务端可以使用客户端的令牌.</p>
<p>令牌里的权限有的没有enable, 要单独开启 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+0x000 Present          : Uint8B</span><br><span class="line">+0x008 Enabled          : Uint8B</span><br><span class="line">+0x010 EnabledByDefault : Uint8B</span><br></pre></td></tr></table></figure>
特权Privilege在访问某个具体的安全对象时并没有作用，Privilege是表示进程是否能够进行特定的系统操作，如关闭系统、修改系统时间、加载设备驱动等。</p>
<h3 id="uac">UAC</h3>
<p>当用户登录Windows时，操作系统会为用户生成一对初始令牌，分别是代表着用户所拥有的全部权限的完整版本令牌(即管理员权限令牌)，以及被限制管理员权限后的普通令牌，二者互为关联令牌;此后，代表用户的进程所使用的令牌都是由普通令牌继承而来，用来进行常规的、非敏感的操作;当用户需要进行一些需要管理员权限的操作时，比如安装软件、修改重要的系统设置时，都会通过弹出提权对话框的形式提示用户面临的风险，征求用户的同意，一旦用户同意，将会切换到当前普通令牌关联的管理员权限令牌，来进行敏感操作。通过这种与用户交互的方式，避免一些恶意程序在后台稍稍执行敏感操作。
<a
href="http://blog.nsfocus.net/analysis-windows-access-authority-inspection-mechanism/">来自</a></p>
<blockquote>
<p>Access Token：是一个包含了登陆会话安全信息的 Windows
软件对象，用于指名一个用户以及他所在组以及相应的特权。 UAC
Token：定义了Windows Vista
用户在UAC支持开启的时候的默认交互式登陆特权。一个 UAC Token
定义了最小的运行特权。 Full
Token：给账户提供了最大的经过授权的特权。Full Token
实际上是由该用户隶属于的用户组决定的。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">通过whoami -all查看当前用户所拥有的Privilege。</span><br></pre></td></tr></table></figure>
<h3 id="其他">其他</h3>
<p>部分受保护进程难以获得debug, 注入等权限.
保护进程的Protection成员不为0. 两种保护类型：Protected
Process(PP)，Protected Process Lite(PPL).
对于Signer为PsProtectedSignerWindows(5)和PsProtectedSignerTcb(6)的保护进程,
其Type和Signer信息会被抽取出来, 组合成sid,
保存到基本令牌中的TrustLevelSid成员中</p>
<p>通过创建受限令牌，可以获得一个普通令牌所有拥有的权限集合的一个子集，用来进行一些低权限操作，降低安全风险。</p>
<p><a
href="http://www.youngroe.com/2015/08/14/Windows/Windows-Permissions-Privilege/">权限编程需要注意的</a>
<a
href="http://www.cppblog.com/weiym/archive/2013/08/25/202751.html?opt=admin">权限编程2</a></p>
<h2
id="用户界面特权隔离-user-interface-privilege-isolation-uipi">用户界面特权隔离
User Interface Privilege Isolation, UIPI</h2>
<p>通过结合强制完整性控制，用户界面特权隔离阻止较低等完整性级别（Integrity
level）的进程向较高等完整性级别进程的窗口发送消息或者安装钩子，但也有一些消息不被阻止。</p>
<p><a
href="https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/user-account-control-allow-uiaccess-applications-to-prompt-for-elevation-without-using-the-secure-desktop">UIAccess</a>
选项The ability to bypass UIPI restrictions across privilege levels is
available for UI automation programs by using UIAccess.
但是必须签名并且安装在指定地点.</p>
<p>UAC level: asInvoker 不询问权限, 但是用户可以右键以管理员权限运行.
highestAvailable时如果用户在admin用户组则和requireAdministrator一样,
必须以管理员权限运行.</p>
<blockquote>
<p>A lower privilege process cannot:</p>
</blockquote>
<blockquote>
<ul>
<li>Perform a window handle validation of higher process privilege.</li>
<li>SendMessage or PostMessage to higher privilege application windows.
These application programming interfaces (APIs) return success but
silently drop the window message.</li>
<li>Use thread hooks to attach to a higher privilege process.</li>
<li>Use Journal hooks to monitor a higher privilege process.</li>
<li>Perform dynamic link library (DLL)–injection to a higher privilege
process.</li>
</ul>
</blockquote>
<h2 id="键盘监控的思路">键盘监控的思路</h2>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 53%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr>
<th>API</th>
<th>适用范围</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>GetAsyncKeyState</td>
<td></td>
<td>每次获取单个按键的状态, 轮询每个键状态, 效率略低</td>
</tr>
<tr>
<td>GetKeyboardState</td>
<td></td>
<td>一次获取所有的键的状态, 和消息队列相关</td>
</tr>
<tr>
<td>SetWindowsHookEx 指定键盘</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="setwindowshookex">SetWindowsHookEx</h3>
<p>在回调函数中，我们将接收KeyboardProc的wParam中的虚拟键码和LowLevelKeyboardProc的KBDLLHOOKSTRUCT.vkCode（wParam指向KBDLLHOOKSTRUCT）。</p>
<p>如果m_ThreadId =
0，则消息钩子是全局消息钩子。针对全局消息钩子，你必须将回调函数置于dll中，并且需要编写2个dll来分别处理x86/x64进程。</p>
<p>针对底层键盘钩子，SetWindowsHookEx的HMod参数可以为NULL或者本进程加载的模块（我测试了user32，ntdll）。</p>
<p>WH_KEYBOARD_LL不需要dll中的回调函数，并且能适应x86/x64进程。</p>
<p>WH_KEYBOARD需要两个版本的dll，分别处理x86/x64。但是如果使用x86版本的全局消息钩子，所有的x64线程仍被标记为“hooked”，并且系统在钩子应用上下文执行钩子。类似的，如果是x64，所有的32位的进程将使用x64钩子应用的回调函数。这就是为什么安装钩子的线程必须要有一个消息循环。</p>
<p>hook是在整个桌面环境(desktop)内的. uac是safe desktop,
另外一个桌面</p>
<p><a href="https://www.anquanke.com/post/id/86403">来自</a> <a
href="https://securelist.com/keyloggers-implementing-keyloggers-in-windows-part-two/36358/">专业文章</a></p>
<p>已知设置钩子是不能跨越完整度保护的.
猜测至少需要最高的完整度级别才能设置全局钩子</p>
<blockquote>
<p>"Process isolation provides a way to extend the authorization model
to common extension points for inter-process communication. For example,
if an application running at medium integrity were to register a hook to
process Windows messages, this hook would not be active in a process
running at the high integrity level."</p>
</blockquote>
<p>所以可能可以安装但是其实不是全局?</p>
<h3 id="subsystem-console">subsystem: console</h3>
<p>是一个过时的东西, 直接用subsystem: windows?? <a
href="https://www.devever.net/~hl/win32con">看这</a></p>
<h2 id="自启动技术">自启动技术</h2>
<p><a href="https://www.jianshu.com/p/cf01fee50fb4">自启动技术</a></p>
<h2 id="bypass-uac">bypass uac</h2>
<p><a
href="https://cqureacademy.com/cqure-labs/cqlabs-how-uac-bypass-methods-really-work-by-adrian-denkiewicz">概述</a></p>
<p>这里研究的是COM接口绕过 <a
href="https://y4er.com/post/bypassuac-with-icmluautil/">详述</a></p>
<h2 id="提权">提权</h2>
<ol type="1">
<li>权限窃取</li>
<li>使用服务的impersonation 真正的关键是分析其中的权限问题</li>
</ol>
<p>首先是bypass UAC, 得到SeDebugPrivilege,
然后就可以直接用窃取的方式得到System 没有UAC时特权很少,
完整度级别为Medium, 过了UAC就是High</p>
<p>现在就看创建服务了. 如果创建服务获取system不需要高完整度, 那就神了.
否则还是要bypass uac, 那还不如上面的方法.
目前我猜测大概是要高完整度的.</p>
<h2 id="远程线程注入">远程线程注入</h2>
<p>远程线程注入首当其冲就是权限问题, 需要debug权限?? !! meterpreter
怎么migrate的</p>
<p>打开一个同级别的进程, Medium的完整度的,
OpenProcess的时候指定什么权限??</p>
<h2
id="raw_input方法的主函数的消息循环">raw_input方法的主函数的消息循环</h2>
<p>发现主函数其实消息非常少... 平时只有一个消息,
开了hook之后每按下和松开都有一个事件. 理解为是winmain的消息传过去的吗...
或者要先给到这边, 才能给到那边winProc
发现如果没有getMessage的循环，无论是Hook的keylog还是rawInput的keylog都不行。创建一个子进程执行而不是在dllmain里面执行好像没什么区别？？？
notepad.exe正常使用？？
我的问题是，notepad.exe这种桌面程序难道不是应该winmain里有自己的Getmessage吗。。。为什么即使是注入也需要自己有getMessage的循环？？</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>换电脑-2021</title>
    <url>/2021/%E6%8D%A2%E7%94%B5%E8%84%91-2021/</url>
    <content><![CDATA[<h1 id="换电脑-2021">换电脑-2021</h1>
<p>电脑终于换上5800u了，这里记录一些换电脑系统重装与迁移的过程。</p>
<p>早就意识到QQ使用了驱动进行自我保护，这几天又出现了读取浏览记录的事件，我就感到我的电脑如果腾讯想干什么我是拦不住的。从此就计划新电脑一定要24小时跑一个虚拟机，用来装这些流氓软件。</p>
<p>具体的方案是家庭版安装hyper-v，然后外部通过windows远程桌面连进去。现在用了快一个多月，还挺不错的，CPU占用也不高。唯一的缺点是内部启动腾讯会议，会使用CPU而不是显卡处理视频，CPU占用较高。所以腾讯会议还是装在外面。</p>
<span id="more"></span>
<h2 id="第一季">第一季</h2>
<h2 id="新机处理">新机处理</h2>
<ol type="1">
<li>处理任务栏，改成小任务栏，开始菜单全部unpin，考虑托盘图标全部显示</li>
<li>windows 更新，BIOS更新</li>
<li>安装7-zip</li>
<li><strong>禁用Windows搜索</strong> - DISM++</li>
<li><strong>禁用Windows错误收集</strong> - DISM++</li>
<li><strong>禁用windows defender</strong> - defender control -
不使用任何杀毒软件</li>
<li>禁用各种托盘图标</li>
<li>安装组策略，hyper-v，WSL2</li>
<li>管理员账号配置，hyper-v的win虚拟机</li>
</ol>
<h2 id="hyper-v-安装win-ame">hyper-v 安装win-AME</h2>
<p>explorer要等很久才显示，关闭增强会话，登录之后发送ctrl-alt-delete然后就可以启动cmd了。等了好久好久才打开了桌面。。。</p>
<ol type="1">
<li><p>按照说明换壁纸</p></li>
<li><p>直接给默认用户加到管理员组去了。然后重启，uac设置always
notify。</p></li>
</ol>
<h2 id="默认电脑增加管理员用户">默认电脑增加管理员用户</h2>
<p>去控制面板，而不是windows设置。增加用户，设置类型，一气呵成。</p>
<p>可能要重启才能完全生效吧？确实是这样。直接设置可能token还是旧的权限。</p>
<p>密码改成一个空格吧，不，直接改成空密码。算了，还是改成空格。</p>
<h2 id="rdp连接qq微信">RDP连接QQ微信</h2>
<p>虚拟机内IP会变？？最关键的是网关和虚拟机ip不在一个网段。。。增加一个新网卡吧</p>
<p>不用啥dhcp了，自己配一个ip吧。</p>
<p>https://github.com/kimmknight/remoteapptool 新建一个bat，start
微信和qq，作为application的目标。application
mode和标准模式不能共存。也就是说如果想要同时拿它做什么的话就还是老实地放弃appMode吧。</p>
<p>另外要增加输入法啊，不然不能打字的。。。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$List</span> = <span class="built_in">New-WinUserLanguageList</span> en<span class="literal">-US</span></span><br><span class="line"><span class="variable">$List</span>.add(<span class="string">&quot;zh-CN&quot;</span>)</span><br><span class="line"><span class="built_in">Set-WinUserLanguageList</span> <span class="variable">$List</span></span><br></pre></td></tr></table></figure>
<p>另外就是微信的托盘图标完全是摆设，无响应。QQ的托盘图标悬浮无法弹出框，可以右键，双击。</p>
<hr />
<p>发现就算是普通的非APP模式也还行，单独放一个桌面，远程桌面的时候选择win键相关的快捷键保留在主机，这样直接Ctrl+Win+方向键直接切换桌面。缺点是虚拟机那边缺失了Win+X这样的快捷键。</p>
<p>确实不错。电脑关机虚拟机自动暂停，开机自动恢复，我只要想用的时候双击rdp连过去就好了。消息要听提示音了。</p>
<h2 id="视频通话的延迟">视频通话的延迟</h2>
<p>开启RemoteFX试试。RDP两边都开启。</p>
<p>主机（RDP客户端）：组策略：计算机配置—管理模板—Windows
组件—远程桌面服务—远程会话客户端—RemoteFX设备重定向。允许管理员和用户</p>
<p>虚拟机（RDP服务端）：组策略：计算机配置—管理模板—Windows
组件—远程桌面服务—远程会话环境—RemoteFX for Windows Server 2008 R2 --
启用第一个</p>
<p>重启试试</p>
<h2 id="非管理员无法调整屏幕和显卡">非管理员无法调整屏幕和显卡</h2>
<p>屏幕刷新率省电和igpu模式在非管理员的armoury
crate这个rog的控制面板里消失。。。</p>
<p>用runas命令运行也不行</p>
<h2
id="窗口半屏总会在另外一边弹出选框">窗口半屏总会在另外一边弹出选框</h2>
<p>设置-系统-多任务处理-贴靠窗口-将窗口对齐的时，显示能够在其旁边对齐的内容
关闭它。</p>
<h2 id="第二季度">第二季度</h2>
<ol type="1">
<li><p>使用下面命令准备系统：然后直接移动硬盘过去。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="variable">%windir%</span>\system32\sysprep\sysprep.exe /generalize /oobe /shutdown</span><br></pre></td></tr></table></figure></li>
</ol>
<p>出现问题：</p>
<ol type="1">
<li>为单个用户安装的appx会造成问题，先卸载</li>
<li>千万要先把微软账户退出改用本地账号啊！！！不然被微软联网登录卡得进不去账号</li>
<li>电脑真的第一次开机要保证不能换任何配件！才能激活。激活之后再换。</li>
</ol>
<p>导入hyper-v的时候先建立起同名网卡再导入。</p>
<p>TODO:</p>
<ol type="1">
<li>如何把旧电脑的微信qq聊天记录导入过去？</li>
</ol>
<h3 id="网络问题">网络问题</h3>
<p>onenote和todo的网络问题还是需要代理，这个需要network
isolation设置，然后挂全局代理解决</p>
<p>而现在遇到各种网络问题反而是DNS问题。</p>
<ol type="1">
<li>使用默认DNS想要登录微软账号有问题</li>
<li>使用微软DNS上普通网站非常卡。</li>
<li>前段时间发现禁用ipv6后就能上简书和知乎了。</li>
</ol>
<p>考虑像我的switchy-omega脚本一样，对黑白名单设置对应的DNS。微软部分网站使用微软dns，其他网站都用本地DNS吧。不，这样太麻烦了，维护成本也高。</p>
<p>我就设置一个方便迅速切换的脚本吧。</p>
<ol type="1">
<li>获取当前默认路由的网卡</li>
<li>设置网卡的DNS地址</li>
</ol>
<p>另外现在ipv4已经耗尽，可以拿到完整的ipv4-地区数据。</p>
<h3 id="hp-audio-自动安装chrome插件">hp audio 自动安装chrome插件</h3>
<p>chrome显示被组织管理了。在chrome://policy/页面可以看到，是设置了对应位置的注册表导致的。</p>
<ol type="1">
<li><p>在https://4sysops.com/archives/audit-changes-in-the-windows-registry/#activate-registry-auditing
如何监控注册表的修改 添加审计规则。在event
viewer里的security里filter事件id：4657,4660</p>
<p><code>Computer\HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome\ExtensionInstallForcelist</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A registry value was modified.</span><br><span class="line"></span><br><span class="line">Subject:</span><br><span class="line">	Security ID:		SYSTEM</span><br><span class="line">	Account Name:		DESKTOP-BDMA890$</span><br><span class="line">	Account Domain:		WORKGROUP</span><br><span class="line">	Logon ID:		0x3E7</span><br><span class="line"></span><br><span class="line">Object:</span><br><span class="line">	Object Name:		\REGISTRY\MACHINE\SOFTWARE\Policies\Google\Chrome\ExtensionInstallForcelist</span><br><span class="line">	Object Value Name:	317</span><br><span class="line">	Handle ID:		0x240</span><br><span class="line">	Operation Type:		New registry value created</span><br><span class="line"></span><br><span class="line">Process Information:</span><br><span class="line">	Process ID:		0x169c</span><br><span class="line">	Process Name:		C:\Windows\System32\SECOMN64.exe</span><br><span class="line"></span><br><span class="line">Change Information:</span><br><span class="line">	Old Value Type:		-</span><br><span class="line">	Old Value:		-</span><br><span class="line">	New Value Type:		REG_SZ</span><br><span class="line">	New Value:		jjnlfodbdchgijlheopgehgnmekbndmf;https://clients2.google.com/service/update2/crx</span><br></pre></td></tr></table></figure>
<p>everything搜索exe发现是驱动附带的程序，在任务管理器里看是SECOMNService
服务的。</p>
<p><code>C:\Windows\System32\DriverStore\FileRepository\seapo64.inf_amd64_057f6b28338feed1</code></p></li>
<li><p>psexec64.exe -s cmd.exe</p>
<p>sc config SECOMNService start= disabled</p>
<p>先禁用看看会不会影响什么。</p>
<p>看了看这个exe，没看到相关的设置逻辑啊，只有一个SEMISCAPI_IsBrowserExtensionInstalled的字符串。。。但是找不到引用。。。</p></li>
</ol>
]]></content>
      <categories>
        <category>Digi</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>自制Ollvm</title>
    <url>/2021/%E8%87%AA%E5%88%B6Ollvm/</url>
    <content><![CDATA[<h1 id="自制ollvm">自制Ollvm</h1>
<p>原本网上没有多少开源的代码混淆器，现在却发现学习OLLVM的人特别多，很多人也有自己的混淆器。</p>
<p>汇编的混淆和LLVM还是挺有意思的。虽然这个项目的进度依然停滞在只学完简单运算混淆的地步，但有时间我应该会回来继续。</p>
<span id="more"></span>
<p>ollvm/armariris/hikari 三个一起学习. <a
href="https://www.leadroyal.cn/?p=1072">ollvm/armariris/hikari
适配llvm10</a></p>
<p>http://mayuyu.io/ 这里有很多关于llvm的</p>
<p>https://iosre.com/t/llvm/10610/39 实现字符串加密</p>
<p>llvm提供了很方便地操作二进制代码的api. 自己移植不一定有利于学习,
移植主要解决的是llvm版本更新的各种杂七杂八的变化,
反而那些主要的逻辑不要求理解.</p>
<p>既然是学习，就好好以LLVM的字节码为基础，而不是看最终的机器码汇编了。</p>
<p>计划: 1. 作为使用者, 使用这几个代码混淆器,
成功编译混淆代码(使用移植好到llvm10的代码) 2. 作为开发者,
学习混淆的原理, 学习代码编写的思路, 熟悉llvm的api. 3.
开始考虑混淆的对策</p>
<p>TODO: 1. 如何自己打开自己的 2. 找合适的软件或者片段，调用我的ollvm。
3. 可视化、或者如何方便查看llvm字节码，甚至生成的机器码</p>
<p>和godbolt结合可视化。</p>
<p>TODO:</p>
<ol type="1">
<li>学习llvm中的Annotation</li>
<li>编译debug版本，配好调试环境，方便gdb源码调试</li>
<li>分析opt怎么通过RegisterPass<HelloPass>增加的命令行选项。看看clang是怎么管理和加载Pass的。</li>
<li>探索Windows下llvm的pass的现状</li>
<li>改下代码格式化的格式，看看怎么把大括号不单独起一行。</li>
<li>指令替换方面把llvm的全加进来，改用llvm的随机化函数。</li>
<li>学学C++的匿名函数的具体原理。闭包，捕获什么的具体规则和实现</li>
</ol>
<p>[toc]</p>
<h2 id="杂谈">杂谈</h2>
<p>-m64
选项生成64位的代码，但是int还是32位大小的。long才是64位大小的。似乎没有选项能让int变成64位大小的。而main函数的返回值因此也是32位的</p>
<p>读取函数的Annotation上，ollvm可能还是比较猛的？搜<code>llvm readAnnotate</code>
炸出一大片分析ollvm的。</p>
<h2 id="常用的命令">常用的命令</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">opt -load lib/LLVMHello.so -help</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">opt -load lib/LLVMHello.so -hello &lt; hello.bc &gt; out.bc</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clang -Xclang -load -Xclang Obfuscation.dll</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clang -c -emit-llvm $1.c #生成bc</span><br><span class="line">clang -S -emit-llvm $1.c #生成.ll的文本形式</span><br></pre></td></tr></table></figure>
<h2 id="如何编写pass">如何编写pass</h2>
<p>要运行的代码是 https://github.com/LeadroyaL/llvm-pass-tutorial ,
这里每个项目是单独的文件夹. 三个项目合在一起, 共用外面的cmake文件.
为了明白这个移植怎么跑起来, 学习源码外的pass项目的建立. 先学下面的项目,
配置好路径. <a
href="https://github.com/abenkhadra/llvm-pass-tutorial">pass-skeleton</a></p>
<p><a href="https://llvm.org/docs/WritingAnLLVMPass.html">如何写一个pass
llvm.org</a> 确实, 写一个pass就真的是一个pass, 出来一个so文件,
在passmanager里过一遍llvm bytecode.
pass的加载和运行暴露在命令行选项.</p>
<ol type="1">
<li>pass项目可以单独在源码外</li>
</ol>
<p>编译的时候需要在 <code>[LLVM_DIR]</code> 找到llvm的配置.
该项目骨架会通过 <code>$LLVM_HOME</code> 环境变量设置好
<code>[LLVM_DIR]</code> 编译出来可以使用opt直接运行pass.
也可以clang编译的时候指定opt加载这个so文件, 然后加上调用so的选项.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clang-7.0 -Xclang -load -Xclang build/skeleton/libSkeletonPass.* something.c$</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>pass项目在llvm源码内</li>
</ol>
<p>可以像他们几个项目一样直接在llvm-project源码内的
<code>/lib/Transform</code> 修改. 并且修改默认加载这个pass,
只需要给出使用的选项.</p>
<h3 id="源码外的pass">源码外的pass</h3>
<p><a
href="http://llvm.org/docs/CMake.html#developing-llvm-passes-out-of-source">Developing
LLVM passes out of source</a></p>
<p>LLVM_HOME 应该是 <code>/usr/lib/llvm-10</code>,
这样就会设置LLVM_DIR为 <code>/usr/lib/llvm-10/lib/cmake/llvm</code>
LLVM_DIR里面有LLVMConfig.cmake, 设置了这个环境变量, cmake中调用
<code>find_package(LLVM REQUIRED CONFIG)</code>
就可以找到llvm作为一个cmake的library</p>
<p>为了构建源码外的pass, 重要的cmake语句有 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.4)</span><br><span class="line">project(llvm-pass-tutorial)</span><br><span class="line"></span><br><span class="line">find_package(LLVM REQUIRED CONFIG)</span><br><span class="line">add_definitions($&#123;LLVM_DEFINITIONS&#125;)</span><br><span class="line">include_directories($&#123;LLVM_INCLUDE_DIRS&#125;)</span><br><span class="line">link_directories($&#123;LLVM_LIBRARY_DIRS&#125;)</span><br><span class="line"></span><br><span class="line">add_subdirectory(skeleton)  # Use your pass name here.</span><br><span class="line">add_subdirectory(ollvm)  # ollvm</span><br><span class="line">add_subdirectory(Hikari)  # Hikari</span><br><span class="line">add_subdirectory(Armariris)  # Armariris</span><br></pre></td></tr></table></figure>
在每个文件夹内的CMakeList里调用 <code>add_library</code>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">add_library(Armariris MODULE</span><br><span class="line">        # List your source files here.</span><br><span class="line">        CryptoUtils.cpp</span><br><span class="line">        StringObfuscation.cpp</span><br><span class="line">        Substitution.cpp</span><br><span class="line">        Flattening.cpp</span><br><span class="line">        Utils.cpp</span><br><span class="line">        include/Transforms/Obfuscation/Flattening.h</span><br><span class="line">        include/Transforms/Obfuscation/StringObfuscation.h</span><br><span class="line">        include/Transforms/Obfuscation/Substitution.h</span><br><span class="line">        include/Transforms/Obfuscation/Utils.h</span><br><span class="line">        Enter.cpp</span><br><span class="line">        )</span><br></pre></td></tr></table></figure></p>
<h3 id="行动">行动</h3>
<p>为了避免编译llvm. 我采用直接apt安装的方式安装llvm,
源码外建立pass项目. 好像安装了llvm-dev 安装后在
<code>/usr/lib/llvm-10</code> 附近有各种编译头文件</p>
<p>在<code>project(llvm-pass-tutorial)</code>之后加上</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set(ENV&#123;LLVM_HOME&#125; /usr/lib/llvm-10)</span><br></pre></td></tr></table></figure>
<h3 id="pass的集成">pass的集成</h3>
<p>我想知道如何无缝集成到clang。</p>
<p>新的passmanager能更细粒度地控制Pass之间的互斥关系。每一个函数都返回了对应invalidate了的其他pass。还没迁移过去。所以可能还是legacy的PM多一些，clang应该还是吧。而legacy的PM，这两种注册方法中</p>
<ol type="1">
<li><p>要有一个ID，初始值不重要，因为是根据ID的地址区别各个函数的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">char Hello::ID = 0;</span><br></pre></td></tr></table></figure></li>
<li><p>注册pass，得到一个命令行。这里是通过构造函数注册的，我们只需要初始化一个类。这种方法似乎只对opt有效？？当有这个选项的时候我们的pass才会被加载</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static RegisterPass&lt;Hello&gt; X(&quot;hello&quot;, &quot;Hello World Pass&quot;,</span><br><span class="line">                             false /* not modify CFG */,</span><br><span class="line">                             false /* pure Analysis Pass */);</span><br></pre></td></tr></table></figure>
<p>这种方法会注册到全局的passRegistry里面。TODO：探索何时被注册了命令行选项。</p></li>
<li><p>加载时自动注册，这里用的是匿名函数，我们可以写一个函数。这种方法对opt无效。对<code>clang -Xclang -load -Xclang Obfuscation.dll</code>
有效。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static RegisterStandardPasses Y(</span><br><span class="line">    PassManagerBuilder::EP_EarlyAsPossible,</span><br><span class="line">    [](const PassManagerBuilder &amp;Builder,</span><br><span class="line">       legacy::PassManagerBase &amp;PM) &#123; PM.add(new Hello()); &#125;);</span><br></pre></td></tr></table></figure>
<p>TODO：研究原理。它会先调用PassManagerBuilder::addGlobalExtension，这个函数则是Transform/IPO里的，它把<code>std::make_tuple(Ty, std::move(Fn), ExtensionID)</code>
放到GlobalExtensions这个static全局Vector里面。最终是populateFunctionPassManager这里把注册的这些东西放进FPM的</p>
<p>怀疑可能这里把我们的Pass放进内部统一的“Pass数据库”里了，opt根据数据库生成命令行选项，每个选项对应一个Pass的启用和关闭。</p></li>
<li><p>命令行选项，加载后通过参数更详细地控制pass</p>
<p>https://stackoverflow.com/questions/13626993/is-it-possible-to-add-arguments-for-user-defined-passes-in-llvm</p>
<p>https://llvm.org/docs/CommandLine.html#commandline-2-0-library-manual</p>
<p>使用commandline api:
​cl::opt。这个工具是完全独立于llvm的，可以拿出来自己用。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  cl::<span class="built_in">ParseCommandLineOptions</span>(argc, argv);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它负责初始化全局变量，选项都反映在全局变量里。因此和opt、clang是否加载使用我们的pass没有关系。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static cl::opt&lt;int&gt;</span><br><span class="line">ObfProbRate(&quot;bcf_prob&quot;, cl::desc(&quot;Choose the probability [%] each basic blocks will be obfuscated by the -bcf pass&quot;), cl::value_desc(&quot;probability rate&quot;), cl::init(defaultObfRate), cl::Optional);</span><br></pre></td></tr></table></figure>
<p>表示解析一个int类型的命令行</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cl::opt&lt;RegisterMyPasses::FunctionPassCtor, <span class="literal">false</span>,</span><br><span class="line">        RegisterPassParser&lt;RegisterMyPasses&gt; &gt;</span><br><span class="line"><span class="built_in">MyPassOpt</span>(<span class="string">&quot;mypass&quot;</span>,</span><br><span class="line">          cl::<span class="built_in">init</span>(&amp;createDefaultMyPass),</span><br><span class="line">          cl::<span class="built_in">desc</span>(<span class="string">&quot;my pass option help&quot;</span>));</span><br></pre></td></tr></table></figure>
<p><strong>llvm::cl::opt&lt; DataType, ExternalStorage, ParserClass
&gt;</strong>
这里的cl初始化，声明了一个自定义parser，parser返回的结果是RegisterMyPasses类型的命令行选项。</p></li>
<li><p><a
href="https://llvm.org/docs/WritingAnLLVMPass.html#id47">Registering
dynamically loaded passes</a></p></li>
<li></li>
</ol>
<h3 id="ubuntu的pass测试">ubuntu的pass测试</h3>
<p>为了方便地测试pass，方便地看到结果。输入是c语言的程序，输出pass前和pass后的llvm
ir。</p>
<p>使用makefile文件</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">%.ll: %.c</span></span><br><span class="line">	clang -S -emit-llvm <span class="variable">$^</span></span><br><span class="line"></span><br><span class="line"><span class="section">%.obf.ll: %.ll</span></span><br><span class="line">	opt -stats -S -load ../build/myobf/libmyobf.so -hello <span class="variable">$^</span> -o <span class="variable">$@</span></span><br></pre></td></tr></table></figure>
<h2 id="llvm的annotation">LLVM的Annotation</h2>
<h3 id="资料搜寻">资料搜寻</h3>
<p>https://groups.google.com/g/llvm-dev/search?q=llvm.global.annotations</p>
<p>https://groups.google.com/g/llvm-dev/c/IiuO8EOM6dI/m/nQdjQ1qOYIgJ</p>
<p>通过google groups搜索mailing
list，最终找到了用法的讨论。在08年的时候有个AnnotationManager，之后被删掉了。2020年11月最近似乎增加了!annotate的新用法，对旧的__attribute__((annotate))
用法可能也做了什么处理？</p>
<p>有些东西可能真的就没有文档。。。？？仔细学习后我发现我的想法错了，可能只是因为用法没有什么特殊的地方，所以不需要单独成文档。最后只是靠看各种其他文档弄懂的，llvm的mailing
list反而用处不大。</p>
<p>主要靠的是：llvm的struct、array类型，getElementPtr指令（复杂结构体的地址计算指令），bitcast指令（类似强制类型转换）</p>
<h3 id="ir解析">IR解析</h3>
<p>tl;dr
全局变量，包括函数的Annotation被放在llvm.global.annotations这个全局变量里。局部变量、函数参数的annotation会产生对<a
href="https://llvm.org/docs/LangRef.html#llvm-var-annotation-intrinsic">llvm.var.annotation</a>这个函数的call指令，相关信息放在函数参数里。</p>
<p>数组类型为<code>&#123; i8*, i8*, i8*, i32 &#125;</code>，类似于<code>&#123;char*, char*, char*, int&#125;</code>
依次为 函数地址、annotation字符串地址、源码文件名、源码内的行号。</p>
<p>对参数的annotate会转化为有内存空间的局部变量，然后对内存空间annotate。此外，因为每个函数的局部空间是通过alloca指令分配的，所以llvm.var.annotation的第一个参数会指向分配的内存空间内部。局部变量的变量名会丢失。</p>
<p>可能通过Debug_info能够找回局部变量名？增加-g选项后生成的ll文件内确实会增加dwarf4信息。会通过<code>call void @llvm.dbg.declare(metadata i32* %2, metadata !14, metadata !DIExpression()), !dbg !15</code>的方式声明局部变量，需要分析一下变量。通过<code>!llvm.module.flags</code>
可以判断是否开启了debug。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Annotation.c</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> a __attribute__((annotate((<span class="string">&quot;hello1&quot;</span>)))) = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">b</span><span class="params">(<span class="type">int</span> __attribute__((annotate((<span class="string">&quot;hello2&quot;</span>)))) c)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">return</span> c + <span class="number">41</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">d</span><span class="params">(<span class="type">int</span> e)</span> __<span class="title function_">attribute__</span><span class="params">((annotate((<span class="string">&quot;hello&quot;</span>))))</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">return</span> e + <span class="number">42</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight llvm"><table><tr><td class="code"><pre><span class="line"><span class="comment">; ModuleID = &#x27;Annotation.c&#x27;</span></span><br><span class="line">source_filename <span class="operator">=</span> <span class="string">&quot;Annotation.c&quot;</span></span><br><span class="line"><span class="keyword">target</span> <span class="keyword">datalayout</span> <span class="operator">=</span> <span class="string">&quot;e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128&quot;</span></span><br><span class="line"><span class="keyword">target</span> <span class="keyword">triple</span> <span class="operator">=</span> <span class="string">&quot;x86_64-pc-linux-gnu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="title">@a</span> <span class="operator">=</span> dso_local <span class="keyword">global</span> <span class="type">i32</span> <span class="number">3</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line"><span class="title">@.str</span> <span class="operator">=</span> <span class="keyword">private</span> <span class="keyword">unnamed_addr</span> <span class="keyword">constant</span> [<span class="number">7</span> <span class="keyword">x</span> <span class="type">i8</span>] <span class="keyword">c</span><span class="string">&quot;hello1<span class="char escape_">\00</span>&quot;</span><span class="punctuation">,</span> <span class="keyword">section</span> <span class="string">&quot;llvm.metadata&quot;</span></span><br><span class="line"><span class="title">@.str.1</span> <span class="operator">=</span> <span class="keyword">private</span> <span class="keyword">unnamed_addr</span> <span class="keyword">constant</span> [<span class="number">13</span> <span class="keyword">x</span> <span class="type">i8</span>] <span class="keyword">c</span><span class="string">&quot;Annotation.c<span class="char escape_">\00</span>&quot;</span><span class="punctuation">,</span> <span class="keyword">section</span> <span class="string">&quot;llvm.metadata&quot;</span></span><br><span class="line"><span class="title">@.str.2</span> <span class="operator">=</span> <span class="keyword">private</span> <span class="keyword">unnamed_addr</span> <span class="keyword">constant</span> [<span class="number">7</span> <span class="keyword">x</span> <span class="type">i8</span>] <span class="keyword">c</span><span class="string">&quot;hello2<span class="char escape_">\00</span>&quot;</span><span class="punctuation">,</span> <span class="keyword">section</span> <span class="string">&quot;llvm.metadata&quot;</span></span><br><span class="line"><span class="title">@.str.3</span> <span class="operator">=</span> <span class="keyword">private</span> <span class="keyword">unnamed_addr</span> <span class="keyword">constant</span> [<span class="number">6</span> <span class="keyword">x</span> <span class="type">i8</span>] <span class="keyword">c</span><span class="string">&quot;hello<span class="char escape_">\00</span>&quot;</span><span class="punctuation">,</span> <span class="keyword">section</span> <span class="string">&quot;llvm.metadata&quot;</span></span><br><span class="line"><span class="title">@llvm.global.annotations</span> <span class="operator">=</span> <span class="keyword">appending</span> <span class="keyword">global</span> [<span class="number">2</span> <span class="keyword">x</span> &#123; <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i32</span> &#125;] [&#123; <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i32</span> &#125; &#123; <span class="type">i8</span>* <span class="keyword">bitcast</span> (<span class="type">i32</span>* <span class="title">@a</span> <span class="keyword">to</span> <span class="type">i8</span>*)<span class="punctuation">,</span> <span class="type">i8</span>* <span class="keyword">getelementptr</span> <span class="keyword">inbounds</span> ([<span class="number">7</span> <span class="keyword">x</span> <span class="type">i8</span>]<span class="punctuation">,</span> [<span class="number">7</span> <span class="keyword">x</span> <span class="type">i8</span>]* <span class="title">@.str</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span>)<span class="punctuation">,</span> <span class="type">i8</span>* <span class="keyword">getelementptr</span> <span class="keyword">inbounds</span> ([<span class="number">13</span> <span class="keyword">x</span> <span class="type">i8</span>]<span class="punctuation">,</span> [<span class="number">13</span> <span class="keyword">x</span> <span class="type">i8</span>]* <span class="title">@.str.1</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span>)<span class="punctuation">,</span> <span class="type">i32</span> <span class="number">3</span> &#125;<span class="punctuation">,</span> &#123; <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i32</span> &#125; &#123; <span class="type">i8</span>* <span class="keyword">bitcast</span> (<span class="type">i32</span> (<span class="type">i32</span>)* <span class="title">@d</span> <span class="keyword">to</span> <span class="type">i8</span>*)<span class="punctuation">,</span> <span class="type">i8</span>* <span class="keyword">getelementptr</span> <span class="keyword">inbounds</span> ([<span class="number">6</span> <span class="keyword">x</span> <span class="type">i8</span>]<span class="punctuation">,</span> [<span class="number">6</span> <span class="keyword">x</span> <span class="type">i8</span>]* <span class="title">@.str.3</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span>)<span class="punctuation">,</span> <span class="type">i8</span>* <span class="keyword">getelementptr</span> <span class="keyword">inbounds</span> ([<span class="number">13</span> <span class="keyword">x</span> <span class="type">i8</span>]<span class="punctuation">,</span> [<span class="number">13</span> <span class="keyword">x</span> <span class="type">i8</span>]* <span class="title">@.str.1</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span>)<span class="punctuation">,</span> <span class="type">i32</span> <span class="number">10</span> &#125;]<span class="punctuation">,</span> <span class="keyword">section</span> <span class="string">&quot;llvm.metadata&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; Function Attrs: noinline nounwind optnone uwtable</span></span><br><span class="line"><span class="keyword">define</span> dso_local <span class="type">i32</span> <span class="title">@b</span>(<span class="type">i32</span> <span class="variable">%0</span>) <span class="variable">#0</span> &#123;</span><br><span class="line">  <span class="variable">%2</span> <span class="operator">=</span> <span class="keyword">alloca</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="keyword">store</span> <span class="type">i32</span> <span class="variable">%0</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%2</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%3</span> <span class="operator">=</span> <span class="keyword">bitcast</span> <span class="type">i32</span>* <span class="variable">%2</span> <span class="keyword">to</span> <span class="type">i8</span>*</span><br><span class="line">  <span class="keyword">call</span> void <span class="title">@llvm.var.annotation</span>(<span class="type">i8</span>* <span class="variable">%3</span><span class="punctuation">,</span> <span class="type">i8</span>* <span class="keyword">getelementptr</span> <span class="keyword">inbounds</span> ([<span class="number">7</span> <span class="keyword">x</span> <span class="type">i8</span>]<span class="punctuation">,</span> [<span class="number">7</span> <span class="keyword">x</span> <span class="type">i8</span>]* <span class="title">@.str.2</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span>)<span class="punctuation">,</span> <span class="type">i8</span>* <span class="keyword">getelementptr</span> <span class="keyword">inbounds</span> ([<span class="number">13</span> <span class="keyword">x</span> <span class="type">i8</span>]<span class="punctuation">,</span> [<span class="number">13</span> <span class="keyword">x</span> <span class="type">i8</span>]* <span class="title">@.str.1</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span><span class="punctuation">,</span> <span class="type">i32</span> <span class="number">0</span>)<span class="punctuation">,</span> <span class="type">i32</span> <span class="number">5</span>)</span><br><span class="line">  <span class="variable">%4</span> <span class="operator">=</span> <span class="keyword">load</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%2</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%5</span> <span class="operator">=</span> <span class="keyword">add</span> <span class="keyword">nsw</span> <span class="type">i32</span> <span class="variable">%4</span><span class="punctuation">,</span> <span class="number">41</span></span><br><span class="line">  <span class="keyword">ret</span> <span class="type">i32</span> <span class="variable">%5</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">; Function Attrs: nounwind willreturn</span></span><br><span class="line"><span class="keyword">declare</span> void <span class="title">@llvm.var.annotation</span>(<span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i8</span>*<span class="punctuation">,</span> <span class="type">i32</span>) <span class="variable">#1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; Function Attrs: noinline nounwind optnone uwtable</span></span><br><span class="line"><span class="keyword">define</span> dso_local <span class="type">i32</span> <span class="title">@d</span>(<span class="type">i32</span> <span class="variable">%0</span>) <span class="variable">#0</span> &#123;</span><br><span class="line">  <span class="variable">%2</span> <span class="operator">=</span> <span class="keyword">alloca</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="keyword">store</span> <span class="type">i32</span> <span class="variable">%0</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%2</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%3</span> <span class="operator">=</span> <span class="keyword">load</span> <span class="type">i32</span><span class="punctuation">,</span> <span class="type">i32</span>* <span class="variable">%2</span><span class="punctuation">,</span> <span class="keyword">align</span> <span class="number">4</span></span><br><span class="line">  <span class="variable">%4</span> <span class="operator">=</span> <span class="keyword">add</span> <span class="keyword">nsw</span> <span class="type">i32</span> <span class="variable">%3</span><span class="punctuation">,</span> <span class="number">42</span></span><br><span class="line">  <span class="keyword">ret</span> <span class="type">i32</span> <span class="variable">%4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>llvm.global.annotations的声明中，最开头的<code>[2 x &#123; i8*, i8*, i8*, i32 &#125;]</code>是类型，紧接着的是主体，ConstantExpr，最末尾是section说明<code>, section "llvm.metadata"</code>。</p>
<p>而ConstantExpr部分就利用bitcast把函数类型转换成i8*类型<code>bitcast (i32* @a to i8*)</code>，再<code>getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i32 0, i32 0)</code>。</p>
<h3 id="pass中的解析方法">Pass中的解析方法</h3>
<p>首先获取Module级别的全局变量 llvm.global.annotations</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GlobalVariable *glob =</span><br><span class="line">      f-&gt;getParent()-&gt;getGlobalVariable(&quot;llvm.global.annotations&quot;);</span><br></pre></td></tr></table></figure>
<p>得到全局变量的初始值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ConstantArray *ca = dyn_cast&lt;ConstantArray&gt;(glob-&gt;getInitializer())</span><br></pre></td></tr></table></figure>
<p>这是一个数组类型，先进行遍历，长度是<code>ca-&gt;getNumOperands()</code>，取下标使用<code>ca-&gt;getOperand(i)</code>。取了后得到ConstantStruct。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ConstantStruct *structAn = dyn_cast&lt;ConstantStruct&gt;(ca-&gt;getOperand(i))</span><br></pre></td></tr></table></figure>
<p>这就是<code>&#123; i8*, i8*, i8*, i32 &#125;</code>结构体，使用<code>structAn-&gt;getOperand(0)</code>这样的方法取0-3的下标得到成员。其中前三个取出来都是ConstantExpr：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ConstantExpr *expr = dyn_cast&lt;ConstantExpr&gt;(structAn-&gt;getOperand(0))</span><br><span class="line">ConstantExpr *note = cast&lt;ConstantExpr&gt;(structAn-&gt;getOperand(1));</span><br></pre></td></tr></table></figure>
<p>第一个基本上都是bitcast</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">expr-&gt;getOpcode() == Instruction::BitCast </span><br><span class="line">expr-&gt;getOperand(0)是Function类型</span><br></pre></td></tr></table></figure>
<p>第二第三个都是getElementPtr，然后先获取GlobalVariable类型的字符串，再获取Initializer得到真正的字符串内容。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">note-&gt;getOpcode() == Instruction::GetElementPtr</span><br><span class="line">GlobalVariable *annoteStr = dyn_cast&lt;GlobalVariable&gt;(note-&gt;getOperand(0))</span><br><span class="line">ConstantDataSequential *data = dyn_cast&lt;ConstantDataSequential&gt;(annoteStr-&gt;getInitializer())</span><br><span class="line">if (data-&gt;isString()) &#123; annotation += data-&gt;getAsString().lower() + &quot; &quot;; &#125;</span><br></pre></td></tr></table></figure>
<h3 id="annotationhello-在pass中读取annotation实例">AnnotationHello
在Pass中读取Annotation实例</h3>
<p>继承一个ModulePass，对每个模块解析一次Annotation。</p>
<p>继承一个FunctionPass函数，在第一个基本块内解析Annotation。</p>
<p>TODO：能否（简单地）一个命令行开启两个Pass？呃，那个Register决定opt是否启用，而</p>
<h2
id="windows平台下的混淆visual-studio-配置使用pass">Windows平台下的混淆：visual
studio 配置使用pass</h2>
<p>经过查阅资料, 没找到, 不能android一样, <a
href="https://stackoverflow.com/questions/48947973/use-llvm-in-a-cmake-build">重新编译才能得到cmake库</a>
编译后将build文</p>
<p>在Windows平台编译不是一个简单的问题，需要各种支持。现在虽然难，但似乎有人成功了。</p>
<p>安装了tdm-Gcc之后用如下的选项编译</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cmake -G Ninja -DLLVM_ENABLE_PROJECTS=&quot;clang&quot; -DLLVM_EXPORT_SYMBOLS_FOR_PLUGINS=On ..\llvm</span><br></pre></td></tr></table></figure>
<p>出现报错，说</p>
<p>cant close file too big</p>
<p>改设置上一些其他的选项试试，看看能不能好一点。可能只能编译release版本的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cmake -G Ninja -DLLVM_ENABLE_PROJECTS=&quot;clang&quot; -DLLVM_EXPORT_SYMBOLS_FOR_PLUGINS=On -DLLVM_INCLUDE_TESTS=Off DLLVM_TARGETS_TO_BUILD=&quot;X86&quot; -DCMAKE_BUILD_TYPE=Release ..\llvm</span><br></pre></td></tr></table></figure>
<p>时间过于漫长，我把环境变量里面的clang提前了，不行的话看看能不能clang自己编译自己。</p>
<p>TODO 描述编译经历</p>
<ol type="1">
<li>坚持使用MSVC编译，使用MSVC自带的开发控制台的x64 native tools</li>
<li>使用上面的方法后，即使用Ninja生成器，不加-hHost=x64，也能正确用上64位的toolchain好像</li>
<li>源码内pass比源码外pass更容易配</li>
</ol>
<p>现在是windows平台，in
source编写pass。如果做成DLL，则不能集成进clang里，这样visual
studio不好调用。</p>
<h3 id="编写混淆pass">编写混淆pass</h3>
<ol type="1">
<li><p>自己编写的pass编译成dll之后是否只能通过opt运行？不能通过clang自动运行？</p>
<p><a
href="https://www.cs.cornell.edu/~asampson/blog/clangpass.html">这里</a>
其实是一种挺Hack的方法，让组件加载dll/so的时候去注册，我在windows上这样加载LLVMHello.dll
会报错 <code>动态链接库(DLL)初始化例程失败。 (0x45A)</code></p>
<p>首先写一个bat自动化进行编译成中间代码和使用pass的过程。</p>
<p>一种方法是源码内编写pass，直接修改相关代码加载pass，这种方法其实挺不容易的，我首先在clang的一些cmakelist里加入了Hello链接进去，但是似乎还是需要注册？需要继续深入了解研究看看源码，看问题4
<a
href="https://medium.com/@mshockwave/writing-llvm-pass-in-2018-part-iv-d69dac57171d">内置的方法</a></p>
<p>否则即使在源码内编写，也出来的是动态库，还是只能opt加载。。。</p></li>
<li><p>头文件缺失的问题怎么解决？visual studio是怎么编译的？</p>
<p>visual studio
最近有了llvm支持。而我自己编译的llvm是没有基本的C++头文件的。用微软的安装包安的clang也是一样，所以可能是手动添加了include路径？</p></li>
<li><p>llvm的pass是如何注册命令行选项的？怎样编译成dll，又如何不出dll而是内置到clang里？</p>
<p>想要内置考虑可以通过<a
href="https://llvm.org/docs/WritingAnLLVMPass.html#building-pass-plugins">llvm
plugin</a>。是否编译成dll和Transform里的自己的pass的CmakeList里的add_llvm_library
里是否加上Module参数有关系。加上就是动态链接，不加上就是静态链接出来。</p></li>
<li><p>Transform的那些pass是怎么加载进clang里的？</p>
<p>lib/CodeGen/CMakeList.txt</p>
<p>tools/driver/CMakeList.txt</p>
<p>这两个地方有clang会link进去的东西。</p>
<p>要去掉自己的MODULE BUILDTREE_ONLY</p>
<p>我编译进去了，但是好像不太行。。</p>
<p>好像要在IPO的PassManagerBuilder::populateFunctionPassManager/populateModulePassManager</p>
<p><a
href="https://medium.com/@mshockwave/writing-llvm-pass-in-2018-part-iv-d69dac57171d">内置的方法</a></p></li>
<li><p>bytecode转可执行文件？</p>
<p>可以直接clang编译成可执行文件 <a
href="https://blog.csdn.net/pc153262603/article/details/89553688">来源</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clang a.o.bc -o struct</span><br></pre></td></tr></table></figure>
<p>首先llc编译成S的汇编文件，再用gcc什么的生成可执行文件 <a
href="https://stackoverflow.com/questions/32523847/how-to-make-llvm-bc-file-executable">来自</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">llc -filetype=obj hello.bc -o hello.o</span><br><span class="line">llc hello.bc -o hello.s</span><br><span class="line">gcc hello.o/s -o hello</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="pass与clang的集成">PASS与Clang的集成</h2>
<h3 id="案例-ollvm做出的修改">案例: ollvm做出的修改</h3>
<p>以下是ollvm4.0和llvm4.0进行对比的不同的文件. 来自<a
href="https://magic-king.net/2020/02/27/ollvm-learning/">这里</a> 使用<a
href="https://truehumandesign.se/s_diffinity.php">Diffinity</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./include/llvm/Transforms/Obfuscation/ # obfuscation的头文件</span><br><span class="line">./include/llvm/Transforms/CryptoUtils.h # obfuscation的头文件</span><br><span class="line">./lib/Transforms/IPO/LLVMBuild.txt</span><br><span class="line">./lib/Transforms/IPO/PassManagerBuilder.cpp # Pass注册</span><br><span class="line">./lib/Transforms/Obfuscation/ # obfuscation source code</span><br><span class="line">./lib/Transforms/CMakeLists.txt</span><br><span class="line">./lib/Transforms/LLVMBuild.txt</span><br><span class="line">./tools/clang # 集成clang,要在gitignore里取消clang的注释</span><br><span class="line">./.gitignore</span><br><span class="line">./CMakeLists.txt</span><br><span class="line">./CODE_OWNERS.TXT</span><br><span class="line">./LICENSE.TXT</span><br></pre></td></tr></table></figure>
<h2 id="ollvm-实现分析">OLLVM 实现分析</h2>
<h3 id="概述">概述</h3>
<ol type="1">
<li><strong>Instruction substitution:</strong>
将加减与或异或这几个指令通过数学方式变成更复杂但等效的计算。</li>
<li><strong>Bogus Control Flow</strong>
将一个基本块的入口加上虚假分支语句，不会执行的分支指向虚假代码。再在出口加上虚假分支，不会执行的分支指向虚假代码，最后将虚假基本块的出口指向真实基本块，构成类似循环的结构。</li>
<li><strong>Control Flow Flattening</strong>
把整个函数的控制流都收到路由变量和分发块的逻辑里来，类似于switch
case。（是不是可以直接做源码级的混淆）更进一步，可以让CRC代码完整性检查的结果参与进来，这样如果代码的CRC不对，就直接影响跳转的逻辑。（但是只有在完全编译链接生成最终的可执行文件的时候才能确定CRC。而如果CRC检查部分的代码是相互依赖的（检查到其他检查部分的代码），则还需要解决依赖关系（利用CRC的线性代数的线性性质））</li>
<li><strong>Basic-block splitting</strong>
这是什么？直接增加虚假分支和基本块？</li>
<li><strong>Code Tamper-Proofing</strong>
有多个check例程，往正常逻辑中插入对它的调用，然后检查值对不对。通过融合进控制流的方法，如果CRC不对的话则之后不会跳转到正确的基本块。</li>
<li><strong>Procedures Merging</strong>
将多个函数合并成一个merged函数，第一个参数用来判断调用的是哪个函数，通过switch
case调用对应的函数。原来的函数被wrapper函数替代，使用varg技术像，merged函数提供正确的参数，再跳转到对应的函数。（如果能在链接时处理，则甚至不需要wrapper函数，而是修改每个调用前push参数的过程增加调用号。）merged函数被其他混淆（如控制流平坦化）处理后能大幅增加抗分析能力。此外这种方法还能防止不分析的情况下直接重用汇编的攻击。</li>
</ol>
<p>未来的方向：
特定于平台的反调试代码，对密码学常量和字符串的混淆，代码水印技术</p>
<h3 id="instruction-substitution">Instruction substitution</h3>
<p>指令替换是最简单的。对于加减与或
异或这五种运算，分别有多种替换方法，ollvm随机选一个替换。增加的命令行选项是每个函数替换多少遍。第一遍替换的是原始的指令，后面每次替换的就是混淆后的指令了，通过反复替换增加复杂度。</p>
<p>这个pass明显需要放在优化pass之后。如何让自己的pass在优化后运行？
可以考虑opt过了pass之后，编译的时候就用 -O0 ?</p>
<p>继承Funcpass的Substitution有几个函数指针数组，在初始化的时候把自己的成员函数填进去，之后通过随机数产生器随机调用。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (Function::iterator bb = tmp-&gt;<span class="built_in">begin</span>(); bb != tmp-&gt;<span class="built_in">end</span>(); ++bb) &#123;</span><br><span class="line">  <span class="keyword">for</span> (BasicBlock::iterator inst = bb-&gt;<span class="built_in">begin</span>(); inst != bb-&gt;<span class="built_in">end</span>(); ++inst) &#123;</span><br><span class="line">    <span class="keyword">if</span> (inst-&gt;<span class="built_in">isBinaryOp</span>()) &#123;</span><br><span class="line">      <span class="keyword">switch</span> (inst-&gt;<span class="built_in">getOpcode</span>()) &#123;</span><br><span class="line">      <span class="keyword">case</span> BinaryOperator::Add:</span><br><span class="line">                  <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> BinaryOperator::Sub:</span><br><span class="line">      ...</span><br></pre></td></tr></table></figure>
<p>真正核心的替换函数，参数只是那个指令<code>BinaryOperator *bo</code>。</p>
<figure>
<img src="image-20200928135000792.png" alt="image-20200928135000792" />
<figcaption aria-hidden="true">image-20200928135000792</figcaption>
</figure>
<p>addNeg：增加一个Neg指令，把加法变成减法。addDoubleNeg同理。</p>
<p>精髓在于BinaryOperator::Create的方法的最后一个参数是InsertBefore，这样按顺序插入到那个指令前面，最后的时候再对原来的指令调用replaceAllUsesWith，用最后生成的指令去替换它就好了。意味着用最后一个指令产生的值去替换它产生的值。</p>
<p>binaryOperator成员如下，rem是取余数的运算符 <a
href="https://llvm.org/docs/LangRef.html#binary-operations">多找找llvm手册</a>
。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Standard binary operators...</span><br><span class="line"> FIRST_BINARY_INST(13)</span><br><span class="line">HANDLE_BINARY_INST(13, Add  , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(14, FAdd , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(15, Sub  , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(16, FSub , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(17, Mul  , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(18, FMul , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(19, UDiv , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(20, SDiv , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(21, FDiv , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(22, URem , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(23, SRem , BinaryOperator)</span><br><span class="line">HANDLE_BINARY_INST(24, FRem , BinaryOperator)</span><br></pre></td></tr></table></figure>
<p>TODO
确实会留下原来被代替的指令。需要在合适的时候调用<code>bo-&gt;eraseFromParent();</code>直接调用会导致iterator出现问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">i = vec.erase(i); </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>LLVM</tag>
      </tags>
  </entry>
  <entry>
    <title>南京大学《软件分析》课程笔记</title>
    <url>/2021/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="南京大学软件分析课程笔记">南京大学《软件分析》课程笔记</h1>
<p>（静态分析）</p>
<p>警告：本笔记可能包含错误推论。有待学成后回来检查。</p>
<p>做了实验是因为碰巧从Github上搜到了原本应该不外传的实验代码。</p>
<span id="more"></span>
<p>[toc]</p>
<h2 id="introduction">01 Introduction</h2>
<p>TODO: 复习补充</p>
<p>假如有一群人，里面有好人有坏人，我们需要抓出坏人。我们能找出一个子集，使得包含所有的坏人，这样的结果是Sound的。Sound关注的是完整性，会Over
Approximate。找出子集使得只包含坏人，不包含好人，这样的结果是Complete的。Complete提供确信性，保证不会抓错好人。</p>
<p>保证能抓到坏人的Completeness我们可以处理掉，保证不会漏掉坏人的Soundness则能够缩小范围，这样的结果我们都称为是Safe的。</p>
<p>may analysis 对应sound，must analysis对应complete。</p>
<h2 id="ir">02-IR</h2>
<p>静态分析一般都在IR上进行。</p>
<h3 id="ast-vs-ir">AST vs IR</h3>
<p>AST
更侧重于语法结构，比如保留了do_while这样的节点，然后分为Body和条件。适合快速的类型检查。静态分析不太需要关心语法结构。IR离控制流反而更近。</p>
<h3 id="实际的ir-soot的3ac">实际的IR-Soot的3AC</h3>
<p>Soot能分析Java程序，它就是产生typed 3AC.</p>
<p>(Soot？JVM) 中常见的invoke指令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">invokespecial: call constructor, call superclass methods, call private methods</span><br><span class="line">invokevirtual: instance method call (virtual dispatch)</span><br><span class="line">invokeinterface: cannot optimization, checking interface implementation.</span><br><span class="line">invokestatic: call static methods</span><br><span class="line"></span><br><span class="line">Java 7: invoke dynamic -&gt; Java static typing, dynamic language on JVM</span><br></pre></td></tr></table></figure>
<p>多个字符串相加会实例化新的StringBuilder，依次对每个字符串调用append，最后toString。</p>
<p>Java的class，静态成员初始化（静态代码块？）会在生成的<code>&lt;clinit&gt;</code>函数中，比如给static
final double pi = 3.14这样的成员赋值。</p>
<h3 id="ssa">SSA</h3>
<p>SSA似乎是3AC的一种形式？如果在分支merge的情况，true分支和false分支对x赋了不同的值，会引入phi-function合并变量，表示定义了哪个就用哪个。</p>
<p>SSA优点：</p>
<ol type="1">
<li><p>能够让Flow insensitive的分析也有一些Flow
sensitive的精确性。</p></li>
<li><p>定义和使用的对应关系是显式的。可能就是不怕变量被中途改掉，找到定义的地方即可。</p></li>
</ol>
<p>缺点：</p>
<ol type="1">
<li>引入太多变量和Phi函数</li>
<li>可能导致machine code不够高效，性能问题</li>
</ol>
<h3 id="cfa-cfg">CFA CFG</h3>
<p>BasicBlock的特性：只能从第一条指令进入，只能从最后一条指令离开。最大的集合</p>
<p>构建BB的算法：找到所有BasicBlock的入口指令：1. 第一条指令 2.
跳转的目标 3. 跳转的下一条指令。然后切分开就是所有的BasicBlock。</p>
<p>构建CFG：如果在BB之间添边：每个无条件跳转只添到跳转目标，每个条件跳转添下一条和跳转目标。如果两个BB相邻并且没有跳转语句，直接添顺序执行的边。最后加上两个特殊的节点，Entry和Exit。</p>
<h2 id="data-flow-analysis-application-i">03-Data Flow
Analysis-Application I</h2>
<p>属于编译后端优化的基础。application-specific的数据是怎么在CFG上流动的。</p>
<h3 id="基础概念">基础概念</h3>
<p>每段statement将输入态转化为输出态。给每个程序点关联一个对所有可能的程序状态的抽象。</p>
<p>Forward Analysis，Backward Analysis</p>
<p>TODO 复习34:36方面的符号。</p>
<p>没有涉及到的分析：Method
Calls，需要跨过程的控制流图，在跨过程分析里学。Aliases：变量没有别名，在指针分析里学。</p>
<h3 id="reaching-definitions-analysis">Reaching Definitions
Analysis</h3>
<p>定义到达分析。分析某处定义能不能到达某处而不被杀掉。这里的3AC的定义指要么是初始化要么是赋值，其实还是关注那处的值能否到达。</p>
<p>对应的实际场景假设是空指针分析，把初始化为null的定义收集起来做分析，判断能否到达使用处，这里是May
analysis，也就是保证任何可能的到达都要计算出来，不会漏掉任何的可能性。</p>
<p>转换函数的公式：减去kill的，加上生成的 <span class="math display">\[
OUT[B]=gen_B\cup(IN[B] - kill_B)
\]</span> 控制流的转换公式：所有可能的控制流的状态的并集。 <span
class="math display">\[
IN[B] = \cup_{P\ a\ predecessor\ of\ B}OUT[P]
\]</span> 定义到达分析的算法：输入CFG（每个基本块的<span
class="math inline">\(kill_B\)</span>和<span
class="math inline">\(gen_B\)</span>），输出每个基本块的IN[B]和OUT[B]</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">OUT[entry] = 空集;</span><br><span class="line"><span class="keyword">for</span> (每个除了entry的基本块 B) &#123;</span><br><span class="line">    OUT[B] = 空集;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (本轮有OUT改变) &#123;</span><br><span class="line">    <span class="keyword">for</span> (每个除了entry的基本块 B) &#123;</span><br><span class="line">        IN[B] = 每个B的前驱（P）的OUT[P];</span><br><span class="line">        OUT[B] = gen_B 并(IN[B] - kill_B);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>经典的迭代算法模板。反复代入规则，直到结果不变。（不动点）</p>
<p>这次的例子中，对每个变量用一个1bit的值表示能否reach，最终对每个基本块都得到了一个bit
vector。</p>
<p>如何证明该算法最终会停下来？</p>
<p>1.gen和kill是不会变的 2.
当IN变大了的时候，增加的要么被kill了，要么存活下来进入OUT，进入OUT的值不会再离开，即OUT是单增的。3.
而最终的OUT集合是有限集合（因为整个程序是有限的）4.
最终总会达到稳定，停下来。（即数列的单增有界必收敛。）</p>
<p>如何证明我们的while条件能保证是最终结果？</p>
<p>只需证本轮无OUT改变的时候即使再迭代也不会改变结果。根据迭代中语句，因为OUT不变，IN也不变，而IN不变，OUT也不会继续变化。</p>
<p>只有一个不动点吗？</p>
<p>无论什么样的分析，都可以归结为Lattice上求解不动点。我们这样求可能会求出最大不动点或者最小不动点。</p>
<h2 id="data-flow-analysis-application-ii">04 Data Flow
Analysis-Application II</h2>
<h3 id="live-variable-analysis">Live Variable Analysis</h3>
<p>变量V在P处活跃的定义：存在以P开头的路径到达V的某个被使用处，且中途没有其他V的定义。</p>
<p>这里（整个数据流分析）的definition似乎既包括声明也包括赋值。</p>
<p><strong>注意辨析和Reaching
Definition的区别</strong>。当前执行到了程序点P，当前状态下有很多已经被定义的变量。这些变量在当前状态下的值中，之后可能会被用到的，就成为Live的，之后肯定不会被用到的就是dead。从变量的角度看，V从被赋值的地方开始活跃起来，如果（当前的值）之后都不可能再被用到了就死了。但是live
variable
中的live，不再是definition的属性，而是variable的属性。我们关心的是variable，而不像Reaching
Definition一样关心的是definition了。我们关心的是variable，不再是definition了。</p>
<p>应用：可以用于寄存器分配。当前不再活跃的值就可以从寄存器放弃了。</p>
<p><strong>适合正向分析还是反向分析？</strong>
一个显著的特点是，如果接下来马上被use，那肯定是live的。每个use的地方象征着liveness区域的（可能的）结束。正向想要判断的话，需要碰到use再返回去给前面的p设置liveness。所以适合反向看。</p>
<p>公式就完全反过来了：从后继节点的IN推前一个节点的OUT <span
class="math display">\[
OUT[B] = \cup_{S\ a\ successor\ of\ B}IN[S]
\]</span> 而逆向的转换函数如下：重点考虑 <code>v=v-1</code>
先use再def，和 <code>v=2;k=v</code> 先def再use的情况 <span
class="math display">\[
IN[B] = use_B\cup(OUT[B] - def_B)
\]</span>
类比之前的情况，基本上是use类似于gen，def类似于kill。使用gen，赋值kill。</p>
<p>这样就有了总体的算法：和之前类似，只是反过来了（类似CFG倒置）。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">IN[<span class="built_in">exit</span>] = 空集;</span><br><span class="line"><span class="keyword">for</span> (每个除了<span class="built_in">exit</span>的基本块 B) &#123;</span><br><span class="line">    IN[B] = 空集;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (本轮有IN改变) &#123;</span><br><span class="line">    <span class="keyword">for</span> (每个除了<span class="built_in">exit</span>的基本块 B) &#123;</span><br><span class="line">        OUT[B] = 每个B的后继（P）的IN[P];</span><br><span class="line">        IN[B] = use_B 并(OUT[B] - def_B);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里进行的是may analysis，一般来说may
analysis初始化为空，对应lattice中的botton，must
analysis初始化为all，对应lattice中的bottom。</p>
<p>注意控制流分叉的地方。如果分叉两边的IN，各有不同的变量live，那分叉的地方的OUT是什么？既然不知道要跳转到哪，就假设都会跳转（sound的over
approximate思想），取交集。因为，假设是寄存器分配的情况，假设变量本来是dead的，你当成了live，那只是浪费了寄存器资源，是over
approximate，是可以的。如果变量是live的，你当成了dead，那之后想用的时候就玩完了，这不可取。所以寄存器分配的例子需要的是soundness而不是completeness。</p>
<h3 id="available-expression-analysis">Available Expression
Analysis</h3>
<p>表达式<code>x op y</code>在p处活跃的定义：1
从entry开始到p的所有路径都需要计算<code>x op y</code>。2
在最后一次计算<code>x op y</code> 后，x和y的值没有改变。</p>
<p>这意味着1
在p点，已经计算好的<code>x op y</code>依然能代表x和y参与运算的结果。2
可以检测global公共子表达式。</p>
<p>bit
Vector，为每个expression定义一个bit，表示当前是否活跃。1表示是Available，0就表示不是</p>
<p>新计算出的表达式被gen了，被定义的变量会kill相关的表达式。所以表达式的转换公式和最开始的Reaching
Definitions Analysis相同。</p>
<p>这次就是Foward + Must
Analysis的例子了，需要取交集。当两处控制流交汇的时候，一边可能是Available，另外一边不是，则只能认为不是，因为能承担重新计算的代价，却不能容许错误。
<span class="math display">\[
IN[B] = \cap_{P\ a\ predecessor\ of\ B}OUT[P]
\]</span> 算法如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">OUT[entry] = 空集;</span><br><span class="line"><span class="keyword">for</span> (每个除了entry的基本块 B) &#123;</span><br><span class="line">    OUT[B] = all; <span class="comment">// 注意！！</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (本轮有OUT改变) &#123;</span><br><span class="line">    <span class="keyword">for</span> (每个除了entry的基本块 B) &#123;</span><br><span class="line">        IN[B] = 每个B的前驱（P）的OUT[P];</span><br><span class="line">        OUT[B] = gen_B 交(IN[B] - kill_B);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于是Must
Analysis，初始化为全1，运算采取交集。之前我们都是初始化为空，采取并集，然后迭代增加。而这里我们初始化为全1，然后使用交不断减少。显然不能初始化为全0再采取交集运算，这样始终是全0。</p>
<p>另外注意entry还是初始化为全零的。</p>
<h3 id="对比">对比</h3>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 25%" />
<col style="width: 26%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr>
<th></th>
<th>Reaching Def</th>
<th>Live Variable</th>
<th>Available Exp</th>
</tr>
</thead>
<tbody>
<tr>
<td>Domain</td>
<td>Set of Def</td>
<td>Set of Variables</td>
<td>Set of exp</td>
</tr>
<tr>
<td>Direction</td>
<td>Foward</td>
<td>Backward</td>
<td>Forward</td>
</tr>
<tr>
<td>May/Must</td>
<td>May</td>
<td>May</td>
<td>Must</td>
</tr>
<tr>
<td>Boundary node</td>
<td>OUT[entry] = 空</td>
<td>IN[exit]=空</td>
<td>OUT[entry] = 空</td>
</tr>
<tr>
<td>Initialization</td>
<td>0</td>
<td>0</td>
<td>all</td>
</tr>
<tr>
<td>Transfer func</td>
<td>减kill并gen</td>
<td>同</td>
<td>同</td>
</tr>
<tr>
<td>Meet合并</td>
<td>并</td>
<td>并</td>
<td>交</td>
</tr>
</tbody>
</table>
<p>总结来说有4种情况，分别是分析方向，和may/must分析的正交。</p>
<p>分析的方向决定了初始化哪个边界节点，和TransferFunction的方向。may/must决定了是用交还是并，初始化是全0还是全1。</p>
<h2 id="data-flow-analysis---foundations-i">05-Data Flow Analysis -
Foundations I</h2>
<h3 id="另一个角度看待迭代">另一个角度看待迭代</h3>
<p>假设是Reaching
Def的分析场景，所有的def构成域V（bitVector的值域）。CFG有k个节点。则将所有CFG在OUT里的值组成长度为k的tuple。
<span class="math display">\[
(OUT[n_1],OUT[n_2],...,OUT[n_k])
\]</span> 每次迭代则看作一个函数，输入<span
class="math inline">\(V^k\)</span>(所有的OUT)，输出一个新的<span
class="math inline">\(V^k\)</span>。不断迭代直到找到不动点。</p>
<p>问题：</p>
<ol type="1">
<li>是否总是能达到不动点？</li>
<li>是否只有一个不动点，我们到达的是最好的那个吗</li>
<li>要花多久到达不动点？</li>
</ol>
<h3 id="偏序">偏序</h3>
<p>偏序集：包含一个集合和一个符号&lt;=。满足1. 自反性Reflectivity
x&lt;=x。2. 反对称性Antisymmetry 如果x&lt;=y且y&lt;=x 则x=y。3.
传递性Transitivity：如果x&lt;=y且y&lt;=z，则x&lt;=z。特点是可以允许两个元素不可比较。</p>
<p>例子：1. &lt;=在自然数上 2. 字符串上的子字符串判断。3. 幂集。</p>
<h3 id="上界和下界">上界和下界</h3>
<p>偏序集中子集的S。如果元素u是S的上界（upper
bound），则每个S中的元素x都&lt;=u。下界同理，每个S中的元素x都有1&lt;=x关系，则1是下界（lower
bound）。</p>
<p>最小上界least upper bound（lub or join）：它&lt;=
S的每个上界元素。最大下界greatest lower bound（glb or meet）。</p>
<p>性质：1. 都不一定在S中。2. 不是每个偏序集合都有lub或glb。 3.
lub或glb有则唯一。</p>
<p>当S中只有两个元素a、b的时候，可以发现，a join b 是最小上界，a meet
b是最大下界。</p>
<h3 id="lattice格">Lattice格</h3>
<p>如果偏序集中任意一对元素都有lub和glb，则这个偏序集称之为格。</p>
<p>如果只满足任意一对元素都有最小上界，则称为join
semilattice。同理还有meet semilattice。</p>
<p>全格Complete
Lattice：任意子集都存在lub和glb。（任何子集都是格。）</p>
<p>对整数上关于&lt;=的格，不是全格，因为正整数集合不存在最小上界。</p>
<p>幂集则满足全格。格中最大的元素成为top，最小的元素称为bottom。</p>
<p>任意有限格都是全格。我们静态分析一般都是Complete finite lattice。</p>
<p>Product
Lattice：n个格的product组成tuple。定义新的偏序关系需要每个对应位置的元素都成立&lt;=关系。全格的product
lattice也是全格。</p>
<h3 id="基于格的数据分析框架">基于格的数据分析框架</h3>
<p>数据分析框架由（D-direction，L-Lattice(以及meet
join运算符)，F-转换函数）组成。这样数据分析框架就可以看作是反复调用转换函数（IN转换OUT的时候）和meet/join运算符（合并控制流的时候），作用于格上的值。</p>
<h3 id="单调性与不动点定理">单调性与不动点定理</h3>
<p>格上函数的单调性： <span class="math display">\[
x\sqsubseteq y \Rightarrow f(x) \sqsubseteq f(y)
\]</span> 不动点定理：</p>
<p>全格<span class="math inline">\((L,\sqsubseteq)\)</span>，1.
L是有限的 2. 函数<span class="math inline">\(f:L\rightarrow
L\)</span>是单调的monotonic。则最小不动点可以通过从开始bottom不断迭代得到。最大不动点可以通过从Top开始不断迭代得到。</p>
<ol type="1">
<li><p>证明不动点存在： <span class="math display">\[
\bot \sqsubseteq f(\bot) \sqsubseteq f^2(\bot) \sqsubseteq ...
\sqsubseteq f^n(\bot)
\]</span> 而L是有限的，导致总是会达到相等的时候。</p></li>
<li><p>证明不动点最小：</p>
<p>假设有另外一个不动点x，由定义有<span class="math inline">\(\bot
\sqsubseteq x\)</span>。反复代用单调性的定义（或者由数学归纳法证）得
<span class="math display">\[
f^{i}(\bot) \sqsubseteq f^{i}(x) = x, i \in N^+
\]</span> 则左边到达不动点的时候还是<span
class="math inline">\(\sqsubseteq x\)</span>
的，因此我们的不动点最小。我们证明了我们迭代得到的不动点会&lt;=任意的不动点。还可以证最小不动点唯一。</p></li>
</ol>
<h2 id="data-flow-analysis---foundations-2">06-Data Flow Analysis -
Foundations 2</h2>
<h3 id="关联我们的迭代算法">关联我们的迭代算法</h3>
<p>bitVector的表示范围是域，类似于幂集，因为把1看做集合内有该元素，0看作集合内没有该元素。每个BB的OUT，即OUT中的每个元素，都是格上的值。每次迭代的OUT总体来看是格的product。而且Complete
Lattice构成的product Lattice也是Complete的。</p>
<p>我们每次迭代的动作：1. 对每个基本块应用状态转换函数。2.
在合并的时候使用join/meet操作。</p>
<h3 id="证明迭代函数单调">证明迭代函数单调</h3>
<ol type="1">
<li><p>gen/kill的状态转换函数是单调的，该gen的总是还在，该被kill的也总是被kill。因此<span
class="math inline">\(if\ x_1&lt;x_2,\ f(x_1) &lt;
f(x_2)\)</span>。</p></li>
<li><p>join和meet函数，可以描述为<span
class="math inline">\(\sqcap/\sqcup: L\times L\rightarrow
L\)</span>，如果有多个控制流就两两调用合并。</p>
<p>这里证明<span class="math inline">\(\sqcup\)</span>，即upper
bound运算是单调的。 <span class="math inline">\(\forall x,y,z \in L,\ x
\sqsubseteq y\)</span>，我们要证明 <span class="math inline">\((x \sqcup
z) \sqsubseteq (y \sqcup z)\)</span>。</p>
<ol type="1">
<li>首先由upper bound的定义，<span class="math inline">\(y \sqsubseteq
(y \sqcup z)\)</span>。</li>
<li>由传递性，<span class="math inline">\(x \sqsubseteq (y \sqcup
z)\)</span>。因此<span class="math inline">\(y \sqcup
z\)</span>也是x的上界。</li>
<li>而由于<span class="math inline">\((x \sqcup
z)\)</span>是x和z的最小的上界，也就是同时是x和z两个值的上界里最小的那个，由这里最小的定义得<span
class="math inline">\((x \sqcup z) \sqsubseteq (y \sqcup
z)\)</span>。</li>
</ol></li>
<li><p>由于迭代函数由这两部分组成，迭代函数主要是对一些IN采取join/meet运算，然后对IN进行状态转换计算，因此每个OUT相比上一轮的OUT也是单调的。因此总的迭代函数，也就是product起来也是单调的。</p></li>
</ol>
<p>TODO 为什么这个不动点是best的。</p>
<h3
id="什么时候到达不动点-算法的复杂度">什么时候到达不动点-算法的复杂度</h3>
<p>格的高度：从Top到Bottom最长的路径的长度。可知格的高度是算法复杂度的上界，因为每次迭代至少会走一步。</p>
<p>而我们的情况其实是格的product。假设单个格的高度是h，有k个基本块（k个值的tuple）。最慢情况每次只有tuple中的一个元素走一步，则每个元素轮流走，至少有h*k次迭代。</p>
<h3 id="maymust分析-格的视角">May/Must分析-格的视角</h3>
<p>我们都是从最Unsafe的Result出发，到达最近的Safe
Result，所以我们得到的是best result。</p>
<p>最开始初始化为0，表示每个点没有任何def能够到达。这里是May
Analysis，关注的是不能漏掉任何null值可能的到达的情况。因此全初始化为0，表示所有null的def都不会到达使用的地方，是一个错误的Unsafe的结果，因为全都漏掉了。</p>
<p>truth，正确的结果，也就是在静态分析的情况下，每个基本块，把真正可能到达的定义标为1。它标志着safe和unsafe的边界，所有满足和truth的偏序大于等于关系的元素就是safe的。因为单独看函数某处，safe的结果就是在truth的基础上，可能会把一些0误报成1的结果。我们的偏序关系就是子集，因此确实safe的结果就是满足有truth这个子集的结果。</p>
<p>如何证明我们停下来的时候是safe的？状态转换函数是精确的，关键就在于这个meet/join函数的选取上我们是over
approximation的。TODO</p>
<p>另外一种达到的一定的最小不动点的解释：状态转换函数是固定的，而这个meet/join函数我们选的还是最小上界，因此我们每次走的都是最小的一步，因此第一个遇到的不动点一定是最小的。是不是要证明这个路径是一维的？不用。我们如果不是从bottom出发，则走出的平行路径一定是大于等于从bottom出发的路径的，但是关键在于提前停怎么办？只要拉到无限，当两边都停了后，因为是同轮次的，所以不动点一定小于等于其他地方出发的不动点。</p>
<p>而must分析类似。</p>
<figure>
<img src="image-20210117213246480.png" alt="image-20210117213246480" />
<figcaption aria-hidden="true">image-20210117213246480</figcaption>
</figure>
<p>如何记忆？</p>
<ol type="1">
<li>如何设置top和bottom（怕有的时候会反过来）？格中，bottom代表“所有人都不是坏人”，是Complete的，top代表“所有人都是坏人”，是sound的。也就是bottom
- No，top -
Yes。分析都是从unsafe到safe的。因为如果从另一头开始，结果就不会动了。所以Must
analysis是从顶部unsafe 的“All
Yes”，不断取交，增加No，直到剩下的都必定是yes。May analysis是从底部
unsafe的“All
No”，不断取并，增加Yes，直到所有的Yes都在范围里。都是从最危险的地方开始，向最安全的方向走，半路上停下来，有种危险的感觉。</li>
</ol>
<h3 id="结果有多精确">结果有多精确</h3>
<p>路径汇聚起来的时候就Meet（/join）起来这种策略，称为MOP（Meet-Over-All-Paths
Solution）。我们为Path，一系列的路径定义Transfer Function，<span
class="math inline">\(F_P\)</span>，为路径上一系列的transfer
function的函数迭代。</p>
<p>某个基本块S_i的MOP指的是从Entry到达S_i的每一条路径的转换函数，输入Entry的OUT值后的最小上界。
<span class="math display">\[
MOP[S_i]=\mathop{\sqcup/\sqcap}\limits_{A\ path\ P\ from\ Entry\ to\
S_i} (F_P(OUT[Entry]))
\]</span>
而有一些Path可能是真实情况下不会被执行到的，所以我们的结果不是完全精确的，不是truth。而有一些循环是可能无数次的，不可枚举的，枚举所有情况是不可能的。</p>
<h5 id="我们的迭代方法-vs-mop的方法">我们的迭代方法 vs MOP的方法</h5>
<p>我们的方法和MOP的方法的明显区别在于，MOP的meet是在最后进行的，而我们可能会提前meet结果在带入下一步的转换函数。</p>
<figure>
<img src="image-20210117220047438.png" alt="image-20210117220047438" />
<figcaption aria-hidden="true">image-20210117220047438</figcaption>
</figure>
<p>接下来证明<span class="math inline">\(F(x\sqcup
y)\)</span>（我们的）和<span class="math inline">\(F(x) \sqcup
F(y)\)</span>（MOP）的关系：<span class="math inline">\(F(x) \sqcup F(y)
\sqsubseteq F(x\sqcup y)\)</span>，即<span class="math inline">\(MOP
\sqsubseteq Ours\)</span>。</p>
<ol type="1">
<li>由F的单调性可得<span class="math inline">\(F(x) \sqsubseteq F(x
\sqcup y)\)</span> 并且 <span class="math inline">\(F(y) \sqsubseteq F(x
\sqcup y)\)</span>。</li>
<li>由<span class="math inline">\(F(x) \sqcup
F(y)\)</span>的最小性，得证<span class="math inline">\(F(x) \sqcup F(y)
\sqsubseteq F(x\sqcup y)\)</span>。</li>
</ol>
<p>当函数F满足分配性(distributive)的时候MOP =
Ours，此时一样准。而我们之前遇到的Bit-Vector or Gen/Kill
problems（用并集和交集操作的）转换函数F都是满足分配性的。而我们下面的这个例子就是不满足分配律的。</p>
<p>仔细想想，MOP代表着程序（在真实场景中）所有可能执行的路径的每种情况都考虑了进来。如果出现了不确定的循环，那路径数量直接变成正无穷。而我们通过在控制流交汇处提前合并，通过将分析结果合并提前到路径叠加之前，类似于运算符交换顺序，极大地降低了复杂度，使得分析变得可行。</p>
<p>2023年9月3日
数据流分析的可分配性是一个非常基本的问题。本质上静态分析之所以能够成功，就是抓住了可分配性的特性，把无限可能的路径，通过分配性在路径合并时解决。这么看的话，有种做算法题的感觉。</p>
<p>可分配性就是，问自己一个问题：如果两条控制流汇聚了，你是转换函数，现在有两种选择，一种是，仿佛有两个程序过来，你转换他们两次，然后为了存储把结果合并，另外一种是，先把结果合并，然后你在去转换，只转换了一次。这两种情况结果是否一样。程序肯定是越多越精确，如果程序先被合并了，那你有可能亏了精度。但是如果你满足交换率，你就不会亏精度。</p>
<h3 id="constant-propagation-常量传播">Constant
Propagation-常量传播</h3>
<p>定义：给定变量x，判断在点p处x的值是否一定是某个常量。</p>
<p>每个节点的OUT值，此时保存的是(x,v)的pair，表示此时某变量可能的值。</p>
<p>特殊的地方：</p>
<ol type="1">
<li><p>Lattice：我们不知道V可能取什么值，而我们只关心是否只会取一个值，于是我们设计域为UNDEF
-&gt; 具体值 -&gt; NAC。这样length为3的lattice。</p></li>
<li><p>Meet Operator的情况：另外是设计Meet
Operator的时候，当UNDEF遇到具体值的时候，我们认为结果是具体值。其实这里是特殊情况，如果编译器给了所有变量初始值比如0的时候，就甚至不存在UNDEF这样的值。这里感觉像把UNDEF作为未定义行为，不保证有稳定的结果。
或者说我们这个pass不管使用未初始化变量的错误，专注于当前优化，这个错误由前面的pass来查，这样就不会出现这种情况。</p></li>
<li><p>转换函数：kill比较简单，如果x被赋值，就kill掉x的pair。gen比较特殊，如果是由其他变量赋值给x，如<code>x=y</code>，定义val函数，表示取当前y相关的pair的value值。此时<code>gen=&#123;(x,val(y))&#125;</code>。如果是<code>x=y op z</code>的情况，需要分情况：</p>
<ol type="1">
<li>当val(y)和val(z)都是常量的时候，x = val(y) op val(z)</li>
<li>val(y)和val(z)有一个是NAC时，x=NAC</li>
<li>否则x=UNDEF。这里也是边界情况吧。如果UNDEF和一个常量得到一个常量的话，这个函数就不是单调的了。TODO：为什么</li>
</ol>
<p>如果不是赋值语句，就直接传下去就好了。</p></li>
</ol>
<h5 id="为什么不满足分配律">为什么不满足分配律</h5>
<p>提前合并可能导致下面这种情况失去精度，因为NAC+NAC也有可能是Constant的。</p>
<figure>
<img src="image-20210118105438408.png" alt="image-20210118105438408" />
<figcaption aria-hidden="true">image-20210118105438408</figcaption>
</figure>
<p>这里还可以看出我们的分析是单调的。</p>
<h3 id="worklist-算法">Worklist 算法</h3>
<p>真正的数据流分析中，往往不是用上面讲的迭代算法，而是这里的Work
List算法， 相当于是迭代方法的一个优化。</p>
<p>我们的迭代算法每次OUT变了，就要重新遍历整个CFG中的基本块。其实只需要遍历真正需要更新的基本块，即被本轮OUT变化影响的基本块，这些基本块的IN可能变，从而他们的OUT可能变。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">OUT[entry] = 空集;</span><br><span class="line"><span class="keyword">for</span> (每个除了entry的基本块 B) &#123;</span><br><span class="line">    OUT[B] = 空集;</span><br><span class="line">&#125;</span><br><span class="line">往Worklist加入所有基本块</span><br><span class="line"><span class="keyword">while</span> (Worklist非空) &#123;</span><br><span class="line">    从Worklist选取基本块B;</span><br><span class="line">    old_OUT = OUT[B];</span><br><span class="line">    IN[B] = 每个B的前驱（P）的OUT[P];</span><br><span class="line">    OUT[B] = gen_B 并(IN[B] - kill_B);</span><br><span class="line">    <span class="keyword">if</span> (old_out != OUT[B])&#123;</span><br><span class="line">        把B的所有后继节点加入Worklist。</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="实验一-constprop">实验一 constprop</h2>
<p>Constant Propagation应该是must
analysis。（D，L，F）中，Direction应该是Forward。Lattice是三层的那个。Transfer
Function就是注意gen和kill。</p>
<p>关键是</p>
<ol type="1">
<li><p>回忆Must analysis初始值应该是危险的Top“all
yes”，（所有变量都是常量）然而这里是UNDEF，而Bottom是“all
no”即NAC。</p></li>
<li><p>由1就可判断，三层lattice中，undef和NAC谁在上谁在下了。NAC在下。另外初始化的时候需要初始化为UNDEF。</p></li>
<li><p>merge函数。之前的分析都是每个变量1bit，然后采取交或者并。而我们现在每个变量对应一个数值，合并的情况自然是定义新的运算，由于是must
analysis，这里称作交，因为不同的数值合并的时候倾向于全零的bottom，NAC。</p></li>
<li><p>控制流合并的时候是meet（交）
operator，binaryOperation的合并是function
f。不同之处在于如果运算的两个参与的数都是常量，则返回运算后的结果。而不是NAC。不是两个值相等的时候就返回这个值。</p></li>
</ol>
<p>先实现meetValue，再实现FlowMap
meet，再实现computeValue，最后transfer。</p>
<p>需要理解的地方：</p>
<ol type="1">
<li>transfer函数中changed变量指的不是out关于in是不是changed，而是本轮的out关于上一轮的out是否变化了。</li>
<li>Map函数的copyFrom函数调用的是put，会覆盖原来的值，并且会返回boolean表示是否修改了。</li>
</ol>
<h3 id="参数作为nac还是undef">参数作为NAC还是UNDEF？</h3>
<p>参数的Jimple语句是<code>p := @parameter0: int</code>，<code>JIdentityStmt</code>类型，属于<code>DefinitionStmt</code>。且左边的p属于<code>Local</code>。因此右边的<code>getRightOp</code>函数的值会传入<code>ComputeValue</code>函数。</p>
<p>右边的<code>@parameter0: int</code>属于ParameterRef类型，不属于几种我们处理的类型，因此被默认的条件处理，返回NAC了。</p>
<h2 id="实验二-dead-code-elimination">实验二 Dead Code Elimination</h2>
<p>基于实验一的constprop，分析跳转的条件，找出可达的分支。通过标记出可达代码，去除不可达的部分。通过找出live
variable，去除dead variable。</p>
<p>首先将实验一的代码复制过来，完善ComputeValue函数，处理其他几种boolean运算。并不是ConstProp自己用到，而是接下来实现的findUnreachableBranches调用这个方法计算condition是不是常量。</p>
<p>接下来就可以实现findUnreachableBranches函数，遍历分支，把不可达的边找出来。</p>
<p>再实现findUnreachableCode函数，遍历图找出可达节点，然后取补集得到不可达节点。</p>
<p>然后实现live variable，</p>
<p>最后实现dead code elimination。</p>
<h3 id="为什么soot用box包裹value">为什么Soot用Box包裹Value？</h3>
<p>References in Soot are called boxes。</p>
<p>TODO</p>
<h3 id="live-variable">live variable</h3>
<p>首先复习live variable analysis。这里使用reversed
CFG，从而还是使用旧框架，流入的还是叫IN，流出的还是叫OUT。</p>
<p>live variable方向为reversed，属于may
analysis，初始化为bottom而不断上升。每个变量用1bit表示live还是dead，bottom表示全部dead。控制流汇集的时候就使用并。</p>
<p>回忆gen和kill是什么：使用gen，赋值kill。重点考虑 <code>v=v-1</code>
先use再def，和 <code>v=2;k=v</code>
先def再use的情况：后面这种是两个赋值语句，属于正常范围。而前面这种类似于<code>t=v-1;v=t;</code>倒着考虑就是先kill后gen。所以处理赋值语句的时候需要先处理赋值，再处理右边的表达式。此外还要注意changed变量设置得对不对。</p>
<p>记得处理IfStmt，顺便处理了InvokeStmt和AssignStmt中的InvokeExpr。</p>
<h2 id="interprocedural-analysis">07-Interprocedural Analysis</h2>
<p>有了过程间分析，就不必对函数的返回结果做最保守的假设，比如函数结果作为NAC。从而增加精度。</p>
<p>基本的思想是增加call edge和return
edge。我们这里关注的是面向对象语言OOPL（java）的调用图构造方法。有Class
hieracy analysis(CHA) Rapid type analysis(RTA) Variable type
analysis(VTA) Pointer analysis
(k-CFA)这几种方法，依次速度越来越慢，但是越来越精确。我们本次课学第一个方法。</p>
<h3 id="java中的方法调用">Java中的方法调用</h3>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 12%" />
<col style="width: 38%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr>
<th>-</th>
<th>static call</th>
<th>special call</th>
<th>Virtual call</th>
</tr>
</thead>
<tbody>
<tr>
<td>指令</td>
<td>invokestatic</td>
<td>invokespecial</td>
<td>invokeinterface<br/>invokevirtual</td>
</tr>
<tr>
<td>Receiver object</td>
<td>no</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>目标方法</td>
<td>静态方法</td>
<td>构造函数，私有实例方法，父类实例方法等</td>
<td>其他实例方法</td>
</tr>
<tr>
<td>相关方法数量</td>
<td>1</td>
<td>1</td>
<td>&gt;=1</td>
</tr>
<tr>
<td>确定性</td>
<td>编译时确定</td>
<td>编译时确定</td>
<td>运行时确定</td>
</tr>
</tbody>
</table>
<p>virtual
call在C++里面是通过虚函数表实现的，子类可以修改表中的函数指针，指向重载的方法。因为即使把receiver
object看作是父类的对象，对它调用某个方法我们也希望调用到子类的方法，所有关键是让子类的方法先于父类的方法调用。</p>
<p>构造调用图的关键在于Virtual
Call。Soot中使用下面这种格式的"signature"：<code>&lt;C: T foo(P,Q,R)&gt;</code>。Virtual
call调用的时候，基于1. receiver object的真正类型-c。2. 调用处的method
signature-m。我们设这一过程为Dispatch(c,m)。调用处的m之所以不准确，因为如果c是m中类型的子类，又重载了它的方法，就需要调用c对应的方法。
<span class="math display">\[
Dispatch(c,m)=
\begin{cases}
    m&#39; &amp; c中非抽象方法里有1.相同名字\ 2. 相同descriptor的方法 \\
    Dispatch(c&#39;,m), &amp; otherwise
\end{cases}
\\
c&#39;是c的父类
\]</span> <a
href="https://stackoverflow.com/questions/7526483/what-is-the-difference-between-descriptor-and-signature">descriptor和signature的区别</a>：descriptor反映参数和返回值，不含名字。signature反映名字和参数，不包含返回值。</p>
<p>dispatch的公式描述了查找策略，就是从子类开始，不断向上找同名同descriptor的方法。</p>
<h3 id="class-hieracy-analysis">Class hieracy analysis</h3>
<p><code>A a = ...;a.foo()</code>既然我们不知道会调用到哪个子类的方法，那就假设可能会调用到任何一个子类中的对应方法。</p>
<p>分析情景：假设我们在Soot中遇到了一个invoke称为cs，参数有一个"signature"称为m：<code>&lt;C: T foo(P,Q,R)&gt;</code>，如果是virtual
call还会多一个Receiver object。Class hieracy analysis的Call
Resilution算法描述如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Resole(cs) &#123;</span><br><span class="line">    T = &#123;&#125;;</span><br><span class="line">	m = cs指令的“signature”参数;</span><br><span class="line">    <span class="keyword">if</span> cs is a <span class="type">static</span> call &#123;</span><br><span class="line">        T = &#123; m &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> cs is a special call &#123;</span><br><span class="line">        定义C^m为m的<span class="class"><span class="keyword">class</span>信息;</span></span><br><span class="line">        T = &#123; Dispatch(c^m,m) &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> cs is a virtual call &#123;</span><br><span class="line">        c = cs的receiver object在声明的时候的类型;</span><br><span class="line">        对c的每个子类 c<span class="number">&#x27;</span>（包括c自己） &#123;</span><br><span class="line">        	往T添加Dispatch(c<span class="number">&#x27;</span>,m);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果是static call，则直接可以找到对应的方法。如果是special
call有三种情况，其中私有方法，自己的构造函数，则就是签名中的m，第三种情况是父类的方法（super关键字），这种情况需要不断回溯，因此我们统一也使用Dispatch函数来处理。（这里可以发现Dispatch的参数c^m是编译器确定的，因此返回的结果也是编译期能够确定的。）</p>
<p>这里是从那个变量声明时的类型向下找每个子类可能调用到的方法，而jvm运行的时候使用dispatch是从当前真正的类型向上找定义的方法，这就说明了对声明为C的类型的变量调用virtual
call，那么被调用的函数所在的类，在继承树上最高不会超过C，最低不会低于变量真正的类型。错了，可能会高过C，但是此时C肯定也“有”这个方法，结果会等于Dispatch(C,m)。</p>
<p>CHA的优点：速度快，只考虑声明时的信息，但是忽略了数据和控制流的信息。缺点：不精确。很容易引入过多的目标函数。之后会通过指针分析的方法改善。</p>
<h3 id="cha构造全程序的调用图">CHA构造全程序的调用图</h3>
<p>我们从出发点开始构造（main函数）。有点类似树（图？）的遍历。从entry开始遍历所有的invoke指令，然后不断加入边，把发现的新方法加入处理队列。</p>
<p><font face="Consolas">BuildCallGraph(<span
class="math inline">\(m^{entry}\)</span>)<br/> WL=[<span
class="math inline">\(m^{entry}\)</span>], CG={}, RM={}<br/>
<strong>while</strong> WL 非空 <strong>do</strong><br/>
<strong>if</strong> m <span class="math inline">\(\not \in\)</span> RM
<strong>then</strong><br/> 把m加入RM;<br/>
<strong>foreach</strong> m中的每个invoke语句cs <strong>do</strong><br/>
T = Resolve(cs)<br/> <strong>foreach</strong> T中每个函数<span
class="math inline">\(m&#39;\)</span> <strong>do</strong><br/>
向CG中加入边 <code>cs -&gt; m'</code>;<br/> 向WL中加入<span
class="math inline">\(m&#39;\)</span>;<br/> return CG;</font></p>
<h3 id="interprocedual-cfg-过程间的控制流图">Interprocedual
CFG-过程间的控制流图</h3>
<p>把所有的CFG放到一起，然后加入call edge和return edge。return
edge指向call之后的下一条语句。没有栈保存返回地址，那return到谁？通过Context-sensetive的分析可以解决，把数据流分开。如果有多个target，则会有多个call
edge和return
edge，这里也有merge的情况。如果有递归函数，则类似之前过程内分析的循环情况，还是一样的分析，沿着边走，直到值稳定下来。</p>
<figure>
<img src="image-20210118145111232.png" alt="image-20210118145111232" />
<figcaption aria-hidden="true">image-20210118145111232</figcaption>
</figure>
<p>这里我们保留调用语句指向下一条语句的边，用于传递函数自己的local数据流。让call
edge代表参数的流动，return
edge代表返回值的流动。call的时候kill掉被赋值的变量，让它的值随着return
edge流回来。</p>
<h2 id="实验三-cha">实验三 CHA</h2>
<h3
id="遍历invoke-interface和invoke-virtual的不同">遍历invoke-interface和invoke-virtual的不同</h3>
<p>在resolve invoke
interface的时候，是否需要遍历子类？应该不需要，因为getAllImplementersOfInterface的时候应该就增加了所有的子类了？</p>
<p>那要不要考虑subinterface？？</p>
<h3
id="从invokeexpr中获取调用出变量的class">从InvokeExpr中获取调用出变量的class</h3>
<p>原本是</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SootClass</span> <span class="variable">current</span> <span class="operator">=</span> method.getDeclaringClass()</span><br></pre></td></tr></table></figure>
<p>表示该方法定义所在的class。但是在下面这个例子里，返回的是A。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class VirtualCall &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        B b = new B();</span><br><span class="line">        b.foo();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class A &#123;</span><br><span class="line">    void foo() &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class B extends A &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>但是其实b的定义处的类型是B，我想要从B开始向下遍历类，通过调试搞出了下面这样的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SootClass</span> <span class="variable">current</span> <span class="operator">=</span> ((RefType)((InstanceInvokeExpr)invoke).getBase().getType()).getSootClass();</span><br></pre></td></tr></table></figure>
<p>VirtualInvokeExpr和InterfaceInvokeExpr这两个interface都是InstanceInvokeExpr的subInterface。多了getBase这个方法获取Local类型的变量（b），然后用getType，强转为RefType，调用getSootClass得到类型（b的类型B）。</p>
<p>但是这真的是正确的答案吗？感觉不应该这么复杂的。。。如果是从A开始遍历子类确实容易遍历到是A的子类而不是B的子类的类型。</p>
<h3
id="观察intra-和interprocedural-constant-propagation">观察Intra-和Interprocedural
constant propagation</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">    int a, b, c;</span><br><span class="line">    CHACP x = new CHACP();</span><br><span class="line">    a = 6;</span><br><span class="line">    b = x.addOne(a);</span><br><span class="line">    c = b - 3;</span><br><span class="line">    b = x.ten();</span><br><span class="line">    c = a * b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>确实能够优化到addOne函数和ten函数。</p>
<h2 id="指针分析">08-指针分析</h2>
<p>CHA的一个重大问题就是如果是interface，则所有implement了这个interface的类都可能是目标。OO中的指针分析分析的就是某个类的变量，指向的到达是什么实例。指针分析的是指向的对象的性质，更应该叫指向分析。指针分析几乎是静态程序分析的基础。Dagstuhl
Seminar 2013的对指针分析的研讨会里这么说。</p>
<p>指针分析：计算一个指针可能指向哪些内存地址。它是一种may
analysis，可以over approximation。</p>
<p>而别名分析分析的是两个指针是否会指向同一个值，它则不怎么关系指针的范围，所有指针分析和别名分析还是很不一样的。而别名分析可以由指针分析结果推导出来。</p>
<h3 id="指针分析的关键要素">指针分析的关键要素</h3>
<table>
<colgroup>
<col style="width: 36%" />
<col style="width: 22%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr>
<th>Factor</th>
<th>Problem</th>
<th>Choice</th>
</tr>
</thead>
<tbody>
<tr>
<td>堆抽象</td>
<td>对堆建模</td>
<td>Allocation-site/Storeless</td>
</tr>
<tr>
<td>上下文敏感性</td>
<td>对调用上下文建模</td>
<td>Context-sensitive/insensitive</td>
</tr>
<tr>
<td>控制流敏感Flow sensitivity</td>
<td>对控制流建模</td>
<td>Flow-sensitive/insensitive</td>
</tr>
<tr>
<td>分析的scope</td>
<td>分析哪些部分</td>
<td>全程序分析、按需分析</td>
</tr>
</tbody>
</table>
<p>上下文敏感技术，不同位置向同一个函数发起的调用，这个函数会分开分析。这个技术对指针分析效果提升非常显著。</p>
<p>流敏感：如何对控制流建模。我们之前的分析全都是数据流敏感的，需要对程序中每个点维护一个结果。流不敏感的方法则非常粗略，相当于只要可能指向就加过来，不管是程序中哪个点。目前Java中的很多分析都是Flow
insensitive的。</p>
<p>Flow
insensitive，意味着无需考虑程序中复杂多样、数量无限的数据流，另外也意味着我们的分析的结果是程序中所有的语句按照任意顺序执行的所有结果的上界。</p>
<h3 id="堆抽象">堆抽象</h3>
<figure>
<img src="image-20210118153134258.png" alt="image-20210118153134258" />
<figcaption aria-hidden="true">image-20210118153134258</figcaption>
</figure>
<p>我们只学习最常用的Store based
model中的Allocation-site技术。表示为每个创建点创建一个对象，即使创建点在循环里，被执行了多次，但是都抽象成一个对象。</p>
<h3 id="java中的指针分析">Java中的指针分析</h3>
<p>Java中有四种指针，局部变量，静态域（全局变量），实例成员，数组元素。数组元素建模为一个能指向多出的域，忽略index。取出的时候也是忽略index。</p>
<p>接下来的分析都是Flow-insensetive的。我们只需要关心会影响到值的语句，不需要考虑所有语句。需要关系的语句有1.
new <code>x = new T()</code>2. Assign <code>x = y</code>3. Store
<code>x.f =y</code>4. Load <code>y = x.f</code>5. Call
<code>r = x.k(a, ...)</code>。其中最复杂的是Call里面三种情况中的Virtual
Call</p>
<h2 id="指针分析基础-1">09-指针分析基础-1</h2>
<h3 id="处理简单语句">处理简单语句</h3>
<p>程序中所有指针包括变量域V，和成员域<span
class="math inline">\(O\times F\)</span>两部分： <span
class="math display">\[
Pointers = V \cup(O\times F)
\]</span>
其中O代表所有的对象，由于采取了Allocation-site的方式，对象的数量在编译期就确定了。F代表了所有的成员组成的域，因此所有的实例域就是O和F的Product。</p>
<p>指向关系
pt：是Pointer到O的幂集的有序对：同时引入pt(p)函数表示p的指向集合。 <span
class="math display">\[
pt = Poniter \rightarrow \mathcal{P}(O)
\]</span></p>
<ol type="1">
<li><p>New语句：对于<code>x = new T()</code>，<span
class="math inline">\(\overline{o_i \in pt(x)}\)</span>表示将<span
class="math inline">\(o_i\)</span>加入x的指向的集合里。这里<span
class="math inline">\(o_i\)</span>既表示某个对象，又表示的是allocation
site。</p></li>
<li><p>Assign语句：对应<code>x = y</code>，有<span
class="math inline">\(\frac{o_i\in pt(y)}{o_i\in
pt(x)}\)</span>，表示所有是y的指向范围的值，也都是x的指向范围。意味着x的指向范围大于y。</p></li>
<li><p>Store语句：<code>x.f = y</code>，有 <span class="math display">\[
\frac{o_i\in pt(x),\ o_j\in pt(y)}{o_j\in pt(o_i.f)}
\]</span>
表示把x指向范围中每个值，的f域都做一遍Assign的操作。这范围有点大啊。</p></li>
<li><p>Load：<code>y = x.f</code>，有 <span class="math display">\[
\frac{o_i \in pt(x),\ o_j \in pt(o_i.f)}{o_j \in pt(y)}
\]</span>
x指向范围内的每个值的f，它们的指向范围全部合起来放到y的指向范围里。还是有点大...</p></li>
</ol>
<h3
id="课程视频没了-----------">-------------课程视频没了-----------</h3>
<p>伤心</p>
<h3 id="pointer-flow-graph-pfg">Pointer Flow Graph (PFG)</h3>
<p>以上只是规则，并没有给出具体的算法。我们面临的相当于约束求解问题。我们用图组织描述出数据间的依赖关系，这样当某个数据变化的时候就可以沿着图更新被依赖的数据。</p>
<p>指针流图PFG是有向图。<span
class="math inline">\(Pointers=V\cup(O\times F)\)</span>
作为Nodes。边，则是<span class="math inline">\(Pointer \times
Pointer\)</span>上的值。</p>
<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 12%" />
<col style="width: 64%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr>
<th>Kind</th>
<th>Statement</th>
<th>Rule</th>
<th>PFG edge</th>
</tr>
</thead>
<tbody>
<tr>
<td>New</td>
<td>x = new T()</td>
<td><span class="math inline">\(\overline{o_i \in pt(x)}\)</span></td>
<td>无</td>
</tr>
<tr>
<td>Assign</td>
<td>x = y</td>
<td><span class="math inline">\(\frac{o_i\in pt(y)}{o_i\in
pt(x)}\)</span></td>
<td><span class="math inline">\(x\leftarrow y\)</span></td>
</tr>
<tr>
<td>Store</td>
<td>x.f = y</td>
<td><span class="math inline">\(\frac{o_i\in pt(x),\ o_j\in
pt(y)}{o_j\in pt(o_i.f)}\)</span></td>
<td></td>
</tr>
<tr>
<td>Load</td>
<td>y = x.f</td>
<td><span class="math inline">\(\frac{o_i \in pt(x),\ o_j \in
pt(o_i.f)}{o_j \in pt(y)}\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<p>New语句需要将对应Allocation
site加入x的指向范围，但是不引入依赖关系，因此对PFG没有影响。Assign语句<code>x=y</code>蕴含着无论y内有什么，都也要放到x内。因此每当y更新，也要更新x。而x变化却不会影响y。因此需要加入y指向x的边。Store语句和Load语句，增加了取属性的这个不确定的操作，因此采取保守策略，对每个可能被指向的对象，取f属性，执行Assign的操作。例如<code>x.f = y</code>就是对任何x可能的对象，加入y的值，因此需要y指向每个x可能指向的对象的f属性。</p>
<figure>
<img src="image-20210119134315358.png" alt="image-20210119134315358" />
<figcaption aria-hidden="true">image-20210119134315358</figcaption>
</figure>
<p><del>TODO:如何理解这里的<span
class="math inline">\(O_i.f\)</span>。我觉得拆开更好吧。设<span
class="math inline">\(O_i \in pt(c)\)</span>，设<span
class="math inline">\(O_k \in pt(d)\)</span>。由于<span
class="math inline">\(pt(c)\subseteq
pt(d)\)</span>，因此会存在属于d而不属于c的部分。所以应该单独拆出来一条边，<span
class="math inline">\(O_k.f\rightarrow
e\)</span>，这样更全面。ppt的写法多增加了a指向属于d而不属于c的部分的边，但我们是May
analysis，多增加依赖关系只是会扩大范围，可以接受。ppt中的<span
class="math inline">\(O_i.f\)</span>应该是合并起来了对所有f的域的引用节点。</del></p>
<p>这里没必要太看懂，继续往后学就好了。之后会为每个Allocation
site的object的每个域建立节点的。</p>
<h3 id="pfg上流动指向信息">PFG上流动指向信息</h3>
<p>指向信息可以顺着PFG流动，从而就直接获得了所有的指向关系pt。</p>
<p>然而这一过程和PFG的构建是相互依赖的。</p>
<h3 id="算法">算法</h3>
<figure>
<img src="image-20210119174158894.png" alt="image-20210119174158894" />
<figcaption aria-hidden="true">image-20210119174158894</figcaption>
</figure>
<p>之后学Datalog处理指针分析的时候我被震惊了，为什么我花大力气学的算法居然能被这种通用的引擎处理。我们之前学习了指针分析的规则，只需要填入初始数据，然后根据规则推导出最终结果即可，复杂之处在于各种规则间互相依赖，根据规则更新了这个数据又影响了那个数据，又要更新。仔细想想，这个算法的本质，就是处理规则间的互相依赖的关系，即当一个数据更新的时候会影响到其他什么数据，不断处理达到最终结果。</p>
<p>首先介绍工作的数据结构：PFG，保存依赖关系。S，程序中所有的语句。指向关系的增加通过Propagate函数中的pt(n)
并等于运算增加，也就是说最终还是反映到pt，这个算法内部没写出来的数据结构内。</p>
<p>WorkList
WL最特殊。每当某个指针需要增加指向的元素的时候，都要组成pair先放到WL里，有点递归的感觉。它是一个List，元素类型为(pointer,
pts)，其中pts是指针需要增加的指向的目标。即<span
class="math inline">\(WL \subseteq
&lt;Pointer,\mathcal{P}(O)&gt;\)</span>。</p>
<p>Solve函数中的处理工作队列的循环，就是负责处理某个指针需要增加元素的情况，也就是负责让增加的元素在PFG上流动，同时处理属性f
TODO。</p>
<p>结合Assign分支理解AddEdge函数：1.
去重：如果边已经存在，则直接返回。2.
让指向集合顺着PFG流动一步，不过也只是先加入工作队列。</p>
<p>主体函数Solve，首先处理掉了所有的普通变量Assign，和New语句。New语句：填了一些工作队列。Assign语句：向PFG中增加了普通变量关系的边，注意此时不会向工作队列增加新的内容，因为pt还是空的。</p>
<h5 id="differential-propagation">Differential Propagation</h5>
<p>工作队列循环，取出一个需要增加的pointer，对象集合的pair，然后找出真正增加的delta，调用Propagate函数，Propagate函数首先把增加的放到pt，也就是最终的结果集合中，然后找出受影响被更新的变量加入工作队列。这里只找出delta的技术称为Differential
Propagation。</p>
<p>这里Worklist的工作方法来看应该是广度优先的。虽然可能Worklist内还是会有冗余，但是在每次处理的这个关卡把住，去除掉重复的，那就能减少很多工作量。</p>
<h5 id="store-and-load">Store and Load</h5>
<p>来到WL工作循环的后半部分。忘掉执行顺序，把各种语句当作一条条约束需要理顺。这个for循环其实就是描述的一种约束关系：当某个变量的指向增加的时候，1.
<code>x.f = y</code>和<code>y = x.f</code>中的<code>x.f</code>会出现新的节点，需要增加PFG的边。</p>
<p>当给一个变量x增加了新的指向可能性的时候，我们开始处理相关的Store和Load情况。第一次执行到此处的时候，pt刚刚从空增加了x对应的对象。其他情况则是x增加了delta内的指向关系。对于delta内的每一个值，我们开始处理x的属性语句，对每个<code>x.f = ?</code>和<code>? = x.f</code>，我们需要假装每个delta里的对象是o_i内的元素，然后像Assign一样调用AddEdge。</p>
<p>理解<code>if n represents a variable x then</code>：这里if什么时候会不成立？当是属性的时候就不成立。1.
属性增加指向的时候意味着Store指令，即<code>x.f = y</code>这种形式，而不会是Load（<code>y= x.f</code>）。2.
我们处理的是3AC，不会有连续的取属性存在<code>x.f1.f2</code>。 =&gt;
这意味着某个变量的属性增加指向的时候，不会增加PFG的依赖关系。一方面<code>x.f=a</code>和<code>a=x.f</code>这两种语句的依赖关系已经被处理过了，另一方面不会存在<code>x.f1.f2=a</code>和<code>a=x.f1.f2</code>这样的语句。</p>
<p>总体来说就是多次取属性的操作会被临时变量拆分开。例如<code>b = new T(); a = b.f; c = a.f</code>，处理到具体Object（Allocation
site）节点的邻居也就是b节点的时候会先增加<span
class="math inline">\(T_1.f\)</span>节点和<span
class="math inline">\(T_1.f\rightarrow a\)</span>，
<strong>TODO</strong>。</p>
<p>是处理某个节点的时候增加和这个节点相邻的节点和相应的边吗？不完全是。处理<code>x.f=y</code>这样的语句，就是为o_i.f增加节点和指向它的边。毕竟不能在程序中直接写<code>o_i.f</code>这种，因为程序又不是基于Allocation
site的，所以必然会有<code>x.f=y</code>这样的x，代表各种allocation
site。于是在x增加指向的时候，就需要处理对应属性节点的增加。此外，还会增加<code>e=x.f</code>这样的数据边，从而增加e这样的新变量。</p>
<p>如何结合Java的分析来理解？我们现在是Context
insensitive的。把每个局部变量加上类和函数的前缀做区分，应该就对应着我们的Variable？</p>
<p>TODO：多对着例子自己推导几遍。多把公式总结几遍。</p>
<h3 id="总结">总结</h3>
<ol type="1">
<li>所有New</li>
<li>所有Assign</li>
<li>Loop：
<ol type="1">
<li>Propagate：增加指向 -&gt; 流动一步</li>
<li>遍历Δ × {Store, Load} 执行Assign操作</li>
</ol></li>
</ol>
<h2 id="指针分析基础-2">10-指针分析基础-2</h2>
<p>本节课的任务只有一个：掌握跨函数的指针分析的算法。</p>
<p>对于语句<code>r = x.foo(a1, a2)</code>，公式基本上是说，如何解决参数指向，如何解决this指向，如何解决返回值的流向。特别注意this指针，不添加PFG边，而是直接暂时传过去？TODO</p>
<figure>
<img src="image-20210119202248454.png" alt="image-20210119202248454" />
<figcaption aria-hidden="true">image-20210119202248454</figcaption>
</figure>
<h3 id="公式分析">公式分析</h3>
<p>公式可以拆分来看，把相同的元素如O_i先看条件中关于O_i的部分，再看结论中关于o_i的部分。</p>
<ol type="1">
<li><p><span class="math display">\[
\frac{o_i\in pt(x), m = Dispath(o_i,k)}{o_i \in pt(m_{this})}
\]</span></p>
<p>因为Allocation
site的Object是真实的，所以每个o_i也是真实的，不再需要像CHA那样猜测每个子类。所以Dispatch一次就可以得到真正被调用的方法。</p>
<p>这个公式给出了method的查找方法，以及this指针的指向。</p></li>
<li><p><span class="math display">\[
\frac{o_u \in pt(aj), 1\le j\le n}{o_u \in pt(m_{pj}), 1\le j\le n}
\]</span></p>
<p>这个比较直观？描述了argument传递变成parameter。即 <span
class="math display">\[
a1\rightarrow m_{p1},a2\rightarrow m_{p2},...,an\rightarrow m_{pn},
\]</span></p></li>
<li><p><span class="math display">\[
\frac{o_v\in pt(m_{ret})}{o_v\in pt(r)}
\]</span></p>
<p>也简单，描述了函数返回值的指向传递给调用处接收的变量，即<span
class="math inline">\(r\leftarrow m_{ret}\)</span>。</p></li>
</ol>
<h3 id="pfg不增加x-m_this">PFG不增加x-&gt;m_{this}</h3>
<figure>
<img src="image-20210120114313716.png" alt="image-20210120114313716" />
<figcaption aria-hidden="true">image-20210120114313716</figcaption>
</figure>
<p>PFG中增加边表示的是依赖关系，<code>m_this = x</code>，如果增加了，那x的所有可能指向都会流向那个函数的指针，如图中，画横线的部分是明显不合适的，因为this指针不可能是那个类型。</p>
<p>从公式的角度讲，关键在于m是依赖于o_i取值的。也就是先外层遍历o_i，确定了o_i的具体值之后，才能确定m，从而让此时的m_this会指向o_i。如果增加PFG边，则当o_i确定了后，pt(x)中的其他值也可能是this的指向，这明显不对。</p>
<p>所以虚线代表什么意思？表示需要分情况考虑，x中只有部分值能够流过去。只有Dispath后确实会返回该method的o_i才会沿着虚线流过去，即<span
class="math inline">\(for\ o_i\in pt(x), if\ m ==
Dispath(o_i,k)\)</span>。</p>
<p>而如果方法是静态的，那么就没有this指针。</p>
<p>是否是Context-sensetive了？不，每个method只考虑了一次，而并不是随着每次调用考虑。</p>
<h3 id="算法-1">算法</h3>
<figure>
<img src="image-20210120115755652.png" alt="image-20210120115755652" />
<figcaption aria-hidden="true">image-20210120115755652</figcaption>
</figure>
<p>ProcessCall就是增加一个foreach处理call的语句。call语句其实就是一个“大型”拓展CFG和赋值的语句。同时算法增加了从entry函数开始的探索方式，不可达的函数不会被分析，最终生成Call
Graph</p>
<p>给节点增加指向的时候要考虑沿着PFG的流动，因此要先加入工作队列，进行复杂的操作。那给当前可达语句集合增加一整个新函数的语句的时候，是否会对已有的结果产生影响？一方面由于函数作用域导致其他函数中的变量不会影响到这个函数，另外，不会增加已有的两个节点之间的边，因为<code>g1.f = g2.f2</code>这样的语句会被临时变量拆分开。所以增加一个可达函数的时候只是普通地处理New和Assign语句一次性解决，让新的边随着节点的增加而增加，不像增加指向的时候那么麻烦。</p>
<p>当某个变量的指向增加的时候，1.
<code>x.f = y</code>和<code>y = x.f</code>中的<code>x.f</code>会出现新的节点，需要增加PFG的边。2.
call调用的目标会增加：当x的指向范围更新了，那么此处就可能有新的方法被调用。因此像处理Load和Store一样，继续处理相关的call。有点类似<code>y= x.f</code>，但是拓展成了一整个函数。</p>
<p>算法和公式是对应的，算法的处理步骤为：1.
由于o_i已经确定，通过Dispatch计算得到m。2.
<del>增加当前o_i到m_this的边。</del>给m_this增加指向范围o_i到WorkList。这条边是独立于当前情况的，而之后的边都是每个（调用点，目标方法）只需要添加一次的。3.
判断是否加入Call Graph（同时去重），没有则加入Call
Graph，AddReachable并增加参数传递边，增加返回值传递边。</p>
<h3 id="总结-1">总结</h3>
<p>初始化新函数“大陆”AddReachable：不在可达函数列表则：加入可达函数列表，语句全部加入可达语句，处理New语句：增加队列，处理Assign语句：加边，流动。</p>
<p>处理调用语句：依次处理可达语句中所有的x.k：1.
Dispatch找到m，增加m_this的指向范围到队列。2.
若次处调用不在CallGraph（当前的（调用点，目标函数）对是新出现的）则：一.
增加CallGraph。2. 初始化新函数大陆。3. 加入参数边和返回值边。</p>
<p>总算法：1. 初始化entry函数大陆 2. 进入工作循环：</p>
<ol type="1">
<li><p>获取当前工作，计算Δ</p></li>
<li><p>Propagate：增加指向pt -&gt; 流动一步</p></li>
<li><p>遍历Δ × {Store, Load,
Call}。其中Store和Load作为Assign处理：加边，流动</p>
<p>Call指令单独处理。</p></li>
</ol>
<p>加入可达语句列表是为了接下来遍历变量x的Store, Load,
Call的时候会在里面找。由于变量都是局部变量（非局部变量都是域，需要先保存到局部变量），所有基本上只要在当前函数找行了？</p>
<p>普通函数调用怎么处理？是采取内联？不，应该只是call语句的不需要this指针的特殊情况。<code>r=x.f()</code>是在处理x的时候处理，但是静态函数调用没有x这样的对象，应该在初始化时处理参数和返回值的传递。</p>
<h2 id="实验四">实验四</h2>
<p>确实和讲的算法很对应。</p>
<ol type="1">
<li><p>回忆几种语句的规则处理</p></li>
<li><p>回忆几种数据结构</p>
<p>利用PFG指针流图辅助，最终的目标是计算pt。</p>
<p>其他辅助的数据结构：WL work list，S reachable statement，RM reachable
Method，CG call graph。</p></li>
<li><p>回忆算法流程</p>
<p>主循环把关好节点指向的增加，把指向沿着PFG传播。增加edge的时候也需要传播。传播由worklist负责。</p></li>
</ol>
<p>代码量挺小的。</p>
<h2 id="context-sensetive-指针分析-1">11-12-Context-Sensetive
指针分析-1</h2>
<p>不同的调用上下文中变量有不同的值，当C.I.的时候，会被混合并传播，进而形成假的数据流。</p>
<h3 id="不同的上下文">不同的上下文</h3>
<ol type="1">
<li>Call-Site Sensitivity：调用链作为上下文标识。衍生：k-Limiting
Context Abstraction</li>
<li>Object Sensitivity：Allocation site序列标识区分。衍生：Type
Sensitivity。在类似Java这样的OO语言中，比Call-Site
Sensitive的效果好。</li>
</ol>
<p>call-site
sensitivity是最古老的，最广为人知的方法。通过从entry开始的调用序列区分每次调用，仿佛每次执行到该函数的时候看一下backtrace区分不同的函数。在面向对象语言（如Java）中，Object
Sensitivity通常比Call-Site
Sensitivity表现更好。如果追求速度，可以进而选用Type Sensitivity。</p>
<figure>
<img src="image-20210121195350997.png" alt="image-20210121195350997" />
<figcaption aria-hidden="true">image-20210121195350997</figcaption>
</figure>
<p>如图中，静态方法调用传参的时候，需要将两次调用区分开，否则数据流就会在同一个参数n上汇聚交错。</p>
<p><strong>Cloning-Based Context Sensitivity</strong></p>
<p>每个方法由context区分，每个context
clone出来一个方法，仿佛是不同的方法似的单独考虑。而每个变量也继承方法的context标识，区分开。</p>
<h3 id="c.s.-heap">C.S. heap</h3>
<p>Java这样的方法非常依赖堆。Context标识也同样需要应用到堆分配上，即Allocation
site分配出的Object也要随着不同的Context区分开。想象有一个method专门用来分配对象，只有<code>return New A()</code>。则只有一个Allocation
site。如果所有的这样分配得到的Object只用一个Object表示，则会导致数据流在这个Object的field上混在一起。</p>
<p>Context-Sensetive不仅需要对不同的调用点利用上下文标识区分开分析，还需要Context-Sensetive
heap，区分在不同上下文中分配的对象。</p>
<p>然而C.S heap只有在C.S的时候才能提高精度。C.I.+ C.S.
heap进行分析时，C.S.
heap就不能提高精度了。因为。C.I.意味着不对函数做区分，C.S.
heap意味着依然对New出来的object依照backtrace做区分。但是由于不对函数和变量做区分，导致即使分配出来的object不同，也直接在allocation
site处被接收的临时变量混在一起，没有任何效果。</p>
<figure>
<img src="image-20210121204017858.png" alt="image-20210121204017858" />
<figcaption aria-hidden="true">image-20210121204017858</figcaption>
</figure>
<p>即图中虽然8行new
X();返回了不同的对象，但是直接在变量x上混在一起，即使区分出来了对象，对它们做的操作也是完全相同的，多出来的对象没有任何效果。</p>
<p>C.S. heap和真正的堆的辨析： TODO</p>
<p>C.S. heap随着Context对调用链的区分而区分不同Context分配的对象。</p>
<p>还是无法区分单次函数调用多次分配的对象，即循环中的Allocation
site的多次调用，Allocation site的固有限制。</p>
<h3 id="公式">公式</h3>
<figure>
<img src="image-20210121160102510.png" alt="image-20210121160102510" />
<figcaption aria-hidden="true">image-20210121160102510</figcaption>
</figure>
<p>Fields不用加Context表示，是因为它所附属的Object已经有了Context标识，毕竟Fields不能单独存在。</p>
<figure>
<img src="image-20210121160536010.png" alt="image-20210121160536010" />
<figcaption aria-hidden="true">image-20210121160536010</figcaption>
</figure>
<ol type="1">
<li>New语句：分配的Object的Context标记，和被赋值的变量一样，继承自当前函数调用的context
c。</li>
<li>Assign：object的传递保持Context标识不变。寻找变量y的时候，找的是当前context的变量。</li>
<li>Store、Load：object的传递保持Context标识不变。c,c'和c''表示当前函数，x指向的某个object，和这个object的域可能指向的object的Context都可能不一样。</li>
</ol>
<p>Call的公式如下： $$ {c':o_ipt(c:x)，\ m =
Dispatch(o_i,k), c^t=Select(c,l,c':o_i)\ c'':o_upt(c:aj),1jn\ c''':o_v
pt(c^t:m_{ret})}</p>
<p>{c':o_ipt(c^t:m_{this})\ c'':o_upt(c^t:m_{pj})\ c''':o_vpt(c:r)} $$
和之前Call的公式差不多，先遍历o_i然后Dispatch得到m，传递this指针。传递参数和返回值。</p>
<p>但是call也是生成新的Context标记的地方。Select的参数如下：</p>
<ol type="1">
<li>当前context：c。</li>
<li>call site的行号：l。</li>
<li>调用的接收对象：c':o_i。</li>
</ol>
<h3 id="算法-2">算法</h3>
<p>PFG自此也是带context的，称为Pointer Flow Graph with C.S.
体现在节点是带context标记的（变量或对象的域）。加边还是一样的加，只不过对同一个方法可能会clone出各种只有context不同的节点。</p>
<figure>
<img src="image-20210121190345121.png" alt="image-20210121190345121" />
<figcaption aria-hidden="true">image-20210121190345121</figcaption>
</figure>
<h3 id="object-sensitivity">Object Sensitivity</h3>
<p>每次函数调用的时候，首先拿来receiver
object的context作为基础，加上receiver object自身。由于我们是allocation
site的堆模型，因此这里的object其实就对于allocation site。</p>
<figure>
<img src="image-20210121201818813.png" alt="image-20210121201818813" />
<figcaption aria-hidden="true">image-20210121201818813</figcaption>
</figure>
<p>和Call-site Sensitivity对比：TODO</p>
<ol type="1">
<li>Object-sensetive还真就只关心Object。对同一个Object调用两次某方法无法区别。保持当前Object不变，把目标Object保存到域中，在另外一个方法里获取再调用，这样也无法区分。</li>
</ol>
<p>有没有任意长Call-site无法识别，而object sensitivity能够识别的？</p>
<p>任意长Call-site能否完全区分object sensitivity的所有情况？</p>
<h3 id="type-seneitivity">Type Seneitivity</h3>
<p>做实验才发现自己没弄清楚。</p>
<p>这是一种随着allocation增长的context。每次函数调用的时候，首先拿来receiver
object的context作为基础，加上receiver object的allocation
site这个语句所在的类。</p>
<p>类似于allocation的时候把所在的类拿过来增长一下，暂时存在object里，调用方法的时候拿出来。</p>
<p>context序列代表的是一路alloc的Object的语句所在的类型。</p>
<figure>
<img src="image-20210215110334026.png" alt="image-20210215110334026" />
<figcaption aria-hidden="true">image-20210215110334026</figcaption>
</figure>
<p>TODO：对比</p>
<h2 id="实验五">实验五</h2>
<p>Cloning-Based Context Sensitivity具体在代码中如何体现？在heap
model和调用时生成标签中，返回了不同的object，则会在PFG和最终的pt上产生不同的节点，从而增加精确性。</p>
<p>指针分析的类实例化后，通过下面的方式设置了heap model和contex
selector。我们需要的就是返回合适的context标记</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">pta.setHeapModel(<span class="keyword">new</span> <span class="title class_">AllocationSiteBasedModel</span>());</span><br><span class="line">pta.setContextSelector(<span class="keyword">new</span> <span class="title class_">ContextInsensitiveSelector</span>());</span><br></pre></td></tr></table></figure>
<p>谁应该被包裹在context里面？根据实验指导，是Callsite、Obj、Type(Method.getClassType)。另外还有两点需要注意，call-site
sensitivity对静态方法的处理和成员方法的处理相同。而对Object和Type
sensitivity来说则是不额外处理，直接传递context。</p>
<p>例如实现k=2的情况，当context没有那么多的时候，还是需要实验DefaultContext和OneContext。</p>
<p>初始化entry函数的时候，当前的Context就是default context。</p>
<p>生成Context标记就是函数调用的过程。可以想象一个函数调用，可能是静态调用，有Method，Callsite，还可能是成员函数，这样还有receiver
Object。</p>
<p>另外一个需要重视的地方就是Heap
Context。CS分析对堆分配也需要区分开来。分配的堆对象需要带上调用的函数的标记。在callsite-s里，不关心object，所以堆对象的context没什么影响。在object、type里，。。。</p>
<p>callsite也带Context吗？语句的context是不是就是Method的Context？</p>
<p>sootclasses-trunk-jar-with-dependencies.jar里面为什么带了bam**o，吓死人了，以为bam**o真的是soot的组成部分。可能是实验不得不用，而不想暴露实验的答案吧。不过jetbrains真是厉害啊，直接反编译了。</p>
<p>最后被坑的原因是：每个k-limiting的context selector，heap
context的limit是k-1。TODO：为什么</p>
<h2 id="安全相关的静态分析">13-安全相关的静态分析</h2>
<h3 id="访问控制-vs-信息流安全">访问控制 vs 信息流安全</h3>
<p>访问控制只是限制访问数据的对象，而信息流安全可以跟踪信息的处理，分配。感觉有点类似污点分析。</p>
<p>信息流，有点像指针分析里面的数据依赖关系PFG图。<code>x=y</code>这样就表示y的信息流向了x。</p>
<p>为信息分配密级，有点像访问控制，但不是访问的时候判断，拒绝，而是分析审计然后警报。</p>
<p>关键在于两点：</p>
<ol type="1">
<li><p>把信息分成不同的安全级别</p>
<p>复杂的级甚至可以是Lattice结构的，只有顺着图方向的流动才被允许。</p></li>
<li><p>信息流动策略：不可影响策略</p>
<p>高密级的变量不能影响到低密级的变量。</p></li>
</ol>
<h3 id="机密性和完整性">机密性和完整性</h3>
<p>机密性保证秘密数据不会泄露，代表了不允许低密级Read高密级。完整性保证重要数据不会被篡改，代表高完整度不可访问低完整度。</p>
<p>直接赋值这样的情况属于显式流动。然而还存在隐藏信道（Covert
Channels）。如：通过控制流影响其他变量，程序时间，触发异常等等信息。但是我们主要关注显式信道</p>
<h3 id="污点分析指针分析">污点分析+指针分析</h3>
<p>常规的污点分析似乎是指动态分析。而我们静态分析通过充分理解程序从而理解程序动态运行的行为，也可以用信息流来做污点分析。污点分析是使用最广泛的信息流分析，既可以分析机密性的泄露，也可以分析完整性是否被部分数据影响。</p>
<p>首先将我们感兴趣的信息标记为Tainted，信息源称为source（如把一些函数的返回值设置为source），其他数据是untainted。我们标记危险的函数为sink。我们分析就是试图找出从source流向sink的可能的路径。</p>
<p>把Source作为Allocation site，把Tainted
data作为(artificial)Object，作为所有Object中的一部分。并且增加新的生成tainted
Object的规则和收集Sink函数参数指向的规则。然后基于指针分析进行推导。</p>
<figure>
<img src="image-20210119215254928.png" alt="image-20210119215254928" />
<figcaption aria-hidden="true">image-20210119215254928</figcaption>
</figure>
<h2 id="datalog-based-program-analysis">14 Datalog-Based program
analysis</h2>
<h3 id="动机">动机</h3>
<p>如何让程序分析也能用描述式的方法，而不必关心具体实现？</p>
<h3 id="datalog">Datalog</h3>
<p>是Prolog的一个子集。没有副作用，没有控制流，没有函数，不是图灵完备的。由数据表Facts和逻辑Rules组成。Datalog不断推导出数据，因此是单调的。而由于规则是<code>安全</code>的，因此总的结果是有限的，所以最终总能停下来。</p>
<p>Predicates意为（谓词、判断）。一个谓词对应一个关系，代表一个数据表。对谓词带上参数成为一个fact，代表对参数中数据属于表中的断言。</p>
<p>Atoms
是Datalog中最基本的元素，形如<code>P(X1,X2,...,Xn)</code>的称为relational
atom。如果<code>(“Xiaoming”,18)</code>在表中，则<code>Age(“Xiaoming”,18)</code>为真。还有arithmetic
atoms，如<code>age &gt;= 18</code>这种变量判断。</p>
<p>Datalog
Rules形如<code>H &lt;-B1,B2,…,Bn.</code>，由Head，箭头，Body组成。意思是当body为true的时候Head也为true。其中<code>,</code>为与逻辑，<code>;</code>为或逻辑，<code>!</code>为非逻辑，复杂逻辑最好多加加括号。</p>
<p>考虑如下规则：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Adult(person) &lt;- Age(person,age), age &gt;= 18.</span><br></pre></td></tr></table></figure>
<p>Datalog可能会遍历Age表赋值person和age变量，然后推导，得到每个Person的Adult是否为true。</p>
<p>谓词分为EDB（extensional database）、IDB（intensional
database）。EDB为给定的数据，IDB是推导出的数据。</p>
<p>Datalog最关键的是支持递归：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Reach(from, to) &lt;- Edge(from, to).</span><br><span class="line">Reach(from, to) &lt;- Reach(from, node), Edge(node, to).</span><br></pre></td></tr></table></figure>
<h3 id="规则安全性">规则安全性</h3>
<p>A rule is safeif every variable appears in at least one
non-negatedrelationalatom</p>
<p>每个变量至少要出现在右侧relational atom一次，被取反的不算。</p>
<p>为了防止自我矛盾：<code>A(x) &lt;- B(x), !A(x)</code>，被取反的不能是当前被递归的。</p>
<h3 id="datalog进行指针分析">Datalog进行指针分析</h3>
<figure>
<img src="image-20210121225505327.png" alt="image-20210121225505327" />
<figcaption aria-hidden="true">image-20210121225505327</figcaption>
</figure>
<figure>
<img src="image-20210121225653380.png" alt="image-20210121225653380" />
<figcaption aria-hidden="true">image-20210121225653380</figcaption>
</figure>
<p>同理，函数调用也被拆分成了三个规则，分别处理this指针，参数，返回值。</p>
<h3 id="datalog进行污点分析">Datalog进行污点分析</h3>
<p>在指针分析的基础上，增加Source表，Sink表，Taint表（call site -&gt;
tainted data）。最终推导出Taint Flow。</p>
<figure>
<img src="image-20210121225956439.png" alt="image-20210121225956439" />
<figcaption aria-hidden="true">image-20210121225956439</figcaption>
</figure>
<p>在指针分析的基础上处理好Source和Sink的情况。把Sink的情况收集起来。</p>
<h3 id="总结-2">总结</h3>
<p>Datalog类似于我们把表格里的公式输入进去，而不管算法部分。</p>
<p>我们学习的算法的好处主要在于精确知道每一步推导对下一步推导的影响是什么。每一步都精确知道下一步该做什么，从而提升效率。</p>
<h2 id="soundness-and-soundiness">15 Soundness and Soundiness</h2>
<p>Soundness关注的是能完全包含真正程序运行的所有可能行为。而实际生活中很难实现。难点如下：</p>
<ol type="1">
<li>Java：反射，native汇编代码，动态类加载</li>
<li>JavaScript：eval函数，DOM等</li>
<li>C/C++：指针的运算，函数指针</li>
</ol>
<p>这些特性过于灵活，强行加以分析只能过度估计，导致过于不精确的结果。因此非专业人士可能过度相信结果（在sound
core上的），专业人士也无法精确解释分析结果到底有多准确。</p>
<h3 id="避开的方法">避开的方法</h3>
<ol type="1">
<li>sound core：部分特性能够Sound分析，特定部分或者太难分析的部分会
under-approximate。提取出适合的作为语言的sound core。</li>
<li>难以分析的特性考虑采取临时策略。</li>
</ol>
<h3 id="soundy">Soundy</h3>
<p>soundy的分析能在unsound处理部分特性的基础上，尽可能抓住所有程序可能的行为。unsound的分析是为了速度或效率等因素，存在忽视部分unsound的行为。</p>
<h3 id="java-reflection">Java Reflection</h3>
<p>最难处理的特性。如果碰到了不分析，肯定会损失一些函数调用、变量赋值。</p>
<ol type="1">
<li>StringConstantanalysis+PointerAnalysis：如果class名，method名，field名是静态字符串，则可以进行分析。</li>
<li>TypeInference+Stringanalysis+PointerAnalysis：调用点看看有没有已知类型的参数（借助指针分析），缩小被调用方法的范围。另外看返回值如果被强制类型转换通过返回值类型推断。getFiled操作通过object的类型，也可以通过返回值的强制类型转换。setField操作通过object类型和传入的类型判断。</li>
<li>Assisted by Dynamic Analysis：custom class loader。</li>
</ol>
<h3 id="native-code">Native code</h3>
<p>感觉native
code，除了实现功能，操作起java来就是reflection式的操作。</p>
<ol type="1">
<li>手动对关键native代码建模：分析时使用Java代码模拟、描述JNI的效果。</li>
<li>BinaryScanning</li>
</ol>
<h2 id="cfl-reachability-and-ifds">16 CFL-Reachability and IFDS</h2>
<p>一方面通过定义Realizable的路径，通过识别并去除un-Realizable的路径，CFL-Reachability，达到了函数调用路径匹配的效果，而不需要Context-sensetive。
TODO CFL-Reachability不太懂</p>
<p>另外学习怎么构造Exploded
Supergraph，构造出来就可以发现，可以将部分程序分析问题表达在图上，通过图可达性解决程序分析问题。</p>
<h3 id="函数调用流匹配">函数调用流匹配</h3>
<p>回忆Meet-Over-all-path，是将所有可能的路径找出，依次计算每个路径，再合并。在函数调用过程中的调用边和return边匹配，导致走return边的时候只有一条真正路径<code>RealizablePaths</code>，其他的并不是真正可执行的路径。</p>
<p>这种调用边导致的问题，可以通过类似括号匹配的算法识别不对的路径并避免。这里引入context-free
language，若某路径在该语言中，称为有CFL-Reachability。调用边作为左括号，加上特有标号，只和同样标号的return边匹配。中间可以有任意的普通边。这里识别的是任意点到任意点的路径，不一定是完整的路径，因此可能会留下待之后被匹配的左括号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">realizable -&gt; matched realizable</span><br><span class="line">-&gt; (_i realizable</span><br><span class="line">-&gt; ε</span><br><span class="line">matched -&gt; (_i matched )_i</span><br><span class="line">-&gt; e</span><br><span class="line">-&gt; ε</span><br><span class="line">-&gt; matched matched</span><br></pre></td></tr></table></figure>
<h3
id="ifdsinterproceduralfinitedistributivesubset-problem">IFDS(Interprocedural,Finite,Distributive,Subset
Problem)</h3>
<p>IFDS处理跨函数的数据流分析，在有限域上，基于distributive的flow
function。提供meet-over-all-realizable-paths(MRP)的结果。主要步骤：</p>
<ol type="1">
<li>构建super graph<span
class="math inline">\(G^*\)</span>（即带call边和return边）</li>
<li>根据需要分析的问题，定义edge的flow function</li>
<li>构建exploded supergraph <span
class="math inline">\(G^\#\)</span>，将流函数转换为graph。TODO</li>
<li>将需要分析的问题Q通过图可达性解决：在<span
class="math inline">\(G^\#\)</span> 上用Tabulation algorithm。</li>
</ol>
<p>Path function 记作 <span
class="math inline">\(pf_P\)</span>，是某条path p上所有Flow
Function的复合。 <span class="math display">\[
pf_P=f_n\circ...\circ f_2\circ f_1
\]</span> MOP和MRP的区别就在于只取了部分realizable的path。 <span
class="math display">\[
MOP_n =\mathop{\sqcup}\limits_{P\in Paths(start,n)} pf_p(\bot)
\]</span></p>
<p><span class="math display">\[
MRP_n =\mathop{\sqcup}\limits_{P\in RPaths(start,n)} pf_p(\bot)
\]</span></p>
<h3 id="supergraph">Supergraph</h3>
<p><span class="math display">\[
G^*=(N^*,E^*)
\]</span></p>
<p>将每个函数的flow graph <span
class="math inline">\(G_1,G_2,...\)</span>放在一起，每个唯一的入口点为<span
class="math inline">\(s_p\)</span>，唯一的出口点为<span
class="math inline">\(e_p\)</span>。每个函数调用点设置node为call node
<span class="math inline">\(Call_p\)</span>，return的点设置node<span
class="math inline">\(Ret_p\)</span>。</p>
<p>每个函数调用有三条边：</p>
<ol type="1">
<li>call-to-return-site edge：<span
class="math inline">\(Call_p\)</span>到 <span
class="math inline">\(Ret_p\)</span>的短边</li>
<li>call-to-start edge：<span
class="math inline">\(Call_p\)</span>到<span
class="math inline">\(s_p\)</span>的调用边</li>
<li>exit-to-return-site edge：<span class="math inline">\(e_p\)</span>
到<span class="math inline">\(Ret_p\)</span>的返回边。</li>
</ol>
<p>最后要给每条边加上lambda函数，首先明确研究的问题</p>
<p>我们定义研究的问题是未初始化的变量被使用的问题。S表示为初始化的变量集合。初始的时候设置为所有变量：<code>λS.&#123;x,g&#125;</code>，每次初始化变量<code>x=0</code>就删去对应的变量：<code>λS.S-&#123;x&#125;</code>。</p>
<p>加上lambda函数的要点：</p>
<ol type="1">
<li>虚线（调用边和返回边）不传递当前的局部变量，只传递参数（和全局变量）。由call
to return
小短边传递局部变量。全局变量也从call边流入，让未初始化的全局变量从return边流回。</li>
<li>调用边的lambda函数需要将传入的参数重命名。返回边需要删去离开作用域的局部变量</li>
<li>使用已有的变量运算需要注意未初始化变量的污染性，运算如果有未初始化值参与，结果也是未初始化的。</li>
</ol>
<figure>
<img src="image-20210128124537981.png" alt="image-20210128124537981" />
<figcaption aria-hidden="true">image-20210128124537981</figcaption>
</figure>
<h3 id="exploded-supergraph">exploded supergraph</h3>
<p>representation relation <span
class="math inline">\(R_f\)</span>指的是之前讲到的lambda函数的关系形式的表示，用于构建Exploded
Supergraph。Exploded
Supergraph将原有的Supergraph的每个节点变成（"explode
into"）D+1个节点，每条边变成对应λ函数的关系表示而得到的巨大的图。</p>
<ol type="1">
<li>边merge的时候怎么办？当然是直接将输出使用同一套节点，此时节点会被多次指向。这差不多是并运算吧。</li>
</ol>
<h4 id="representation-relation">representation relation</h4>
<p>D+1个输入节点，D+1个输出节点。关系就是这（D+1）×（D+1）上有序对的集合。
<span class="math display">\[
R_f = \{(0,0)\} \qquad Edge: 0 \rightarrow 0 \\
\cup \{(0,y)|y\in f(\phi) \} \qquad Edge: 0 \rightarrow d_1 \\
\cup \{ (x,y)\ |\ y \not\in f(\phi)\ and\ y \in f(\{x\}) \} \qquad Edge:
d_1 \rightarrow d_2
\]</span> 公式含义：</p>
<ol type="1">
<li>首先一定有（0，0）边。</li>
<li><span
class="math inline">\(f(\phi)\)</span>指即使输入空集（从0节点进入）也能增加的元素。即gen。
TODO check</li>
<li><span class="math inline">\(f(\phi)\)</span>和<span
class="math inline">\(f(\phi)\)</span>之外的元素分开考虑。意味着如果存在（0，y1），则不会有其他元素也指向y1。</li>
<li>接下来看<span
class="math inline">\(f(\phi)\)</span>之外的元素，是否存在输入x的时候的输出<span
class="math inline">\(f(\{x\})\)</span>是对应的y，有则加入（x,y）边。</li>
<li>可以发现，去掉某个元素时（kill），则没有任何边指向它（以它为终点）。</li>
</ol>
<figure>
<img src="image-20210128152531750.png" alt="image-20210128152531750" />
<figcaption aria-hidden="true">image-20210128152531750</figcaption>
</figure>
<h4 id="flow-function表达data-fact">Flow Function表达data fact</h4>
<p>看单个flow
function的图，如果能走到下方的某个点，则表示此处的OUT包含它。</p>
<p>TODO</p>
<ol type="1">
<li>为什么traditional flow function不能复合到一起？</li>
<li>将多个连接起来的图中入口到出口的可达关系，压缩成单个图，就是将多个flow
function复合起来？</li>
</ol>
<figure>
<img src="image-20210128160132226.png" alt="image-20210128160132226" />
<figcaption aria-hidden="true">image-20210128160132226</figcaption>
</figure>
<p>此外，此时再回顾之前unrealizable的path的识别，就会发现派上用场了。不只要可达，还要realizable。因此该问题也不是简单的图可达性问题。</p>
<h4 id="tabulation-algorithm">Tabulation Algorithm</h4>
<p>如果存在realizable路径，从&lt;s_main,0&gt;到&lt;n,d&gt;，则表示在n这点处有d这个data
fact，此时d会被涂成蓝色。而且提供的是MRP的方案。</p>
<p>简单来说：从起始点开始，把可达的点标记成蓝色。不详细学习算法</p>
<ol type="1">
<li>处理返回的时候，需要找到对应的调用边返回</li>
<li>第一次处理的时候将函数调用总结成一个summary
edge。（把整个函数的调用到结束点的可达关系总结起来？？TODO）之后再次调用相同函数的时候复用结果</li>
<li>可达的点都标蓝</li>
</ol>
<h3 id="distributivity">Distributivity</h3>
<ol type="1">
<li><p>能否做常数传播（constant
propagation）？它是之前那个比较特殊的，域是无限的。那我只考虑有限的常量可以吗？NO</p>
<p>TODO</p></li>
<li><p>能否做指针分析？NO</p></li>
</ol>
<p>Distributivity（分配性）：F(X^Y) = F(X) ^ F(Y)。</p>
<p>仔细想想flow
function的图表示，可以发现无法表示both逻辑，即需要两个输入同时成立，才会成立结果。</p>
<p>如果需要多个input data
facts得出一个新的结果，则此时该分析就不满足分配性，不能用IFDS。因为IFDS将每个data
fact，和它的传播（每个edge）分开单调考虑了。</p>
<p>思考题：</p>
<figure>
<img src="image-20210128165511145.png" alt="image-20210128165511145" />
<figcaption aria-hidden="true">image-20210128165511145</figcaption>
</figure>
<p>TODO</p>
<h4 id="ifds与指针分析">IFDS与指针分析</h4>
<p>看下面的例子：</p>
<figure>
<img src="image-20210128165817475.png" alt="image-20210128165817475" />
<figcaption aria-hidden="true">image-20210128165817475</figcaption>
</figure>
<p>这个例子说明通过IFDS进行指针分析的致命问题是别名信息。假设x和y是别名，为了得到正确的结果，需要同时考虑x和y，因此最后分析起来还是不满足分配律的。</p>
<p>TODO</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>PL</tag>
      </tags>
  </entry>
  <entry>
    <title>烽火HG6201M交叉编译transmission</title>
    <url>/2019/HG6201m%E5%85%89%E7%8C%AB%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/</url>
    <content><![CDATA[<h1
id="烽火hg6201m交叉编译transmission成功">烽火HG6201M交叉编译transmission成功!!</h1>
<p>我家本来wifi是靠二楼的路由器的，后来发现光猫可以发射wifi，没想到三楼的光猫信号比二楼的wifi还好！！
自从看到了这个光猫的账号密码，而且光猫带usb接口，登进去发现内存和cpu都很不错，而且自带samba文件共享！！顿时我对这款光猫就陷入了无尽的崇拜,甚至想再买一块来当开发板玩。</p>
<span id="more"></span>
<p>最近用惯了samba共享硬盘做nas，而且手头刚好有一个功率更大的和光猫电源相同dc头的12v电源，也不用怕硬盘供电不足了哈哈哈。正好硬盘盒有多，直接一个usb接上去。</p>
<p>bt做种本来有很多大文件，我用fat32的文件系统被4g的限制卡住肯定不行，我直接接我的硬盘，NTFS分区不能识别，我就想着编译一个ntfs-3g进去，但是后来没想到这光猫居然支持ntfs！！只不过不支持GPT的分区表，我改成MBR的分区表就成了，插上去自动识别！！连接后自动挂载到/mnt下，usb1_n这种格式！！不过没想到它似乎不支持ext系列文件系统。</p>
<p>接下来就是编译transmission了，为了transmission，还要编译各种它的依赖，curl，openssl什么的。openssl的动态库在光猫里有，但是因为没有头文件不能用在transmission里。。。我只能从头开始，先想办法安装旧版本的gcc，然后还不能直接上最新版本，各种挑选合适的旧版本，编译zlib，openssl，curl，libevent，百度解决各种报错，最后终于编译出来了transmission。而且我想着有了curl就可以自己写脚本搞ddns了！最近光猫有了ipv6，这样我无论在哪里都可以访问我的NAS了哈哈哈（后来发现这个ipv6虽然是公网的，但经常ping不通，无语。不知道为什么，可能移动的ipv6的路由没做好？）
然而我高兴得太早了，一运行curl就说invalid
instruction。依赖curl的transmission也是，会报错不能运行。现在看感觉可能和openssl没选好架构，没加-mtune
34kc这个编译选项有关系。
最简单的交叉编译还是GO语言的，windows下一个环境变量就搞定了，可以直接放过去跑。</p>
<p>最后我还是失去了兴趣，入了openwrt的设备做nas。</p>
<p>之前了解到buildroot这个东西，听说它先要编译一个gcc，再用新的gcc去编译libc，整个linux系统等等东西，感觉它编译的太多了会很麻烦，没想到这才是真正方便的方法啊！！！这几天搞了一下，很容易就成功了。然而我已经买了其他设备做nas了。只能希望能帮到其他想拿这个光猫做NAS的人吧。</p>
<p>这光猫的web端用的是java，印象里java是很大一个，很占内存的，它居然能跑起来，虽然不知道是不是标准版的。而且这光猫的cpu使用率感觉从来都是20%以下，一般只有个位数。内存好像也挺大的。我之前网有一段时间很卡，而且光猫的samba也，就一直在怀疑是不是光猫，后来发现是蓝牙</p>
<p>------------光猫相关信息------
https://www.right.com.cn/forum/thread-783839-1-1.html
光猫各个挂载点都满了，几M的空间都没有，除了/osgi目录，大概有50M的空间？不记得了。编译好的东西可以放在这里或者直接放在挂载的硬盘或者优盘上面。</p>
<p>在根目录下面到处翻，还是能找到很多他们开发系统的信息的，要是没找到他们用的buildroot和linux内核版本，我可能就不会搞这个编译了。</p>
<p>好像是MTK的什么CPU，没有什么路由器用同款。 光猫是MIPS架构 大端序
mips32v2 34kc架构</p>
<p>下面是翻到的一些关键信息：
2017108-SmartHG_MTK7526_Engineering_CMCC-coverity Linux (none)
2.6.36-svn159641 #15 SMP Thu Nov 2 10:18:12 CST 2017 mips unknown
mips-linux-glibc-4.9.3
proj/mtk04854/glibc-4.9.3/buildroot-2015.08.1/output/build/glibc-2.20/build/csu/start.o</p>
<p>--------编译过程------------
我顺便上传下我的build-root的.config文件。
用别人的二进制文件确实不好，万一被下了毒呢。不过我还是把我编译好的上传一下，毕竟自己之前也想下载别人编译好的。
总之用ubuntu，去buildroot官网下载2015.08.1的版本，然后解压，把.config文件覆盖进去，就可以编译了。主要是选择对mips32，再选v2架构，toolchain里选2.6.36内核头文件
如果选glibc-4.9.3，它要求动态编译，我想了想还是选了静态编译，用uglibc，反正静态编译不需要加载库，这个版本不一样没关系。
gcc里面我勾选了c++支持和宽字符支持（不选宽字符可以少一个报错），nano需要宽字符。然后再勾选想要的包。直接选transmission，我还选了nano，vi一直懒得学用得不习惯。然后看什么顺眼就选了什么。我瞎选了很多包，导致要下载很多东西。
还有一个地方选并行数，根据cpu线程数选吧，我选了8。类似于make -j8吧。
buildroot真是强啊，想要什么包选什么包
或者把我上传的.config文件放到目录下，相当于使用我的配置了，可以看着上面的图片在配置里删。然后直接make。
接下来就是解决下载国外网站的网速问题了。可以考虑先全部下载好放到dl文件夹里面。省的卡在那里。不过这些源码包都挺小的。
或者有条件的直接proxychains -q make</p>
<p>这里会遇到几个报错，直接按顺序给出对应的解决网址：大家见招拆招吧</p>
<ol type="1">
<li>一开头就遇到的host-m4什么的错误
https://blog.csdn.net/Jun626/article/details/104870430</li>
<li>uclibc的宽字符的报错（不选宽字符就不会有吧）：
https://dev.archive.openwrt.org/ticket/13095.html
这个需要下载patch打patch -p1</li>
<li>gcc-final的
https://unix.stackexchange.com/questions/335717/how-to-handle-error-compiling-gcc-4-7-0-using-gcc-6-2-1</li>
</ol>
<p>我编译了算是2.5次，一次是编译的动态库，顺便也发出来吧，后面又觉得要选宽字符。大概率不会遇到什么其他的报错了。
跑起来挺快的。不包括解决报错的时间只花了半小时不到。</p>
<p>--------光猫的samba-------
ps一下就可以看到运行的smbd的路径，也可以找到改密码的smbpasswd。这里的用户好像要和linux系统中的用户对应，但是不好创建用户，所以推荐使用root用户，好像是smbpasswd-aroot然后就可以设置密码。然后在配置文件里面允许下root登录。因为感觉不设密码还是不安全</p>
<p>下面贴出我光猫samba的配置文件。之前配的时候看日志发现不能设置charset，因为编译的时候就不支持其他charset。我也不记得改了哪里了，应该能用吧
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">smbpasswdfile=/flash/cfg/app_conf/samba/smbpasswd</span><br><span class="line">workgroup=WORKGROUP</span><br><span class="line">guestaccount=root</span><br><span class="line">netbiosname=Fiberhome-samba_test</span><br><span class="line">serverstring=SambaServer</span><br><span class="line">dnsproxy=no</span><br><span class="line">#displaycharset=cp936</span><br><span class="line">#unixcharset=UTF-8</span><br><span class="line">#doscharset=cp936</span><br><span class="line">loglevel=0</span><br><span class="line">logfile=/dev/null</span><br><span class="line">interfaces=0.0.0.0/0[::]/0</span><br><span class="line">loadprinters=no</span><br><span class="line">security=user</span><br><span class="line">socketoptions=TCP_NODELAYSO_RCVBUF=65536SO_SNDBUF=65536</span><br><span class="line">usesendfile=yes</span><br><span class="line">deadtime=5</span><br><span class="line">[usbshare]</span><br><span class="line">comment=AllStoragedevices</span><br><span class="line">forceuser=root</span><br><span class="line">forcegroup=root</span><br><span class="line">public=no</span><br><span class="line">writable=yes</span><br><span class="line">browseable=yes</span><br></pre></td></tr></table></figure></p>
<hr />
<p>其实这些编译的东西我没有全部测试，毕竟已经买了openwrt做NAS，我就用了下curl是正常的，使用https需要设置-cacert到旁边的etc/ssl/certs/ca-certificates.crt。感觉应该能用，不会真的打脸翻车，又报invalid
instruction吧，不过跑transmission需要自己搞一个配置文件，启动的时候设置好配置文件夹的路径。
顺便还编译了nginx 建议使用前做好备份，万一误删了什么就不好了。
这里都是静态编译的，直接把想要的复制出来放到优盘里，再插上光猫，开启telnet进去启动。比如transmission-daemon复制出来，在旁边的文件夹放好配置文件，启动的时候加上参数。
可以加上自己的开机启动脚本。开机自动启动一下transmission，然后再自己写个ddns脚本更新ipv6地址。参考：https://hotfeel.me/?p=119</p>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>Embedded</tag>
      </tags>
  </entry>
  <entry>
    <title>Java复习笔记</title>
    <url>/2019/Java%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="java复习笔记">Java复习笔记</h1>
<ol type="1">
<li>各种数据类型的存储范围 <span id="more"></span></li>
</ol>
<h3 id="下面摘自清华的java慕课课件">下面摘自清华的java慕课课件</h3>
<ol start="2" type="1">
<li><p>标识符 ▫ 标识符是一个名称，与内存中的某个位置（地址） 相对应 ▫
标识符的第一个字符必须是下列字符之一：  大写字母 (A-Z)  小写字母 (a-z)
 下划线(_)  美元符号 ($) ▫ 标识符的第二个字符及后继字符必须是： 
上述列表中的任意字符  数字字符 (0-9)</p></li>
<li><p>数值型文字量 数据类型 文字量 byte,short,int
十进制数，开头不为0；0X跟十六进制数，如0XF1C4； 0跟八进制数，如0726 long
同上，但后面跟l或L，如：84l，0X1F39L float
数字后跟f或F，如1.23456F，1.893E2F double 后面可选d或D做后缀，如：1.23D
boolean true或false</p></li>
<li><p>扩展转换 ▫ byte, char, short, int, long, float, double ▫
从一种整数类型到另一种整数类型，或者从 float到double的转换不损失任何信息
▫ 从整数类形向float或double转换，会损失精度 • 窄化转换 ▫ double, float,
long, int, short, byte,char ▫ 窄化转换可能会丢失信息</p></li>
<li><p>隐含转换 ▫ 赋值转换  将表达式类型转换为制定变量的类型 ▫
方法调用转换  适用于方法或构造方法调用中的每一个参数 ▫ 字符串转换 
任何类型（包括null类型）都可以转换为字符串类型 
只当一个操作数是String类型时， 适用于+运算符的操作数</p></li>
<li><p>数组是对象 ▫ 动态初始化 ▫ 可以赋值给Object类型的变量 ▫
在数组中可以调用类Object 的所有方法 ▫ 每个数组都有一个由 public final
修饰的成员变量： length ，即数组含有元素的个数（length可以是正
数或零）</p></li>
</ol>
<p>注：声明新数组时的new也一样说明了数组是一个Object
<code>arrayName=new Type[componets number];</code>
这里数组也像其他类一样做了自己的初始化（给自己分配空间）。</p>
<ol start="7" type="1">
<li>两种数组 基本类型数组的每个元素都是一个基本类型的变
量；引用类型数组的每个元素都是对象的的引用</li>
</ol>
<p>创建数组的时，如果没有指定初始值，数组 便被赋予默认值初始值。 ▫
基本类型数值数据，默认的初始值为0； ▫ boolean类型数据，默认值为false; ▫
引用类型元素的默认值为null。</p>
<ol start="8" type="1">
<li><p>复制数组
<code>public static void arraycopy(Object source , int srcIndex ,Object dest , int destIndex , int length )</code></p></li>
<li><p>数组的数组 <code>int[ ][ ] myArray = new int[3][5] ;</code>
我之前错误的理解方式是int[3]作为一个类型，int[3][5]就是5个长3的数组。
但是还是python的理解方式对 <code>myArray = [int[5],int[5],int[5]]</code>
所以无论是new后面的int[3][5],还是取值时的myArray[2][4],都表示取出。int[3]表示第一次可以取三个，从0到2，myArray[2][4]表示先取第三个再取第五个。
现在回首发现好像所有的语言数组都是这样的，行优先</p></li>
<li><p>switch switch-expression、常量值value1到valueN必须是整形或字符型
但是最近好像增加了对string的支持</p></li>
<li><p>逗号 java里不用逗号符，但是可以用于for语句里面的分隔</p></li>
<li><p>可变长参数 • 可变长参数使用省略号表示，其实质是数组。 •
例如，“String … s”表示“String[] s” 。 •
对于具有可变长参数的方法，传递给可变长参数的实际参数可以是
零个到多个对象。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static double maxArea(Circle c, Rectangle... varRec) &#123;</span><br><span class="line">Rectangle[] rec = varRec;</span><br><span class="line">for (Rectangle r : rec) &#123;</span><br><span class="line">//…</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>包 一个包可以包含若干个类文件，还可包含若干个包</p></li>
<li><p>编译单元 • 一个Java源代码文件称为一个编译单元，由三部分组成： ▫
所属包的声明（省略，则属于默认包）； ▫ Import
（引入）包的声明，用于导入外部的类； ▫ 类和接口的声明。 •
一个编译单元中只能有一个public类，该类名与文件名相同，编译
单元中的其他类往往是public类的辅助类，经过编译，每个类都会
产一个class文件。</p></li>
</ol>
<p>注：所以并不是一个文件只存一个类，而是只让存一个public类</p>
<ol start="15" type="1">
<li><p>类的成员访问权限控制 公有(public) ▫
可以被其他任何方法访问(前提是对类成员所属的类有访问权限) •
保护(protected) ▫ 只可被同一类及其子类的方法访问 • 私有(private) ▫
只可被同一类的方法访问 • 默认(default)(无修饰) ▫
仅允许同一个包内的访问；又被称为“包（package)访问权限”
注：主要不记得最后的默认</p></li>
<li><p>构造方法内的this关键字 •
可以使用this关键字在一个构造方法中调用另外的构造方法； •
代码更简洁，维护起来也更容易； •
通常用参数个数比较少的构造方法调用参数个数最多的构造方法。</p></li>
<li><p>对象的自动回收 • 无用对象 ▫ 离开了作用域的对象； ▫
无引用指向对象。 •
Java运行时系统通过垃圾收集器周期性地释放无用对象所使用的内存。 •
Java运行时系统会在对对象进行自动垃圾回收前，自动调用对象的finalize()方法。</p></li>
<li><p>finalize()方法 • 在类java.lang.Object中声明，因此 Java中的每一
个类都有该方法： protected void finalize() throws throwable •
用于释放资源。 • 类可以覆盖（重写）finalize()方法。 •
finalize()方法有可能在任何时机以任何次序执行。</p></li>
<li><p>枚举类 特点： 一、 只有有限个实例化的对象 --&gt;可以用==判断
所有枚举类型都隐含继承（扩展）自java.lang.Enum，因此枚举类型不能再继承其他任何类
枚举类型的构造方法必须是包内私有或者私有的。定义在枚举开头的常量会被自动创建，不能显式地调用枚举类的构造方法。
例子： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public enum Planet &#123;</span><br><span class="line">MERCURY (3.303e+23, 2.4397e6),</span><br><span class="line">VENUS (4.869e+24, 6.0518e6),</span><br><span class="line">EARTH (5.976e+24, 6.37814e6),</span><br><span class="line">MARS (6.421e+23, 3.3972e6),</span><br><span class="line">JUPITER (1.9e+27, 7.1492e7),</span><br><span class="line">SATURN (5.688e+26, 6.0268e7),</span><br><span class="line">URANUS (8.686e+25, 2.5559e7),</span><br><span class="line">NEPTUNE (1.024e+26, 2.4746e7);</span><br><span class="line">private final double mass; // in kilograms</span><br><span class="line">private final double radius; // in meters</span><br><span class="line">Planet(double mass, double radius) &#123;</span><br><span class="line">this.mass = mass;</span><br><span class="line">this.radius = radius;</span><br><span class="line">&#125;</span><br><span class="line">private double mass() &#123; return mass; &#125;</span><br><span class="line">private double radius() &#123; return radius; &#125;</span><br><span class="line">// universal gravitational constant (m3 kg-1 s-2)</span><br><span class="line">public static final double G = 6.67300E-11;</span><br><span class="line">double surfaceGravity() &#123;</span><br><span class="line">return G * mass / (radius * radius);</span><br><span class="line">&#125;</span><br><span class="line">double surfaceWeight(double otherMass) &#123;</span><br><span class="line">return otherMass * surfaceGravity();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
枚举型变量可以带自己的操作方法，甚至构造方法，但是只能在声明时调用构造方法，从而只有有限个实例对象。</p></li>
<li><p>通配符泛型 •使用通配符 可以使程序更为通用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class ShowType &#123;</span><br><span class="line">public void show (GeneralType&lt;?&gt; o)&#123;</span><br><span class="line">    System.out.println(o.getObj().getClass().getName());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>有限制的泛型 •在参数“ Type” 后面使用“ extends”
关键字并加上类名或接口名，表明参数所代表的类型必须是该类的子类或者实现了该接口
▫注意，对于实现了某接口的有限制泛型，也是使用 extends 关键字，而不是
implements 关键字</p></li>
<li><p>构造方法中调用多态方法
•在构造方法内调用准备构造的那个对象的动态绑定方法
▫被调用方法要操纵的成员可能尚未得到正确的初始化
▫可能造成一些难于发现的程序错误 所以要注意
•用尽可能少的动作把对象的状态设置好； •如果可以避免，不要调用任何方法；
•在构造方法内唯一能够安全调用的是在超类中具有 final
属性的那些方法（也适用于 private 方法，它们自动具有 final
属性）。这些方法不能被覆盖，所以不会出现前述的潜在问题。</p></li>
</ol>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>堆块Unlink的理解</title>
    <url>/2019/%E5%A0%86%E5%9D%97Unlink%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="unlink">unlink</h1>
<p>程序里肯定会有指向堆块的地址.
而在我们的组织堆块的链表里面也是保存的堆块地址,
能否让堆块以为程序里这保存的地址是其他的堆块指向他的呢?</p>
<span id="more"></span>
<p>在双向链表里面, 堆块们通过链表的形式排队. 当有堆块要离开的时候,
他就要进行工作交接, 否则一走了之的话链表就断了.</p>
<p>工作交接具体是两个内容, 和前面的链表说, 你后面的兄弟不再是我了,
我要走了, 这是我后面的兄弟, 它以后才是你后面的兄弟了,
向后找的时候去找它. 同样和后面的兄弟说要照顾好原来自己前面的堆块
也就是让forword块保管好自己的back指针,
让back块保管好自己的forward指针.</p>
<p>由于堆块经常被骗, 他们只好长个心眼, 不能改了别人的指针.
让后面的堆块照顾好自己前面的堆块时, 需要修改的是后面的堆块的fd指针,
这个指针原来的值就是堆块自己. 让前面的堆块照顾好自己后面的堆块时,
需要修改的是前面的堆块的bk指针, 这个指针原来的值就是堆块自己.
如果不是自己, 就肯定是被骗了, 这时候堆块就报警了, 程序就报错了</p>
<p>这里先讲一个任意地址写的故事, 程序会分配堆块, 自己保存好堆块指针,
需要数据就根据堆块指针去找, 如果我们能够随意改写堆块指针,
不就可以达到想写(读)哪里就写哪里的效果了吗? 那怎么改写呢?
我们先放开这个问题</p>
<p>但是unlink, 并没有这么简单, 我们接下来仔细分析一下
程序里面指向堆块的指针和libc里用的不太一样, 程序里是指向堆块的内容,
而libc里则是堆块结构体的头部, 向前偏移了0x10字节.
另外就是一般利用的是前向合并时的unlink. 当free一个堆块,
会前后检查free的堆块, 合并起来, 这样就不会有相邻的free块.
而free的块肯定都是在bins里的, 而且不是fastbin,
因为fastbin的块没有标成free. 所以free一个堆块的时候,
前向合并前一个堆块的时候, 就要把前面的堆块从链表里拿出来,
合并完再放到合适的链表里. 利用unlink时, 我们利用堆溢出漏洞,
修改unlink块溢出到下一块, 去除previous in use bit, 并伪造prev size,
这里伪造的size要小0x10字节, 刚好是用户内容域,
伪造的堆块小10字节也是为了和程序内指向堆块内容的指针合作.
这样free后面的块的时候, 就会对前面的伪造的小一号的堆块进行unlink,
所以unlink时伪造堆块的fd和bk指针指向哪里? 回顾之前的知识, 可以知道, fd
的bk(+0x18) = 自己(堆块指针) bk 的fd(+0x10) = 自己(堆块指针) 反过来 fd =
自己指针 - 0x18 bk = 自己指针 - 0x10</p>
<p>效果就是把自己指针先改成自己的bk, 再改成自己的fd, 即自己的指针指向了
自己指针 - 0x18 这个地址可不得了, 不是堆段了, 而是程序数据域了,
旁边很可能就是其他堆块的指针, 去改他们就可以任意地址写了</p>
<p>作用: UAF-&gt;溢出 要求: 修改free的堆块,
知道另外一处指向堆块的指针</p>
<h1 id="虚假堆快">虚假堆快</h1>
<p>需要能错位header, 再使用fastbin attack</p>
<p>错位到main_arena 改写top chunk地址, 达到任意分配堆块的目的</p>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>CTF</tag>
      </tags>
  </entry>
  <entry>
    <title>天枢的新手入门指南 Q&amp;A</title>
    <url>/2019/%E5%A4%A9%E6%9E%A2%E7%9A%84%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%20Q&amp;A/</url>
    <content><![CDATA[<p>这篇文章是2019年7月31日从天枢新人群里复制来的。增加自己博客的文章数</p>
<h1 id="天枢的新手入门指南-qa">天枢的新手入门指南 Q&amp;A</h1>
<h2 id="什么是天枢">什么是天枢</h2>
<h3 id="天枢战队">天枢战队</h3>
<span id="more"></span>
<blockquote>
<p>​
天枢战队是来自北京邮电大学（BUPT）的一群小伙伴组成的安全团队。队名“天枢”是北斗七星的第一颗星，它代表了聪慧和才能。核心团队有十五人左右，活跃在国内外大大小小的赛事上。大家聚在一起，乐于学习、研究和交流各个方向的安全技术，提高北邮信息安全氛围。</p>
<p>​
队员们专精的技能千奇百怪：手捏网线就能发包，口算sha256比2080ti还快，盯着字节码即可逆向操作系统，双击Chrome就能v8逃逸，通过人眼扫描面部即可微信添加好友等。</p>
</blockquote>
<h3 id="天枢社团">天枢社团</h3>
<blockquote>
<p>​
天枢社团的主要作用就是向天枢战队输送新生力量，提高北邮的民间信息安全能力与氛围。定期组织CTF交流，提高自身的信息安全技能</p>
</blockquote>
<h3 id="如何加入天枢战队">如何加入天枢战队</h3>
<p>天枢战队在每年5月底6月初会举办<code>TSCTF</code>邀请赛，在线上赛取得突出成绩，或者在其他比赛中有优异成绩即可进入天枢战队</p>
<h3 id="天枢社团的预想组织架构">天枢社团的预想组织架构</h3>
<ul>
<li>中心组
<ul>
<li>活动（负责相关活动的宣传，组织，评定，场地，以及后期的报销等事宜）//这里可能可以细分？</li>
<li>技术（负责相关活动的技术维护）</li>
</ul></li>
<li>XX战队（负责参加各种比赛，包括但不限于国赛，XCTF联赛等，人数大概维持在20人-30人左右）</li>
</ul>
<h3 id="天枢社团预想学习模式">天枢社团预想学习模式</h3>
<ol type="1">
<li>在开学初进行战队的初级选拔(大概招30人吧，我也不清楚)，主要选拔一些有基础，或者说感兴趣并想坚持的人。</li>
<li>开学之后会进行1-2个月左右的学习，然后进行选拔，抽取前20(概率还是挺大的)</li>
<li>每周面向全校（主要是战队）进行沙龙，不同方向和领域可以分开进行活动。</li>
<li>每月进行一次战队的交流，比赛（评定），分享学习经验。提高合作水平</li>
<li>战队会进行定期考核，当无法完成相应任务，会从战队中移除。</li>
</ol>
<h2 id="什么是ctf">什么是CTF</h2>
<blockquote>
<p>​ CTF（Capture The
Flag）中文一般译作夺旗赛，在网络安全领域中指的是网络安全技术人员之间进行技术竞技的一种比赛形式。CTF起源于1996年DEFCON全球黑客大会，以代替之前黑客们通过互相发起真实攻击进行技术比拼的方式。发展至今，已经成为全球范围网络安全圈流行的竞赛形式，2013年全球举办了超过五十场国际性CTF赛事。而DEFCON作为CTF赛制的发源地，DEFCON
CTF也成为了目前全球最高技术水平和影响力的CTF竞赛，类似于CTF赛场中的“世界杯”
。(百度百科)</p>
</blockquote>
<p>CTF的几个方向
Web（网络安全）,Pwn（二进制安全）,Re（逆向工程）,Crypto（密码学）,Misc（流量分析，图片隐写，取证，等其他方向）</p>
<h2 id="方向介绍入门书籍及练习网站">方向介绍，入门书籍及练习网站</h2>
<h3 id="web">Web</h3>
<blockquote>
<p>网络安全，及负责各种数据库，网页，等网络产品的漏洞挖掘及其利用</p>
</blockquote>
<p><strong>书单</strong></p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 41%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr>
<th>书名</th>
<th>网购链接（没有打广告）</th>
<th>电子书链接</th>
</tr>
</thead>
<tbody>
<tr>
<td>白帽子讲Web安全</td>
<td><a
href="https://detail.tmall.com/item.htm?spm=a230r.1.14.16.6c384122VZ3uBX&amp;id=596872157850&amp;cm_id=140105335569ed55e27b&amp;abbucket=3">白帽子讲Web安全</a></td>
<td>群文件自取</td>
</tr>
<tr>
<td>代码审计 企业级Web代码安全架构</td>
<td><a
href="https://detail.tmall.com/item.htm?spm=a230r.1.14.9.396746e1Anlg9X&amp;id=594217706164&amp;cm_id=140105335569ed55e27b&amp;abbucket=3">代码审计</a></td>
<td><a
href="https://u1475340.ctfile.com/fs/1475340-228355356">下载</a></td>
</tr>
<tr>
<td>Sndav弱鸡的博客</td>
<td><a href="http://blog.boyblog.club">博客</a></td>
<td></td>
</tr>
<tr>
<td>离别歌的博客</td>
<td><a href="https://www.leavesongs.com/">博客</a></td>
<td></td>
</tr>
<tr>
<td>郁离歌丶的博客</td>
<td><a href="http://yulige.top/">郁离歌丶的博客</a></td>
<td></td>
</tr>
<tr>
<td>SecWiki</td>
<td><a href="https://sec-wiki.com/">SecWiki</a></td>
<td></td>
</tr>
<tr>
<td>WooYun镜像站</td>
<td><a href="http://www.anquan.us/">WooYun镜像站</a></td>
<td></td>
</tr>
<tr>
<td>CTF-Wiki</td>
<td><a href="https://ctf-wiki.github.io/ctf-wiki/">Wiki</a></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>练习网站</strong></p>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 67%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr>
<th>网站</th>
<th>地址</th>
<th>难度</th>
</tr>
</thead>
<tbody>
<tr>
<td>攻防世界</td>
<td><a href="http://adworld.xctf.org.cn">攻防世界</a></td>
<td>初级-困难</td>
</tr>
<tr>
<td>北京联合大学OJ</td>
<td><a href="https://buuoj.cn/">BUUOJ</a></td>
<td>中等</td>
</tr>
<tr>
<td>Github CTFTraining</td>
<td><a
href="https://github.com/CTFTraining/CTFTraining">CTFTraining</a></td>
<td>中级-困难</td>
</tr>
</tbody>
</table>
<h3 id="pwn">Pwn</h3>
<blockquote>
<p>二进制安全，负责各种二进制程序（ELF，EXE等）的漏洞挖掘及其利用</p>
</blockquote>
<p><strong>书单</strong></p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr>
<th>书名</th>
<th>网购链接</th>
<th>电子书地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>0day安全:软件漏洞分析技术</td>
<td><a
href="https://detail.tmall.com/item.htm?spm=a230r.1.14.33.47641d36xHPMdd&amp;id=595379481437&amp;ns=1&amp;abbucket=3">0day安全:软件漏洞分析技术</a></td>
<td>群内自取</td>
</tr>
<tr>
<td>汇编语言</td>
<td><a href="https://item.jd.com/12259774.html">汇编语言</a></td>
<td></td>
</tr>
<tr>
<td>程序员的自我修养（装载，链接与库）</td>
<td>自己淘宝吧</td>
<td><a
href="https://pan.baidu.com/s/1cALpx_D_9CR9hWWM9rIMwQ">百度网盘，提取码：73pe</a></td>
</tr>
<tr>
<td>深入理解计算机系统</td>
<td>同上</td>
<td><a
href="https://pan.baidu.com/share/init?surl=gtB8fEUUtFj8blwJnajICQ">百度网盘，提取码：yx0s</a></td>
</tr>
<tr>
<td>glibc内存管理ptmalloc2源代码分析</td>
<td>同上</td>
<td><a
href="https://pan.baidu.com/s/1-0odrFdV0Dn7xgehicuz0A">百度网盘，提取码：su8n</a></td>
</tr>
<tr>
<td>xxrw的blog</td>
<td><a href="https://xiaoxiaorenwu.top">博客</a></td>
<td></td>
</tr>
<tr>
<td>天枢-p4nda的blog</td>
<td><a href="http://p4nda.top/">博客</a></td>
<td></td>
</tr>
<tr>
<td>天枢-YM的blog</td>
<td><a href="https://e3pem.github.io">博客</a></td>
<td></td>
</tr>
<tr>
<td>天枢-17的blog</td>
<td><a href="https://sunichi.github.io/">博客</a></td>
<td></td>
</tr>
<tr>
<td>r3kapig-swing的blog</td>
<td><a href="https://bestwing.me/">博客</a></td>
<td></td>
</tr>
<tr>
<td>VidarTeam-Veritas501的blog</td>
<td><a href="https://veritas501.space/">博客</a></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>资料</strong> | 网站 | 地址 | | ---- | ---- | | CTF-Wiki | <a
href="https://ctf-wiki.github.io/ctf-wiki/">Wiki</a> | | CTF-ALL-In-One
| <a
href="https://github.com/firmianay/CTF-All-In-One/">CTF-ALL-In-One</a> |
| Shellcode网站1 | <a href="https://shell-storm.org/">Shell-Storm</a> |
|Shellcode网站2|<a
href="https://www.exploit-db.com/shellcodes">shellcode</a>|
|北京邮电大学瑶光战队学习资料|<a
href="https://github.com/xiaoxiaorenwu/-">北邮瑶光</a>|
|i春秋的pwn基础教程|<a
href="https://bbs.ichunqiu.com/search.php?mod=portal&amp;searchid=117&amp;searchsubmit=yes&amp;kw=pwn%E5%85%A5%E9%97%A8">i春秋搜索pwn入门</a>|
|看学知识库|<a
href="https://www.kanxue.com/chm-search-pwn.htm">看雪知识库</a>|
|libc搜索|<a href="http://libcdb.com/">libc搜索</a>|</p>
<p><strong>刷题网站</strong> | 网站 | 地址 | 难度 | | ---- | ---- | ----
| | 攻防世界 | <a href="http://adworld.xctf.org.cn">攻防世界</a> |
初级-困难 | | 北京联合大学OJ | <a href="https://buuoj.cn/">BUUOJ</a> |
中等 | | Github CTFTraining | <a
href="https://github.com/CTFTraining/CTFTraining">CTFTraining</a> |
中级-困难 | | PwnableKr | <a href="https://pwnable.kr">PwnableKr</a> |
初级-中级 | | PwnableTw | <a href="https://pwnable.tw/">PwnableTw</a> |
中级-困难 | | Jarvisoj | <a href="https://Jarvisoj.com">Jarvisoj</a> |
初级-中级| | CTFWP | <a href="http://www.ctfwp.com">CTFWP</a> | 中级
|</p>
<h3 id="re">Re</h3>
<blockquote>
<p>逆向工程，负责逆向程序算法，破解程序限制</p>
</blockquote>
<p><strong>书单</strong></p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr>
<th>书名</th>
<th>网购链接</th>
<th>电子书地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Re4b(Reverse Engineer For beginner)</td>
<td><a href="https://item.jd.com/12166962.html">Re4b</a></td>
<td>群内自取</td>
</tr>
<tr>
<td>加密与解密</td>
<td><a
href="https://detail.tmall.com/item.htm?spm=a230r.1.14.189.1d8238f5fF5n7B&amp;id=580607194609&amp;ns=1&amp;abbucket=3">加密与解密</a></td>
<td><a href="https://pan.baidu.com/s/18PhiF_STy4413w4rlfZKfQ">百度云</a>
提取码: hpdb</td>
</tr>
<tr>
<td>CTF-Wiki</td>
<td><a href="https://ctf-wiki.github.io/ctf-wiki/">Wiki</a></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>练习网站</strong></p>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 67%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr>
<th>网站</th>
<th>地址</th>
<th>难度</th>
</tr>
</thead>
<tbody>
<tr>
<td>攻防世界</td>
<td><a href="http://adworld.xctf.org.cn">攻防世界</a></td>
<td>初级-困难</td>
</tr>
<tr>
<td>北京联合大学OJ</td>
<td><a href="https://buuoj.cn/">BUUOJ</a></td>
<td>中等</td>
</tr>
<tr>
<td>Github CTFTraining</td>
<td><a
href="https://github.com/CTFTraining/CTFTraining">CTFTraining</a></td>
<td>中级-困难</td>
</tr>
</tbody>
</table>
<h3 id="crypto">Crypto</h3>
<blockquote>
<p>密码学，负责通过密码以及数学知识，破解相应密码</p>
</blockquote>
<p><strong>书单</strong></p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr>
<th>书名</th>
<th>淘宝链接</th>
<th>电子书地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>现代密码学</td>
<td></td>
<td></td>
</tr>
<tr>
<td>CTF-Wiki</td>
<td><a href="https://ctf-wiki.github.io/ctf-wiki/">Wiki</a></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>练习网站</strong></p>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 67%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr>
<th>网站</th>
<th>地址</th>
<th>难度</th>
</tr>
</thead>
<tbody>
<tr>
<td>攻防世界</td>
<td><a href="http://adworld.xctf.org.cn">攻防世界</a></td>
<td>初级-困难</td>
</tr>
<tr>
<td>北京联合大学OJ</td>
<td><a href="https://buuoj.cn/">BUUOJ</a></td>
<td>中等</td>
</tr>
<tr>
<td>Github CTFTraining</td>
<td><a
href="https://github.com/CTFTraining/CTFTraining">CTFTraining</a></td>
<td>中级-困难</td>
</tr>
</tbody>
</table>
<h3 id="misc">Misc</h3>
<blockquote>
<p>杂项，负责各种其他安全相关，比如取证，隐写，区块链等</p>
</blockquote>
<p><strong>书单</strong></p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr>
<th>书名</th>
<th>网购链接</th>
<th>电子书地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>CTF-Wiki</td>
<td><a href="https://ctf-wiki.github.io/ctf-wiki/">Wiki</a></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>练习网站</strong></p>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 67%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr>
<th>网站</th>
<th>地址</th>
<th>难度</th>
</tr>
</thead>
<tbody>
<tr>
<td>攻防世界</td>
<td><a href="http://adworld.xctf.org.cn">攻防世界</a></td>
<td>初级-困难</td>
</tr>
<tr>
<td>北京联合大学OJ</td>
<td><a href="https://buuoj.cn/">BUUOJ</a></td>
<td>中等</td>
</tr>
<tr>
<td>Github CTFTraining</td>
<td><a
href="https://github.com/CTFTraining/CTFTraining">CTFTraining</a></td>
<td>中级-困难</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>CTF</tag>
      </tags>
  </entry>
  <entry>
    <title>树莓派与resbian</title>
    <url>/2019/%E6%A0%91%E8%8E%93%E6%B4%BEresbian/</url>
    <content><![CDATA[<h1 id="树莓派与resbian">树莓派与resbian</h1>
<span id="more"></span>
<h2 id="上手系统安装">上手系统安装</h2>
<p>下载系统镜像，解压。。。
一般发行版下载的系统的iso，但是树莓派系统是img的压缩包，要先解压。</p>
<p>刷镜像一般用win32diskimager。linux用dd命令。
也就是说，如果你经常刷系统，拿到树莓派如果先不急着拓展文件系统空间，安装完一些软件，就可以拿回来用win32diskimager读img镜像出来留着。
刷完反射性地在boot的根目录下新建ssh空文件。 然后就是启动，一句sudo
raspi-config打开vnc。
树莓派还是对桌面玩家友好😭，图形界面比命令行调乱七八糟的参数好得多。</p>
<p>一些闲话：
回忆起很久以前ubuntu等桌面版还不知道用什么刷到优盘的时候，有个opensusu的小工具也是刷优盘镜像的。主要需要对磁盘的二进制读写能力，才能写出启动盘。
最近装了一次win10，以前装win7还会用用ultraISO的写入硬盘镜像到优盘，现在它已经落后变得垃圾了，写入不是卡死就是不能启动，现在用rufus-3.6p.exe这个小巧的程序特别强。装系统的时候才了解到难道uefi已经支持ntfs了吗
已经是第二次不能从sd卡启动了。。。是不是uefi歧视sd卡。。。只能用优盘，也不知道是不是驱动不一样。</p>
<h2 id="journalctl">journalctl</h2>
<p>直接执行，进行日志的查看 参数： -n 3 查看最近三条记录 -perr
查看错误日志 -overbose 查看日志的详细参数 --since
查看从什么时候开始的日志 --until 查看什么时候截止的日志</p>
<p>这条命令主要是因为我之前用手机充电器，这里会报低电压警告
最近买了新电源，用这个命令来看看还会不会警告。果然换了电源就看不到了</p>
<h2 id="电源管理">电源管理</h2>
<p>sudo iw dev wlan0 set power_save on|off
这条命令关闭wifi的电源管理，否则wifi不稳，我以前通过wifi进行ssh不可靠就是因为这个和电源</p>
<h2 id="安装无线网卡驱动">安装无线网卡驱动</h2>
<p>手头有一块垃圾的tenda U6，是rtl8192eu的，还有一张rtl8812au
https://github.com/Mange/rtl8192eu-linux-driver
https://github.com/aircrack-ng/rtl8812au 按照github的readme进行设置，
我有一次只是安装rtl8192eu的dkms模块，没有进行教程接下来的设置操作，就开不了机，只能重刷系统😭。
开机就可以执行 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install git raspberrypi-kernel-headers build-essential dkms;</span><br></pre></td></tr></table></figure> 让它慢慢下载</p>
<h2 id="networkmanager">networkManager</h2>
<p>这里我需要给树莓派固定的ip，但是发现这次树莓派每次启动wifi网卡mac地址都随机化，每次一个新ip，还查不出这个网卡是哪个厂商的。。。
但是图形化界面没有设置的地方，还是ubuntu的network-manager-gnome友好，里面有这个选项。
于是试图使用network-manager-gnome管理无线网
本来以为network-manager-gnome是gnome桌面专用的东西，后来装了才发现lxde照用不误，有桌面环境就行。
sudo apt-get install network-manager-gnome
这里安装后菜单就出现了advanced network Configuration 修改配置文件 sudo
nano /etc/NetworkManager/NetworkManager.conf <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[main]</span><br><span class="line">plugins=ifupdown,keyfile</span><br><span class="line"></span><br><span class="line">[ifupdown]</span><br><span class="line">managed=false</span><br></pre></td></tr></table></figure>
把false改成true
#注：managed这里表示是否管理/etc/network/interfaces里配置了的网络接口
修改/etc/network/interfaces，在末尾加上如下内容 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">allow-hotplug wlan0</span><br><span class="line">iface wlan0 inet dhcp</span><br><span class="line">        hwaddress b8:27:eb:00:00:00</span><br></pre></td></tr></table></figure> 相关原理：
下面基于2019年7月31日下载的raspbian系统
树莓派的这个发行版的网络组件和其他发行版不一样。一般linux首先读取/etc/network/interfaces，剩下没有被管理的网络接口被network-manager管理。
树莓派的网络也使用了networkmanager，而不使用interfaces文件，下面是树莓派默认的/etc/network/interfaces
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># interfaces(5) file used by ifup(8) and ifdown(8)</span><br><span class="line"></span><br><span class="line"># Please note that this file is written to be used with dhcpcd</span><br><span class="line"># For static IP, consult /etc/dhcpcd.conf and &#x27;man dhcpcd.conf&#x27;</span><br><span class="line"></span><br><span class="line"># Include files from /etc/network/interfaces.d:</span><br><span class="line">source-directory /etc/network/interfaces.d</span><br><span class="line"></span><br></pre></td></tr></table></figure>
而它include的/etc/network/interfaces.d是一个空文件夹，所以raspbian是不用interfaces的。
任何修改/etc/network/interfaces的教程现在都已经过时了，修改该文件会造成兼容性问题，具体表现在桌面右上角的图标失灵，不能正常管理网络。
桌面右上角的网络管理的图标比较简陋，软件包名称是lxplug-network，根据名字可以知道，这个应该是lxde的插件，不过肯定是用在raspbian的pixel桌面上的，而且lxplug-
还是一个系列，还包括蓝牙什么的，它在github上的链接是
https://github.com/raspberrypi-ui/lxplug-network
听说原开发者已经退休了。。。 当右上角的图标失灵时，显示Connection to
dhcpcd lost. 点击显示No wireless interface found.
这里可以看出它管理网络使用的是dhcpcd，c代表client，d是deamon守护进程。
下面这个帖子在小白互助的时候，一位大神出来说了一句技术内幕。看来有关树莓派的问题还是到官方论坛搜索比较好，接触全球的帖子。
https://www.raspberrypi.org/forums/viewtopic.php?f=28&amp;t=242721&amp;p=1482723&amp;hilit=%2Fetc%2Fnetwork%2Finterfaces+mac+random#p1482723
其中关键的一句： dhcpcd has a wpa_supplicant hook in Stretch.
Stretch是Debian9的代号现在都到debian10 buster了。
也就是说，这个管理程序还是用的是wpasupplicant，不是让你去interfaces里点名用wpasupplicant，而是它在dhcpcd里面它自己调用！用wpagui也可以管理到！
至于静态ip，树莓派的桌面环境可以设置。而且如果想在配置文件配置也是在dhcpcd.conf里配置。
https://www.jianshu.com/p/bd918ef98a4d</p>
<p>其他相关页面 https://wiki.lxde.org/en/LXNM
https://wiki.lxde.org/en/LXDE-Qt</p>
<h2 id="换tuna源">换tuna源</h2>
<p>虽然树莓派基金会的镜像也能用，但是还是清华的快一些。
https://mirrors.tuna.tsinghua.edu.cn/help/raspbian/</p>
<h2 id="dump镜像">dump镜像</h2>
<p>树莓派还是不要用太大的sd卡，完全没必要。现在因为不想以后换系统的时候重新配置文件，现在打算直接把整个sd卡做个镜像压缩一下。8g其实完全足够了。我用的32g的卡，为了省空间，打算先压缩分区大小再dump出来。</p>
<ol type="1">
<li>fsck磁盘检查 要把树莓派关机，把卡拿下来，去别的linux系统上检查 sudo
fsck /dev/sda2 -f
使用-f强制检查但是我检查了，还是后面报有node不对，忘了之前是怎么搞的了</li>
<li>使用diskgenius压缩分区。
gparted还真的不容易做压缩分区，看来还是diskgenius好啊</li>
</ol>
<p>一不小心用了这个感觉挺危险的办法：
https://access.redhat.com/articles/1196333
https://askubuntu.com/questions/780284/shrinking-ext4-partition-on-command-line
还要删除分区再建立。。。</p>
<p>之后构建img文件还是使用win32diskimager，没办法，没什么其他好软件。
不过可以勾选只备份已有分区，挺好，没想到小工具能做到这么实用，我要是也能写出这样的工具就好了。</p>
<h2 id="samba">samba</h2>
<p>windows 清除登录密码 加上选项 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">min protocol = SMB3</span><br><span class="line">security = user</span><br></pre></td></tr></table></figure></p>
<p>debug samba <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service smbd stop</span><br><span class="line">sudo smbd -F -S -d=10</span><br></pre></td></tr></table></figure> 此时再连接, 就可以看到debug信息了.</p>
<p>关键配置1 要加密或者签名 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server signing = mandatory</span><br><span class="line">smb encrypt = mandatory</span><br></pre></td></tr></table></figure> 关键配置2 guest account
要手动设置</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Raspberrypi</tag>
      </tags>
  </entry>
  <entry>
    <title>NativeSummary：Java/C安卓应用无源码污点分析。</title>
    <url>/2022/NativeSummary/</url>
    <content><![CDATA[<p>让原有的安卓污点分析工具（如FlowDroid），支持通过JNI接口调用的汇编代码（C语言代码）的分析。</p>
<p>不使用符号执行等动态分析技术，而是使用二进制静态分析技术。</p>
<span id="more"></span>


	<div class="row">
    <embed src="/2024.assets/NativeSummary__ISSTA_24__Camera_Ready.pdf" width="100%" height="550" type="application/pdf">
	</div>





	<div class="row">
    <embed src="/2024.assets/Presentation-NativeSummary.pdf" width="100%" height="550" type="application/pdf">
	</div>



<p>这是论文之前的“手稿”。感兴趣的话只需要看上面的论文即可。</p>
<!-- 因为用来翻译，所以一些英式中文是故意的。 -->
<p>这个题目可以分为两个部分 1.
逆向部分：将APK中的二进制库拿出来，分析基于JNI接口的汇编代码在干什么。
2. 跨语言部分：C语言和Java语言的差异摆在那里，如何污点分析。</p>
<p>通过探索得到了下面的方案：</p>
<ol type="1">
<li>首先分析Java部分找到native函数。然后对应到二进制库中的导出函数，即找到二进制的入口点。</li>
<li>依次分析每个JNI函数。至少把JNI API的调用提取出来。</li>
<li>基于观察，部分JNI函数还是非常接近Java里面的一些操作的。比如<code>SetObjectField</code>对应Java里面设置对象的成员，<code>CallObjectMethod</code>对应Java里面调用函数。基于这个思想，把相关的调用转换成Java语句。</li>
<li>为了兼容现有的框架，将生成的Java语句重打包到应用里。因为现有的（只支持Java虚拟机部分代码）的APK污点分析工具，除了都输入一个APK，也没什么额外的拓展接口了。所以通过重打包实现兼容。</li>
</ol>
<p>（这一段还是不放进去）
Java侧分析和native侧分析很不一样。Java侧字节码含有的信息较多，大量工具直接基于JVM字节码直接分析。而native侧分析和C/C++源码层分析还是非常割裂。二进制分析往往采用符号执行、fuzzing等方式，而源码层则可以采用基于抽象解释的分析技术。我们相信，在足够的逆向工程努力下，我们也可以对二进制代码使用基于抽象解释的指针分析等技术。</p>
<h2 id="contributions">Contributions</h2>
<ol type="1">
<li>提出了一种兼容现有Java 侧分析框架的二阶段跨语言分析方法。</li>
<li>通过使用静态分析技术分析汇编语言代码，相比于符号执行技术，提升了分析的鲁棒性（和代码覆盖率）。</li>
<li>把现有的工具打包为了docker镜像，极大地提升了现有工具的可用性和用户友好性。</li>
</ol>
<h2 id="背景">背景</h2>
<h3 id="java侧污点分析框架">Java侧污点分析框架</h3>
<p>现有的Java污点分析框架很成熟，甚至出现了大量论文评估现有的Java污点分析框架，如ReproDroid，《Analyzing
Android Taint Analysis Tools: FlowDroid, Amandroid, and
DroidSafe》。这些工具利用现有的java分析技术，利用soot框架转换为Jimple这样的中间表示，分析dex字节码。然而，开发者可以通过JNI接口调用通常用C语言编写的本地代码，在java侧表现为带有native标识符但没有函数体，如Lising
1中所示。</p>
<p>由于二进制分析和跨语言分析的难度，现有的工具只能采取保守的黑盒策略。他们忽略了本地代码调用的副作用，并假设数据流只会在参数和返回值之间发生。
该模型仅涵盖本机函数仅进行计算但实际上它们可以调用 Java
端函数并修改全局或实例状态的情况。</p>
<h3 id="jni的使用">JNI的使用</h3>
<p>当一个开发者使用JNI时，首先在Java侧声明native函数，使用javap【TODO】生成对应的C语言函数签名，编写函数体。编译为动态链接库，运行时则加载，JVM获取导入函数，增加函数映射。然而还有另外一种方式，即在JNI_OnLoad函数中使用RegisterNatives注册函数。</p>
<p>JNI静态绑定和动态绑定。</p>
<h3 id="二进制分析与抽象解释">二进制分析与抽象解释</h3>
<p>现有的往往使用符号执行。但是符号执行往往会遇到路径爆炸，我们使用抽象解释的分析能增加探索到的路径。</p>
<p>（分享之前选择二进制分析的相关背景知识？）
VSA是一种相比符号执行更轻量级的静态分析方法。他基于抽象解释，抽象每个程序点每个变量可能的取值。它结合了指针分析和数值分析，对程序的数值分析促进了地址访问的解析，而对地址访问的精确处理使得程序的数值分析更精确，两者相互促进。</p>
<p>BinAbsInspector，TODO</p>
<h2 id="例子">例子</h2>
<blockquote>
<p>例子要体现： 1. 我们能够支持对Java侧的调用。 1.
我们能够支持对native侧的数据流分析。Jucify做不到。 1.
我们能够支持高级特性。</p>
</blockquote>
<blockquote>
<p>例子的特点： 1.
我二进制分析，直接只分析了数据流部分，即使内部分为了多个函数，也能考虑到数据流，然后转换为单个函数。比如global
id里面的全局数据流 2. 可以包含一些我们支持的高级用法。比如file
leak里面的native特有的函数。</p>
</blockquote>
<p>（开场怎么说？Native code分析很难？Native
code对数据流分析很重要？不，为了说明跨语言分析的难点）
<del>为了说明本地代码对数据流分析的重要性</del>为了说明我们数据流分析的整体流程，我们给出了一个例子。恶意应用开发者能使用和实例一样的代码泄露用户隐私。和传统</p>
<p>（说一下App的数据流泄露流程）</p>
<p>（说一下我们的处理方式。）</p>
<p>Lising
1-2展示了一个例子。正如很多现有论文【cite】所说，本地代码已经被广泛应用。现实中的恶意应用开发者很可能使用本地代码以躲避现有分析工具的分析。</p>
<p><strong>处理JNI相关的API</strong>
直觉是，很多JNI相关的操作都能被转换为对应的Java操作，比如，这个例子中的CallObjectMethod可以被转化为一个java
method call，比如GetObjectField能被转换为Field read。</p>
<p><strong>处理native code中的数据流</strong>
虽然在例子中不明显，但很容易想到C/C++中有更多独有的传播数据流的语言特性。很难直接找出一个简单的方式去incorporate
Java和C/C++的数据流区别，特别是当出现了很深的函数调用，复杂的指针传递数据，而这些很难在java侧找到等价物。
实际上，这些对保留敏感的穿过native
code的污点数据流并不是必要的。因此，我们选择不在java侧反映复杂的控制流和函数结构，仅为每个native
方法创建一个Java函数体。二进制中的数据流仅被用于解析Java操作之间的数据流。为了避免类型系统的冲突，有时需要使用自定义的类型转换方法或强制类型转换。<del>，利用强制类型转换避免类型系统的约束</del>。</p>
<p><strong>ID as global variable</strong>
相关ID的缓存，也是一个难点。这意味着我们需要考虑从JNI_OnLoad到后续函数的，经过全局变量的数据流。这对我们的二进制分析提出了挑战。</p>
<p><strong>Native specific sources and
sinks</strong>现实生活的app中可能会大量的使用各种各样的使用纯Native的source和sink点，无法一次性考虑到。我们采取了动态的方式，根据二进制侧动态链接库的导入函数去动态创建为特殊的Java侧native函数声明，同时将他们导出为Flowdroid的格式，便于进一步的处理。</p>
<p>正如Listing3中所示，我们为open, write 和
close构建了对应的native方法，并将write标记为Sink点，从而让现有工具成功检测到隐私泄露问题。</p>
<h2 id="相关挑战">相关挑战</h2>
<h3 id="二进制分析">二进制分析</h3>
<p>java那边已经有很多成熟的分析工具，而二进制代码侧虽然已经有大量和成熟的研究，但一方面二进制代码的分析如今依然无法做到全自动，需要有经验的逆向工程师，另外一方面，相关的技术和源码级分析也大相径庭。二进制分析方面的自动分析，主要有符号执行，fuzzing这种把代码近似看作黑盒的工具。【扩写一下。】而</p>
<p>为了能够对二进制代码做静态分析，首先要借助类似Ghidra这样的二进制分析平台。【Ghidra介绍】其次是选用静态分析。我们首先考虑使用基于VSA的静态分析，选择了基于Angr的静态分析，但是后面发现它的VSA分析非常难用，疏于维护，需要自己的大量修改，且效果较差，这一点在其他paper中也有提到【cite】。在本项目进行到一半的时候，科恩实验室开源了BinAbsInspctor，于是我们重新基于BAI实现。</p>
<p>BAI使用了基于抽象解释的二进制分析技术，它将每个内存区域或者寄存器抽象为K-Set，相关的lattice如图所示【】。当可能的值小于等于K个时，使用一个集合抽象表示。当集合元素超过K个时，放弃精度使用Top表示。我们没有使用了BAI的Z3，因此假设所有的路径都可能，并在路径交汇的地方进行合并。此外，跨函数分析方面是k-callsite-sensitive。我们为了效率，把跨函数值设为了最低的1。没有任何widening技巧加速迭代过程，求解器直接迭代到不动点为止。</p>
<blockquote>
<p>直接将这种基于抽象解释的方法应用于二进制分析会遇到一个关于callee
saved reg和frame
pointer的问题。我们早期使用BAI时遇到了这个问题，症状表现为复杂函数调用有寄存器和内存都变为了Top。</p>
</blockquote>
<p>抽象解释的这种框架在落地到二进制方面会遇到非常大的困难。我们直接使用BAI的时候出现了大量的精度下降问题，即大量寄存器和栈空间都变成了TOP，分析时间也居高不下，结果调查发现了是静态分析没有很好地处理callee
saved reg的问题。一主要的困难就是难以将activation
record直接抽象出来。尤其是参数和callee saved reg 【加一个calling
convention的图，一个函数调用的二进制指令，一个调用栈】。</p>
<p>callee saved register
是在调用约定中，约定在调用前后需要保持不变的寄存器，被调用者如果使用了这个寄存器，则需要在函数开头保存到栈上，函数结尾返回前恢复。另外值得注意的是，函数调用的参数，是调用者push到栈上的，被调用者也不会为参数额外分配空间，而是直接访问栈底。导致在栈上出现了这种交错的局面。即，本应属于被调用者的函数参数被放到了调用者栈上，本应属于调用者的寄存器被放在了被调用者那边。可以想象，如果抽象解释也用这种栈布局将会带来问题，在源码层可以直接分析得到的结果在二进制层将需要额外的context
sensitive level.</p>
<blockquote>
<p>在抽象解释的视角下，就好像是把部分和调用无关的局部变量保存到callee的栈上，相关的变量可能由于敏感度不足而混合。在n-callsite-sensitive的场景下，这些受到影响的变量会等效于损失一层callsite-sensitive。此外，仔细观察epilogue可以发现，最后寄存器的恢复（最后的pop指令）依赖于frame
pointer的精确保留，而frame pointer本身也是callee saved register。</p>
</blockquote>
<blockquote>
<p>起初，callee saved寄存器由于精度不足导致frame
pointer混合了其他的值。在函数结尾的时候无法正确恢复自身保存callee saved
register，又会导致caller的frame
pointer被损坏，最终形成了链式反应，影响整个调用链上的函数的分析。不仅影响了分析结果，还会使得消耗更多的时间才能迭代到达不动点。</p>
</blockquote>
<p>想象这样的场景，分析使用了1-callsite-sensitive，frame
pointer在调用其他函数的时候作为callee saved
寄存器而与来自其他函数的frame
pointer混合，导致不精确，在函数结尾的时候，由于有太多种load的可能，BAI直接返回了Top。从而caller保存的寄存器也无法恢复，进一步损害caller的fp，从而形成链式反应，导致调用链上的callee
saved
register都出现问题，变成了TOP，直接导致很多局部变量都丢失，在函数调用后大量寄存器和变量都只剩下Top。不仅精度下降了，迭代到Top的时间也更长。</p>
<p>simply one level of precision degradation seems not a big deal, but
when it combines with frame pointer and callee saved register, it causes
a big crash on precision.</p>
<p>但是实际给我们带来分析困难的情况更为复杂。在函数开头的时候会有这样的情况：
即使用了framepointer，并且在函数结尾的时候基于frame
pointer的值恢复到sp。问题在于，BAI里只对SP做了特殊处理，即使sp被弄坏了，每次调用前还是能恢复。但是fp就不一样了，基本上就是一个简单的指针数据</p>
<p>仔细观察结尾可以发现，callee saved
reg是在修改sp后恢复的。寄存器的值的正确恢复依赖于fp（r4）的值的精确保留。然而fp也是普通的callee
saved
register，当调用其他函数的时候会被保存到栈上，由于上面提到的精度下降问题，fp的值会在调用返回的时候无法精确解析，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">000199cc f0  b5           push       &#123; r4, r5, r6, r7, lr &#125;</span><br><span class="line">000199ce 03  af           add        r7,sp,#0xc</span><br><span class="line">...</span><br><span class="line">00019c7e fc  1f           subs       r4,r7,#0x7</span><br><span class="line">00019c80 05  3c           subs       r4,#0x5</span><br><span class="line">00019c82 a5  46           mov        sp,r4</span><br><span class="line">00019c84 f0  bd           pop        &#123; r4, r5, r6, r7, pc &#125;</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>我们只有1-callsite
sensitive，当调用链过长的时候，还是会出现merge的情况 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A -&gt; B -&gt; C</span><br><span class="line">D -&gt; B -&gt; C</span><br></pre></td></tr></table></figure>
两个C的栈上数据会被合并。栈上保存了寄存器，因此来自不同B的栈上变量会混在一起，返回到B后如果遇到内存读写，出现了不精确的问题，就会读出TOP。比如上面的frame
pointer出现了问题，导致pop的值出现了问题。</li>
</ol>
<p>我们采取的方法是，</p>
<p>此外，tail call也对我们的分析产生了影响。Tail
call在汇编层表现为函数末尾的普通跳转，不会识别为函数调用，仿佛函数体发生了重叠。除了部分plt段外部函数调用需要特殊处理外，似乎没有很大的影响。最后值得注意的是对32位代码和64位代码的支持，因为真实应用中依然存在大量的32bit代码。虽然没有特别多的问题，但在编程的时候需要额外注意。</p>
<h3 id="跨语言分析">跨语言分析</h3>
<ol type="1">
<li><p>创建静态分析的JNI环境 -- 放到后面去</p></li>
<li><p>summaryIR的设计。</p></li>
<li><p>JNI调用的转换。</p></li>
</ol>
<h3 id="java侧框架解耦">Java侧框架解耦</h3>
<p>为了实现对Java侧框架解耦，我们的初始想法是，能否重打包。</p>
<h2 id="设计">设计</h2>
<p>在本节，我们在3.1节中介绍了NativeSummary的架构，并在之后的小节中介绍了各个模块的实现细节。</p>
<p>图1展示了NativeSummary的总体架构，由3个模块组成。</p>
<p>（TODO 画个图，表示从哪些JNI API转换为哪些Java调用）</p>
<h3 id="映射解析模块">映射解析模块</h3>
<p>映射解析模块用于静态绑定的简单解析并将.so文件解压出来以便于进一步分析。在APK中，二进制代码作为动态链接库被按架构放在lib/文件夹下。首先我们会选择我们支持的架构中，对应文件夹下动态链接库数量最多的架构作为主要分析的架构，并收集.so文件中以Java开头的导出符号。其次是提取并解析Dex文件，收集Java侧代码中所有带有native
modifier的函数。最后，我们会根据JNI的name
mangling规范，将Java侧JNI函数对应到native侧函数入口，生成native函数的签名，并输出为json格式。如果发现有JNI_OnLoad函数也会放到json中，以便二进制分析模块处理动态解析的情况。</p>
<!-- 新加 -->
<p>由于项目早期是基于Angr的VSA，因此这一部分代码使用Python语言编写，但是已经移除了angr的依赖，而是使用更轻量级和高效的pyelftools模块[TODO
cite]。Dex的解析使用了androguard模块[TODO
cite]，由于它会做一些交叉引用分析，这一块的耗时最多。</p>
<h3 id="二进制分析模块">二进制分析模块</h3>
<p><strong>Invocation</strong>：二进制分析模块的范围是单个so文件。把.so文件，和静态解析的json结果作为输入。首先会为当前APK创建一个Ghidra
project，并使用GhidraHeadless命令行工具导入每个.so文件，并将我们的插件提供的入口脚本作为PostScript参数。导入时Ghidra会有一些预分析，在代码段划分函数边界并创建函数，识别常见的libc导入函数，创建交叉引用等。</p>
<p><strong>JNI环境布置</strong>：内存布局如图[TODO]所示。JNI调用需要JNIEnv*作为参数，JNI_OnLoad需要JavaVM*作为参数。我们的抽象解释在分析过程中可以计算出对这种结构体中函数指针的调用，因此我们只需要在地址空间中布置好相关结构体即可。首先为每个JNIAPI创建对应的外部函数，然后按照结构体的定义布置好指向刚才创建的函数的起始地址作为函数指针。启动分析时，直接将对应的参数设置为布置的函数指针的地址即可。</p>
<p><strong>不透明数据流追踪</strong>：JNI
API调用时数据流有多种情况。</p>
<ul>
<li>不透明的JNI对象：根据JNI标准，这种对象通常是jobject、jclass、jmethod等指针大小的不透明类型，由GetObjectClass等类型返回，只能原样传递回相关的API。单独实现为特殊的region似乎更好，但为了实现的简洁性，我们复用了Global空间（用于整数和指针）的一块高位范围。表现为一个非常大的负数或者内核的地址空间。不透明类型本身也不该被程序操作，因此不会有太大问题。</li>
<li>buffer类型：native
code可能会调用malloc等内存分配函数。调用GetStringUTFChars这种api时也会返回一块可操作的内存。因此我们使用BAI的堆模型，分配一块新的Heap
Region，同时（带上污点？）。但是这种方式在面对动态生成的字符串，字符串处理函数的时候还是会遇到问题。</li>
<li>整数类型：我们使用BAI的污点追踪功能，返回一个带有污点的Top值。不仅让条件判断都判断为可能满足【去掉前面说的assume
all paths are possible】，同时保证了能够追踪数据流。</li>
</ul>
<p><del>然而，还是有很多conercase无法解析。比如动态生成的数据，各种字符串处理函数，strcat。【TODO】</del></p>
<p><strong>动态注册解析</strong>：JNI_OnLoad函数的动态注册往往是简单地按照规范使用RegisterNative函数，传入作为全局变量的含有动态注册信息的结构体。因此也出现过基于静态扫描寻找结构体的动态注册解析方式。我们对JNI_OnLoad函数运行相同的静态分析，在RegisterNative函数建模时获取动态注册的结构体。</p>
<p><strong>缓存的ID</strong>【找个更专业的词】：使用JNI接口时有一种缓存MethodID，classID的编程模式可以提高性能【cite】，但也给我们带来了新的挑战。我们将JNI_OnLoad相关的调用也放入summaryIR中，保存JNI_OnLoad对全局变量的修改。当其他函数使用到这种全局变量的值的时候，在解析时会直接引用到JNI_OnLoad中的指令。表现在IR中：允许其他函数引用JNI_OnLoad中API调用的返回值。在后续的类型分析中从而正确解析相关的类型。</p>
<p><strong>总结</strong> 1.
启动分析前，我们还根据注册信息为每个入口函数设置对应的signature信息，并
1.
如果有JNI_OnLoad函数，则先分析它，并在对RegisterNatives函数的建模中记录动态注册信息。最后为新增的函数设置参数和返回值类型。
1.
根据参数类型设置好对应的抽象值，启动静态分析。分析过程中，外部函数建模代码负责记录外部函数调用，并处理返回值。
1.
分析完成或超时后，我们获取调用点处的寄存器和内存情况，解析调用参数，解析返回值，创建summary
IR并输出。</p>
<h3 id="summary-ir">summary IR</h3>
<!-- 新增 -->
<p>我们模仿编译器的设计，设计了一套简单的IR用于表示二进制分析的结果，语法如图所示【参考
c-summary写下】。体现外部函数调用，和数据流在函数参数，调用参数，调用返回值，函数返回值之间的数据流关系。【或者直接说，和相关的数据流关系】。主要的直觉是，表示当前注册的JNI函数可能调用到的所有外部函数（包括JNI接口），以及参数，返回值和外部函数调用的参数之间的数据流关系。分析单个JNI函数时可能native侧会调用大量的函数，而我们最后在IR中只转换为一个函数。IR中没有控制流相关的结果，因为我们没有找到很好的方式提取数据流。</p>
<p>指令的顺序是按照在静态分析时第一次遇到的顺序。所以可能会出现，前面的指令引用到后面指令的返回值的情况，给后续Java语句生成带来了一些挑战。此外，为了处理【缓存的ID】的情况，
我们还允许引用JNI_OnLoad函数里得到的值。</p>
<p>一个函数的summary IR的语法可以被以下的语言表示 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Module&gt;        :=      &lt;Function&gt;*</span><br><span class="line">&lt;Function&gt;      :=      &#x27;define&#x27; &lt;Type&gt; &#x27;@&#x27; &lt;FunctionName&gt; &#x27;(&#x27; &lt;Param&gt;* &#x27;)&#x27; &#x27;&#123;&#x27; &lt;Instruction&gt;* &#x27;&#125;&#x27;</span><br><span class="line">&lt;Instruction&gt;   :=      &lt;CallInst&gt; | &lt;PhiInst&gt; | &lt;RetInst&gt;</span><br><span class="line">&lt;CallInst&gt;      :=      &lt;Value&gt; &#x27;=&#x27; &#x27;call&#x27; *ID* &lt;Value&gt; ( &#x27;,&#x27; &lt;Value&gt; )*</span><br><span class="line">&lt;RetInst&gt;       :=      &#x27;ret&#x27; &lt;Value&gt;</span><br><span class="line">&lt;PhiInst&gt;       :=      &lt;Value&gt; &#x27;=&#x27; &#x27;phi&#x27; &lt;Value&gt; ( &#x27;,&#x27; &lt;Value&gt; )*</span><br><span class="line">&lt;Value&gt;         :=      &lt;Param&gt; | &#x27;null&#x27; | &#x27;top&#x27; | NUMBER | STRING | &#x27;%&#x27; ID | &#x27;@&#x27; ID</span><br><span class="line">&lt;Param&gt;         :=      &lt;Type&gt; ID</span><br><span class="line">&lt;Type&gt;          :=      ID</span><br><span class="line"></span><br><span class="line">&#x27;void&#x27; | &#x27;int&#x27; | &#x27;long&#x27; | &#x27;short&#x27; | &#x27;byte&#x27; | &#x27;char&#x27; | &#x27;float&#x27; | &#x27;double&#x27; | &#x27;boolean&#x27; | &#x27;null&#x27; | &#x27;array&#x27; &lt;Type&gt; | &#x27;object&#x27;</span><br></pre></td></tr></table></figure></p>
<h3 id="java语句生成模块">Java语句生成模块</h3>
<p>由于二进制和java语言之间的差异，我们无法找到直接转换的方式，而是基于观察发现，部分JNI接口的使用模式对应着一些Java语句的操作，做尽力而为的转换。相关的转换见表【】</p>
<p>但是在具体的转换过程中，我们发现还是有很多代码逻辑需要在生成函数体之前完成。因此我们模仿编译器中端架构，将代码组织为了Pass的形式</p>
<p>java语句生成模块的相关Pass如图所示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">预加载分析 -&gt; 外部函数调用转换 -&gt; JNI类型分析 -&gt; 函数体生成</span><br></pre></td></tr></table></figure>
<p><strong>JNI类型分析</strong>：在JNI调用中有这样的编程模式，获取classID，methodID后传入相关的API。我们将ID相关的调用映射到对应的Soot对象，便于后续分析的使用。然而在现实生活中的例子里也会出现相关的字符串没有在二进制分析处被正确解析的情况，会导致本分析无法解析出对应的ID，影响后续的相关Java操作的生成。</p>
<p>此外，IR还需要考虑缓存ID的编程模式。</p>
<p>函数体生成：调用Soot的API，创建Jimple代码，利用</p>
<p><strong>未知导入函数的调用</strong>：二进制代码可能会因为引入了相关库函数而导入了其他动态链接库的函数。因此我们难以完整地考虑所有外部函数。我们创建了一个java类【叫什么来着】，将未知的导入函数对应创建一个static函数，从而将相关的调用转换为Java函数的调用。</p>
<p>自动类型推断：创建java侧函数需要提供函数签名。但是C语言导入函数只有名字。我们需要推断出它们的签名。对于已知的常用库函数，比如libc，Ghidra会自动设置签名，我们通过Ghidra的函数签名接口获取函数签名。但是对于未知的库函数怎么获取参数数量？</p>
<p>TODO，搞完几个native_leak再回来写。</p>
<p><strong>APK重打包</strong>：Soot能直接加载APK，并输出为APK格式。它首先排除在排除列表中的类，将所有加载的dex字节码转换为jimple
ir，再将加载的字节码重新转换为字节码。然而，我们在加载部分真实应用的库函数代码时遇到了一些报错（eg:
android.support.constraint.solver.LinearEquation.replace）。我们试图让soot保留部分代码，但是需要对soot代码结构有较大修改。我们最后的方案是首先让soot输出dex文件，然后根据需要修改的class，将dex文件和原有APK中的dex重打包，从而最大程度减少对原有代码的修改，同时增加效率。</p>
<h2 id="evaluation-实验和思路">Evaluation 实验和思路</h2>
<p>RQ1 是测试集，比较完善。增加表对比支持的JNI函数的功能性。</p>
<ol type="1">
<li>背景：真实应用数据集上，使用的sources和sinks。</li>
<li>成功跑出的数量，增加的native边数量，增加的native相关的数据流。发现的易用性问题等各种问题。</li>
<li>我们跑出的flow是否准确？找一下一些我们native相关的flow，稍微分类一下。</li>
</ol>
<h2 id="evaluation">Evaluation</h2>
<blockquote>
<p>各个模块的代码量说一下，列个表？【TODO】 我们</p>
</blockquote>
<p>各个模块的代码量如图【TODO】所示，我们通过回答三个RQ来进行评估。</p>
<ul>
<li>RQ1: NativeSummary在测试集中表现如何
<!-- - RQ2: NativeSummary在真实应用数据集上的效率如何？ --></li>
<li>RQ2: NativeSummary在真实应用数据集中是否有助于污点分析。</li>
</ul>
<h3 id="rq0-native-code-in-the-wild">RQ0 native code in the wild</h3>
<p>按照本地代码中外部，java侧函数调用的频率，展示一个相关的统计。说明和数据流相关的函数调用有很多，就算没有也可以辅助逆向。</p>
<h3 id="rq1-benchmark">RQ1 Benchmark</h3>
<p>这一节中，我们evaluate NativeSummary by comparing with Jucify and
JN-SAF on two benchmarks: 1. NativeFlowBench from JN-SAF[] 2.
NativeFlowBenchExtended designed by us.</p>
<p><strong>NativeFlowBench</strong>：NativeFlowBench是[JN-SAF]中提出的，人工构造的App
benchmark，用来测试JN-SAF的性能，并且被后续工作【μDep】沿用。我们从中排除了3个使用了NativeActivity的app，因为支持起来麻烦而且在现实生活中使用的很少。值得提及的是，我们包含了ICC相关的App，因为我们的方法能够直接支持它。</p>
<p>NativeFlowBench只考虑到了最为简单的几种native
code的使用方式，而且关注的是对Java侧的操作，基本上每个测试用例都可以直接翻译为Java函数，无法反映真实世界中native
code的使用。我们省略了其中三个App，即NativeActivity的App，因为我。
<del>Jucify也提出了自己的benchmark，但没有较好的分类，且包含了字符串混淆这种favor符号执行的用例。</del></p>
<p>Jucify[TODO cite] also brings up its own benchmark. We didn't include
it because it lacks good classification, and includes test cases that
favor symbolic execution like string obfuscation.</p>
<p>我们在NativeFlowBench上的结果如图所示【】。</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Benchmark</th>
<th style="text-align: center;">Result</th>
<th style="text-align: left;">Benchmark</th>
<th style="text-align: center;">Result</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">native_complexdata</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">icc_nativetojava</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_compexdata_stringop</td>
<td style="text-align: center;">xx</td>
<td style="text-align: left;">native_heap_modify</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_dynamic_register_multiple</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">native_leak</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_leak_dynamic_register</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">native_leak_array</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_method_overloading</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">native_noleak</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_multiple_interaction</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">native_noleak_array</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_multiple_libraries</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">native_nosource</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_set_field_from_arg</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">native_source</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_set_field_from_arg_field</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;">native_source_clean</td>
<td style="text-align: center;">◯</td>
</tr>
<tr>
<td style="text-align: left;">native_set_field_from_native</td>
<td style="text-align: center;">◯</td>
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Jucify没有跑NativeFlowBench，因为NativeFlowBench中大量使用了<code>__android_log_print</code>这个native侧leak函数，而Jucify没有考虑native
leak的情况。他们没有考虑native的sink点，即android_log_print函数</p>
<p>NativeSummary能处理绝大多数的例子，达到和JN-SAF基本相同的准确率。native_source_clean这个例子中，imei被保存为一个数据对象的成员，这个对象被传入native
method中对应成员被重新赋值为常量字符串，最后这个成员变量被打印。我们使用Jadx手动查看了重打包的APK中的代码，正确反映了对应语义，因此我们认为这个误报是FlowDroid的精度不足所致，而JN-SAF的Java侧分析框架是Amandroid[TODO]，因此没有这个问题。<del>为了验证，我们重新从源码编写了一个对应Java代码的应用，FlowDroid依然能够检测出来。</del></p>
<p>NativeFlowBench is far from being representative of real world usage
of JNI interface. So it can barely reflect native code usage in
real-world apps. By manually examing real world codes, we summarized
other cases.</p>
<p><strong>NativeFlowBenchExtended</strong>：基于我们对real world
apps中native
code使用的观察，我们发现了很多NativeFlowBench没有考虑到的更为复杂的JNI
API的用法，并总结为了一个Benchmark：</p>
<p>each testing one perspective of our newly discovered inter-language
challenges</p>
<ul>
<li><p>native
copy：将传入的Java字符串转换为C语言字符串，并使用memcpy复制，再创建一个新的Java字符串返回。这个用例能够测试对Native自身的数据流的追踪。</p></li>
<li><p>native
encode：基于上一个用例，但将复制改为base64编码。提高了对native侧数据流追踪的要求。</p></li>
<li><p>native file leak, native socket
leak：使用NDK提供的API写入文件，进行检测。</p></li>
<li><p>native global id：在JNI_OnLoad中预先计算JNI调用中使用的到的Method
IDs，Class
IDs，以boost性能。它要求分析器能够处理使用全局变量的跨函数数据流。这个用例来自对【】应用的用法的观察。这个case来自我们对【】应用的源码的观察。</p></li>
<li><p>native
handle：基于在【那个开源gif库】中观察到的使用模式，将一个malloc得到的堆指针作为jlong类型返回到java侧作为句柄，传入其他API使用。</p></li>
</ul>
<p>把那边毕设的表格移过来</p>
<p>在NativeFlowBench上我们能达到和JN-SAF一样的准确率。在NativeFlowBenchExtended上，我们准确率更高。</p>
<p>Benchmark
app只能覆盖到JNI接口的一部分使用方法，而现实应用中，本地代码的使用要复杂得多，因此我们没有计算相关的准确率。</p>
<p>由于不知道这些复杂情况在真实应用中的分布，因此在这些测试数据集上的准确率难以反映真实应用中的分析情况。更不用说，真实应用中还可能有没考虑到的情况，以及交互使用导致的更复杂的情况。因此我们不计算在这些数据集上的准确率。</p>
<p><strong>RQ1 Answer</strong>:
我们的工具在NativeFlowBench上达到了和效果最好的工具一样的precision。在NativeFlowBenchExtended中，我们能handle很多其他工具没有考虑到的情况。</p>
<h3 id="rq2">RQ2</h3>
<p><strong>数据集</strong>：</p>
<p><del>测试效率的数据集，我们使用了JN-SAF采用的NativeFlowBench，以及我们自己设计的拓展数据集。对于效率和真实数据集上的表现，</del>
<del>我们排除了不包含native方法，或不包含so的apk。</del></p>
<p>我们在两个真实应用的数据集中测试我们的工具，并和JN-SAF,Jucify对比，如表【展示数据集和初筛结果】所示，分别是F-Droid数据集【cite，并且标上访问日期】，和Malradar数据集【cite】。
我们首先运行了FlowDroid作为baseline。然后，我们运行每个工具，将其发现的敏感信息流与baseline做对比。我们没有和μDep对比，因为它不仅需要运行一个安卓模拟器，较为heavy
weight，同时它还有部分脚本是基于IDA，这个商业软</p>
<p>我们将每个工具打包了并发布了为docker
image，使得任何人都可以非常便利地通过一行命令内启动各个工具。</p>
<!-- μDep通过使用基于fuzzing的方法，提取native函数的参数和返回值之间的数据流关系。 -->
<p><strong>数据集预处理</strong> 我们通过同步F-Droid
repo的方式下载F-Droid数据集。repo中包含相同App的不同版本，我们进一步做了去重处理。为了筛选出我们感兴趣的，包含有native
code的app，我们筛选出至少包含一个shared object(.so
file)同时至少有一个方法带有native modifier的app。
此外，我们发现在F-Droid数据集中有大量flutter应用，尽管这种应用的APK中包含native库，但这种应用的代码在javascript字节码文件中，我们的分析无法产生有用的结果，因此我们将其过滤掉，通过匹配libflutter.so文件名。</p>
<!-- Native Activity的情况？ -->
<p><strong>实验的设置</strong>： 我们的实验跑在在服务器（两个64核Epyc
7713，256G内存）上，但是我们通过使用docker的"--cpus
1"flag限制了CPU为单线程的性能，同时通过docker的"--memory=32G"flag限制了最大可用内存为32G。</p>
<p><strong>Sources和Sinks的选取</strong>：数据流结果会大量受到Sources和Sinks文件的影响【要不要cite】。我们基于TaintBench中从各个现有工具中合并得到的sources和sinks点，然后，我们将它转换为每个工具能接受的的格式，并对它们做出相应的修改以让它们使用。看似这个source和sink过于verbose，但正如后文所示，真正的穿过native的flow数量并不多。</p>
<!-- 它删去了过于trivial的点（String和常见数据结构的方法）。然后，我们将Sources和Sinks文件转换为每个工具的格式，并对它们做出相应的修改以让它们使用。 -->
<!-- source和sink点对分析的效果有很大影响。【引用论文】直接使用flowdroid默认的ssource，sink效果并不好。我们首先基于taint bench合并的source和sink点，然后通过手动查看分析结果，删除了大量trivial的结果涉及的source和sink点。 -->
<p>首先，我们对每个工具统计了能够成功地完整输出污点数据流结果的app数量，如表【todo】所示，因为在面临真实世界中的app时，很多应用在分析时产生了报错。我们把成功输出taint
flow结果视为一次成功的运行。其中有271个app能同时被所有tool成功分析。然后，我们统计了每个工具输出的数据流总数量。</p>
<p>更进一步地，我们分析了每个工具的二进制分析部分的输出，统计了他们分析的的被注册的native函数的数量，以及在分析中发现的对java的调用边数量。
-
可能有人会问，java调用边能代表分析的效果吗，但在JNI函数的使用中，对Java侧的调用是最主要的，</p>
<p>此外，我们尝试了直接比较增加native分析前后，报告出来的污点数据流的变化情况。更具体地，比较jucify，nativeSummary和Flowdroid。但我们发现，即使在完全相同的设置下，flowdroid也会表现出约17%的数据流变化，远大于真正因为native分析而导致的数据流变化，因此我们放弃了这种对比方式。</p>
<p>JNSAF发现的flow似乎远小于其他基于FlowDroid的工具，这一点在miuDep和【analyzing
three】中也被证实了。一方面Amandroid的检查结果会在完全相同的输入下有很大波动。另一方面，由于是按需的分析，binary分析会在java侧分析遇到native函数时启动，因此也会影响bianry分析的函数数量。这也可能是为什么JN-SAF的总分析时间也相对较短。</p>
<p>此外，我们发现，当Jucify的binary分析超时时，相关的数据处理会被直接跳过，导致现有的分析结果也无法被Java侧分析利用。因此其实只有很少部分【】的apk真正被修改了。绝大多数的app都相当于直接运行flowdroid。</p>
<p>（再画个表，包含flow的数量，和native有关的flow数量，ns里额外包含和Native相关的flow数量）</p>
<h4 id="用户友好性">用户友好性</h4>
<p>现有工具似乎并没有很好地为真实世界中的应用做准备。
Jucify没有输出任何flows的具体信息，而仅仅打印了是否有任何flow through
native。我们通过修改了源码让它把污点流输出xml格式。此外，它使用了自定义的Sources和
Sinks格式，而不是使用flowdroid的格式，且Sources和sinks文件位于jar包内部，更改它需要重新编译。</p>
<p>JN-SAF自从2018年12月后就不再更新，并基于一个使用python2的旧版本angr。当我们正在使用真实世界中的应用测试JN-SAF的时候，发现大多数的App(91.32%
on F-Droid dataset, 88.51% on Malradar dataset) 报错说“loadBinary can
not finish within 1
minutes”【todo找一下】。我们通过人工查看JN-SAF的源码，发现JN-SAF在反编译APK的dex字节码时，硬编码了一个1分钟的超时时间，这一点绝对不用户友好。因此我们修改了它和其他两处超时时间，并重新编译工具。（无法轻易port到最新版angr）
此外，可能是使用了旧版的apktool，依然有【TODO】数量的APK在解包APK时出错。</p>
<h4 id="dataflow-results">Dataflow results</h4>
<p><strong>JN-SAF</strong>：</p>
<p>JN-SAF检测到的flow总数量过少，经过调查，我们认为原因是JN-SAF使用的Java侧分析框架Amandroid的不稳定性在分析real
world apps时，正如<a
href="https://people.ece.ubc.ca/mjulia/publications/Analyzing_Android_Taint_Analysis_Tools_TSE_2021.pdf">《Analyzing
Android Taint Analysis Tools: FlowDroid, Amandroid, and
DroidSafe》</a>里所confirm的，Amandroid
在同一环境中每次独立运行时报告的数据流数量变化很大。</p>
<!-- 工具的介绍移到introduction里？ -->
<p><strong>Jucify</strong>
Jucify仅分析了native到java的调用边缘们，但它没分析控制流，或参数和返回值之间的数据流。它通过猜测参数和返回值之间的数据流的去生成bodies，而且实现也不够完善，这意味着它生成的数据流几乎不能被信任。这可能也是为什么它在实验中相比baseline差异最大。（它的实现也不完善）</p>
<p>Jucify不用户友好。</p>
<p><del>我们其中一个初始动机就是现有的工具无法在真实应用数据集中得到有用的结果，因为太多的应用都超时了。</del></p>
<!-- 初步的映射解析数据分析？多个架构的选择情况？ -->
<!-- We summarized the number of shared objects in different ISAs in the apps of
S2 and S3. There are 15,203 native libraries in dataset S2 and
S3. 73.0% of them (11,096 shared objects) are in ARM/ARM-
64 (armeabi, armeabi-v7a, and arm64-v8a), and 21.1% of them
(3,215 shared objects) are in X86/X86-64. Only around 5.9%
are in MIPS/MIPS-64, which we do not support analyzing. On
the other hand, in dataset S2 and S3, we find no native Activity
component, which we fail to resolve and is also reported to
be very rare in the datasets of JN-SAF -->
<!-- 我们和JN-SAF和Jucify做对比。我们统计了在F-Droid数据集上和Malradar数据集上各个工具的运行时间散点图，如图所示。【Jucify自身的超时时间是二进制分析的还是总的？说一下】。有xx%的应用都超时了。对于JN-SAF【有超时时间吗，没有就我们自己设置一个。说一下】我们有 -->
<p><img src="flows.png" /></p>
<h3 id="rq3">RQ3</h3>
<p>为了进一步确认RQ2中flow的情况，我们手动分析了。</p>
<h2 id="limitation">Limitation</h2>
<p>无法完整反映二进制侧的语义，比如控制流。</p>
<p>无法分析各种复杂的C++面向对象代码，此外，二进制代码还可能由Rust，go这种语言编写。</p>
<h2 id="相关工作">相关工作</h2>
<p>（要不要画个表，但是只有这三四个工作，分别标注Java侧分析框架，分析技术（符号执行、fuzzing），加上C-Summary可以再标个是否需要源码。还可以带上C-Summary的那个反编译的工作。是否支持动态注册？）</p>
<p>JN-SAF，Jucify，muDep是三个最相关的工作。JN-SAF提出了一种基于summary的自底向上分析，按需分析native函数，但是也因此和Java侧框架Amandroid耦合过深。Jucify提出了基于调用的统一表示，通过angr获取对Java侧的调用，并基于猜测的方法生成函数体。因此他们仅能完善调用边，无法分析更深入的数据流。此外，他们还不支持动态注册。muDep采取了一种基于fuzzing的方法，通过不断改变参数，观察其他参数和返回值的变化，从而判断数据流关系。他们使用基于IDA
scipts的自动处理脚本去解析调用边。</p>
<p>C-Summary 源码层。但转换后的代码仍然直接包含JNI
interface的调用，需要修改Java侧框架处理这些函数调用。此外，它会保留部分JNI原语，需要修改Java侧分析框架处理。（此外，它也没那么综合完善，依然有很多复杂情况没有考虑到。）一个更进一步的工作基于现有的反编译器去分析没有源码的JNI程序。它没有开源。（我们认为这种方案在真实应用上还会遇到更多困难。）</p>
<p>有一些其他的没那么相关的： 1.
在早些的时候有一些C语言到Java语言的转换技术。然而，他们的目标是为了运行，而不是静态分析，因此我们认为它会生成一些复杂的用法，这样的用法现有的静态分析器会难以处理。
1. JNILight
形式化地定义了JNI接口下，同时包含C语言和Java语言的语义。【TODO从论文找更精确的定义】基于它或许能重新定义一套更完善的分析框架。</p>


	<div class="row">
    <embed src="/2022.assets/毕设论文-2022年5月17日-王纪开.pdf" width="100%" height="550" type="application/pdf">
	</div>



]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>StaticAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始编写反编译器-WebAssembly</title>
    <url>/2022/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E5%8F%8D%E7%BC%96%E8%AF%91%E5%99%A8-WebAssembly/</url>
    <content><![CDATA[<p>NotDec：从零开始编写反编译器： https://github.com/am009/NotDec</p>
<ul>
<li>2022年10月5日
项目目前处于起步阶段，希望有大佬能来一起参与开发。</li>
</ul>
<span id="more"></span>
<h3
id="为什么要反编译-二进制分析和源码分析的差距到底在哪">为什么要反编译？
二进制分析和源码分析的差距到底在哪？</h3>
<p><strong>程序分析和程序变换相结合</strong>：我一直在思考，二进制分析和源码分析的差距到底在哪？我们知道，源代码一般是不能被直接执行的，我们之所以能够在源代码这个层次上编程，得益于最初编译技术的发展。程序在编译后变成了机器能理解的代码，但是同时也变得更复杂了。从这个角度看，编译器也可以看作是一种混淆，而我们去除混淆后不仅能更容易理解，也使得静态分析更加容易。</p>
<p>我们知道，机器执行的是汇编指令，有各种寄存器，内存，然后高层的数据类型，比如结构体和数组，在汇编指令的层次也不复存在。但最关键的是，每个函数的局部变量，变成了线性内存中维护的栈空间。（callee
saved register和寄存器也是，但是这里暂时不提）举一个很简单的例子。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> arr[<span class="number">3</span>] = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> b = <span class="number">1</span>;</span><br><span class="line"><span class="type">int</span> c = <span class="number">2</span>;</span><br><span class="line">arr[input()] = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>如果直接分析汇编指令，就有点类似下面的形式。可以看到对数组的访问可以影响后面的所有变量。这种出现问题的情况还有很多。现在有不少针对二进制代码的定制化静态分析，但是因为处理了很多这样的复杂情况，效率上也是远远比不上源码的分析效率的。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> arr[<span class="number">6</span>];</span><br><span class="line">arr[input()] = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>既然编译器会增加这么多复杂性，很自然的想法是怎么将编译器做的变换，逆着变换回去，变成原来的更简单的形式。这自然而然地让人想到了反编译。反编译技术的架构一般如下：除了最后的控制流分析，前面的步骤基本上就是我们想要的。</p>
<p>反编译器架构：</p>
<ol type="1">
<li>前端：将字节码转为LLVM IR</li>
<li>中端：优化与分析
<ol type="1">
<li>分析函数参数、分析callee saved register (wasm可以跳过这个阶段)</li>
<li>SSA构建：使得前端可以有些冗余的alloca，由SSA构建来将相关alloca消除。
（编译原理相关）</li>
<li>GVNGCM：Global Value Numbering and Global Code Motion
优化算法，有强大的优化能力，有助于反混淆等。（编译原理相关）</li>
<li>内存分析：将各种通过内存访问的变量显式地恢复出来。可能要用到指针分析算法，类型恢复等。关键词：Memory
SSA。</li>
</ol></li>
<li>后端：高层控制流恢复，将字节码转为AST，打印为高级语言的形式。</li>
</ol>
<p>有的人可能会说反编译器可能不能保证静态分析的安全性（soundness），但是随着反编译技术的发展，很多分析手段都是较为通用的，同时能够在遇到异常情况的时候报出警告，告知相关不安全的判断。</p>
<h3
id="当我们说转ir的时候我们在说什么">当我们说转IR的时候，我们在说什么</h3>
<p>在反编译过程中，随着分析的深入，我们的IR也从low level变得更加high
level。引用《Static Single Assignment for Decompilation》第6页（1.1
source code）附近说的，源代码可以说分为几个层次：</p>
<ol type="1">
<li>高质量，带注释源码（Well written, documented source code, written by
the best human programmers.）</li>
<li>丢失了注释，函数名和各种变量名，结构体成员名字（Source code with few
to no comments, mainly generic variable and function names, but
otherwise no strange constructs. This is probably the best source code
that a fully automatic decompiler could generate.）</li>
<li>同上，但是偶尔有奇怪的（底层的）东西（occasional strange
constructs）</li>
<li>没有从内存中识别变量，所有的内存访问都是通过地址计算（Source code
with no translation of the data section. Accesses to variables and data
structures are via complex expressions such as <em>(v3</em>4+0x8048C00).
Most registers in the original program are represented by generic local
variables such as v3.）</li>
<li>同上，而且所有原始的寄存器也存在（but all original registers are
visible.）</li>
<li>同上，相当于套了一个虚拟机，整个程序就是一个巨大的switch结构，根据不同的opcode去执行不同的指令。（but
even the program counter is visible, and the program is in essence a
large switch statement with one arm for the various original
instructions）</li>
</ol>
<h3 id="现有的wasm反编译器">现有的wasm反编译器</h3>
<p>正如上文所说，现有的“反编译器”，很多的问题都在于没有去理解更深入的语义。</p>
<p>wasm有层次化的几个语言特性，也就意味着优化程度较高的代码对更底层的使用往往更少，导致简单的折叠出来的代码也有不差的效果。但是实际上并没有多少“反编译”的工作在里面。</p>
<ol type="1">
<li>栈 对应着SSA</li>
<li>local 对应着没有转为SSA的局部变量</li>
<li>内存中另外维护的栈 对应着需要取地址的变量，最为复杂。</li>
</ol>
<p>观察现有的“反编译器”：</p>
<ol type="1">
<li>wasm2c
这是wabt的一个工具，可以配套一些外围代码让wasm转换后的C语言能够运行起来。它比套虚拟机好一些，因为wasm指令还是比较简单的，可以转换为C语言指令，而不用弄一个巨大的switch
case。</li>
<li>wasm-decompile 这也是wabt的一个工具，</li>
<li>wasmdec
github上的一个简单的开源项目。很多这种“反编译器”一看代码量非常小，必然是不可能有完善的反编译分析的。问题也在于没有对内存有足够的分析。</li>
<li>jeb-pro
这个软件包含一个商业的反编译器，之前在安卓和二进制那边都有一些名气。二进制那边出名的反编译器大多都不怎么支持wasm和EVM，但是它似乎对EVM字节码和wasm都有支持。这种从二进制那边过来的反编译器想必基础更加扎实，效果应该也更好。</li>
</ol>
<h2 id="wasm的反编译">wasm的反编译</h2>
<ol type="1">
<li>前端：wasm字节码转LLVM IR
<ul>
<li>wasm独特的，可静态类型检查的栈结构，需要稍微特殊地处理一下。</li>
<li>wasm独特的控制流，处理起来也不是那么简单。</li>
</ul></li>
<li>中端：优化与分析
<ol type="1">
<li>分析函数参数、分析callee saved register (wasm可以跳过这个阶段)
<ul>
<li>wasm作为新时代的字节码标准，作为在浏览器运行中的标准，层次就比汇编高了很多，反编译也更加容易。这里主要说的是，汇编中需要指令和数据的区分，函数的识别，函数参数与保存的寄存器的处理，而这些在wasm中完全不需要。</li>
</ul></li>
<li>SSA构建：使得前端可以有些冗余的alloca，由SSA构建来将相关alloca消除。
（编译原理相关）（可以直接用LLVM的）</li>
<li>GVNGCM：Global Value Numbering and Global Code Motion
优化算法，有强大的优化能力，有助于反混淆等。（编译原理相关）（可以直接用LLVM的）
<ul>
<li>还有很多LLVM的pass可以用过来，可以参考RetDec用的。</li>
</ul></li>
<li>内存分析：将各种通过内存访问的变量显式地恢复出来。可能要用到指针分析算法，类型恢复等。关键词：Memory
SSA。</li>
</ol></li>
<li>后端：高层控制流恢复，将字节码转为AST，打印为高级语言的形式。</li>
</ol>
<h3 id="wasm的栈处理与wasm混淆">wasm的栈处理与wasm混淆</h3>
<figure>
<img src="wasm-design-rationale.png"
alt="wasm设计时就考虑了解码为ssa" />
<figcaption aria-hidden="true">wasm设计时就考虑了解码为ssa</figcaption>
</figure>
<p>其实底层看，wasm的栈机制和结构化控制流，和一个东西很像。在SSA形式的IR中，用于替换Phi指令的语义等价的另一种表示形式是basic
block argument。<a
href="https://mlir.llvm.org/docs/Rationale/Rationale/#block-arguments-vs-phi-nodes">MLIR</a>也提到了，<a
href="https://news.ycombinator.com/item?id=22432344">这里</a>也有相关的讨论。。所以其实wasm字节码的栈部分其实应该可以直接转成SSA形式。</p>
<p>如果你还是不确定Phi指令和Basic
Argument是一个东西的话：因为Phi指令必须在基本块开头，而且必须对每个precessor都有一个对应的值，即操作数数量和precessor数量相同。（如果你说未初始化的变量。。那可以在entry块给每个变量赋值为undef，这样必然有值存在）然后想象把Phi指令的操作数直接保存到这条边上，更进一步放到跳转过来的每个jump语句处，然后phi指令对应的value还是放在当前基本块开头，这样其实就变成了BasicBlockArgument。</p>
<p>那wasm的栈到底要怎么转为SSA形式呢？我们可以参考basic block
argument思想，在每个block或者loop块，为每个block的argument创建Phi指令，最后再移除trivial的Phi指令即可。</p>
<p>wasm和其SSA的对应形式其实也是对应的。比如，在字节码层面直接进行控制流平坦化，可能遇到栈上的东西不平衡的形式。而栈对应着SSA的值，其实在OLLVM那边的控制流平坦化也会遇到处理Phi指令的问题。他们的策略是demote
ssa的值，降级到普通load-store的形式，这个就对应到wasm的local了。意味着我们也应该将导致栈不平衡的值作为local处理。这三个层次从上到下，限制越来越少，即下面的层次完全可以替代上面的层次，但是同时也越来越难以分析，因为其实限制越多越利于分析。</p>
<ol type="1">
<li>栈 对应着SSA</li>
<li>local 对应着没有转为SSA的局部变量</li>
<li>内存中另外维护的栈 对应着需要取地址的变量，最为复杂。</li>
</ol>
<p><strong>wasm的混淆自身有没有独特（specific
challenge）之处呢？</strong>
我觉得还是有的，核心其实就在转换这部分。通过先转为现有SSA，再转回Wasm的方式，最大程度复用了混淆中共通的逻辑，那么额外需要的逻辑自然就是wasm特有的挑战了。如果不转为IR直接混淆确实会将部分wasm特有的挑战和混淆逻辑混合在一起，应该是让事情更复杂了。</p>
<h3 id="wasm的控制流处理">wasm的控制流处理</h3>
<p>最近出来了wasm 2.0。看了下好多复杂的东西。不过wasm 1.0
（MVP）还是非常简单的。对于每个控制流相关的指令</p>
<ol type="1">
<li>block，loop分别对应在结尾，开头，增加一个label。</li>
<li>if对应一些label和br_if，br代表直接跳转，br_if同理，根据语义找到对应的跳转目标，生成条件跳转即可。</li>
<li>br_table看似比较麻烦，看了下和LLVM的switch语句对应得非常好啊。也是根据不同的值跳转到不同的边。</li>
</ol>
<h3 id="ssa-ir的选择---为什么用这个ir">SSA IR的选择 -
为什么用这个IR？</h3>
<p>搜了一下，wasm相关的IR有bineryen，和Cranelift。他们内部都有SSA相关的表示。cranelift作为SSA
IR，和LLVM IR在很多方面是非常相似的。但是最后各种选择可能</p>
<ol type="1">
<li>bineryen：非常有名，命令行工具是wasm-opt好像。它使用的IR似乎已经有点<a
href="https://github.com/WebAssembly/binaryen/issues/663">架构上的问题</a></li>
<li>Cranelift:
wasmtime的编译器架构中使用的IR。也支持SSA。但是没想到它居然直接添加了类似vmContext这种隐藏的参数，同时将全局变量lower到了用offset表示。</li>
</ol>
<p><strong>为什么不用现有的开源代码里面的转换部分？</strong>
确实存在相关的项目：</p>
<ol type="1">
<li><a href="https://github.com/WAVM/WAVM">WAVM</a>和<a
href="https://github.com/gwsystems/aWsm">aWsm</a>
这两个都有编译器，而且也是LLVM
IR的。所以里面很多转换相关的逻辑都是可以抄的。</li>
<li>WAMR wasm-micro-runtime
基于LLVM的，但是是C语言，使用LLVM-C-API，我们打算用的是C++的API。所以不太合适。</li>
</ol>
<p>但是他们似乎也有类似的问题：</p>
<ol type="1">
<li>转换出来的IR带有很多“无关”函数。因为这些VM的编译器要么是JIT要么是AOT，都得带上运行需要的外围函数。和我们的目标还是有所偏离的。</li>
</ol>
<p>另外一个非常奇怪的事情是，(在各种C/C++的wasm
runtime项目中，wavm和wamr)，wasm二进制格式解析也没有特别通用统一的库。大家好像都自己写了一套。（除了rust的项目，rust好像都用的wasmparser）</p>
<p>TODO: 内存分析，控制流恢复，AST生成</p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>WebAssembly</tag>
        <tag>Decompile</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>反编译相关资料阅读</title>
    <url>/2022/%E5%8F%8D%E7%BC%96%E8%AF%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<p>反编译相关资料阅读笔记</p>
<span id="more"></span>
<h3 id="重要资源">重要资源</h3>
<p><strong>Working Conference on Reverse Engineering
(WCRE)：</strong></p>
<p>https://ieeexplore.ieee.org/xpl/conhome/1000635/all-proceedings</p>
<p><strong>PPREW-5: Proceedings of the 5th Program Protection and
Reverse Engineering Workshop</strong> 这个期刊好啊。</p>
<p>https://dl.acm.org/conference/pprew</p>
<p><strong>SSPREW: Software Security, Protection, and Reverse
Engineering Workshop</strong></p>
<p>https://dl.acm.org/conference/ssprew</p>
<p>其他：</p>
<ul>
<li><a
href="https://github.com/avast/retdec/blob/05c9b11351d3e82012d823fa3709f940033768cf/publications/README.md">RetDec的publication</a></li>
<li><a
href="https://www.backerstreet.com/decompiler/type_analysis.php">Decompiler
Design - Type Analysis</a> 居然有介绍反编译器架构的网站。</li>
</ul>
<p>Github的两个list：</p>
<ul>
<li>https://github.com/yasong/Awesome-Info-Inferring-Binary</li>
<li>https://github.com/SystemSecurityStorm/Awesome-Binary-Rewriting</li>
</ul>
<h2 id="读论文">读论文</h2>
<p>一篇很好的综述：<a
href="https://yurichev.com/mirrors/vanEmmerik_ssa.pdf">Static Single
Assignment for Decompilation (Boomerang)</a>
感觉可以抓住优化方面的脉络。</p>
<p>摸着引用看论文确实有点用</p>
<h3 id="控制流结构恢复-structural-analysis">控制流结构恢复-structural
analysis</h3>
<p>很多都是借用现有的type recovery，重点去讲structure recovery。</p>
<ul>
<li><p>【Phoenix】Native x86 Decompilation Using Semantics-Preserving
Structural Analysis and Iterative Control-Flow Structuring <a
href="https://kapravelos.com/teaching/csc591-s20/readings/decompilation.pdf">paper
link</a></p>
<p>Edward Schwartz's PhD thesis (<a
href="https://users.ece.cmu.edu/~ejschwar/papers/arthesis14.pdf"
class="uri">https://users.ece.cmu.edu/~ejschwar/papers/arthesis14.pdf</a>)
里面进一步介绍了Phoenix反编译器</p>
<p>这篇论文关注控制结构的恢复。控制结构的恢复最早是基于interval
analysis的（？这是什么得学一学）。后面才被细化为structural
analysis</p></li>
<li><p>【Dream】No More Gotos: Decompilation Using Pattern-Independent
Control-Flow Structuring and Semantics-Preserving Transformations
https://www.ndss-symposium.org/wp-content/uploads/2017/09/11_4_2.pdf</p>
<p>slides：
https://www.ndss-symposium.org/wp-content/uploads/2017/09/11NoMoreGotos.slide_.pdf</p>
<p>code?： https://github.com/USECAP/dream</p></li>
</ul>
<h3 id="类型恢复---type-recovery">类型恢复 - Type Recovery</h3>
<ul>
<li><p>【TIE】Principled Reverse Engineering of Types in Binary
Programs. <a
href="http://users.ece.cmu.edu/~aavgerin/papers/tie-ndss-2011.pdf">链接</a>
这篇基于VSA搞了自己的DVSA，主要区别是StridedInterval里可以放除esp外的变量符号？。重点主要在后面的约束求解部分。后面的类型系统和求解部分也非常复杂TODO。</p></li>
<li><p>【DIVINE】: DIscovering Variables IN Executables
这篇还是VSA系列的那些人写的。讲先用最简单的semi
naive方法鉴别变量，跑VSA，然后拿VSA结果去生成约束跑ASI。迭代几次得到最好的结果。
里面说如果变量是8字节大小，那VSA直接无法处理，值总是Top（32位程序）。那就不能直接把内存最大切分粒度搞成4字节？？</p></li>
<li><p>【REWARDS】Automatic Reverse Engineering of Data Structures from
Binary Execution https://www.cs.purdue.edu/homes/xyzhang/Comp/ndss10.pdf
TODO</p></li>
<li><p>【retypd】https://arxiv.org/pdf/1603.05495.pdf
需要进一步学习类型系统的高级知识，比如subtyping。它不仅开源，而且不需要VSA的指针信息。可以与之前需要VSA的结合？<del>但是似乎没有说怎么从一整块栈内存中识别出变量。</del></p></li>
<li><p>【SecondWrite】https://user.eng.umd.edu/~barua/elwazeer-PLDI-2013.pdf</p></li>
</ul>
<h3 id="变量恢复">变量恢复</h3>
<p>变量恢复和类型恢复关联较大。如果把函数开头分配的栈空间看作一个巨大的结构体，变量恢复就转换成了类型恢复。</p>
<p><a
href="https://www.cs.virginia.edu/~yk2bb/data/osprey_sp21.pdf">OSPREY:
Recovery of Variable and Data Structure via Probabilistic Analysis for
Stripped Binary</a> <a
href="https://www.cs.purdue.edu/homes/zhan3299/res/SP21a_slides.pdf">slides</a>
把变量的访问看作变量存在的暗示，同时存在很多这样的暗示，使用概率性的推导。好像是基于后面那篇BDA的工作。</p>
<h3 id="c-反编译">C++ 反编译</h3>
<p>C++的类给反编译带来了额外的困难，涉及到（复杂的）约束求解等。</p>
<ul>
<li><p>https://edmcman.github.io/papers/ccs18.pdf C++反编译 Using Logic
Programming to Recover C++ Classes and Methods from Compiled
Executables</p></li>
<li><p>SmartDec: Approaching C++ Decompilation.</p></li>
<li><p>Reconstruction of Class Hierarchies for Decompilation of C++
Programs.</p></li>
</ul>
<h3 id="vsa相关">VSA相关</h3>
<ul>
<li><p>WYSINWYX: WHAT YOU SEE IS NOT WHAT YOU EXECUTE
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.637&amp;rep=rep1&amp;type=pdf
第三章讲了VSA的事情。它也讲了很多二进制分析的事情。</p>
<p>■ 文中提到的一些其他的没有用到VSA的方法：</p>
<p>[33] C. Cifuentes and A. Fraboulet. Interprocedural data flow
recovery of high-level language code from assembly. Technical Report
421, Univ. Queensland, 1997.</p>
<p>[34] C. Cifuentes and A. Fraboulet. Intraprocedural static slicing of
binary executables. In Proc. Int. Conf. on Software Maintenance (ICSM),
pages 188–195, 1997.</p>
<p>[35] C. Cifuentes, D. Simon, and A. Fraboulet. Assembly to high-level
language translation. In Proc. Int. Conf. on Software Maintenance
(ICSM), pages 228–237, 1998.</p>
<p>[45] S.K. Debray, R. Muth, and M. Weippert. Alias analysis of
executable code. In Proc. Principles of Programming Languages (POPL),
pages 12–24, January 1998.</p></li>
<li><p>基础的VSA：https://research.cs.wisc.edu/wpis/papers/cc04.pdf
Analyzing Memory Accesses in x86 Executables</p></li>
<li><p>Improved Memory-Access Analysis for x86 Executables
http://research.cs.wisc.edu/wpis/papers/etaps08.invited.pdf GMOD-Based
Merge Function</p>
<p>这篇论文开头爆炸：Research carried out during the last decade by our
research group [64, 65, 6, 56, 55, 7, 8, 36, 4, 49, 9] as well as by
others [48, 22, 33, 14, 2, 31, 13, 44, 32, 3, 54, 37, 21, 46, 28, 19,
16, 34, 66] has developed the foundations for performing static analysis
at the machine-code level. 能找到非常多的其他paper了？</p>
<p>没想到相比于源码级的分析，二进制级的分析还有好处。有很多源码层没有指明的实现细节（比如C++的表达式求值顺序），源码级分析想要sound需要考虑所有可能的实现，而二进制级的分析只需要考虑编译器选择的实现。</p></li>
<li><p>《DIVINE: DIscovering Variables IN Executables》 （VSA with
ASI(Automated Struct
Identification)）（栈变量恢复）VSA可以用于一定程度的变量恢复。</p></li>
<li><p>https://www.zybuluo.com/SmashStack/note/847219 这人想要实现Value
Set Analysis到RadecoIL上。</p></li>
<li><p>https://github.com/radareorg/radeco/tree/master/radeco-lib/src/analysis/valueset
这里也有人实现，还有WYSINWYNX那个论文相关的东西？</p></li>
<li><p>http://www-verimag.imag.fr/~mounier/Enseignement/Software_Security/slides_lecture_7.pdf
这个课件讲到了一点点。这门课是和安全相关的。TODO，不太看得懂。</p></li>
<li><p>https://www.ndss-symposium.org/wp-content/uploads/bar2021_23002_paper.pdf
研究VSA对人工分析的帮助。（对学习VSA没啥用）</p></li>
</ul>
<h3 id="其他">其他</h3>
<ul>
<li><p>【DecFuzzer】How far we have come: testing decompilation
correctness of C decompilers
https://dl.acm.org/doi/abs/10.1145/3395363.3397370</p>
<p>代码在：https://github.com/monkbai/DecFuzzer</p>
<p>functionality-preserving disassembling and C style control structure
recovery [17, 31, 47, 64, 65, 67]</p>
<p>变量恢复static analysis and inference techniques [10, 12, 13, 30,
54].</p>
<p>fool-proof techniques for binary disassembling and decompilation [17,
31, 64-67].</p>
<p>EMI编译器测试看了下是插入了不影响语义的代码之后去开编译优化，发现优化器做出的错误决定而导致的crash。比如把一个不该执行的循环内操作提到外面。错误判断一些分支恒为真或假。是设置Csmith的输出使得只生成一个函数？？</p>
<p>本来Csmith生成的代码很多全局变量的使用。如果全局变量改变了，很难手动找到是哪个函数？它是生成了局部变量，然后把对全局变量的使用全替换成了局部变量，函数结束的时候把局部变量的值update到全局变量，这样如果全局变量变了，就肯定是在最后update的时候改变的。那手动看的时候不要继续找内部怎么使用？这样做有什么好处吗。。。可能是方便找到这个函数到底涉及到了哪些全局变量，然后方便只提取这些到反编译结果的全局变量？？</p></li>
<li><p>C Decompilation : Is It Possible? 2009的一篇:
http://web.archive.org/web/20180517094139/http://decompilation.info/sites/all/files/articles/C%20decompilation.pdf</p>
<p>第二章相关工作里面有不少引用：</p>
<p>structural analysis：[4–6]，这个也用在了编译器：[8]。</p>
<p>unification-based algorithm for recovery of types：Mycroft [9]</p>
<p>现有反编译器：DCC decompiler [7]. Boomerang [11], REC [12] and
Hex-Rays plug-in [13]</p></li>
<li><p>【rev.ng】rev.ng: A Multi-Architecture Framework for Reverse
Engineering and Vulnerability Discovery.
https://www.rev.ng/downloads/iccst-18-paper.pdf</p>
<p>这个反编译器开源了lifter：先转到Qemu IR然后转到LLVM
IR。这个好像也不太和反编译相关，也只是搞插桩、fuzzing的。</p></li>
<li><p>Evolving Exact Decompilation
https://www.cs.unm.edu/~eschulte/data/bed.pdf
好像和主流的反编译技术不是特别相关。</p></li>
</ul>
<p><strong>最近的新论文</strong></p>
<ul>
<li><p>https://www.usenix.org/system/files/sec19-guo.pdf DEEPVSA:
Facilitating Value-set Analysis with Deep Learning for Postmortem
Program Analysis 这篇参考意义不大，是ML结合的。</p></li>
<li><p>BDA: Practical Dependence Analysis for Binary Executables by
Unbiased Whole-Program Path Sampling and Per-Path Abstract
Interpretation</p></li>
<li><p>BinPointer: Towards Precise, Sound, and Scalable Binary-Level
Pointer Analysis</p>
<p>里面提到了https://www.cse.psu.edu/~gxt29/papers/cfgByDatalog_NDSS21.pdf
BPA: Refining Indirect Call Targets at the Binary
Level这篇也值得读。用了块内存的抽象解释。</p></li>
</ul>
<h3 id="其他零散资料">其他零散资料：</h3>
<ul>
<li><p>https://github.com/cmu-sei/pharos 涉及到很多反编译技术</p></li>
<li><p>https://news.ycombinator.com/item?id=11218138
两个人的讨论。里面推荐对两篇文章的逆向引用搜索：https://scholar.google.com/scholar?as_ylo=2018&amp;hl=en&amp;as_sdt=2005&amp;sciodt=0,5&amp;cites=1148004013363547510&amp;scipsc=
https://scholar.google.com/scholar?cites=7322807636381891759&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</p></li>
<li><p>https://github.com/toor-de-force/Ghidra-to-LLVM
https://uwspace.uwaterloo.ca/bitstream/handle/10012/17976/Toor_Tejvinder.pdf?sequence=3&amp;isAllowed=y
Ghidra
Pcode编译到IR。代码太简单了。。栈内存好像是alloca出来的，可能还是想保持语义想运行。</p></li>
<li><p>https://github.com/decomp/decomp 这人也想基于LLVM
IR然后去优化。https://github.com/decomp/doc 相关文档</p></li>
<li><p>The Decompilation Wiki.
http://www.program-transformation.org/Transform/DeCompilation</p></li>
<li><p>https://github.com/repzret/dagger 反编译到LLVM
IR。aarch64还在开发过程中。https://llvm.org/devmtg/2013-04/bougacha-slides.pdf
介绍的slides</p>
<p>dagger主要讲的是反编译到IR上，找到语义等价的LLVM
IR的指令的过程。感觉有点像编译器后端的Instruction
Selection，可能能用上利用DAG（有向无环图）选择指令的技术。它是作为llvm的fork编写的，2017后就没有维护了。和llvm耦合好严重啊，都不知道哪里是它的代码。好像好复杂。</p></li>
<li><p>https://github.com/JuliaComputingOSS/llvm-cbe
曾经IR到C有一个backend，2016年被移除了。现在有人接手</p></li>
<li><p>https://corescholar.libraries.wright.edu/cgi/viewcontent.cgi?article=3277&amp;context=etd_all
LLVM IR based decompilation。</p></li>
<li><p>https://github.com/lifting-bits/sleigh
sleigh作为Ghidra的反编译器，是用C++写的，而且汇编到pcode的lift部分也是它负责的。所以用Ghidra可能也只要用这个就可以了。</p></li>
<li><p>https://blog.grimm-co.com/2020/11/automated-struct-identification-with.html
Ghidra上的ASI</p></li>
</ul>
<h3 id="领域的大佬">领域的大佬</h3>
<p>TODO</p>
<p>https://www.cse.psu.edu/~gxt29/publications/ Gang Tan</p>
<h3 id="retdec-栈恢复源码解读">retdec 栈恢复源码解读</h3>
<p>源码在<code>retdec\src\bin2llvmir\optimizations\stack\stack.cpp</code></p>
<p>大体要做的，是把栈指针的偏移访问，都改成alloca。 1.
函数开头sub了栈指针，改成对应大小的alloca 1. 处理load/store -
如果是load：改为对对应alloca的对应偏移的load -
如果是store：改为对对应alloca的对应偏移的store</p>
<p>在上面算法的基础上，增加一个map，从变量映射到栈偏移。然后在load和store的时候尝试将ptr解析为栈指针的偏移。然后在对应大小的地方创建变量。</p>
<h3 id="retypd解读">retypd解读</h3>
<h4 id="monoid">monoid</h4>
<p>读《Haskell趣学指南》的Monoids一节，理解一下。</p>
<h3 id="unification-based-type-inference-algorithms">unification-based
type inference algorithms</h3>
<p>https://www.cs.cornell.edu/courses/cs3110/2011sp/Lectures/lec26-type-inference/type-inference.htm</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>CTF</tag>
        <tag>Decompile</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>反编译-代码混淆-程序分析与编译优化</title>
    <url>/2022/%E5%8F%8D%E7%BC%96%E8%AF%91-%E4%BB%A3%E7%A0%81%E6%B7%B7%E6%B7%86-%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E4%B8%8E%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>这个暑假参加了那个编译系统设计赛，经历“磨难”后，不得不说确实视野开阔了很多。曾经CTF比赛中拿各种代码混淆完全没有办法，曾经下定决心想要学反编译却完全不知道从何下手。曾经自己搞代码混淆，看见LLVM
IR也是一头雾水。</p>
<p>而现在，视野终于开阔了许多，能够有一些这几个领域的全局的视野了。</p>
<span id="more"></span>
<h3 id="推荐的学习路线">推荐的学习路线</h3>
<p>不得不说，编译器中后端的知识，包括SSA构建，SSA上的GVN等优化算法。和反编译密切相关。</p>
<ol type="1">
<li>《Static Single Assignment for Decompilation》
强烈推荐！！！之前看了很多反编译的论文，讲的都是类型恢复，或者怎么从IR恢复到上层控制流语句。完全没有提底层寄存器分配之类的问题。是这本书让我知道了到底反编译是怎么解决各种寄存器分配导致的问题的！！但是需要一些SSA相关的前置知识</li>
<li>各大反编译器的publication
<ol type="1">
<li>Retdec https://github.com/avast/retdec/tree/master/publications</li>
</ol></li>
<li>《How Far We Have Come: Testing Decompilation Correctness of C
Decompilers》这篇论文挺好的，虽然没有直接讲反编译的原理。不仅特别新，而且给我们搞反编译的人带来了信心。</li>
</ol>
<p>关于编译原理的学习资源与路线，参考另外一篇文章。</p>
<h3 id="其他学习资源">其他学习资源</h3>
<p>最开始有一段时间真的是一点资源都没有。。但是现在看来，怎么着我也应该想想是不是又逆向相关的会议。确实，有了下面这些会议，起码逆向方面的论文是不愁看不完了。</p>
<p>Working Conference on Reverse Engineering (WCRE)
https://ieeexplore.ieee.org/xpl/conhome/1000635/all-proceedings WCRE
Working Conference on Reverse Engineering PPREW-5: Proceedings of the
5th Program Protection and Reverse Engineering Workshop 这个期刊好啊。
https://dl.acm.org/conference/pprew SSPREW: Software Security,
Protection, and Reverse Engineering Workshop
https://dl.acm.org/conference/ssprew</p>
<p><strong>其他我收藏的链接</strong></p>
<p>Github的两个list
https://github.com/yasong/Awesome-Info-Inferring-Binary
https://github.com/SystemSecurityStorm/Awesome-Binary-Rewriting</p>
<p>https://news.ycombinator.com/item?id=11218138
两个人的讨论。里面推荐对两篇文章的逆向引用搜索：https://scholar.google.com/scholar?as_ylo=2018&amp;hl=en&amp;as_sdt=2005&amp;sciodt=0,5&amp;cites=1148004013363547510&amp;scipsc=</p>
<p>https://scholar.google.com/scholar?cites=7322807636381891759&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</p>
<p>https://github.com/toor-de-force/Ghidra-to-LLVM
https://uwspace.uwaterloo.ca/bitstream/handle/10012/17976/Toor_Tejvinder.pdf?sequence=3&amp;isAllowed=y
Ghidra
Pcode编译到IR。代码太简单了。。栈内存好像是alloca出来的，可能还是想保持语义想运行。</p>
<p>https://github.com/decomp/decomp 这人也想基于LLVM
IR然后去优化。https://github.com/decomp/doc 相关文档
https://github.com/avast/retdec/blob/05c9b11351d3e82012d823fa3709f940033768cf/publications/README.md
RetDec的publication</p>
<p>The Decompilation Wiki.
http://www.program-transformation.org/Transform/DeCompilation</p>
<p>dagger主要讲的是反编译到IR上，找到语义等价的LLVM
IR的指令的过程。感觉有点像编译器后端的Instruction
Selection，可能能用上利用DAG（有向无环图）选择指令的技术。它是作为llvm的fork编写的，2017后就没有维护了。和llvm耦合好严重啊，都不知道哪里是它的代码。好像好复杂。</p>
<p>https://github.com/repzret/dagger 反编译到LLVM
IR。aarch64还在开发过程中。https://llvm.org/devmtg/2013-04/bougacha-slides.pdf
介绍的slides</p>
<p>https://github.com/JuliaComputingOSS/llvm-cbe
曾经IR到C有一个backend，2016年被移除了。现在有人接手</p>
<p>https://corescholar.libraries.wright.edu/cgi/viewcontent.cgi?article=3277&amp;context=etd_all
LLVM IR based decompilation。</p>
<p>https://github.com/lifting-bits/sleigh
sleigh作为Ghidra的反编译器，是用C++写的，而且汇编到pcode的lift部分也是它负责的。所以用Ghidra可能也只要用这个就可以了。</p>
<p>https://github.com/cmu-sei/pharos 涉及到很多反编译技术</p>
<h3 id="看论文的一些笔记">看论文的一些笔记</h3>
<p>2022年9月18日</p>
<p>很多都是借用现有的type recovery，重点去讲structure recovery。</p>
<p>C Decompilation : Is It Possible ? 2009的一个:
http://web.archive.org/web/20180517094139/http://decompilation.info/sites/all/files/articles/C%20decompilation.pdf
第二章相关工作里面有不少引用 structural
analysis：[4–6]，这个也用在了编译器：[8]。 unification-based algorithm
for recovery of types：Mycroft [9]</p>
<p>现有反编译器：DCC decompiler [7]. Boomerang [11], REC [12] and
Hex-Rays plug-in [13]</p>
<p>【Phoenix】Native x86 Decompilation Using Semantics-Preserving
Structural Analysis and Iterative Control-Flow Structuring
https://kapravelos.com/teaching/csc591-s20/readings/decompilation.pdf
Edward Schwartz's PhD thesis (<a
href="https://users.ece.cmu.edu/~ejschwar/papers/arthesis14.pdf"
class="uri">https://users.ece.cmu.edu/~ejschwar/papers/arthesis14.pdf</a>)
covers in detail the Phoenix decompiler, which is another good
jumping-off point.
这篇论文关注控制结构的恢复。控制结构的恢复最早是基于interval
analysis的？这是什么得学一学。后面才被细化为structural analysis</p>
<p>【Dream】No More Gotos: Decompilation Using Pattern-Independent
Control-Flow Structuring and Semantics-Preserving Transformations
https://www.ndss-symposium.org/wp-content/uploads/2017/09/11_4_2.pdf
slides：
https://www.ndss-symposium.org/wp-content/uploads/2017/09/11NoMoreGotos.slide_.pdf
code?： https://github.com/USECAP/dream</p>
<p>【DecFuzzer】How far we have come: testing decompilation correctness
of C decompilers https://dl.acm.org/doi/abs/10.1145/3395363.3397370
香港科技大学的综述 代码在：https://github.com/monkbai/DecFuzzer
论文下载不到，SCI
hub太强了。https://sci-hubtw.hkvisa.net/https://dl.acm.org/doi/10.1145/3395363.3397370
functionality-preserving disassembling and C style control structure
recovery [17, 31, 47, 64, 65, 67] 变量恢复static analysis and inference
techniques [10, 12, 13, 30, 54]. fool-proof techniques for binary
disassembling and decompilation [17, 31, 64-67].
EMI编译器测试看了下是插入了不影响语义的代码之后去开编译优化，发现优化器做出的错误决定而导致的crash。比如把一个不该执行的循环内操作提到外面。错误判断一些分支恒为真或假。
是设置Csmith的输出使得只生成一个函数？？
本来Csmith生成的代码很多全局变量的使用。如果全局变量改变了，很难手动找到是哪个函数？它是生成了局部变量，然后把对全局变量的使用全替换成了局部变量，函数结束的时候把局部变量的值update到全局变量，这样如果全局变量变了，就肯定是在最后update的时候改变的。那手动看的时候不要继续找内部怎么使用？这样做有什么好处吗。。。可能是方便找到这个函数到底涉及到了哪些全局变量，然后方便只提取这些到反编译结果的全局变量？？
这篇论文可以研究一下重编译的技术。怎么单独提取出一个文件。怎么合并两个C语言文件。这样我想要用别人的汇编代码也可以用了。</p>
<p>【RetDec】没有论文好像。slides:
https://2018.pass-the-salt.org/files/talks/04-retdec.pdf 中端用到了LLVM
IR，但是最开始生成的IR也是那种全局变量表示寄存器的形式，不知道最后的时候有没有好一点。也许只是用LLVM
IR去做一些控制流的pattern
matching？不过有变量识别的Pass。有机会研究一下IR和变量识别的情况。</p>
<p>Evolving Exact Decompilation
https://www.cs.unm.edu/~eschulte/data/bed.pdf</p>
<p>【rev.ng】rev.ng: A Multi-Architecture Framework for Reverse
Engineering and Vulnerability Discovery.
https://www.rev.ng/downloads/iccst-18-paper.pdf
这个反编译器开源了lifter：先转到Qemu IR然后转到LLVM
IR。这个好像也不太和反编译相关，也只是搞插桩、fuzzing的。</p>
<p>类型恢复 【TIE】Principled Reverse Engineering of Types in Binary
Programs. http://users.ece.cmu.edu/~aavgerin/papers/tie-ndss-2011.pdf
这篇搞了自己的DVSA，主要区别是SI里可以放除esp外的变量符号？。重点主要在后面的约束求解部分。后面的类型系统和求解部分也非常复杂TODO。</p>
<p>【SecondWrite】https://user.eng.umd.edu/~barua/elwazeer-PLDI-2013.pdf</p>
<p>【DIVINE】: DIscovering Variables IN Executables
这篇还是VSA系列的那些人写的。讲先用最简单的semi
naïve方法鉴别变量，跑VSA，然后拿VSA结果去生成约束跑ASI。迭代几次得到最好的结果。
里面说如果变量是8字节大小，那VSA直接无法处理，值总是Top（32位程序）。那就不能直接把内存最大切分粒度搞成4字节？？</p>
<p>【REWARDS】Automatic Reverse Engineering of Data Structures from
Binary Execution https://www.cs.purdue.edu/homes/xyzhang/Comp/ndss10.pdf
TODO</p>
<p>【retypd】https://arxiv.org/pdf/1603.05495.pdf
需要进一步学习subtyping
TODO。它不仅开源，而且不需要VSA的指针信息。可以与之前需要VSA的结合？</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>CTF</tag>
        <tag>Decompile</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>编译原理学习与编译系统赛</title>
    <url>/2022/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E8%B5%9B/</url>
    <content><![CDATA[<p>暑假参加了编译系统设计赛，受益匪浅。在比赛初期，拖延症严重，同时经常感觉学习资源匮乏，而且也还在摸黑阶段，心理压力下经常就会高估学习的困难，觉得是不可逾越的大山。尤其是编译器后端，这方面相关的学习资源感觉非常匮乏。现在看来，前期确实没能重视一些重要的学习资源，后面走弯路学会了已经晚了。</p>
<span id="more"></span>
<p>2022年10月28日
现在我已经是SSA的狂热粉了，SSA看似只是一种中间表示形式，实际上对分析有着非常底层（基础）的地位。打个比方，普通的程序计算用变量，变量就是一个个槽位，数据可以出去和进来。而SSA就是去除了变量这个中间商，让数据直接从赋值的地方运送到使用的地方（读变量）。</p>
<p>不得不说，学了理论还是要实践才能有更深的理解。从最早的操作系统开始，到现在编译原理，真正自己完成一个小型的编译器，操作系统之后，那种感觉是之前反复看书看视频学理论完全没有的。不仅掌握得更深，知道了相关的东西是如何落地的，知道和其他东西的联系，更重要的是有一种能够把握知识体系，一览全局的感觉。就好像去一个位置的地域探索，当你把主干道都走了一遍之后，即使有的地方没去过，它在什么方位也能知道。</p>
<p>编译器学习大概有这几个主线</p>
<ol type="1">
<li>前端：从零开始，学习自动机理论，词法分析，语法分析。然后可以实践语法分析，尝试写parser，使用ANTLR等。更进阶的可以看看《parsing
technique》，光是当作科普书也挺有意思的。曾经看到老旧的编译器教材说，之后的中间表示有什么三地址码什么的。反正我学到现在是没有那些东西的，直接LLVM
IR吧。</li>
<li>中端：开始接触LLVM IR，开始接触SSA相关理论。更深入地学SSA
construction，学SSA
destruction。然后接触一些SSA上的优化算法，比如GVN等。</li>
<li>后端：开始了解指令选择和寄存器分配理论。指令选择的话，我们手写简单的编译器应该是难以做到那种给每个指令写配置然后自动生成什么的。然后实践一些图着色的寄存器分配算法。后端寄存器分配这里，如果你觉得线性扫描可能会简单一点的话，那还真不一定。建议直接实现图着色。
大致的经历是，</li>
</ol>
<p>对于参加编译器比赛来说，手把手的实验教程是真的救星：</p>
<ol type="1">
<li><p>北航mini-sysY实验教程：https://github.com/BUAA-SE-Compiling
https://buaa-se-compiling.github.io/miniSysY-tutorial/
这个教程依然是偏前端的，时候早期学习完词法分析，语法分析后实践加深理解。</p></li>
<li><p>北大编译课实践教程：这个是参加比赛时久仰大名的 邢其正
大佬的教程。https://github.com/pku-minic/online-doc
https://pku-minic.github.io/online-doc/
在当时大量教程止步于前端到中端就结束的时候，只有这个教程讲到了后端。</p></li>
</ol>
<p>除了传统的龙书虎书鲸书之外，还有一本书不得不说，《Engineering a
compiler》中文版是《编译器设计》
https://book.douban.com/subject/20436488/
。讲得浅显易懂。建议优先于龙书虎书鲸书看。9.3章非常好，对SSA介绍也比较详细。</p>
<p><a href="https://pfalcon.github.io/ssabook/latest/book-v1.pdf">《SSA
book》</a>挺有名的，之前学程序分析就听说了。但是我个人其实看得不多。甚至ssa构建都是“偷懒”用的<a
href="https://pp.info.uni-karlsruhe.de/uploads/publikationen/braun13cc.pdf">《simple
and efficient ssa
construction》</a>里的简单算法，不需要折腾支配边界的计算什么的。</p>
<p>后端的书有： 1. 《Instruction selection: Principles, Methods, and
Applications》。顶着英文看。这本书我之前看起来还是有点费劲的，但是没必要完全看懂不是吗，看下来算是对指令选择这一块有了总体的印象。最后实践上（参加编译器比赛）来说，可能最后还是采取“宏展开”（其实就是对每个IR单独写分支生成机器指令），然后加上一些窥孔优化的思路。里面的一些高级思路基本没用起来。没想到在后端指令选择这里居然也和前端学到的语法分析能扯上关系。
1. <a
href="https://publikationen.bibliothek.kit.edu/1000007166/6532">《Register
Allocation for Programs in SSA Form》</a> 新一代寄存器分配</p>
<p>寄存器分配的书看后文</p>
<p>LLVM相关的书有：</p>
<ol type="1">
<li><a href="http://www.aosabook.org/en/llvm.html">The Architecture of
Open Source Applications: LLVM</a></li>
<li>《LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries》</li>
<li>《Learning LLVM 12》 这两本新书来自Packt
Publishing，非常优质的资源，不可多得</li>
</ol>
<p>LLVM在Youtube上也有很多视频</p>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=m8G_S5LwlTo">《2019
EuroLLVM Developers’ Meeting: V. Bridgers &amp; F. Piovezan “LLVM IR
Tutorial - Phis, GEPs and other things, oh my! - Vince Bridgers (Intel
Corporation)”》</a> <a
href="https://llvm.org/devmtg/2019-04/slides/Tutorial-Bridgers-LLVM_IR_tutorial.pdf">配套PPT</a>
这个视频用来学习GetElementPtr指令非常好</li>
<li><a href="https://www.youtube.com/watch?v=ar7cJl2aBuU">2019 LLVM
Developers’ Meeting: A. Warzynski “Writing an LLVM Pass: 101”</a>
源码外的Pass：不和LLVM代码放在一起，不需要重新编译LLVM
基于NewPassManager：新版PassManager API，即将成为默认PM</li>
<li><a href="https://www.youtube.com/watch?v=3QQuhL-dSys">2019 LLVM
Developers’ Meeting: J. Paquette &amp; F. Hahn “Getting Started With
LLVM: Basics”</a> 前半部分 讲了LLVM IR
Pass需要考虑到的一些东西，users的概念，讲了移除基本块和指令时需要注意的。</li>
<li><a href="https://www.youtube.com/watch?v=5kkMpJpIGYU">《2019 LLVM
Developers’ Meeting: S. Haastregt &amp; A. Stulova “An overview of Clang
”》</a></li>
<li><a href="https://www.youtube.com/watch?v=3QQuhL-dSys">2019 LLVM
Developers’ Meeting: J. Paquette &amp; F. Hahn “Getting Started With
LLVM: Basics”</a> 介绍了后端</li>
</ol>
<h3 id="其他资源">其他资源</h3>
<p>优质的（浅显易懂的）学习资源是学习前期永远稀缺的资源。有时候你想找都不知道怎么找。所以这里列出我记下来的所有资源：</p>
<p><a
href="https://buaa-se-compiling.github.io/miniSysY-tutorial/challenge/mem2reg/help.html">mem2reg
实验指导 · GitBook (buaa-se-compiling.github.io)</a></p>
<p><a href="http://c9x.me/compile/bib/">The Compiler Writer Resource
Page (c9x.me)</a> 一个人的资源分享</p>
<p>针对arm的优化算法：乘法转移位：Division by invariant integers using
multiplication. CPU文档，乘法是6-8周期，除法是10-12周期</p>
<p>ARM手册看Cortex-A72 software Optimization Guide.</p>
<p><a
href="https://www.bilibili.com/video/BV1Lf4y1y78n?vd_source=e9f223609ade8d8a4012f354190eda15">C＃C++17系列+动手编写编译器与虚拟机项目（原版共400小时）_哔哩哔哩_bilibili</a></p>
<p><a
href="https://tobyho.com/video-series/Live-Code-LLVM-Tutorial-Walkthrough.html">Series:
Live Code: LLVM Tutorial Walkthrough (tobyho.com)</a></p>
<p>https://mapping-high-level-constructs-to-llvm-ir.readthedocs.io/en/latest/README.html</p>
<p><a href="https://github.com/elvin-du/tinyscript">elvin-du/tinyscript:
自制的一个编译器，
用于学习，完整实现了词法分析，语法分析，中间代码（SSA）生成，机器码生成，和基于寄存器的虚拟机
(github.com)</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/111635473">编译器资料3
关于编译器和静态分析的一些课程 - 知乎 (zhihu.com)</a></p>
<p><a
href="https://www.zhihu.com/people/rednaxelafx/answers">RednaxelaFX -
知乎 (zhihu.com)</a>
这人是编译器大佬，他的回答能帮我们节省很多时间：包括什么技术需要看什么论文，有哪些实现</p>
<p>book of runtime</p>
<p>对于LLVM之类的编译器是如何实现在构造 SSA 形式的 IR 的时候，计算出
def-use 链？ - RednaxelaFX的回答 - 知乎
https://www.zhihu.com/question/41999500/answer/93243408</p>
<p>Phi node 是如何实现它的功能的？ - RednaxelaFX的回答 - 知乎
https://www.zhihu.com/question/24992774/answer/29740949</p>
<h3 id="ssa构建与gvn的强大优化能力">SSA构建与GVN的强大优化能力</h3>
<p>我之前一直挺疑惑，编译器的优化到底具体在哪里。甚至之前编译器写了一半还是不太知道。就比如我随便找一个C语言代码，想不清楚编译器具体是怎么优化出来的。比如下面这个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// test if-else-if</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">ifElseIf</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">int</span> a;</span><br><span class="line">  a = <span class="number">5</span>;</span><br><span class="line">  <span class="type">int</span> b;</span><br><span class="line">  b = <span class="number">10</span>;</span><br><span class="line">  <span class="keyword">if</span>(a == <span class="number">6</span> || b == <span class="number">0xb</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (b == <span class="number">10</span> &amp;&amp; a == <span class="number">1</span>)</span><br><span class="line">      a = <span class="number">25</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (b == <span class="number">10</span> &amp;&amp; a == <span class="number">-5</span>)</span><br><span class="line">      a = a + <span class="number">15</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      a = -+a;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译器比赛的时候先追求功能测试，所以没有搞任何ssa的东西。那时候也还是不知道这种该怎么优化。生成出来的IR是下面这样的。</p>
<p>直观感觉，很多条件判断可以搞出来优化掉。但是之前听说的优化，都是什么常量表达式给计算一下，公共子表达式消除一下，都是这种比较浅的。看下面的IR可以看到也没什么可以直接优化的啊，因为你获取变量都还是load加载出来的，但是好像没看到什么分析能够直接追踪你load到底加载了什么东西，然后去优化。所以当时就感觉自己不太懂。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">define i32 @ifElseIf()&#123;</span><br><span class="line">entry:</span><br><span class="line">  %a_0 = alloca i32 </span><br><span class="line">  %b_1 = alloca i32 </span><br><span class="line">  store i32 5, i32* %a_0</span><br><span class="line">  store i32 10, i32* %b_1</span><br><span class="line">  %0 = load i32, i32* %a_0</span><br><span class="line">  %1 = icmp eq i32 %0, 6</span><br><span class="line">  %2 = zext i1 %1 to i32</span><br><span class="line">  %3 = icmp ne i32 0, %2</span><br><span class="line">  br i1 %3, label %if_true_0, label %or_right_1</span><br><span class="line"></span><br><span class="line">or_right_1:</span><br><span class="line">  %4 = load i32, i32* %b_1</span><br><span class="line">  %5 = icmp eq i32 %4, 11</span><br><span class="line">  %6 = zext i1 %5 to i32</span><br><span class="line">  %7 = icmp ne i32 0, %6</span><br><span class="line">  br i1 %7, label %if_true_0, label %if_false_0</span><br><span class="line"></span><br><span class="line">if_true_0:</span><br><span class="line">  %8 = load i32, i32* %a_0</span><br><span class="line">  ret i32 %8</span><br><span class="line"></span><br><span class="line">tmp_2:</span><br><span class="line">  br label %if_end_0</span><br><span class="line"></span><br><span class="line">if_false_0:</span><br><span class="line">  %9 = load i32, i32* %b_1</span><br><span class="line">  %10 = icmp eq i32 %9, 10</span><br><span class="line">  %11 = zext i1 %10 to i32</span><br><span class="line">  %12 = icmp ne i32 0, %11</span><br><span class="line">  br i1 %12, label %and_right_4, label %if_false_3</span><br><span class="line"></span><br><span class="line">and_right_4:</span><br><span class="line">  %13 = load i32, i32* %a_0</span><br><span class="line">  %14 = icmp eq i32 %13, 1</span><br><span class="line">  %15 = zext i1 %14 to i32</span><br><span class="line">  %16 = icmp ne i32 0, %15</span><br><span class="line">  br i1 %16, label %if_true_3, label %if_false_3</span><br><span class="line"></span><br><span class="line">if_true_3:</span><br><span class="line">  store i32 25, i32* %a_0</span><br><span class="line">  br label %if_end_3</span><br><span class="line"></span><br><span class="line">if_false_3:</span><br><span class="line">  %17 = load i32, i32* %b_1</span><br><span class="line">  %18 = icmp eq i32 %17, 10</span><br><span class="line">  %19 = zext i1 %18 to i32</span><br><span class="line">  %20 = icmp ne i32 0, %19</span><br><span class="line">  br i1 %20, label %and_right_6, label %if_false_5</span><br><span class="line"></span><br><span class="line">and_right_6:</span><br><span class="line">  %21 = load i32, i32* %a_0</span><br><span class="line">  %22 = sub i32 0, 5</span><br><span class="line">  %23 = icmp eq i32 %21, %22</span><br><span class="line">  %24 = zext i1 %23 to i32</span><br><span class="line">  %25 = icmp ne i32 0, %24</span><br><span class="line">  br i1 %25, label %if_true_5, label %if_false_5</span><br><span class="line"></span><br><span class="line">if_true_5:</span><br><span class="line">  %26 = load i32, i32* %a_0</span><br><span class="line">  %27 = add i32 %26, 15</span><br><span class="line">  store i32 %27, i32* %a_0</span><br><span class="line">  br label %if_end_5</span><br><span class="line"></span><br><span class="line">if_false_5:</span><br><span class="line">  %28 = load i32, i32* %a_0</span><br><span class="line">  %29 = sub i32 0, %28</span><br><span class="line">  store i32 %29, i32* %a_0</span><br><span class="line">  br label %if_end_5</span><br><span class="line"></span><br><span class="line">if_end_5:</span><br><span class="line">  br label %if_end_3</span><br><span class="line"></span><br><span class="line">if_end_3:</span><br><span class="line">  br label %if_end_0</span><br><span class="line"></span><br><span class="line">if_end_0:</span><br><span class="line">  %30 = load i32, i32* %a_0</span><br><span class="line">  ret i32 %30</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>后面搞了SSA构建，学了挺久的。搞出来之后发现优化的机会立马出来了。下面是ssa构建后的IR。SSA构建的原理就是，本来变量都是直接load的，使用LLVM的伪ssa形式。SSA构建负责在每个load的地方，确定你到底load是之前store的谁，然后把之前store进去的东西直接拿过来。即load和store都没了，值直接传递到了它该有的地方。明显可以看到，只需要搞一下常量表达式计算，优化一下必定跳转某个分支的条件跳转就可以了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">define i32 @ifElseIf()&#123;</span><br><span class="line">entry:</span><br><span class="line">  %0 = icmp eq i32 5, 6</span><br><span class="line">  br i1 %0, label %if_true_0, label %or_right_1</span><br><span class="line"></span><br><span class="line">or_right_1:</span><br><span class="line">  %1 = icmp eq i32 10, 11</span><br><span class="line">  br i1 %1, label %if_true_0, label %if_false_0</span><br><span class="line"></span><br><span class="line">if_true_0:</span><br><span class="line">  ret i32 5</span><br><span class="line"></span><br><span class="line">if_false_0:</span><br><span class="line">  %2 = icmp eq i32 10, 10</span><br><span class="line">  br i1 %2, label %and_right_4, label %if_false_3</span><br><span class="line"></span><br><span class="line">and_right_4:</span><br><span class="line">  %3 = icmp eq i32 5, 1</span><br><span class="line">  br i1 %3, label %if_true_3, label %if_false_3</span><br><span class="line"></span><br><span class="line">if_true_3:</span><br><span class="line">  br label %if_end_3</span><br><span class="line"></span><br><span class="line">if_false_3:</span><br><span class="line">  %4 = icmp eq i32 10, 10</span><br><span class="line">  br i1 %4, label %and_right_6, label %if_false_5</span><br><span class="line"></span><br><span class="line">and_right_6:</span><br><span class="line">  %5 = sub i32 0, 5</span><br><span class="line">  %6 = icmp eq i32 5, %5</span><br><span class="line">  br i1 %6, label %if_true_5, label %if_false_5</span><br><span class="line"></span><br><span class="line">if_true_5:</span><br><span class="line">  %7 = add i32 5, 15</span><br><span class="line">  br label %if_end_5</span><br><span class="line"></span><br><span class="line">if_false_5:</span><br><span class="line">  %8 = sub i32 0, 5</span><br><span class="line">  br label %if_end_5</span><br><span class="line"></span><br><span class="line">if_end_5:</span><br><span class="line">  %a_0_5 = phi i32 [ %7, %if_true_5 ], [ %8, %if_false_5 ]</span><br><span class="line">  br label %if_end_3</span><br><span class="line"></span><br><span class="line">if_end_3:</span><br><span class="line">  %a_0_4 = phi i32 [ 25, %if_true_3 ], [ %a_0_5, %if_end_5 ]</span><br><span class="line">  ret i32 %a_0_4</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>后面我们继续想怎么实现基于SSA的优化。之前理论学习的时候虽然听说过什么常量表达式计算啊，公共子表达式什么的这种简单优化，但是看他们往届参赛队员的经验分享的时候，好像都没怎么提到。但是他们都提到了一个叫GVN
GCM的优化。《Global Code Motion Global Value
Numbering》这篇论文。刚学完SSA构建看这篇论文感觉挺容易看懂的。推荐去看，直接获取一手资料。</p>
<p>简单介绍一下，GCM能够把计算的代码放到尽可能少被执行到的地方，比如很深的分支判断里。或者放到循环外面，同时保证语义正确。这里我们主要关注GVN。它是一个强大的优化，涵盖了公共子表达式消除，常量计算，控制流优化等等优化手段，即只用这一个就够了。而且还非常系统，通用，直接从之前那些小优化要不要实现，怎么组合的问题里解脱。基本的思路是，程序的任何计算都给他生成一个哈希值，然后每次要做什么计算都去查表，保证不会重复计算。然后放入表前做好常量计算等优化。这里不详细讲了。</p>
<p>GVN和控制流优化迭代优化后的IR如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">define i32 @ifElseIf()&#123;</span><br><span class="line">entry:</span><br><span class="line">  ret i32 -5</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>直接全给优化没了！！！这时候我才彻底明白编译器到底是怎么优化代码的。总结：SSA构建本身（某种意义上）就有很强的优化能力，加上GVN这样的“高级”优化算法，让编译器有了非常强大的通用优化能力。</p>
<h3 id="ssa-构建">SSA 构建</h3>
<p>《Simple and Efficient Construction of Static
Single》这篇论文真的是强。感觉ssa这种理论上也比较简洁的东西也应该有简洁的构建算法。一方面网上大家都说的是最早的那个构建算法，SSA
book里面也只提到了那个初始的构建算法，导致这个算法感觉比较先进，而且采用新的算法也可以让自己学新的东西，因为不太会去抄。所以我直接上了这个算法。</p>
<p>（虽然后面还是出现了bug，我对着那个论文里的伪代码实现算法，好像是说，那个replaceBy函数用一个值替换掉某个trivial的Phi指令的时候，在currentDef这个map里可能有些变量还指向这个phi，然后导致了问题。论文里也没细说要replaceBy要怎么实现，感觉就是直接在指令层面replace
all use
with，没有提到map的问题。直接替换map感觉复杂度太高了。。。我后面是用之前OJ做并查集题目那边的灵感，额外用一个map表示原来被替代的phi被谁替换了，然后readVariable函数查map的时候额外查一下这个表。最后算是解决了问题。。。</p>
<h3 id="寄存器分配与调用约定约束">寄存器分配与调用约定约束</h3>
<p>最开始的时候没怎么学寄存器分配，导致一直有一个疑问：调用约定会规定比如返回值放到r0，参数放到r0-r3，那我寄存器分配怎么考虑这种约束呢？而且如果有这样的场景<code>&#123; int x1 = func1(); func2(0, x1) &#125;</code>那么这个x1因为是func1的返回值，在call指令后会放在r0，那么在冲突图上，就有一个预着色节点x1必须着色为r0，然后我又要传给func2的第二个参数，x1就要放到寄存器r1，那么在冲突图x1作为预着色节点又应该被着色为r1。然后论文里说，预着色节点是必须遵守的，那我这不就完全冲突了吗？怎么回事？预着色节点真的必须遵守？</p>
<p>后面才知道原来有一个阶段叫register
coalescing，就是解决这种调用约定约束带来的问题的。当生成冲突图的时候，如果遇到这种调用约定的约束，比如x1作为函数返回值会在call指令后被放到r0，其实会生成两个节点，一个节点代表r0，是预着色节点，然后同时生成一个没有着色节点代表x1，同时会立刻生成一个mov指令，把r0的值mov到x1，使用mov指令解除了x1和r0的绑定关系。。。这个着色了的r0节点才是真正的不可更改颜色的。然后后面register
coalescing阶段就是用来尽可能地消除move指令的。。。</p>
<h3 id="我们的编译器">我们的编译器</h3>
<p>毕竟为了答辩都花那么多时间准备PPT了，为什么不水一篇博客让更多人看到呢？我们是2022年的无色透明队，在比赛最后几个小时大佬们的“屯flag”（CTF界说法）的冲击下，最后算是保住了一个三等奖。</p>


	<div class="row">
    <embed src="/2022.assets/编译系统设计赛-答辩.pdf" width="100%" height="550" type="application/pdf">
	</div>



<h3 id="参加编译系统设计赛---架构选型">参加编译系统设计赛 -
架构选型</h3>
<h4 id="前中端">前中端</h4>
<p>不得不说Java应该还是比C++好用的。我们用Java写编译器感觉挺好的。设计IR的时候没这么想，直接对着LLVM
IR specification的文本格式，设计成员域，直接toString方法转成LLVM
IR。这样直接可以先写前端，然后用clang直接验证我们的正确性。这也是他们经验分享推荐的做法。</p>
<p>唯一可以变的地方可能是，现在流行Basic Block Argument替代Phi节点（<a
href="https://mlir.llvm.org/docs/Rationale/Rationale/#block-arguments-vs-phi-nodes">MLIR</a>和北大的那个教程都提到了）。我们最开始的时候完全不熟SSA，所以也不敢乱动，既不知道phi是什么，也不知道如果改用basic
block
argument了，那些SSA上的算法该怎么改。现在看来，本来Phi指令也必须放在基本块开头，basic
block
argument也差不多的意思，只不过如果你想从Phi找到Phi指令的操作数的时候，得去前驱基本块那边找它传过来的argument罢了。差别还是不大的。而且确实简化了结构，不用维护Phi指令操作数和前驱基本块的对应关系了。</p>
<h4 id="后端---寄存器分配">后端 - 寄存器分配</h4>
<h5 id="ssa解构后寄存器分配">SSA解构后寄存器分配</h5>
<p>不可能没有走弯路的。我们一开始不熟悉后端，寄存器分配不知道怎么做，于是就参照Engineering
a
compiler那边实现了一个local寄存器分配（后面被证明是最大的性能瓶颈）。队友他觉得lsra比图着色简单，开始看Java的寄存器分配算法，结果说写了几百行也不太缺点最后能不能写完，同时看到其他队伍也有从lsra转型图着色的。我们最后看了之前“燃烧我的编译器”队的图着色，惊讶他们怎么这么一点代码就实现了图着色分配，有了迅速实现的灵感。他们的做法其实算是，保留两到三个寄存器用于修复一切问题，然后剩余的寄存器直接构建冲突图，然后给每个节点计算权重，然后直接分配。省去了原本反复迭代的复杂步骤。</p>
<p>总之，寄存器分配这边先实现一个简单的寄存器分配还是必要的。我之前看<a
href="https://pku-minic.github.io/online-doc/#/lv9p-reincarnation/reg-alloc">北大的那个教程</a>的时候，完全不理解，什么叫不分配寄存器。后面浪费大量时间在我的垃圾Local寄存器分配上之后，才明白。不分配寄存器并不是说真的不分配，而是说，只用最少的寄存器完成分配，每个指令在开始前从栈上把东西加载出来，结束后把东西保存会栈上，即使用最少的寄存器（一般两个寄存器就可以了），把其他的寄存器空出来。</p>
<p>详细来说，是有一个映射表保存已经完成的寄存器分配，然后我们用两个额外留出来的寄存器，完成“修复”工作。也就是说无论你前面怎么分配，甚至完全不分配，我后面只用两个寄存器都可以给你修好。这样不仅实现了一个简单的寄存器分配算法，后面还可以通过增加前置的分配阶段完成简单图着色分配。</p>
<h5 id="基于ssa的寄存器分配">基于SSA的寄存器分配</h5>
<p>寄存器分配方面，（从我看过的里）推荐下面的资料：</p>
<ol type="1">
<li>《Iterated Register
Coalescing》这个是传统的思路。学习还是要学的。介绍了基础的迭代式寄存器分配策略，有多个阶段，每个阶段可能会做出一些决策导致又要从头开始分析（毕竟要找最佳的分配），但是往往并不会迭代太多次。编译器比赛里面大多数队伍都是采用的这种策略（或它的简化版）。</li>
<li>基于SSA的（图着色）寄存器分配系列：
<ol type="1">
<li>《SSA Elimination after Register Allocation》</li>
<li><a
href="https://publikationen.bibliothek.kit.edu/1000007166/6532">《Register
Allocation for Programs in SSA Form》</a>
看着像一本书，其实好像是学位论文。写得非常好。里面不仅仅是讲SSA寄存器分配，而是各种都有涉及，而且讲得挺好（浅显易懂）的。强烈推荐，即使不打算用基于SSA的寄存器分配的人也应该看看。</li>
</ol></li>
</ol>
<p>为什么要用基于SSA的（图着色）寄存器分配呢？想象这样的场景，当你苦苦地一天天加班加点写寄存器分配写了很长，比赛结束发现隔壁队伍大佬居然就用了极少的代码量就完成了这一部分，而且性能还比你好很多，这不得直接气晕过去。而基于SSA的寄存器分配可能就是这种神器（虽然我们因为时间原因并没有写出来，不过ayame他们好像就是用了SSA的寄存器分配）。</p>
<p>基于SSA的寄存器分配指的是，在寄存器分配的时候依然保持SSA形式，在分配结束后才解构SSA。先解构SSA再寄存器分配更容易，因为你如果先分配，再去直接解构，往往会发现，我寄存器都没了，但是解构SSA需要做变量复制，我没有寄存器作为中介无法挪动值了。但同样，如果能解决这一问题，那么同样会很好地简化寄存器分配的实现。</p>
<p>更重要的是，基于SSA的寄存器分配在理论上也更优雅。传统的寄存器分配往往会告诉你，寄存器分配已经是NP完全问题了，因为冲突图的图着色是NP完全的。然而，当你在SSA形式上进行寄存器分配时，它构建出的冲突图有特殊的性质，能够在多项式时间内找到解！！！也就是说，传统的思路你先SSA解构然后再寄存器分配，其实SSA解构这一步是增大了寄存器分配的难度的！！完全不需要那种迭代式的解构，整个图着色分配架构直接是线性的！！不仅效率上优于传统方法，代码量也明显可以感觉可以降下来！！唯一需要的就是额外的理论学习，里面有一些图算法需要好好学一下。</p>
<p>总结：现在回顾，寄存器分配在编译器比赛的开发上其实是可以渐进完成的：从最开始的只用两个寄存器去分配，到后面构建冲突图，计算权重，优先分配权重高的，后面分配不了就不分配，让前面只用两个寄存器分配的逻辑去修复，到最后SSA的寄存器分配。我们之前花太多时间在Local寄存器分配还是太亏了。又复杂性能又差</p>
<h3 id="培训经验分享时我的笔记">培训经验分享时我的笔记</h3>
<p>于剑 小林家的编译器队，分享参赛经验</p>
<p>怎样赶紧搭一个能跑的框架：中端优化空着，后端寄存器分配不太能跳过，寄存器不够的时候用栈空间的逻辑还是得写，但是分配可以写简单的版本。</p>
<p>约定IR，前端要比较完整的功能，终端后端优化pass都可以不要，寄存器分配写个简单版本</p>
<p>后端还是要写很多东西才能跑起来，他们那时候就进度有点落后了。</p>
<p><strong>前端</strong>
不是重点，但是却是正确性问题出现最多的地方。隐藏的功能测例：看名字猜内容。</p>
<p>sys-Y里的const的规则，必须是一个编译期常量。当const类型出现在数组长度里，需要它的值才能知道具体大小，尤其是生成数组访存的时候需要知道上一维的长度。处理字面量的时候小心-2147483628，本来是合法的，如果分成一个负号运算和正数就不合法了。</p>
<p>短路运算。变量初始化。全零放入bss，不全零放入data段。如果有运行期计算的值，生成运算代码放在main前执行。数组的变量初始化比较玄妙。</p>
<p><strong>IR</strong> 他们也是先生成load/store然后mem2reg
pass变成SSA。前年给的建议：直接用LLVM IR。中间转LLVM
IR，可以查哪里的bug，可以对比后端性能。</p>
<p>比较重要的pass：mem2reg、function inline、global value
numbering、global code motion、dead code elimination。</p>
<p><strong>后端</strong>
读ARM指令集文档，庞大，先了解整体结构，整数寄存器，调用约定，控制流转移。多写一点汇编代码确认自己的理解，可以调用libc里面的函数。多用godbolt.org，如果不知道怎么做一个算术运算什么的。</p>
<p>后端首先遍历IR，生成机器指令组成的控制流图。一条IR语句不止一条机器指令。SSA
destruction要处理Phi指令，前置块点的mov。</p>
<p>寄存器分配之前由于还有接近SSA的性质，有的优化会非常方便，指令合并，常量传播。spill，就是指放不下放到栈上，对spill估价的算法调了非常长的时间。寄存器分配好了可以消除mov，条件码也可以消除一些分支。</p>
<p><strong>自动化测试</strong></p>
<p>还是要搭建自动化测试，push上去等一段时间就可以回来看了。非常方便，甚至可以和gcc、llvm做对比。</p>
<p>触发：特点分支发生更新、手动触发web hook，指定commit
id和命令行参数。</p>
<p>结果：一堆json，写个脚本对比效果。</p>
<p>考虑到树莓派性能，不建议把编译编译器和展示结果放到树莓派上。</p>
<p><strong>自动并行化</strong></p>
<p>把循环静态分成num_threads段，每段一个线程来跑。用汇编实现__create_threads和__join_threads函数，使用了clone、waittid、exit三个系统调用。</p>
<p>为了共用栈，所以也不能调用syscall的包装函数，所以要inline
syscall。而且还要安排比较奇怪的栈布局。所以不推荐实现为公用栈。</p>
<p><strong>时间</strong>
差不多18号开始写代码，差不多写了两个月。第一个月的时候才基本能完全跑起来，前端在各种功能测试用例调通了。</p>
<h3 id="其他经验分享的笔记">其他经验分享的笔记</h3>
<p><strong>第一次分享：</strong></p>
<p>最后是反思和建议。</p>
<p>IR里最好加一层分析循环的信息。转IR后循环信息可能丢失。重视循环，循环是很重要的部分。非常需要注意循环的优化。</p>
<p>比赛前期以通过功能点为追求。复杂的寄存器分配可以先放一放，跑通为第一追求。跑通修好各种bug再去做寄存器分配。有的优化做起来非常困难，效果也不一定好。做优化之前可以先尝试手写优化后的汇编，然后运行测试一下之后的结果。本来打算做SIMD，跳转表。预期效果不是很好。</p>
<p>做好版本管理。并行化调通了，最后提交的代码没有合并进去。测试的分支上有公共bug，忘了有一个bug的修复没有合进去，忘了在哪里修的。</p>
<p>本地CI不用排队，对开发进度影响很大。JDK编译编译器，和生成文件还是要在高性能的地方跑，生成后再发给树莓派。有的测试点生成的样例特别大，最好树莓派和电脑要网线连接。1分钟编译，5分钟跑完性能。</p>
<p>GCC比LLVM复杂。他们也学习了第一届清华的Trivial
compiler的设计，也学习了中科大的特等奖的设计。</p>
<p>https://www.bilibili.com/video/BV17g411d7wj</p>
<p>窥孔优化：融合乘加，临近load
store指令对。复制传播，指令调度（效果不是很好），向量化（只对于非常简单的样例，效果不理想）。</p>
<p>测试和调试方面，自动化测试脚本，显示编程错误汇编错误还是执行错误。。。clang测试中间代码的正确性。。。直接生成LLVM。。。gdb调试比较重要。决赛的时候他们创建太多分支了。小组每周两次组会，交流讨论。。。</p>
<p>帮助很大的资料，engeneering a compiler，ssa
book，先学习了龙书第九章。然后从虎书，鲸书学习了。</p>
<p>第二个人（ayame作者）比第一个人好多了，第一个人太水了。</p>
<p>通用向量化太难，所以还是放弃。乱序多发射的，所以想搞调度还是算了，效果不是很好。</p>
<p>有些用例是隐藏的，寄存器分配，带来了很多困难。线性扫描最后被放弃了，太复杂了，而且还没有图着色好。图着色调试起来非常困难。推荐同时写一个trivial的分配方式，比如引用计数。codegen后面保证没有bug后再调试寄存器分配。</p>
<p>虚空debug很痛苦。总结在这两个方面。gvn
gcm的pass容易出错。AST翻译到中间表示的时候，选择语句if-else结构连接，写不好容易产生bug，循环控制语句，break和continue，多层嵌套翻译的时候要注意对应的是那个循环。短路运算也是问题。不规则数组初始化的时候的问题。</p>
<p>决赛两天通宵的。。。这两天主要就是尝试自动并行化。通用的很难做，后面发现可以针对常见模式的并行化，循环之间没有依赖。通宵调出来，开启之后导致其他部分又错了。。最后决赛阶段也没开启。决赛的本地CI很重要，评测卡死，要自己搭建自己的评测机子。两三个小时才能提交一次。比赛也就两天。</p>
<p>最后分享学习路线。翻译IR的时候用visitor模式，类似递归下降。用antlr的时候要改下文法，比如左递归。中层IR采用SSA，了解什么是SSA，engeneering
a compiler
9.3章。SSA构建算法参考LLVM博客和代码。采用LLVM的方案，先生成mem
ssa，然后mem2reg。一篇论文：simple and efficient ssa form
13年的。然后构建完会进行一些优化。最后转换成汇编，也参考engeneering a
compiler
9.3章，介绍了会遇到的问题。除了转换部分，SSA的一个重点是优化算法，看论文：global
code motion global code numbering.
非常强大的优化算法。采用SSA的话，看ssa-book。最后是在底层上面的一些优化，首先是armv7直接读文档，参考。armv7的坑在功能测试点会遇到，比如立即数范围不连续。代码寻址长度有限制。。。这一点在功能测试点会遇到。</p>
<p>寄存器分配会极大影响性能，通常来说，图着色和线扫。图着色可以参考一些论文，我们去年参考的是
iterator register
allocating。llvm的是线性扫描的算法，有博客和youtube视频。SSA可以采取面向SSA的算法，图特殊，相比于普通的更快，效率更高。后端窥孔优化主要是人看生成的汇编，哪里可以优化，可以采取一些数据流分析。可以用GCC
o3和llvm o3对比。看看他们采取了什么优化模式。</p>
<p>比赛分工：一个人负责HIR和MIR构建。两三个人负责中间代码优化。他们直接用LLVM的MIR。一到两人负责体系结构方面。体系结构上能做的优化不太多。中层优化比较多。CI搭建的问题：一个人兼职。推荐调研阶段搭好。</p>
<p>时间安排：4-5月报名，开始调研工作，完成CI。6-7月初期末考试，做些简单的东西，开始写visitor，设计中层底层架构。7月是主要工作的时间，10天完成visitor，同时完成后端翻译，寄存器分配，中间先不做，争取导出汇编，过一部分功能测试点。下旬做优化。有一些极端的场景，一个代码里几千行代码，大量debug工作。同时做优化。如果这个时候有时间还可以调研更复杂的优化。自动并行化和自动向量化。按照去年的经验特等奖需要尝试自动并行化的。决赛阶段能做的不多，主要是debug，之前没完成的优化紧急突击。</p>
<p>代码管理，非常重要，分出branch不能太多。commit
1000多次。搞好软件工程。要规范好代码提交。明确分支代表的含义。master稳定版本，develop开发版本，日常开发汇总，feature和fix。</p>
<p>合理利用tag标记版本，rebase和pull
request保证history。git的常用操作，stash
blame。指定命名规范。善于利用issue，发现了bug可以记录一下，修复了直接关掉非常方便。</p>
<p>自动测试的问题。测试流程分为三个部分。官方提供的gitlab平台，高性能x86服务器，运行测试用例的树莓派集群。高性能x86服务器发现CI测所有功能样例，性能样例有很长时间。尤其是编译花的时间长。编译测试半个小时。高性能服务器可以缩短为10几分钟。</p>
<p>gitlab可以触发CI，可以手动指定。gitlab
runner，编译测试样例，发送到树莓派终端。树莓派结果反馈回来也给服务器给gitlab。测试数据非常大，直接放到树莓派里面，不要每次传输。好复杂。。。</p>
<p>调试的方法：去年ayami，antlr生成parser，中端翻译成LLVM
IR，可以用解释器去调试。后端转LIR，寄存器分配，汇编代码gdb调试，发挥了很大作用。后端调试都是靠gdb。自动并行化，gdb可以调多线程。</p>
<p>最后是参考资料。几篇论文。</p>
<p>对性能不是很关注的测试点可以qemu进行调试。</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>静态分析学习资源分享</title>
    <url>/2022/%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<p>静态分析学习资源分享。</p>
<span id="more"></span>
<p>不得不说，在学习资源上，书 &gt; 课程 &gt;
论文/博客。对于论文，更早发表的更容易看懂。书则要找中文的，最新出版的。</p>
<p>静态分析方面中文书目前应该还没出来，因此最好和国际接轨，学好英语看英文书。英文书其实也不多，有如下几本：</p>
<ol type="1">
<li><p>《Introduction to Static Analysis An Abstract Interpretation
Perspective (Xavier Rival, Kwangkeun Yi) 》 MIT Press 2020</p>
<p>极力推荐。新出版的书整体水平和可读性就是高很多。</p></li>
<li><p>《Principles of Program Analysis》 第二版 2005</p></li>
</ol>
<p>学习资源拿到手看一下，如果讲的都是已经会了的可以扔，如果讲的太难可以记下来，以后回来再看，最后目的都是找到刚好符合自己水平的。</p>
<p>还有各种开源项目的publications</p>
<ol type="1">
<li>SVF http://svf-tools.github.io/SVF/</li>
<li>Frama-C https://frama-c.com/html/publications.html</li>
<li>Python和C跨语言的Mopsa https://mopsa.lip6.fr/</li>
</ol>
<h2 id="之前的总结">之前的总结</h2>


	<div class="row">
    <embed src="/2022.assets/程序静态分析学习资料分享-wjk.pdf" width="100%" height="550" type="application/pdf">
	</div>



]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>StaticAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker与UFW防火墙共存</title>
    <url>/2023/Docker%E4%B8%8EUFW%E9%98%B2%E7%81%AB%E5%A2%99%E5%85%B1%E5%AD%98/</url>
    <content><![CDATA[<p>Docker与UFW防火墙共存</p>
<span id="more"></span>
<p>2023年9月22日
最终还是完全放弃了这个方案，这个方案在docker重启的时候会出现问题，把重启ufw和重启docker关联起来是很有问题的，确实在forward链上做防护更好。</p>
<p>“众所周知”，Docker和UFW（ubuntu自带的防火墙，Uncomplicated
Firewall）等一系列防火墙都是不太能共存的。但是最近学校护网，需要打开防火墙。</p>
<p>UFW与Docker不能共存，肯定也有其他人忍不了。最知名的方案大概是<a
href="https://github.com/chaifeng/ufw-docker#%E5%A4%AA%E9%95%BF%E4%B8%8D%E6%83%B3%E8%AF%BB">ufw-docker</a>项目。然而当我看到里面所说的为什么不选用在input链上做那一段的时候，我觉得我想要的就是在input链上防护！折腾由此开始。</p>
<p>最后用了<a
href="https://stackoverflow.com/questions/30383845/what-is-the-best-practice-of-docker-ufw-under-ubuntu/58098930#58098930">这个</a>回答的方案。</p>
<p><a
href="https://github.com/moby/moby/issues/4737#issuecomment-456792819">这个github
issue</a> 涉及的讨论，里面有人提到要改<code>MANAGE_BUILTINS</code></p>
<h3 id="操作步骤">操作步骤</h3>
<ol type="1">
<li>修改<code>/etc/default/ufw</code>， 把no改成MANAGE_BUILTINS=yes</li>
<li>修改<code>/etc/ufw/after.rules</code>（把下面的加到结尾）
注意把eno1改成网卡名字！！ <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Put Docker behind UFW</span><br><span class="line">*filter</span><br><span class="line">:DOCKER-USER - [0:0]</span><br><span class="line">:ufw-user-input - [0:0]</span><br><span class="line"></span><br><span class="line">-A DOCKER-USER -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT # 只有加上这个才能允许docker的响应包回来。</span><br><span class="line">-A DOCKER-USER -i eno1 -j ufw-user-input</span><br><span class="line">-A DOCKER-USER -i eno1 -j DROP</span><br><span class="line">COMMIT</span><br></pre></td></tr></table></figure></li>
<li>依次重启ufw和docker <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ufw reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="背后的经验">背后的经验：</h3>
<p>如果不增加MANAGE_BUILTINS=yes
刚开始的时候好像没事，但是后面（加规则？和）reload好像会导致ufw直接爆炸。似乎是ufw没有管理DOCKER-USER这个链，但是它引用了ufw-user-input，导致reload过程中关闭ufw的时候无法删掉ufw-user-input链，从而ufw爆炸，解决办法是用sudo
iptables -X ufw-user-input手动删掉这个链</p>
<p>如果不重启docker，好像docker的网络直接紊乱了。启动需要转发端口的container的时候报错
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker: Error response from daemon: driver failed programming external connectivity on endpoint laughing_northcutt (d38a235dfd7d9a54d19598945713b2d4c47a71eaaef4d9e4e1136d537656673e):  (iptables failed: iptables --wait -t filter -A DOCKER ! -i docker0 -o docker0 -p tcp -d 172.17.0.2 --dport 80 -j ACCEPT: iptables: No chain/target/match by that name.</span><br><span class="line"> (exit status 1)).</span><br></pre></td></tr></table></figure></p>
<p>最后一定要注意，每次重启ufw之后都要重启docker，因为MANAGE_BUILTINS=yes之后会把docker自己的ipatables规则都删掉！！需要重启docker增加一下它自己的规则。（经过对比前后iptables
-L输出的区别发现）。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title>锐捷校园网IPv6的／64内网中继配置：ndp-proxy、relay</title>
    <url>/2022/%E9%94%90%E6%8D%B7%E6%A0%A1%E5%9B%AD%E7%BD%91IPv6%E7%9A%84%EF%BC%8F64%E5%86%85%E7%BD%91%E4%B8%AD%E7%BB%A7%E9%85%8D%E7%BD%AE%EF%BC%9Andp-proxy%E3%80%81relay/</url>
    <content><![CDATA[<p>锐捷校园网IPv6的／64内网中继配置：ndp-proxy、relay</p>
<span id="more"></span>
<h2 id="tldr">TL;DR</h2>
<ol type="1">
<li>Interfaces » WAN6 » DHCP server » IPv6 Settings里，勾选Designated
Master，RA 设置relay，DHCPv6 禁用，NDP proxy设置relay。<strong>勾选learn
routes。</strong></li>
<li>Interfaces » LAN » DHCP server » IPv6 Settings里，不能勾选Designated
Master，RA 设置relay，DHCPv6 禁用，NDP proxy设置relay。<strong>勾选learn
routes。</strong></li>
<li>注意wan的IPv6
Settings就别动了，全禁用。wan和wan6一起设置relay会导致RA通过wan转发到外面去。</li>
</ol>
<p>然后使用 <a href="https://github.com/EarthCompass/ns_dup">ns_dup</a>
这个小工具。用openwrt的procd挂着</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/sh /etc/rc.common</span><br><span class="line">USE_PROCD=1</span><br><span class="line">START=99</span><br><span class="line"></span><br><span class="line">start_service() &#123;</span><br><span class="line">        procd_open_instance</span><br><span class="line">        procd_set_param command /bin/ash -c &quot;/root/ns_dup eth3.2109 br-lan &gt; /dev/null&quot;</span><br><span class="line">        procd_set_param respawn $&#123;respawn_threshold:-3600&#125; $&#123;respawn_timeout:-5&#125; 0</span><br><span class="line">        procd_close_instance</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="有人乱发ra怎么办">有人乱发RA怎么办</h4>
<p>由于学校网关设备没有启动RA抑制，导致其他人的配置错误会导致IPv6出现问题。可以通过防火墙，仅允许学校网关的RA包进入。以OpenWRT配置为例：</p>
<ul>
<li>获取网关MAC地址：WireShark抓包，随便找个包，<code>80:05:88</code>开头的MAC就是锐捷设备，或者先用icmpv6过滤找Router
Advertisement包。</li>
<li>默认不允许RA包进入：找到 网络 - 防火墙 - Traffic Rules
里面的自带规则：<code>Allow-ICMPv6-Input</code>，然后 修改 - 高级设置 -
Match ICMP Type里面取消勾选 router-advertisement。保存</li>
<li>允许网关设备的ICMPv6：增加一条规则，比如名为允许网关Input。<code>Incoming IPv6 - protocol ICMP - From wan - MAC xx:xx:xx:xx:xx:xx To this device</code>。这里填写上面找到的正确的网关地址。</li>
</ul>
<h3 id="问题描述">问题描述</h3>
<h4 id="锐捷校园网认证">锐捷校园网认证</h4>
<p>在校园网网页认证的情况下，IPv4应该是只能有一个的，但是IPv6可以有多个。因为现代设备会利用ipv6巨大的地址段，自动在/64子网下生成一个临时ip地址。这一过程是完全和外界没有沟通的（应该），所以在校园网认证那边看来，就是自己网段下凭空出来了一个新的ipv6。经过长时间的使用，可以确信锐捷校园网认证是通过mac地址识别这种新增的用户的。只要你的mac地址认证了，那么上面过的任何包都可以通过认证。</p>
<p>另外，旁路由的情况也和IPv4类似，IPv4只要加个网关就能上网，IPv6则是加条默认路由就可以了。但是要在防火墙禁掉Openwrt默认发出来的ICMP6-redirect消息。这个消息会让机子重新主动连学校路由器。</p>
<h4
id="在64地址下如何让内网机器有ipv6">在/64地址下如何让内网机器有IPv6</h4>
<p>校园网认证的问题暂且不提。IPv6真正的问题是在于路由。校园网只会给里面的设备/64的地址，即不会分配到任何前缀。而其实前缀一般到/64就到底了，从这种意义上说，不能再往下划分任何子网了。但是校园网内确实有路由器的需求。那么解决办法必然是2选1。（第一个方案缺点是非公网地址，外网无法直连，而且配置非常麻烦。这里直接略过。）</p>
<ol type="1">
<li>NAT6</li>
<li>relay模式中继，直接拿公网地址。</li>
</ol>
<p>当你路由器的wan接口有了一个/64的地址之后，那么很自然，这整个/64网段都会必然会被路由到wan接口出去。然而，relay模式把RA消息relay进来了，LAN的机器也是这个网段。这就导致了尴尬的路由问题。假设内网机器想要ping外网ipv6，包走到路由器，路由器从wan发出去，没问题。但是当服务器的响应包从wan回来的时候，到了路由器这里。路由器一看目的地址是wan接口的/64网段，直接把包又丢回wan接口了。。。</p>
<h4 id="ndp-proxy">ndp proxy</h4>
<p>NDP，这里主要关注NS和NA，可以想象成是IPv4的ARP。即，我知道包要从这个接口发出去了，但是我要填以太网的mac地址，那我填谁的mac地址呢？解决的是这个问题。这时，需要发送NS请求，询问某个ip地址（网关或者包的目的ip）的机器的mac地址是什么。这时，对面就会发NA响应回来，通告mac地址。</p>
<p>而NDP
proxy就是用来解决这种情况的，无论是odhcpd，还是ndppd，都支持在wan监听，发现NS转发进来，如果里面主机响应了，就会增加内核中ipv6的neighbor的缓存表，此时如果开启了对应选项，odhcpd和ndppd都会增加一条/128的专门针对这个主机的路由。从而解决路由问题。</p>
<h4 id="ndp-proxy的落败">ndp proxy的落败</h4>
<p><a
href="https://forum.openwrt.org/t/ipv6-ndp-relay-works-only-on-second-attempt/107157/6">forum.openwrt.org/t/ipv6-ndp-relay-works-only-on-second-attempt</a>
（似乎ndppd更好些？然而并不是）</p>
<p><a
href="https://github.com/DanielAdolfsson/ndppd/issues/71">ndppd/issues/71</a>
不支持转发主机主动发出去的包</p>
<p><a
href="https://blog.icpz.dev/articles/notes/odhcpd-relay-mode-discuss/#中继模式的局限性以及可能的解决方法">odhcpd
中继模式原理、局限以及解决方案 | Silent Blog (icpz.dev)</a>
正如这篇文章里工作条件里提到的5个步骤，为什么需要5个步骤呢？就是因为现在的ndp
proxy有一个非常离谱的缺陷，即只能转发别人发的NS，不能转发路由器自己发出的NS到lan里。这可能是内核的设计问题。内核其实给了什么socket机制，让你只监听NS包，但是这里只能监听到外面来的，不包括自己发出去的。</p>
<p>比如我内网机子有一个<code>::aaaa</code>的IP，接入我自己的路由器，然后再接入学校路由器。只有学校路由器发NS请求问<code>::aaaa</code>的mac地址是什么的时候，这个包才能被转发到lan内，触发NA响应，然后触发上述的ndp
proxy的增加路由机制。</p>
<p>然而经过测试，学校的路由器完全不会发这个NS请求，不知道是缓存了还是什么情况。导致还是最开始的那个问题，缺一条路由。有响应包直接到路由器，但是路由器不会往内网转。非常讽刺的是，其实路由器自身会不断发NS包问内网谁是<code>::aaaa</code>，但是经过路由之后，这个NS包还是往wan口发走了。。。也就是说，路由器一直在往wan口找人，却不知道人其实就在自己背后的lan口那边。</p>
<p><a href="https://github.com/DanielAdolfsson/ndppd/issues/69">ndppd
does receive locally generated neighbor discovery · Issue #69 ·
DanielAdolfsson/ndppd (github.com)</a> （现在的ndp
proxy，包括odhcpd和ndppd，都不支持转发主机主动发出去的包）</p>
<p>但是这个问题的临时解决方案也非常简单，ping一下路由器的公网ip地址即可。ping外面的机子还不管用，必须要ping路由器的公网ipv6。此时路由器就会发现，原来我内网有个邻居，然后触发上面的增加路由机制。</p>
<p>其实现在ipv6已经非常接近正常了，也就是发现没有ipv6的时候要ping一下路由器。在Openwrt上的配置也非常简单：（这里假设interface
wan的协议是dhcpv4 client，interface wan6的协议是dhcpv6
client，并且路由器自身ipv6已经正常）</p>
<ol type="1">
<li>Interfaces » WAN6 » DHCP server » IPv6 Settings里，勾选Designated
Master，RA 设置relay，DHCPv6 禁用，NDP proxy设置relay。<strong>勾选learn
routes。</strong></li>
<li>Interfaces » LAN » DHCP server » IPv6 Settings里，不能勾选Designated
Master，RA 设置relay，DHCPv6 禁用，NDP proxy设置relay。<strong>勾选learn
routes。</strong></li>
<li>注意wan的IPv6
Settings就别动了，全禁用。wan和wan6一起设置relay会导致RA通过wan转发到外面去。</li>
</ol>
<p>其实可以就这样将就着用了。</p>
<h3 id="继续折腾">继续折腾</h3>
<p>为了追求完美，每次用ipv6还要ping一下多麻烦啊。仔细想一下问题，其实本质上非常简单，就是差最后一条回到lan的路由。然而就是这追求的一点完美，折腾了好几天都没搞出来。</p>
<ol type="1">
<li><p>如果我把整个/64段都路由到lan内</p>
<ol type="1">
<li>缺点1：这个网段机器有的在lan内，有的在lan外。加了这个就无法通过ipv6访问路由器外同网段的机器了。</li>
</ol></li>
<li><p>好麻烦啊，明明包就在路由器外边了，就差最后一步连接就架起来了。我最近学了netfilter，nftables，我直接把外面的IPv6包都复制一份进来。</p>
<ol type="1">
<li><p>花了一天拼出了下面的命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft delete table netdev testv6</span><br><span class="line">nft add table netdev testv6</span><br><span class="line">nft add chain netdev testv6 na &#123; <span class="built_in">type</span> filter hook ingress device wan priority -1 \; &#125;</span><br><span class="line">nft add rule netdev testv6 na ether <span class="built_in">type</span> ip6 dup to <span class="string">&quot;br-lan&quot;</span> counter <span class="built_in">return</span></span><br><span class="line">nft add rule netdev testv6 na counter <span class="built_in">return</span></span><br></pre></td></tr></table></figure></li>
<li><p>关键的规则就只有一个，即<code>ether type ip6 dup to "br-lan"</code>。把所有ipv6包都复制一份进来。但是在lan这边，链路层肯定是不太对的，源mac地址是路由器lan网卡，目的mac地址应该是内网机器的网卡mac。<code>ether type ip6 ether saddr set xx:xx:xx:xx:xx:xx dup to "br-lan"</code>虽然改了源MAC地址，但是不知道目的mac地址怎么改了。。。有没有简单的办法知道目的mac地址吗？但是其实这就是NDP做的事情啊。。。如果NDP完美了，上面的方案也就完美了。</p>
<ol type="1">
<li>非常神奇的一件事情是，如果你此时正好在wireshark抓包，会发现自己的ipv6是好的。一旦关掉wireshark，ipv6就没了。可能和网卡是否在混杂模式有关。（值得试一试，即此时再将网卡打开嗅探模式，是否内网v6能正常工作）</li>
</ol></li>
</ol></li>
<li><p>既然上面NDP
proxy的问题是不能抓自己发出的NS包，那我直接用nftables规则把NS包复制一份到LAN口不就行了吗。（话说内核不能直接指定一下，NS包往多个接口发吗，反正目的地址都是广播地址。只要我路由器往LAN发了NS包，自然就知道内网有neighbor了。）（也许是经过路由表路由了）</p>
<ol type="1">
<li><p>搜nftables规则的时候，想在netdev类型里hook
egress方向的包。但是发现报错，一搜是内核版本太低了，我的openwrt22.03是5.10内核，然而需要5.17才行。</p></li>
<li><p>但是发现tc （traffic control）可以实现这个功能</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">先用nftables把出去的NS包标记上mark 4</span><br><span class="line"></span><br><span class="line">tc qdisc add dev wan root handle 1: htb default 30</span><br><span class="line">tc class add dev wan parent 1: classid 1:30 htb rate 1000mbit ceil 2000mbit burst 15k</span><br><span class="line">tc class add dev wan parent 1: classid 1:10 htb rate 1000mbit ceil 2000mbit burst 15k</span><br><span class="line">tc filter add dev wan parent 1:0 prio 1 \</span><br><span class="line">    protocol ipv6 u32 \</span><br><span class="line">    match mark 4 0xff \</span><br><span class="line">    action mirred ingress mirror dev wan</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>抓包，确实有NS包复制过来了。然而源mac地址不对。就算有NA响应，路由器会接收吗。。。话说改MAC地址啥的，不就是ndp
proxy做的事情吗？应该要改挺多的吧，我直接用这种规则应该应付不过来？</p></li>
<li><p>我能不能直接把这个NS包重新发给自己，从而触发ndp
proxy的转发，发到内网？在尝试这一条的时候，我路由器崩了。</p></li>
</ol></li>
<li><p>路由器你就不能智能一点吗，我tcp包都从你那过了，你还不知道我在lan吗？即在lan口上嗅探包的源IP地址，如果有进入lan口的包，源IP地址在同网段，则增加一条路由。更进一步，如果长时间没有相关请求，可以删除对应的路由。</p>
<ol type="1">
<li><code>libnetfilter_queue</code>这个库支持用户态处理过滤后的包。更进一步，<code>libnetfilter_log</code>支持用户态处理规则记录的包。我可以写一个用户态程序。再进一步，ulogd是一个用了这个库的程序，而且opkg可以直接安装，我直接下载下来配好，然后自己只要写一个python啥的读它的日志，就可以获取到源ipv6了。</li>
</ol></li>
</ol>
<h4 id="dhcpv6方案">dhcpv6方案</h4>
<p>折腾了这么久，也是非常的累。想到了之前有一篇文章里，那个人也放弃了ndp
proxy。</p>
<p><a
href="https://quantum5.ca/2019/03/08/ndp-proxy-route-ipv6-vpn-addresses/">ndp-proxy-route-ipv6-vpn-addresses</a></p>
<p>本质上就是要知道lan那边有哪些ip，从而加路由。dhcp不就是用来分发IP的吗，让内网机器直接通过dhcp要地址，然后通过dnsmasq的hook加ndp
proxy。</p>
<p>更进一步，可以直接用dhcpv6给内网分发一个小网段，然后直接加静态路由，让这个小网段的包进入lan。</p>
<p>累了，本来还想着说自己搞一个包嗅探，然后加一条路由的程序。这个dhcpv6方案也不错，能用就行。（缺点是，别人一看就知道你这个IP不对劲，肯定是自己配的）</p>
<ol type="1">
<li><p>在Openwrt上也可以非常简单地原生配置：</p>
<ol type="1">
<li>lan的ipv6 setting里，开启dhcpv6 server，RA
server。RA里面关闭slaac，开启Manage的flag。</li>
<li>关闭lan接口Advanced Setting里的IPv6 assignment
length然后把wan的/64地址复制一份到那边lan接口。此时客户端就可以分到这个/64段的地址</li>
<li>注意odhcpd的这个选项：dhcpv6_hostidlength默认值是12 <a
href="https://openwrt.org/docs/techref/odhcpd">openwrt.org/docs/techref/odhcpd</a>
即客户端地址除了低12位，其他会是全零（<a
href="https://github.com/openwrt/odhcpd/issues/84">https://github.com/openwrt/odhcpd/issues/84</a>）。</li>
<li>再加一个/116的静态路由即可。</li>
</ol></li>
<li><p>自己起一个dnsmasq，可以手选一个IP段。RA的发送还是可以交给odhcpd，毕竟有图形界面。</p>
<p><a href="https://wiki.archlinux.org/title/dnsmasq#Test">dnsmasq -
ArchWiki (archlinux.org)</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># dnsmasq -k --conf-file=./dnsmasq.conf --log-facility=- --log-debug</span><br><span class="line"># ipconfig /release6 以太网</span><br><span class="line"># ipconfig /renew6 以太网</span><br><span class="line"></span><br><span class="line">port=0 # disable dns</span><br><span class="line">listen-address=::</span><br><span class="line"></span><br><span class="line"># enable-ra</span><br><span class="line">interface=br-lan</span><br><span class="line"></span><br><span class="line">dhcp-range=::4321:1,::4321:ffff,constructor:br-lan</span><br></pre></td></tr></table></figure></li>
</ol>
<p>还有没考虑的就是，如果IPv6地址前缀经常变怎么办。。。只能说再看吧。</p>
<p>配置还是得追求简单，可复现，容易维护。太累了自己承担不住。</p>
<h3 id="学习资源">学习资源：</h3>
<h4 id="nftables">nftables</h4>
<p><a
href="https://wiki.nftables.org/wiki-nftables/index.php/Quick_reference-nftables_in_10_minutes#Icmpv6">Quick
reference-nftables in 10 minutes - nftables wiki</a></p>
<h4 id="tc-traffic-control-qdisc">tc traffic control qdisc</h4>
<p>[<a href="https://arthurchiao.art/blog/lartc-qdisc-zh/">译] 《Linux
高级路由与流量控制手册（2012）》第九章：用 tc qdisc 管理 Linux 网络带宽
(arthurchiao.art)</a></p>
<p><a
href="https://tonydeng.github.io/sdn-handbook/linux/tc.html">流量控制 ·
GitBook (tonydeng.github.io)</a></p>
<p><a
href="https://openwrt.org/docs/guide-user/network/traffic-shaping/packet.scheduler#actions">openwrt.org/docs/guide-user/network/traffic-shaping/packet.scheduler</a></p>
<h4 id="ipv6">IPv6</h4>
<p>《IPv6技术精要》（美）格拉齐亚尼 著</p>
<h4 id="其他">其他</h4>
<p>最后分享一下我的<a
href="https://forum.openwrt.org/t/solved-usr-share-nftables-d-table-post-not-in-the-right-place/142961/6">v2ray透明代理配置</a></p>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>Embedded</tag>
        <tag>Networking</tag>
        <tag>Openwrt</tag>
      </tags>
  </entry>
  <entry>
    <title>Fuzz快速上手指南</title>
    <url>/2023/Fuzz%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p>Fuzz快速上手指南</p>
<span id="more"></span>
<p>不得不说，学习使用LibAFL的过程，就是学习Fuzz架构的过程。基于LibAFL的baby
fuzzer教程，就可以了解到fuzzer的架构。LibAFL是基于Rust语言，高度可自定义的组件化fuzzer。他们的开发者正尝试用LibAFL复刻AFL++，libfuzzer等多个知名fuzzer，这足以说明LibAFL的强大。</p>
<p>Fuzzing的很重要的一部分就是调试崩溃和修复漏洞。这个和fuzz本身一样重要。这个暂时没涉及</p>
<p>本文涵盖以下内容：</p>
<ul>
<li>AFL的coverage map设计
<ul>
<li>PCGUARD模式</li>
<li>cmplog/input to state/redqueen</li>
</ul></li>
<li>Mutators
<ul>
<li>honggfuzz中的Mutator</li>
<li>AFL中的splice和havoc</li>
<li>MOpt</li>
</ul></li>
</ul>
<h3 id="学习资源">学习资源</h3>
<ul>
<li><a
href="https://github.com/antonio-morales/Fuzzing101">fuzz101</a></li>
<li><a
href="https://github.com/mykter/afl-training">AFL-TRAINING</a>。</li>
</ul>
<h2 id="fuzzer-架构">Fuzzer 架构</h2>
<h3 id="libafl的主要模块">LibAFL的主要模块</h3>
<ul>
<li>Executor：指定InProcess（当前地址空间）还是ForkServer（执行其他程序），或者InProcessFork。</li>
<li>Observer：主要功能是存储和上次执行有关的易失性数据，然后后续的Feedback可以获取这些observer，确定。</li>
<li>Feedback：包括确定是否interesting的普通feedback，以及确定是否达到目标的Objective
Feedback。默认Objective的不会放到queue里。
<ul>
<li>因为反馈的是一个bool值，feedback可以使用逻辑运算符feedback_or和feedback_and。</li>
</ul></li>
<li>Input和TestCase。Input就是普通的buffer，或者复杂的结构体。TestCase则是Input的高级封装，方便存到磁盘。</li>
<li>Corpus：一般至少两个，一个存储感兴趣的Input，一个存达到Objective的Input。</li>
<li>Mutator：对输入进行变换。Mutator之间可以进行组合。</li>
<li>Generator：如果没有初始输入的话，可以用它来生成随机字符串作为初始输入</li>
<li>Stage：阶段，在每次fuzz时执行一次。比如mutationStage，负责mutate，并测试mutate出来的结果是否interesting。其次可以增加一些Observe的stage，对当前输入进行观察，获得数据，比如TracingStage，执行程序，然后用Observer收集一些信息。CalibrationStage，给输入定一个合适的超时时间。</li>
</ul>
<p>然而即使是InProcessExecutor，为了保证持续fuzz，有时会用一个<code>SimpleRestartingEventManager</code>，以从而在崩溃的时候重新起当前进程。在初始化的时候调用<code>SimpleRestartingEventManager::launch</code>，它内部会把主线程挂住，然后起子线程做真正的fuzzing，然后每次在子线程死了的时候重新fork。这也导致lldb调试的时候得额外加上<code>,"initCommands": ["settings set target.process.follow-fork-mode child"]</code>。</p>
<h2 id="afl的coverage-map设计">AFL的coverage map设计</h2>
<p>即使是几年后的现在，最初<a
href="https://github.com/google/AFL/blob/master/docs/technical_details.txt">AFL的coverage
map设计</a>依然被沿用。</p>
<p>本质上AFL的coverage
map还是衡量的边覆盖率。很自然会想到，通过插桩在运行时维护一个从每条边到它执行时经过的次数的map。然而这样做了之后可能占内存很多，也很慢。和Hash函数的思想类似，通过放弃可解释性，放弃追溯具体是那条边的能力，以增加效率。</p>
<p>AFL在每个分支处插桩以下代码。每次fuzz执行前将对应coverage区域清零，执行结束后shared_mem（默认64
kB）被填充了每条边执行次数的信息。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">cur_location = &lt;COMPILE_TIME_RANDOM&gt;;</span><br><span class="line">shared_mem[cur_location ^ prev_location]++; </span><br><span class="line">prev_location = cur_location &gt;&gt; <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>在执行时，每个分支处的随机数就代表了当前分支。每个随机数右移一位后就代表它作为prev_location时的值。异或操作得到的随机数代表具体的一条边。可以想象这些边作为下标均匀分布在数组的槽中，冲突概率较小，从而大致数组每个元素代表每个边经过的次数。</p>
<p>这个方法有明显的几个优点</p>
<ul>
<li>插桩时只需要生成随机数，时间和内存效率高</li>
<li>运行时仅对每个分支增加几条汇编指令的开销，时间效率高。</li>
<li>shared_mem内存大小可调，内存效率高。</li>
</ul>
<p>对于fork
server架构的fuzzer，这块内存可以直接作为共享内存，直接读取子进程的coverage
map。对于in
proc的fuzzer，则直接读取对应内存位置。此时该shared_mem区域可能作为一个全局数组/指针，在静态/动态链接时作为符号导出，fuzzer通过名字引用。</p>
<p><strong>coverage
map过小可能产生大量冲突？</strong>：确实有可能，而且这也是AFL++的<a
href="https://github.com/AFLplusplus/AFLplusplus/blob/stable/instrumentation/README.lto.md">lto模式的优化</a>之一。随机数的随机特性，肯定会没那么均匀，导致部分数组成员同时记录了多条边，然后有些数组成员没有代表任何边。</p>
<p>LTO指link time
optimization.平时编译是按照编译单元，一个文件一个文件直接转换为汇编，然后在汇编层链接。在LTO模式下，编译器每次编译一个文件会先不生成汇编，而是保留便于分析的IR到object文件。在链接到一起的时候，即生成可执行文件的时候，此时有了程序的所有IR代码，能做的优化也更多了。</p>
<p>LTO允许部分优化推迟到链接后进行。之前（AFL-LLVM模式）是分文件生成汇编，此时每个编译单元内，插桩逻辑单独运行，为分支生成随机数。如果能把插桩推迟到最后一起做，则可以在生成随机数的时候相互协调，保证coverage
map里每个数组成员都只代表一条边。</p>
<p>LTO模式不仅代码优化更好，而且插桩也有无冲突的优点，因此它也是使用AFL++时推荐能开则开的模式。</p>
<p><strong>coverage衡量指标的优化</strong></p>
<p>AFL++也提供了很多<a
href="https://github.com/AFLplusplus/AFLplusplus/blob/stable/instrumentation/README.llvm.md#3-options">其他模式</a></p>
<ul>
<li>Context sensitive
coverage：区分不同caller。比如函数A和B都调用了C，那么C里的同一条边，因为考虑的调用者，反馈的覆盖信息就会不同。
<code>map[current_location_ID ^ previous_location_ID &gt;&gt; 1 ^ hash_callstack_IDs] += 1</code></li>
<li>n-gram branch
coverage：根据之前从哪个边走过来的，区分不同的当前边：<code>map[current_location ^ prev_location[0] &gt;&gt; 1 ^ prev_location[1] &gt;&gt; 1 ^ ... up to n-1] += 1</code></li>
</ul>
<p><strong>其他</strong></p>
<ul>
<li>多线程并发修改coverage
map时可能存在竞争问题：设置<code>AFL_LLVM_THREADSAFE_INST</code></li>
</ul>
<h3 id="边执行次数的bucket设计">边执行次数的bucket设计</h3>
<p>coverage
map的成员是1字节，即会记录这条边从0到255的执行次数。AFL进一步细分，把执行次数分为如下8类。即，在程序执行完后，对每个字节应用一个函数，从0-255映射到0-7。</p>
<blockquote>
<p>1, 2, 3, 4-7, 8-15, 16-31, 32-127, 128+</p>
</blockquote>
<p>虽然信息量减少了，但是这样能关注更重要的信息：从执行1次，到执行2次或三次，有可能就有了新的突破，对一个执行了很多次的循环的次数增加则不需要那么敏感。</p>
<h3 id="afl的queue设计">AFL的Queue设计</h3>
<p>除了每次程序执行的coverage map，AFL维护一个全局的coverage
map，包含了之前执行时遇到的所有边。如果某次执行发现了新的边，则当前的输入就会认为是interesting的，放入队列中。</p>
<p>另外，每次执行都会设置超时时间。背后的思想是，即使有些输入能增加1%的coverage，但是会花了上百倍的执行时间，从务实的角度考虑也要排除这种情况。说不定后面就有更高效的方式覆盖到相同的代码了。毕竟速度和效率是fuzzing的精髓之一。</p>
<h2 id="afl的forkserver设计">AFL的forkServer设计</h2>
<p>被fuzz的程序，首先我们一般得给他弄成输入一个buffer的形式。比如经典的<code>LLVMFuzzerTestOneInput</code>。然后main函数可以选择从第一个参数读入文件名，然后把文件内容喂给这个函数，也可以选择stdin读入直接解析。具体怎么弄是根据AFL命令行，指定被测程序的命令行那部分。就是<code>afl++ &lt;afl flags&gt; -- @@</code>这种东西，然后会把<code>@@</code>替换成被测程序的输入。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是这样每次都要启动一次程序，启动成本就上去了。所以说这种fork的fuzzer就不如一些inProcess的fuzzer速度快了吗？也并不是，因为引入了forkServer的机制和<a
href="https://github.com/AFLplusplus/AFLplusplus/blob/stable/instrumentation/README.persistent_mode.md">persistent
mode</a>。</p>
<p><strong>Snapshot
LKM</strong>：LibAFL的开发者发现fork太慢之后，提出了一种方法：增加一个专为fuzz设计的snapshot内核模块。代码在<a
href="https://github.com/AFLplusplus/AFL-Snapshot-LKM">AFL-Snapshot-LKM</a>。可以给一整块地址打快照，fuzz结束后再恢复。但是还是下面的Persistent
Mode用的更多。</p>
<p><strong>Persistent
Mode</strong>：通过在编写harness的时候增加<code>__AFL_FUZZ_INIT();</code>，在fuzz的函数外面增加循环(<code>while (__AFL_LOOP(10000)) &#123;</code>)，以及相关的重置状态的操作，这样并不是每次执行都重新fork，而是每次fork可以fuzz很多次。从而接近in
process的fuzzer的效率，带来10-20x的速度提升。此外，通过共享内存（<code>__AFL_FUZZ_TESTCASE_BUF</code>）直接发送fuzz输入（比如<a
href="https://github.com/AFLplusplus/LibAFL/blob/74783c2027c0ccf54a90f03ab21e7c1aae4a1b2f/libafl/src/executors/forkserver.rs#L1232">这里</a>），绕过文件系统，也可以增加效率。</p>
<p>编写persistent
mode的harness的时候，需要调用初始化<code>__AFL_INIT();</code>，fuzz循环<code>while (__AFL_LOOP(10000)) &#123;</code>。在<code>__AFL_INIT();</code>内部调用了AFL提供的特殊函数，其中包括了父进程和子进程的握手机制。</p>
<p><strong>Pipe&amp;Timeout</strong>：现在往往使用的ForkServer都是开启persistent
mode，同时也开启timeout功能的。所以这一块他们具体是怎么沟通交流的呢？这里有三个进程：Fuzzer，Driver
Parent（下面简称DP），Driver
Child（下面简称DC）。首先Fuzzer进程启动，调用了ForkServer管理端，管理端会在一个特殊的FD（<code>#define FORKSRV_FD 198</code>）创建pipe用于和DP通信。在实例化ForkServer的时候启动DP。DP直接根据环境变量映射Coverage
Map共享内存，然后进行功能协商和握手，可以设置coverage
map大小，是否共享内存传递输入，是否开启cmplog模式。</p>
<p>总结每轮Fuzzer想要运行一次的循环里，相关的pipe通信： 1.
Fuzzer写入四字节<code>was_killed</code>，表示上次是否杀死了child，指示DP是否要保留上次PID。把DP从read
FORKSRV_FD的阻塞中恢复。 1. DP fork出DC并写入DC的PID，把pid传给fuzzer。
1. Timeout时：Fuzzer向DC发送kill，此时依然需要读取DP的wait返回值。 1.
正常执行：（persistent
mode）DC给自己发送SIGSTOP，暂停运行，让DP从wait中恢复。 1. DP
wait结束写入四字节wait返回值 1.
DP在写入前通过<code>WIFSTOPPED</code>判断是否DC
stop了自己，是的话才能在下一次运行时复用DC的PID。否则重新fork。 1.
崩溃发生时：Fuzzer可以通过wait的返回值判断是否发生崩溃。 1.
DP读四字节<code>was_killed</code>阻塞等待下一次运行</p>
<p>这里DP也是一个稳定的进程，不会因为fuzz导致的崩溃而退出，它通过Pipe，把PID和wait的结果都传递给fuzzer了，相当于把fork出来的子进程还是交给fuzzer管理。如果这个子进程超时了，也是由fuzzer发送sigkill信号杀进程。这里还有一个小的条件竞争，即DP同时等到了DC的stop信号，同时Fuzzer那边也发送过kill信号。这种情况下还是需要重新fork。</p>
<p><strong>握手</strong></p>
<ol type="1">
<li>fuzzer在forkserver模式下启动
被fuzz的进程的时候会设置一系列环境变量，包括<code>__AFL_SHM_ID</code>等。</li>
</ol>
<ul>
<li><code>__AFL_SHM_ID</code>: 传递edge coverage map的共享内存ID</li>
<li><code>__AFL_SHM_FUZZ_ID</code>: 传递输入的共享内存ID</li>
<li><code>__AFL_CMPLOG_SHM_ID</code>: 传递cmplog map的共享内存ID</li>
</ul>
<ol type="1">
<li>被fuzz进程在<code>__AFL_INIT();</code>时，根据环境变量，设置好共享内存等变量。同时会向fuzzer发送四字节的flags，里面设置了自己支持的功能对应的比特位。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cc_params[cc_par_cnt++] =</span><br><span class="line">    <span class="string">&quot;-D__AFL_LOOP(_A)=&quot;</span></span><br><span class="line">    <span class="string">&quot;(&#123; static volatile const char *_B __attribute__((used,unused)); &quot;</span></span><br><span class="line">    <span class="string">&quot; _B = (const char*)\&quot;&quot;</span> PERSIST_SIG</span><br><span class="line">    <span class="string">&quot;\&quot;; &quot;</span></span><br><span class="line">    <span class="string">&quot;extern int __afl_connected;&quot;</span></span><br><span class="line">    <span class="string">&quot;__attribute__((visibility(\&quot;default\&quot;))) &quot;</span></span><br><span class="line">    <span class="string">&quot;int _L(unsigned int) __asm__(\&quot;__afl_persistent_loop\&quot;); &quot;</span></span><br><span class="line">    <span class="comment">// if afl is connected, we run _A times, else once.</span></span><br><span class="line">    <span class="string">&quot;_L(__afl_connected ? _A : 1); &#125;)&quot;</span>;</span><br></pre></td></tr></table></figure>
<p>这里<code>_B</code>是一个字符串<code>#define PERSIST_SIG "##SIG_AFL_PERSISTENT##"</code>，不太重要。关键是<code>_L</code>的定义。这里的意思大概是转而调用了__afl_persistent_loop函数。</p>
<h2 id="afl的其他模式">AFL的其他模式</h2>
<h3 id="什么是pcguard">什么是PCGUARD？</h3>
<p>PCGUARD是AFL的默认模式，名字<a
href="https://stackoverflow.com/a/68919788/13798540">可能源自插桩pass的名字</a>。它就是简单地在每个基本块前插桩。</p>
<p>在这个clang的<a
href="https://clang.llvm.org/docs/SanitizerCoverage.html#tracing-data-flow">文档</a>里提到了相关的插桩选项。比如<code>-fsanitize-coverage=trace-pc-guard</code>就是普通的coverage插桩。</p>
<h3 id="什么是persistent-mode">什么是persistent mode？</h3>
<p><a
href="https://github.com/AFLplusplus/AFLplusplus/blob/stable/instrumentation/README.persistent_mode.md">AFL++的文档</a>介绍了，persistent
mode是指在fork server架构下，每次fork会fuzz多次target。</p>
<p>这里指，AFL会在运行二进制后，让程序停在main函数，然后每次fuzz前尝试复制这个进程去fuzz，以避免初始化的开销，有点类似fork。如果程序有复杂的初始化逻辑，还可以选择合适的位置，推迟这里“fork”的点。</p>
<h3
id="cmploginput-to-stateredqueen"><code>cmplog</code>/<code>input to state</code>/<code>redqueen</code></h3>
<p>当fuzzing遇到多字节比较的时候，很难通过随机变换生成对应的字节出来。<a
href="https://github.com/AFLplusplus/AFLplusplus/blob/stable/docs/fuzzing_in_depth.md#b-selecting-instrumentation-options">AFL++的fuzzing_in_depth.md</a>里有一些简单的介绍，有两种方式解决：</p>
<ul>
<li><code>laf-intel</code>/<code>COMPCOV</code>：将多字节比较，拆分为很多单字节比较。</li>
<li><code>cmplog</code>/<code>input to state</code>/<code>redqueen</code>：当出现这种多字节比较的时候，对应的字节会被反馈给AFL++，作为关键词用于mutate填充。这种方式比前一种更加高效。</li>
</ul>
<p>AFL的cmplog模式，需要编译两个binary，一个设置环境变量<code>AFL_LLVM_CMPLOG=1</code>后开启了cmplog的，以及一个没有开启cmplog的binary。平时执行的时候就用没有开启cmplog的，减少开销。</p>
<p>LibAFL里通过<code>-fsanitize-coverage=trace-pc-guard,trace-cmp</code>开启了cmp比较语句的插桩。在<a
href="https://github.com/AFLplusplus/LibAFL/blob/bc91436ef47a6dfad7f19d0ab1a5af5fac97556b/libafl/src/observers/cmp.rs#L300">Observer的pre_exec</a>中执行清空map的操作。</p>
<h4 id="cmplog的步骤">CmpLog的步骤</h4>
<p>正如文档里所说，细节得看<a
href="https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_04A-2_Aschermann_paper.pdf">RedQueen
paper</a>，另外还有这篇文章<a
href="https://arxiv.org/pdf/2211.08357.pdf">《Improving AFL++ CmpLog:
Tackling the bottlenecks》</a>介绍了cmplog当前实现的不足。</p>
<p>然而，根据<a href="https://arxiv.org/pdf/2211.08357.pdf">《Improving
AFL++ CmpLog: Tackling the
bottlenecks》</a>，AFL里面的CmpLog模式，和RedQueen
paper里的还不太一样。RedQueen
paper里用很大篇幅介绍绕过checksum的事情，CmpLog没有实现。另外，实现的细节也不太一样。但是还是根据这篇paper里描述的解读</p>
<p>CMPLog最基本的思想是，程序里面很多字节和输入里的字节有对应关系。比如我在程序里发现了一个四字节比较，一边是“abcd”，一边是“00ELF”，同时发现这个abcd在程序输入中也出现了。此时我就可以增加一个mutate关系：把“abcd”mutate成“00ELF”。</p>
<p><strong>Colorization</strong>：（见paper的第5页右侧，Ⅲ.A.v）简单应用上面的方法可能出问题：比如我们种子输入，可能里面有很长一段全都是<code>\x00</code>这种字节。如果生成一个“”到其他东西的mutate，那么会导致可以应用的地方太多。如paper中的例子所示：</p>
<figure>
<img src="redqueen1.png" alt="为什么需要引入Colorization阶段？" />
<figcaption
aria-hidden="true">为什么需要引入Colorization阶段？</figcaption>
</figure>
<p>Colorization阶段基于现有输入变换得到一个新的输入，相比原来的输入多了更多的熵。同时我们可以在两个输入上观察应用的行为，在应用mutation时，可以要求两边在相同的输入都可以这样mutate。即，在两个输入上观察那个四字节比较，比如输入1是“”
和“00ELF”，然后“”在input的offset是offset1，colorized的input是“abcd”和“00ELF”，然后“abcd”在input里的offset也是相同的offset1。</p>
<p><strong>详细算法细节：LibAFL</strong>：这里解读LibAFL里自己实现的CmpLog技术。</p>
<p>CmpLogMap为什么是二维数组：首先是最简单的<code>CmpLogInstruction</code>结构体，包含了两个被对比的值（u8,u16,u32,u64），表示两个值被cmp了。但是整个Map是一个二维数组（<a
href="https://github.com/AFLplusplus/LibAFL/blob/0b38fabeb009a201cce87cc0e56a57f5ea4199dc/libafl_targets/src/cmps/mod.rs#L253">代码</a>），默认高32，宽65536。宽很好理解，不同插桩点的cmp值。高则代表了单个位置的cmp指令，被执行多次，可能遇到多次不同的cmp情况。</p>
<p>从Map到Metadata：<code>CmpObserver</code>在执行结束的时候，会处理（<a
href="https://github.com/AFLplusplus/LibAFL/blob/bc91436ef47a6dfad7f19d0ab1a5af5fac97556b/libafl/src/observers/cmp.rs#L131">代码</a>）Map，得到可能的mutation作为metadata存入state。而处理的时候有简单的过滤。CmpLog具体怎么处理，由于RedQueen
paper它自己不是很开源，这一块具体怎么做还是非常模糊。LibAFL这里简单过滤了loop相关的cmp。在遍历单个cmp的多次执行的时候，如果发现有一边在大部分的执行时是简单的递增或者递减。那么这个cmp不是很有意义。</p>
<p>具体mutate的时候，则是双向mutate。随机选取输入的一个offset，向后搜索。如果当前位置的字节，取出数字来，刚好等于两边cmp
entry里面任意一边的值，则把当前字节替换成另外一边的值。这意味着有可能会使得本次mutate直接skip。</p>
<p>CmpLogMap被定义为一个rust的全局变量（见<a
href="https://github.com/AFLplusplus/LibAFL/blob/0b38fabeb009a201cce87cc0e56a57f5ea4199dc/libafl_targets/src/cmps/mod.rs#L397">这里</a>），在<a
href="https://github.com/AFLplusplus/LibAFL/blob/0b38fabeb009a201cce87cc0e56a57f5ea4199dc/libafl_targets/src/cmplog.c">cmplog.c</a>文件里有相关的处理操作。这个cmplog.c是通过rust编译的，见<a
href="https://github.com/AFLplusplus/LibAFL/blob/bc91436ef47a6dfad7f19d0ab1a5af5fac97556b/libafl_targets/build.rs">libafl_targets/build.rs</a>。在构建过程中，有一些变量是动态生成到一个rust文件的：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">/// The size of the edges map</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> EDGES_MAP_SIZE: <span class="type">usize</span> = <span class="number">65536</span>;</span><br><span class="line"><span class="comment">/// The size of the cmps map</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> CMP_MAP_SIZE: <span class="type">usize</span> = <span class="number">65536</span>;</span><br><span class="line"><span class="comment">/// The width of the aflpp cmplog map</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> AFLPP_CMPLOG_MAP_W: <span class="type">usize</span> = <span class="number">65536</span>;</span><br><span class="line"><span class="comment">/// The height of the aflpp cmplog map</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> AFLPP_CMPLOG_MAP_H: <span class="type">usize</span> = <span class="number">32</span>;</span><br><span class="line"><span class="comment">/// The width of the `CmpLog` map</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> CMPLOG_MAP_W: <span class="type">usize</span> = <span class="number">65536</span>;</span><br><span class="line"><span class="comment">/// The height of the `CmpLog` map</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> CMPLOG_MAP_H: <span class="type">usize</span> = <span class="number">32</span>;</span><br><span class="line"><span class="comment">/// The size of the accounting maps</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> ACCOUNTING_MAP_SIZE: <span class="type">usize</span> = <span class="number">65536</span>;</span><br></pre></td></tr></table></figure>
<p><strong>详细算法细节：AFL++</strong></p>
<figure>
<img src="cmplog.png" alt="Cmplog原理示意图" />
<figcaption aria-hidden="true">Cmplog原理示意图</figcaption>
</figure>
<p>因此，我们现在有两个输入。每个输入执行后都有一系列的CmpLog的项。每个项里面记录了两个比较的值。但是因为不确定哪边是Magic
Header，哪边是和我们input有对应的值。因此我们需要对左右分两种情况。</p>
<p><img src="cmplog-algo1.png" width="60%"/></p>
<!-- ![cmplog-algo1](cmplog-algo1.png) -->
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">算法</span><br><span class="line">for replication, pattern in CmpLogs</span><br><span class="line">  for taint_region in regions</span><br><span class="line">    for byte in taint_region</span><br><span class="line">      考虑从当前字节到region结尾这一段</span><br><span class="line">      对两种情况调用处理函数</span><br></pre></td></tr></table></figure>
<p>正如这个函数所示</p>
<p><img src="cmplog-algo2.png" width="60%"/></p>
<!-- ![](cmplog-algo2.png) -->
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">解释上图里的算法</span><br><span class="line">尝试一个字节一个字节的来，把当前考虑的这一段替换成对应magic byte（有点子字符串匹配算法的感觉）。每替换一个字节运行一下。</span><br><span class="line">for 每个字节</span><br><span class="line">  检查两个对应关系：</span><br><span class="line">    1 （I2S对应关系）当前改的字节，和当前cmplog的pattern对应上 （o_pattern[i]==orig_buf[idx+i]）</span><br><span class="line">    2 改了这个字节之后运行，当前cmplog确实这个字节跟着改变了。（pattern[i]==buf[idx+i]）</span><br><span class="line">    如果对应关系不成立则break。</span><br><span class="line">  替换当前字节并运行。</span><br></pre></td></tr></table></figure>
<p>对于常量的比较，即使是8字节比较，但是实际上比较的可能是4字节，甚至2字节单字节。再加上大小端序，对每个比较都能分出下面8种情况。</p>
<p><img src="bswap.png" /></p>
<p><strong>算法的缺点：执行爆炸</strong></p>
<p>所以，之所以会执行爆炸，主要是两点：</p>
<ol type="1">
<li>常量比较，由于考虑了多种比较情况，尤其是2字节单字节的情况，导致出现特别简单的单字节替换，在整个输入（实际上taint
bytes）里有太多的替换的地方。</li>
<li>buffer比较，由于每次只替换一个字节，导致如果有很多连续的相同字节，有可能有阶乘的复杂度。和子字符串比较算法里出现的情况类似。每次替换一下就执行一下程序，导致执行次数爆炸。</li>
</ol>
<h4 id="libafl实现细节">LibAFL实现细节</h4>
<h2 id="mutation">Mutation</h2>
<p><a
href="https://aflplus.plus/libafl-book/core_concepts/mutator.html">LibAFL里对Mutator的介绍</a>很简单。Mutator是一个<a
href="https://docs.rs/libafl/0.11.1/libafl/mutators/trait.Mutator.html">Trait</a>，包含两个函数，mutate和post_exec。同时，<a
href="https://aflplus.plus/libafl-book/core_concepts/stage.html">Stage</a>也很重要，Mutational
Stage也会对语料库里的输入进行修改。</p>
<h3 id="honggfuzz的mutator"><a
href="https://honggfuzz.dev/">honggfuzz</a>的mutator</h3>
<p>honggfuzz的mutator就放在最外层的<code>honggfuzz/mangle.c</code>和<code>mangle.h</code>里。在mangle.c的最底部即可看到一个mangleFuncs数组。</p>
<p>一个值得注意的是，里面的随机数有很多是用的选取函数<code>mangle_getLen</code>，会经常倾向于更小的数字。</p>
<ol type="1">
<li><a
href="https://github.com/google/honggfuzz/blob/88709ce60f45ee13666a2628f03467c57429c7db/mangle.c#L687">mangle_Shrink</a>：随机选取一个offset，然后选取一个长度（大部分情况是0-16随机选，1/16的可能性是0到<当前offset到末尾的距离>里选），然后删掉从这个offset到offset+len的数据。</li>
<li><a
href="https://github.com/google/honggfuzz/blob/88709ce60f45ee13666a2628f03467c57429c7db/mangle.c#L675">mangle_Expand</a>：同上选取一个长度：（大部分情况是0-16随机选，1/16的可能性是当前offset到<程序最大输入长度>里选）。然后把从offset开始的数据向后搬运len个距离，如果要求了printable，则会把中间新增的字节填充为空格。</li>
<li>mangle_Bit：修改某个bit</li>
<li>mangle_IncByte、mangle_DecByte：将某个字节加1或者减1。如果要求是printable就麻烦一点，在printable范围内带模加减。</li>
<li>mangle_NegByte：将某个字节取反。</li>
<li>mangle_AddSub：随机选择1，2，4字节范围的值看作整数，然后生成一个范围内的，可正可负的值，加上去。</li>
<li>mangle_MemSet：随机选择一个offset，然后从0到<当前offset到末尾的距离>里随机选一个长度，随机选一个byte，然后有50%概率memset，50%概率插入（此时类似Expand）。</li>
<li>mangle_MemClr：同上，但是byte选0（printable的时候选空格）</li>
<li>mangle_MemSwap：随机选择一个offset，然后从0到<当前offset到末尾的距离>里随机选一个长度。操作两次得到两个offset和长度，取较小的长度，然后交换内容。</li>
<li>mangle_MemCopy：随机选择一个offset，然后从0到<当前offset到末尾的距离>里随机选一个长度，这样选出一块内容。随机找个offset，有50%概率覆盖，50%概率插入（此时类似Expand）。</li>
<li>mangle_Bytes：在buf中随机插入或覆盖1-2个随机字节。</li>
<li>mangle_ASCIINum：在buf中随机插入或覆盖一个十进制（可带负号）数字。</li>
<li>mangle_ASCIINumChange：在buf中找到一个现有的十进制数字，然后修改。有8种可能：加1，减1，乘2，除2，覆盖为随机值，加减0-256的随机数，取反。</li>
<li>mangle_ByteRepeat：选取一段范围，插入或者覆盖，重复随机offset里的某个字节。</li>
<li>mangle_Magic：有220个magic值，随机选里面的插入或者覆盖。</li>
<li>mangle_StaticDict：随机选dict里的值插入或者覆盖。</li>
<li>mangle_ConstFeedbackDict：需要开启cmpFeedback模式，然后从cmp
feedback数组里面随机选一个值出来。</li>
<li>mangle_RandomBuf：随机选择一个offset，然后从0到<当前offset到末尾的距离>里随机选一个长度，这样选出一块内容。然后插入或者填充随机的字节。</li>
</ol>
<h3 id="afl中的splice和havoc">AFL中的splice和havoc</h3>
<blockquote>
<p>第一次进行变异的种子文件首先要进入deterministic
stage，在这一阶段每个变异操作会对种子文件的每个byte或者bit进行变异，以此生成庞大数量的测试用例来测试目标程序。在结束了deterministic
stage后，进入havoc
stage，AFL从变异操作中随机选Ro个对种子文件进行变异，并使用变异后的测试用例来测试程序。第三个阶段是splicing
stage，进入这一阶段的判断条件很苛刻，如果AFL变异了seed
pool中的所有种子文件，得到的测试用例仍然没有发现新的interesting test
cases，AFL才会执行这一阶段，splicing
stage只执行一个变异操作：随机选取另一个种子文件，将它和当前文件的部分内容拼接在一起，然后重新进入havoc
stage进行变异。（摘自<a
href="https://www.inforsec.org/wp/?p=3950">InForSec通讯</a>）</p>
</blockquote>
<p>AFL的<a
href="https://afl-1.readthedocs.io/en/latest/user_guide.html">文档</a>里有下面的介绍：</p>
<blockquote>
<p>havoc - a sort-of-fixed-length cycle with stacked random tweaks. The
operations attempted during this stage include bit flips, overwrites
with random and “interesting” integers, block deletion, block
duplication, plus assorted dictionary-related operations (if a
dictionary is supplied in the first place).</p>
</blockquote>
<p>havoc是很多操作的叠加。</p>
<blockquote>
<p>splice - a last-resort strategy that kicks in after the first full
queue cycle with no new paths. It is equivalent to ‘havoc’, except that
it first splices together two random inputs from the queue at some
arbitrarily selected midpoint.</p>
</blockquote>
<p>splice会选择两个输入，在某个位置把它们拼接起来。</p>
<p>其他介绍：</p>
<ul>
<li><a
href="https://www.zrzz.site/posts/49460ecb/">AFL-变异策略</a></li>
</ul>
<h2 id="schedule">Schedule</h2>
<p>Fuzzing的调度分为两个方面，</p>
<ul>
<li>Input调度：对每个queue里的testcase，mutate、执行、判断是否interesting，这三个步骤一起作为一轮。调度策略决定执行多少轮。
<ul>
<li><code>StdMutationalStage</code>：获取一个从零到最大mutate次数（默认128）的随机数，mutate这些次数。（代码在<a
href="https://github.com/AFLplusplus/LibAFL/blob/d53503b73ea0425ffdcfbc467c167b02632077b6/libafl/src/stages/mutational.rs#L190">这</a>）</li>
<li>Power
Schedule：给每个queue中的输入打一个energy分，根据分数决定在这个输入上做mutate的次数。
<ul>
<li><code>StdPowerMutationalStage</code>使用的是<code>CorpusPowerTestcaseScore</code>。</li>
<li><code>EcoPowerMutationalStage</code>使用的是<code>EcoTestcaseScore</code></li>
</ul></li>
</ul></li>
<li>Mutator调度：仅用单个mutator，mutate一次，可能不足以发现新的路径。在单次mutate内部，可以叠加mutator。用哪个mutator多一些，用哪个mutator少一些，是否组合，怎么组合。
<ul>
<li><code>ScheduledMutator</code>：内部封装多个其他mutator，在1到迭代次数（默认7）中随机选择一个数字，每次随机选个mutator，对单个input
mutate这些次数，返回上层作为一次mutate。（代码在<a
href="https://github.com/AFLplusplus/LibAFL/blob/d53503b73ea0425ffdcfbc467c167b02632077b6/libafl/src/mutators/scheduled.rs#L104">这</a>）</li>
</ul></li>
</ul>
<p>例1：对于下面的代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Setup a randomic Input2State stage</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">i2s</span> = StdMutationalStage::<span class="title function_ invoke__">new</span>(StdScheduledMutator::<span class="title function_ invoke__">new</span>(tuple_list!(I2SRandReplace::<span class="title function_ invoke__">new</span>())));</span><br></pre></td></tr></table></figure>
<p>我们可以解读为：随机叠加<code>I2SRandReplace</code>1-7次作为单次mutate。mutate并执行1-128次。</p>
<p>例2：对于下面的代码</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Setup a MOPT mutator</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">mutator</span> = StdMOptMutator::<span class="title function_ invoke__">new</span>(</span><br><span class="line">    &amp;<span class="keyword">mut</span> state,</span><br><span class="line">    <span class="title function_ invoke__">havoc_mutations</span>().<span class="title function_ invoke__">merge</span>(<span class="title function_ invoke__">tokens_mutations</span>()),</span><br><span class="line">    <span class="number">7</span>,</span><br><span class="line">    <span class="number">5</span>,</span><br><span class="line">)?;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">power</span> = StdPowerMutationalStage::<span class="title function_ invoke__">new</span>(mutator);</span><br></pre></td></tr></table></figure>
<p>我们可以解读为：将havoc和<code>tokens_mutations</code>(cmplog)合并作为mutator，使用MOpt调度Mutator的叠加，每个testcase上的尝试次数使用<code>StdPowerMutationalStage</code>调度。</p>
<h3
id="mutator调度-mopt-optimized-mutation-scheduling-for-fuzzers">(Mutator调度)
MOpt: Optimized Mutation Scheduling for Fuzzers</h3>
<p><a
href="https://www.inforsec.org/wp/?p=3950">InForSec通讯</a>有些相关的介绍。</p>
<p>MOpt这篇paper，改进了AFL里面havoc阶段的Scheduler的过程。</p>
<p>LibAFL里也实现了这篇paper的方法。</p>
<h3 id="libafl代码里的mutation流程">LibAFL代码里的mutation流程</h3>
<p>LibAFL的mutation stage的主要逻辑在这个<a
href="https://github.com/AFLplusplus/LibAFL/blob/d53503b73ea0425ffdcfbc467c167b02632077b6/libafl/src/stages/mutational.rs#L118"><code>perform_mutational</code></a>函数。</p>
<ul>
<li>首先确定为了当前输入，打算进行多少次mutate，存入变量num。</li>
<li>MutatedTransform机制，可以根据testcase和state转换输入，目前似乎只是从TestCase解出input。</li>
<li>循环num次
<ul>
<li>复制一份输入</li>
<li>对输入调用mutator变换：mutator可以返回MutationResult::Skipped，表示变换失败，直接continue</li>
<li>运行输入，判断是否interesting（<code>fuzzer.evaluate_input</code>）。
<ul>
<li>evaluate_input_with_observers：执行程序，执行observer，执行<code>scheduler.on_evaluation</code>，执行<code>process_execution</code>。
<ul>
<li>process_execution这里会判断是否找到bug（<code>ExecuteInputResult::Solution</code>），或者interesting（<code>ExecuteInputResult::Corpus</code>），或者都不是。
<ul>
<li>对于interesting的输入，复制</li>
</ul></li>
</ul></li>
</ul></li>
<li>执行Mutator的post_exec</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>FFmpeg+Santinizer编译时的奇怪问题</title>
    <url>/2023/FFmpeg+Santinizer%E7%BC%96%E8%AF%91%E6%97%B6%E7%9A%84%E5%A5%87%E6%80%AA%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>FFmpeg+Santinizer编译时的奇怪问题，不得不感叹软件世界的复杂性，总是会有奇奇怪怪的问题，还好有开源，不然都无法debug。</p>
<span id="more"></span>
<p>在<a
href="https://github.com/am009/fuzzbench/tree/SBFT24">参与SBFT'24
Fuzzing
competition</a>时遇到了这个bug。fuzzbench里编译ffmpeg的时候出现了奇怪的编译报错（剧透：和sanitizer有关系），首先上来就说我符号找不到，而且很多。搜了一下发现大多都是汇编里的符号，ffmpeg里面很多手写的汇编代码，直接和C语言链接起来。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ld.lld: error: undefined symbol: ff_yuv2yuv_422p10to8_sse2</span><br><span class="line">&gt;&gt;&gt; referenced by colorspacedsp_init.c:96 (/src/ffmpeg/libavfilter/x86/colorspacedsp_init.c:96)</span><br><span class="line">&gt;&gt;&gt;               colorspacedsp_init.o:(ff_colorspacedsp_x86_init) in archive libavfilter/libavfilter.a</span><br><span class="line"></span><br><span class="line">ld.lld: error: undefined symbol: ff_yuv2yuv_422p10to10_sse2</span><br><span class="line">&gt;&gt;&gt; referenced by colorspacedsp_init.c:96 (/src/ffmpeg/libavfilter/x86/colorspacedsp_init.c:96)</span><br><span class="line">&gt;&gt;&gt;               colorspacedsp_init.o:(ff_colorspacedsp_x86_init) in archive libavfilter/libavfilter.a</span><br><span class="line"></span><br><span class="line">ld.lld: error: undefined symbol: ff_yuv2yuv_422p10to12_sse2</span><br><span class="line">&gt;&gt;&gt; referenced by colorspacedsp_init.c:96 (/src/ffmpeg/libavfilter/x86/colorspacedsp_init.c:96)</span><br><span class="line">&gt;&gt;&gt;               colorspacedsp_init.o:(ff_colorspacedsp_x86_init) in archive libavfilter/libavfilter.a</span><br><span class="line"></span><br><span class="line">ld.lld: error: undefined symbol: ff_yuv2yuv_422p12to8_sse2</span><br><span class="line">&gt;&gt;&gt; referenced by colorspacedsp_init.c:96 (/src/ffmpeg/libavfilter/x86/colorspacedsp_init.c:96)</span><br><span class="line">&gt;&gt;&gt;               colorspacedsp_init.o:(ff_colorspacedsp_x86_init) in archive libavfilter/libavfilter.a</span><br><span class="line"></span><br><span class="line">ld.lld: error: too many errors emitted, stopping now (use --error-limit=0 to see all errors)</span><br><span class="line">clang++: error: linker command failed with exit code 1 (use -v to see invocation)</span><br></pre></td></tr></table></figure>
<p>辛酸的debug过程就不说了。只能说还是得多搜代码，同时找一个正确编译的环境去对比。</p>
<p>最后发现问题在于configure的时候，makefile里多了一个<code>X86ASMFLAGS=-f elf64 -DPIC -DPREFIX -g -F dwarf</code>。关键在于这个<code>-DPREFIX</code>，它会导致汇编链接出来的符号多一个下划线前缀，从而导致符号找不到。</p>
<p>而为什么会增加<code>-DPREFIX</code>这个配置？发现是在configure.sh里由<code>extern_prefix</code>变量控制的。这个变量的判断规则如下：让编译器创建一个只有一个全局变量的对象，然后用nm读取符号名字，看看有没有什么前缀。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">test_cc &lt;&lt;EOF || die &quot;Symbol mangling check failed.&quot;</span><br><span class="line">int ff_extern;</span><br><span class="line">EOF</span><br><span class="line">sym=$($nm $TMPO | awk &#x27;/ff_extern/&#123; print substr($0, match($0, /[^ \t]*ff_extern/)) &#125;&#x27;)</span><br><span class="line">extern_prefix=$&#123;sym%%ff_extern*&#125;</span><br></pre></td></tr></table></figure>
<p><strong>有问题的构建</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@2c0808a63794:/src/ffmpeg# nm -g /tmp/ffconf.0T9GnOK3/test.o</span><br><span class="line">0000000000000008 C ___asan_globals_registered</span><br><span class="line">                 U __asan_init</span><br><span class="line">                 U __asan_register_elf_globals</span><br><span class="line">                 U __asan_unregister_elf_globals</span><br><span class="line">                 U __asan_version_mismatch_check_v8</span><br><span class="line">0000000000000000 B __odr_asan_gen_ff_extern</span><br><span class="line">                 w __start_asan_globals</span><br><span class="line">                 w __stop_asan_globals</span><br><span class="line">0000000000000000 B ff_extern</span><br></pre></td></tr></table></figure>
<p><strong>正常的构建</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@c043e1ed694c:/src# nm -g /tmp/ffconf.OTqSYv4r/test.o</span><br><span class="line">                 U __asan_init</span><br><span class="line">                 U __asan_register_globals</span><br><span class="line">                 U __asan_unregister_globals</span><br><span class="line">                 U __asan_version_mismatch_check_v8</span><br><span class="line">0000000000000000 B ff_extern</span><br></pre></td></tr></table></figure>
<h3 id="原因">原因</h3>
<p>可以发现，这个awk的匹配可能有问题，匹配到了__odr_asan_gen_ff_extern，认为会有前缀，且前缀是<code>__odr_asan_gen_</code>。然而其实根本没有前缀，那个符号就好好地在最下面。导致了ffmpeg对配置的误判。</p>
<p>但是这个<code>__odr_asan_gen_</code>前缀是什么呢？搜了一下发现了大佬的<a
href="https://maskray.me/blog/2023-10-15-address-sanitizer-global-variable-instrumentation#odr-indicator">博客</a>。ODR代表One
Definition
Rule，一个名字只能对应一个定义的变量，这里sanitizer尝试帮你判断了是否有重名的变量，然后这个符号就是这个功能产生的。关闭odr相关功能可能就可以解决这个问题？</p>
<p>可能就是因为用的clang版本太新了，新版的把<code>-fsanitize-address-use-odr-indicator</code>设为了默认。这里尝试把它关掉，即加上<code>-fno-sanitize-address-use-odr-indicator</code>。</p>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>PL基础入门</title>
    <url>/2023/PL%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>PL基础入门</p>
<span id="more"></span>
<h2 id="资源">资源</h2>
<ul>
<li><a
href="https://csdiy.wiki/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/CS242/#_1">Stanford
CS242 Programming Languages</a></li>
<li><a href="https://helloqirun.github.io/misc/popl22.html">[POPL'22
Tutorial] Program Analysis via Graph Reachability: Past, Present, and
Future</a></li>
</ul>
<h2 id="类型和程序设计语言">《类型和程序设计语言》</h2>
<p>对照学习中文版《类型和程序设计语言》和英文版<a
href="https://github.com/MPRI/M2-4-2/blob/master/Types%20and%20Programming%20Languages.pdf">《Types
and Programming Languages》</a></p>
<p>还记得最早学编程的时候，会去想函数是什么。而现在，脑海里自动出现什么调用栈，返回地址。也许类型系统是当初就应该学的。</p>
<h3 id="第一部分-无类型系统">第一部分 无类型系统</h3>
<p>无类型系统是图灵完全的。当整个系统中只有函数的形式，一切都是函数的树的形式，信息也被存储在函数的树状结构中。</p>
<h4 id="第三章-无类型算术表达式">第三章 无类型算术表达式</h4>
<p>本章讨论的是布尔和数的无类型演算。</p>
<ul>
<li>succ,pred,iszero共同组成了自然数相关的判断的基本元素。true,false,if-then-else，构成了bool类型和条件判断的基本元素。</li>
</ul>
<p>相关概念：</p>
<ul>
<li>元变量，有点类似语法中的非终结符，是一个可以用其他项代换的“变量”。</li>
<li>表达式，和项，这两个词现在可以替换使用。但是后面章节里，表达式的范围更大，因为除了包括语言中的表达式（项），还包括类型系统中的表达式等。</li>
<li>推导规则：写一个横线，上面写前提，下面写结论。没有前提的规则称为公理。我们这里的推导规则实际上是规则模式，因为前提和结论可以包含“元变量”，需要匹配出来，背后代表的是无限多个具体规则。</li>
<li>语法：定义一个集合，包含所有可能存在的项。书中用
归纳定义，推导规则定义，具体定义
三种方法定义了相同的集合。最后证明了这样定义出来的集合就是满足语法规则的最小集合。</li>
</ul>
<p>最后书中证明了，这里定义的集合是满足这三个语法条件的最小的集合。此外，定义的过程中区分了常量出来。因此得到一个推论，每个项目要么是常量，要么形如succ
t, pred t, iszero t 或 if t then t else t的形式。</p>
<p><strong>项上归纳原理</strong>：可以以三种方式归纳证明一些关于项的定理：深度归纳、长度归纳、结构归纳。</p>
<p><strong>形式化语义的三种方法</strong>：</p>
<ul>
<li>操作语义：定义一个简单的抽象机器。抽象指将语言中的项作为状态。机器的行为由一个转换函数定义，要么转换要么声明机器已经停止。有时语义可以看作将t作为初始状态时达到的最后状态。这里描述的是小步语义。还有一种大步语义形式，有时称为自然语义。</li>
<li>指称语义：语义不只是机器状态，而且是某个数学对象。包括一个语义域的集合和将项映射到域中元素的解释函数。需要为语言特征寻找合适的语义域。有时候所选的语义域的性质可以推导出程序行为。由语义定义域的性质甚至可以得出在一个语言中有些事情是不可能发生的。</li>
<li>公理语义：公理方法用规则本身作为语言的定义，一个项的语义就是，从公理规则出发，我们能推导出的关于这个项的性质。</li>
</ul>
<p>在1980年前后，操作语义逐渐成为主流。这本书也只用操作语义</p>
<p><strong>语义和求值</strong></p>
<p>布尔表达式的操作语义有如下几个部分：</p>
<ul>
<li>语法部分
<ul>
<li>项本身的语法</li>
<li>值：它定义了项的一个子集，可以作为求值的最终结果</li>
</ul></li>
<li>求值关系（也叫归约）
<ul>
<li>如果抽象机器有某个状态，则此时可以按照该规则求值一步。</li>
</ul></li>
</ul>
<p>有三条求值关系，IfTrue，IfFalse和E-If。其中只有E-If有前提条件，且注意到求值关系<code>-&gt;</code>的定义的递归性：使用E-If规则时要求有前提<code>t1 -&gt; t2</code>，而这里的箭头正是我们正在定义的求值关系，更精确地说是一步求值关系。</p>
<p><strong>求值顺序</strong>：求值关系里可以蕴含求值顺序，比如书中仅允许if
then
else表达式对条件部分进行修改，并不允许先对then/else部分进行求值。</p>
<p><strong>求值关系</strong>：一个项的pair可以说是一个关系，表示一个项可以推导为另外一个项。当我写下一个求值推导：t1
-&gt; t2时，这里就蕴含了一个求值关系(t1,t2)。我们说，项的pair
(t1,t2)在求值关系中。</p>
<p><strong>规则被某个关系满足</strong>：规则有很多可能的实例（即将规则中的变量替换成具体的项）。如果一个关系<strong>符合/满足</strong>一条规则，对任何一个实例，则满足下面两个条件中至少一个：①
不符合前提：实例的前提不在关系中。②满足结论：实例的结论在关系中。</p>
<p>这里应该看反例，只有当两个条件都被违反的时候，我们才说一个关系不满足一条规则。实例的前提在关系中（违反第一条），实例的结论不在关系中（违反第二条）。就说明这个实例不符合这个规则。</p>
<p><strong>一步求值关系<code>-&gt;</code></strong>：一个<em>最小</em>的项上的二元关系，满足上面列出来的三个求值规则。当一个项<span
class="math inline">\((t1,t2)\)</span>的pair在求值关系里，我们称，求值推断
t1 -&gt; t2 是可推导的。</p>
<p><strong>求值树</strong>：可以把推导过程，按照横线上方是前提，下方是结论的方式写成一个倒着的树。由于只有E-If规则有前提，所以它是内部节点，另外两个规则是叶子节点。现在是细长的线，等后面有多前提的规则时它会更像树。</p>
<p><strong>一步求值的确定性</strong>：如果t1 -&gt; t2，且t1 -&gt;
t3，那么t2 ==
t3。表达的意思是：因为一步求值是确定的，则只会求出一个唯一的项。</p>
<p><strong>对推理结构的归纳</strong>：这里用证明 一步求值的确定性
来解释这个证明方法。因为我们这里是关于推导关系的定理，我们看t1 -&gt;
t2的推导的根部。根部用的式子如果是IfTrue，那么t1必然是一个if-else的形式，而且前提条件为true。因为前提条件已经是true了，那么t1
-&gt;
t3的推导的根部不可能是If-False。因为前提条件true不能再进一步求值，那么t1
-&gt; t3的推导的根部不可能是E-If。因为只剩下一个求值规则，那么t1 -&gt;
t3的推导的根部肯定也是相同的IfTrue，此时直接得到t2 == t3。</p>
<p><strong>范式</strong>：如果一个项，不能再被求值规则继续求值，则这个项是范式。每个值（定义操作语义时，作为最终结果的项的集合）都是范式</p>
<p>书中中间还有一些别的内容：</p>
<ul>
<li>习题中可以给语言扩充一个error项，这样总是可以继续求值，只不过最终可能求值到这个错误项，判断为错误。</li>
<li>本章介绍的表达式演算的具体实现。</li>
</ul>
<h4 id="第五章-无类型lambda演算">第五章 无类型lambda演算</h4>
<blockquote>
<p>除了这种lambda演算之外，pi演算已经成为定义基于消息并发语言的语义核心语言。</p>
</blockquote>
<p><strong>函数（过程）抽象</strong>：借助参数命名表示某种一般的执行演算。在需要的时候实例化，提供参数的值。而lambda演算则用最可能纯的方式表示这种函数定义和应用。</p>
<p><strong>lambda演算-项</strong>：①变量：x，②抽象：λx.t，③应用：t t</p>
<p><strong>抽象语法和具体语法</strong>：注意表明写的语法和实际的语法树之间的差异。我们这里是以语法树为准。语法规则上，应用有左结合，函数抽象体尽可能向右拓展。</p>
<p><strong>变量和元变量</strong>：真正在语言中，作为项的是变量。有时候为了抽象表示，用t表示所有语言中的项，此时是元变量。有时为了节约空间，定义简写<code>s=λy.xy</code>，这种也是元变量。</p>
<p><strong>辖域，囿界</strong>：在<code>λx.t</code>中，λx是一个绑定器，辖域是t。t中出现的x是囿界的，被这个抽象所界定。而单独出现的则是自由变量。比如x在<code>λy.xy</code>中是自由的。</p>
<p><strong>封闭项，组合子</strong>：一个不含自由变量的项是封闭项，也成为组合子。</p>
<p><strong>操作语义</strong>：纯lambda演算的语义依赖于，将函数应用与参数的操作。表示为：<code>(λx.t1) t2 -&gt; [x -&gt; t2] t1</code>。这种方括号的形式表示代换。虽然只有一个操作，但也有不同的求值策略。</p>
<ul>
<li>全beta规约（full beta-reduction）：任何时刻可以规约任何约式</li>
<li>规范（normal
order）策略：最左边，最外面的约式第一个被规约。但是如果最外面的不能再规约，还是可以进一步规约抽象内部的。这个策略和下面的策略都能保证每个项单步归约是确定的。</li>
<li>按名（call by name）策略：不允许在抽象内部进行规约。</li>
<li>按值调用策略：只有最外面的能被规约，并且函数参数必须规约完毕为一个值。</li>
</ul>
<p><strong>lambda演算中的程序设计</strong>：labmda演算很强大，可以表示布尔类型，数值类型，以及相应的运算。注意我们描述的是编程语言的语义，这里不关心执行速度问题，关心的是编程语言的表达能力。谁能想到简单的纯lambda演算居然能做到这么多事情。后续拓展了原生的bool和数值类型后，也可以很方便地进行转换。但是，这个转换内遇到求值策略的时候有一些问题。但是，这种使用纯lambda的Church数值的系统，可以定义出和使用正常数值的运算系统的等价关系，即两边运算的结果是一样的，没有很明显的差别。</p>
<ul>
<li>多参数：柯里化，即使用高阶函数，允许部分应用得到部分函数partial
function。</li>
<li>Church
bool式：定义<code>tru = λt. λf. t</code>（两个参数选择前者）和<code>fls = λt. λf. f</code>（两个参数选择后者）。另外可以定义似乎没什么用处的test函数，以及逻辑运算函数，将逻辑运算转换为这种选择关系。</li>
<li>序对：<code>pair = λf.λs.λb. b f s</code> 参数依次是first second
select。首先应用first和second，可以得到一个pair：<code>λb. b f s</code>，正好形成一个便于获取第一个还是第二个值的形式。这时候参数给一个tru或者fls就可以取第一个或者第二个了。但是，我们想要的是<code>fst (pair v w)</code>这种pair作为被应用的东西的形式。所以我们定义为<code>fst = λp. p tru</code>，转换一下。</li>
<li>Church 数值
（丘奇数）：<code>C0 = λs. λz. z</code>参数分别是successor，zero，然后返回一个被应用了n次的zero项，表示做某件事情n次。设计一个scc函数、plus函数、求幂函数变得有些有挑战性。
<ul>
<li>Church数的减法比加法更困难：定义前驱函数就很困难。需要定义一个（n-1,n）的pair序列，用ss函数不断将序列推进。然后用数字自身的含义，即做某事情n次，应用在ss和(0,0)上，然后取n-1部分。</li>
</ul></li>
</ul>
<p>使用纯lambda演算的时候，如果有求值策略的限制，比如按值调用策略，那么就会导致有些操作无法化简，即使它可能和化简后的函数确实完全一样。完全一样的意思是，如果把没给完的参数都应用进去，无论参数是什么，两个函数得到的结果最终会一样。直观上会得到一团很复杂的函数，虽然代表一个很简单的东西，但是想要化简过去却很麻烦。</p>
<p><strong>递归</strong>：发散组合式omega<code>(λx. x x) (λx. x x)</code>没有范式，能一直规约下去，因此称为发散的。想要编写递归，需要用到不动点组合式fix。递归编写的问题在于函数体，当你定义<code>f = xxx</code>的时候，xxx里面是不能用到f的，因为f还没被定义。首先，我们定义<code>g = λf. xxx</code>此时xxx里可以使用f，按照正常的递归函数的方式去定义。然后我们定义真正的f
<code>factorial = fix g</code>即可。这种方法能工作的核心是，<code>factorial n -&gt;* (g factorial) n -&gt; ([f -&gt; factorial] xxx) n</code>，这里就开始符合递归函数定义了，而且如果xxx里面化简时没有化简出带factorial的部分，则递归可以停止</p>
<p><strong>形式化定义</strong>：形式化定义一个语言，复习之前的内容，包括定义语法上有哪些项，有哪些推导规则。</p>
<ul>
<li>语法：定义V为变量名的集合。我们用递归定义项的集合。①单独变量名属于项。②如果t1属于项，x属于变量名集合中的合法变量名，则<code>λx.t1</code>也属于项
③如果两个项的应用，也属于项。</li>
<li>自由变量集合：定义一个方便的函数FV(t)，表示t中的自由变量集合。比如单独的变量，没有被约束的变量。</li>
<li>推导规则-代换：直观的想法是把代换像乘法分配律一样深入到每个部分，然后如果最后只需要代换单个变量，是的话就代换。但是在变量命名上有一些问题。比如我们要代换x
-&gt; z：
<ul>
<li>①如果发现要代换的值 x 突然有个界定
<code>λx. t</code>，此时就不应该继续进入代换了。</li>
<li>②和上一个相反的错误：如果发现被代换进去的东西
z，本来是一个自由变量的，但是出现了一个<code>λz. t</code>，再代换里面的t，此时代换出来的z变成被lambda约束的变量了，这也不对。</li>
</ul>
最后我们得到了避免捕捉的代换，遇到问题需要对变量z重新命名。我们称这种重新命名为alpha转化。</li>
<li>具体的操作语义：在定义求值关系上，细节决定了具体的求值顺序。根据写出来的规则不同，隐含着采用的是完全beta规约，规范序还是懒惰求值。</li>
</ul>
<h3 id="第九章-简单类型的lambda演算">第九章 简单类型的lambda演算</h3>
<p>注意到单独写一个项，如果不知道参数的类型，则有时也不知道函数体的类型。考虑参数类型被显式标注的语言，比如C语言。隐式标注的语言需要额外的类型推导算法，但并没有什么额外的不同。</p>
<p><strong>类型上下文</strong>：我们用 <span
class="math inline">\(\Gamma\)</span>
表示类型上下文，即一系列类型的假设。然后用 <span
class="math inline">\(\vdash\)</span> 符号表示类型上下文的应用。 <span
class="math inline">\(\Gamma \vdash t: T\)</span> 的意思是，在类型上下文
<span class="math inline">\(\Gamma\)</span>
中，项t的类型为T。假如有个函数λx.t2，当参数的类型是T1的时候，我们可以推导函数体的类型，把函数体中遇到的参数x假定为T1类型：</p>
<p><span class="math display">\[
\frac{\mathrm{x}: \mathrm{T}_1 \vdash \mathrm{t}_2: \mathrm{T}_2}{\vdash
\lambda \mathrm{x}: \mathrm{T}_1 \cdot \mathrm{t}_2: \mathrm{T}_1
\rightarrow \mathrm{T}_2}
\]</span></p>
<p>同时我们定义dom函数， <span
class="math inline">\(dom(\Gamma)\)</span> 表示被 <span
class="math inline">\(\Gamma\)</span> 界定的变量集合。</p>
<h4 id="第十五章-子类型">第十五章 子类型</h4>
<p>子类型和其他孤立的语言特性很不一样，它对很多其他特性都有着影响。我们这里首先主要关注的是函数和结构体。</p>
<p>S是T的子类型记作<code>S &lt;: T</code>。</p>
<p>约定子类型有自反性和传递性，即前序，preorder。往往子类型关系也会满足antisymmetry，即如果<code>S &lt;: T</code>
且 <code>S &lt;: T</code> 则
<code>S == T</code>，此时满足偏序关系，partial
order。由于结构体有标签置换规则，即标签顺序不同的认作不同类型，但是是其他相同标签的子类型，所以我们这里讨论的不满足偏序。</p>
<p><strong>安全代换原则</strong>：任何能用父类型的地方，也可以用子类型代换。子类型比父类型包含的信息量更多。</p>
<p><strong>width
subtyping</strong>：字段越多，越属于子类型。忘记字段时，相当于转为父类型。可以将一个结构体类型类型<code>&#123;x:Nat&#125;</code>理解为至少包含Nat类型的字段x的结构体类型集合。</p>
<p><strong>Depth
subtyping</strong>：允许结构体单个字段用子类型替换。</p>
<p><strong>函数类型的子类型</strong>：子类型对参数的要求更低，即参数是原类型的父类型（逆变，contravariant），结果的要求更高，返回值是原来的子类型（协变，covariant）。</p>
<h3 id="第十六章-子类型">第十六章 子类型</h3>
<h4 id="算法子类型化">算法子类型化</h4>
<p><strong>S-RCD将width/depth/perm结合的子类型定理</strong>：如下图所示。如果把字段看作集合，且把子类型关系看作相等，则结构体的子类型关系可以表示为集合的子集关系。</p>
<p><span class="math display">\[
\frac{\left\{1_i{ }^{i \in 1 . . n}\right\}
\subseteq\left\{\mathrm{k}_j{ }^{j \in 1 . . m}\right\} \quad
\mathrm{k}_j=1_i \text { implies } \mathrm{S}_j&lt;:
\mathrm{T}_i}{\left\{\mathrm{k}_j: \mathrm{S}_j{ }^{j \in 1 . .
m}\right\}&lt;:\left\{1_i: \mathrm{T}_i{ }^{i \in 1 . . n}\right\}}
\]</span></p>
<p>根据这个可以得到判断两个类型是不是有子类型关系的算法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">subtype(S, T) = </span><br><span class="line">if T = Top, then true</span><br><span class="line">    else if S = S1→S2 and T = T1→T2</span><br><span class="line">        then subtype(T1, S1) ∧ subtype(S2, T2)</span><br><span class="line">    else if S = &#123;kj:Sj j∈1..m&#125; and T = &#123;li:Ti i∈1..n&#125;</span><br><span class="line">        then &#123;li i∈1..n&#125; ⊆ &#123;kj j∈1..m&#125;</span><br><span class="line">            ∧ for all i there is some j ∈ 1..m with kj = li</span><br><span class="line">                and subtype(Sj , Ti)</span><br><span class="line">    else false.</span><br></pre></td></tr></table></figure>
<p>子类型关系在实际应用中，会遇到不知在何处将类型变为子类型的情况。通过对推导树的观察可以发现，有一种改写方法可以把子类型化不断推迟到推导树末尾。这个过程中只有一种推导无法推迟，那就是函数的应用语句。我们更新应用规则，在应用时同步应用子类型关系。最终得到了推导包含子类型化语言的项的类型的算法。</p>
<h2
id="advanced-topics-in-types-and-programming-languagesattapl">《Advanced
Topics in Types and Programming Languages》(ATTAPL)</h2>
<h3 id="第十章-基于约束的ml类型推导">第十章 基于约束的ML类型推导</h3>
<p>这里有<a href="http://cristal.inria.fr/attapl/">拓展版</a></p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven使用本地JAR文件</title>
    <url>/2023/Maven%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0JAR%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<p>Maven，如果想要修改底层依赖的库，先clone下来修改构建，然后使用本地JAR文件。StackOverflow的高票回答里有一些坑。记录一下。</p>
<span id="more"></span>
<h3 id="背景">背景</h3>
<p>Soot加载新的APK总是报错，而且报错了就停了。能不能让它忽略当前报错，直接放弃当前method
body呢？基于这个想法我开始修改soot源码，最后的方案在<a
href="https://github.com/am009/soot/commit/d3934e6c39a6e2993b02c7f2793d59d26c49afe3">这个commit</a>。</p>
<h2 id="遇到的问题">遇到的问题</h2>
<h3 id="编译时跳过测试">编译时跳过测试</h3>
<p>修改了Soot代码，直接编译会说一些测试异常。使用<code>mvn -Dmaven.test.skip=true package</code>在打包时跳过异常。</p>
<h3 id="maven引用本地jar文件">maven引用本地jar文件</h3>
<ul>
<li><strong>基于scope=system的方式</strong></li>
</ul>
<p>网上搜索首先会看到<a
href="https://stackoverflow.com/a/22300875">这个回答</a>，它推荐使用system类型的依赖：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.sample<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>sample<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>system<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;project.basedir&#125;/src/main/resources/Name_Your_JAR.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>然而，再看看就发现很多地方说这种方式不好，比如已经depricated了。直接劝退我的，是我用的shaded插件（和依赖一起打包为一个jar），不会把这种依赖加进来，直接报错找不到<code>Soot.G</code>这个类。</p>
<ul>
<li><strong>基于<code>mvn install:install-file</code>的方式</strong></li>
</ul>
<p>于是采用回答里的<a
href="https://stackoverflow.com/a/4955695">第二种方法</a>，安装到本地maven缓存。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mvn install:install-file \</span><br><span class="line">   -Dfile=$SCRIPTPATH/sootclasses-trunk.jar \</span><br><span class="line">   -DgroupId=org.soot-oss \</span><br><span class="line">   -DartifactId=soot \</span><br><span class="line">   -Dversion=4.5.0-SNAPSHOT1 \</span><br><span class="line">   -Dpackaging=jar \</span><br><span class="line">   -DgeneratePom=true</span><br></pre></td></tr></table></figure>
<p>问题在于，这种方式引入的依赖似乎不会引入递归的依赖。比如我发现缺了很多soot的依赖。</p>
<ul>
<li><strong>基于maven-install-plugin的方式</strong></li>
</ul>
<p>根据<a
href="https://maven.apache.org/guides/mini/guide-3rd-party-jars-local.html">官方文档</a>，如果那边jar是maven构建的，则可以使用下面这种方式直接安装到本地缓存，因为读取了jar里的<code>pom.xml</code>文件。既然都有了pom了，依赖信息也在了。但是坑点是版本要改成3.0.1以上，因为其实这个是个已知的问题，很晚才修复。<a
href="https://stackoverflow.com/questions/27554781/maven-install-file-isnt-resolving-dependencies#comment129402640_27554971">这个comment</a>救了我。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 删除本地的缓存</span><br><span class="line"># mvn dependency:purge-local-repository -DmanualInclude=&quot;org.soot-oss:soot&quot;</span><br><span class="line">mvn org.apache.maven.plugins:maven-install-plugin:3.0.1:install-file -Dfile=$SCRIPTPATH/sootclasses-trunk.jar</span><br></pre></td></tr></table></figure>
<p>最后发现怎么还是在跑的旧代码，可能是shaded插件的问题。还是得删掉targets文件夹。</p>
<h3 id="检查依赖问题">检查依赖问题</h3>
<p>使用<code>mvn dependency:tree</code>可以打印树状的依赖图</p>
<h3 id="vscode-java插件关联本地代码">VSCode Java插件关联本地代码</h3>
<p>根据这个<a
href="https://github.com/redhat-developer/vscode-java/issues/2391">issue</a>里说的，看来只能在那边创建<code>-src</code>后缀的jar文件，可能要同时放到本地maven仓库？</p>
<h3 id="总体构建脚本">总体构建脚本</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 获取脚本当前路径</span></span><br><span class="line">SCRIPTPATH=<span class="string">&quot;<span class="subst">$( cd -- <span class="string">&quot;<span class="subst">$(dirname <span class="string">&quot;<span class="variable">$0</span>&quot;</span>)</span>&quot;</span> &gt;/dev/null 2&gt;&amp;1 ; pwd -P )</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 防止还是用的旧的库</span></span><br><span class="line"><span class="built_in">rm</span> -rf <span class="variable">$SCRIPTPATH</span>/target</span><br><span class="line"></span><br><span class="line"><span class="built_in">pushd</span> ~/soot</span><br><span class="line"><span class="comment"># 生成patch留存</span></span><br><span class="line">git diff --cached &gt; <span class="variable">$SCRIPTPATH</span>/mypatch.patch </span><br><span class="line"><span class="comment"># 构建依赖的库的jar包</span></span><br><span class="line">mvn -Dmaven.test.skip=<span class="literal">true</span> package</span><br><span class="line"><span class="built_in">cp</span> target/sootclasses-trunk.jar <span class="variable">$SCRIPTPATH</span>/</span><br><span class="line">mvn org.apache.maven.plugins:maven-install-plugin:3.0.1:install-file -Dfile=<span class="variable">$SCRIPTPATH</span>/sootclasses-trunk.jar</span><br><span class="line"><span class="built_in">popd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建真正的项目</span></span><br><span class="line">mvn package</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Openwrt的GRETap6隧道的MTU问题</title>
    <url>/2023/Openwrt%E7%9A%84GRETap%E9%9A%A7%E9%81%93%E7%9A%84MTU%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>TLDR：如何使用GRE
Tap隧道不会遇到MTU问题？使用IPv4连接（gretap4），同时（在第一次创建接口时！！）关闭GRE接口配置中的“设置Don't
Fragment”选项。</p>
<span id="more"></span>
<h2 id="背景">背景</h2>
<p>两个发射wifi的路由器用GRETap通过IPv6在链路层组网，我在这边wifi通过SSH连接那边路由器有线连接的台式机，诡异地连不上去。经过调研发现应该是MTU的问题。</p>
<h3 id="ipv4和ipv6的mtu处理">IPv4和IPv6的MTU处理</h3>
<p>MTU是指最大传输单元。当数据包在互联网上通过路由经过各种各样的链路的时候，不同链路能传的最大包大小不同，包太大就需要被分片或者丢弃。分包都会造成性能开销，所以最合适的包大小当然是整个链路里面最小的那个包大小。</p>
<p>IPv4同时允许分片和Path MTU Discovery(PMTUD)。</p>
<ul>
<li>PMTUD就是指路由器直接把包丢了，向发送端发个icmp消息说包太大了，你重新按这个大小发包吧。</li>
<li>分片就是指中间的路由器可以通过设置Fragment标记进行分片，将一个包直接拆成两个包。</li>
</ul>
<p>IPv6在设计时直接完全禁止了分片的存在，没有分片标志位了。包如果太大只能被丢弃，然后使用PMTUD通知发送端。</p>
<h2 id="局域网直接访问的问题">局域网直接访问的问题</h2>
<p>GRE隧道技术，通过在IP层里封装链路层的包，实现了二层组网。经过封装的包会出现这样的层次结构。</p>
<p>以太网 --(封装)--&gt; IP --(封装)--&gt; GRE --(封装)--&gt; 内层以太网
--(封装)--&gt; 内层IP --(封装)--&gt; ...</p>
<p>同时GRE隧道不支持分片，因此原本能传的大包，经过隧道之后因为多封装了外侧的以太网+IP+GRE头，包会变大，导致超出MTU。</p>
<p>而且如果在隧道中间丢包，则PMTUD也无法正常工作。关键的问题在于，GRETap不在IP层。也就是说，现在在链路层L2组网。如果我要ssh连接隧道另一头的机子，连接时直接通过链路层，中间没有任何的路由。虽然实际上我们包被中间的路由器用GRE隧道封装了，但是路由器即使知道你笔记本这个包太大了传不了，想和你笔记本说一下，说你包太大了，如果通过ICMP的packet
too
big消息说的话，这属于L3层了。在笔记本看来，我是直接和那边机子沟通啊，你怎么突然过来插一脚，根本不会理会。</p>
<p>推荐阅读：<a href="https://www.rfc-editor.org/rfc/rfc7588.html">RFC
7588
GRE隧道的分片方案</a>。这篇RFC介绍了各大企业在使用GRE隧道时遇到分片问题时，由于默认的协议不支持分片，从而设计自己的方案，并对协议做出拓展的事情。</p>
<h2 id="ipv4时的gretap解决方案">IPv4时的GRETap解决方案</h2>
<p>Linux内核的GRE隧道，最近支持了<code>ignore-df nopmtudisc</code>选项。（如果是IPv4封装的GRE）在最外层的IP包处强制允许分片。这样即使单个包太长，中间的路由器也可以直接分片传输。</p>
<p>然而，因为IPv6完全不支持包分片，IPv6的GRE隧道就不能这么做了。</p>
<h2 id="跨交换机gretap6组网">跨交换机GRETap6组网</h2>
<p>上面说的都是使用GRE通过互联网创建隧道。但是实际上我们想做的是通过IPv6，跨学校交换机在两个房间组网。如果经过交换机的这个链路支持很大的MTU，那我们隧道就应该没问题。经过测试，交换机能传输大的以太网包。但是我们发现，怎么改接口的MTU都不管用。</p>
<p>不断抓包，使用nping命令直接发送以太网包发现，IPv6和IPv4的MTU居然不一样。先把网卡MTU配置为2000。首先使用<code>nping -c 1 --icmp --dest-mac 00:0C:29:72:2D:59 1.1.1.1 --data-length 1954</code>
可以发出总大小为2000的以太网包。但是如果转而想发送IPv6，使用
<code>ping -s 11472 -Mdo 2001:250:4000:511d:114:514:1919:810</code>
提示<code>ping: local error: message too long, mtu: 1500</code>。</p>
<p>进一步搜索找出了问题的根源：IPv6的RA路由通告会通告当前网段的MTU大小。通过设置静态地址，忽略RA，可以使得MTU正确地变成网卡配置的MTU。</p>
<h2 id="mss-clamping">MSS Clamping</h2>
<p><a
href="https://blog.ipspace.net/2013/01/tcp-mss-clamping-what-is-it-and-why-do.html?m=1">这个视频</a>很好地介绍了MSS
Clamping的原理。</p>
<p>如果链路中MTU出现了问题，则每次都得发送一个PMTUD的消息，减小传输大小，然后才能正常通信。这在每次通信时都增加了一个round
trip的延迟开销</p>
<p>MSS是TCP的一个协商出来的参数，也是最大的传输大小。路由器防火墙(在Masquerade的同时？)，如果发现链路的MTU很小，可以在协商的时候把TCP的MSS直接弄小一点。这样就直接省去了这个round
trip步骤。</p>
<h3 id="其他">其他</h3>
<p><strong>诊断</strong>：</p>
<ul>
<li>这个<a
href="https://www.reddit.com/r/sysadmin/comments/737c1z/friendly_reminder_if_ssh_sometimes_hangs/">Reddit帖子</a>提到这种SSH连接停住的现象很可能是MTU问题。确实很可能是MTU的问题。通过直接把笔记本接到那边路由器，或者连那边的wifi，问题都不再出现。</li>
<li>这个人也有<a
href="https://forum.vyos.io/t/ip6gre-and-fragmentation/11710">IPv6
GRETap的MTU问题</a></li>
</ul>
<p><strong>Path MTU Discovery
(PMTUD)原理</strong>：虽然本地机子的MTU不会变，但是发包后路由器就会返回icmp消息说，你太长了，然后本地机子就会用mtu1300.</p>
<p><a
href="https://forum.openwrt.org/t/solved-gretap-tunnel-and-mtu-size-problem/14182/8">这个帖子</a>里和我遇到了相同的问题。想想GRE包在被包裹之后，传递给那边的时候，还是通过IP层传的。<a
href="https://forums.gentoo.org/viewtopic-t-1007394-start-0.html">这个帖子</a>也尝试详细描述这个问题。</p>
<p>在<a
href="https://bugzilla.kernel.org/show_bug.cgi?id=14837">内核</a>那边也有相关的讨论：
- 最底下提到了<code>ignore-df nopmtudisc</code>这两个选项。<a
href="https://stackoverflow.com/questions/42545112/linux-gretap-net-ipv4-ip-gre-c-how-to-set-value-of-key-tun-flags">这个回答里</a>也有相关的例子
-
中间看到一些，bridge按照标准会丢大于自己MTU的包，这个好像无关，bridge取的是最小的MTU。</p>
<h3 id="openwrt的支持">OpenWRT的支持</h3>
<p><strong>Package GRE</strong>：先看看GRE包的<a
href="https://github.com/openwrt/openwrt/blob/ae500e62e2938e112ae1fc6aa7389e8c7b784b13/package/network/config/gre/files/gre.sh">源码</a>吧，稍微看看就可以发现，这里调的是<code>proto_send_update</code>，是<code>netifd-proto.sh</code>里面的函数。引用到了另外一个仓库：<code>netifd</code>。而<code>netifd</code>并不是调的ip
link命令，而是直接C语言底层实现相关操作。</p>
<p>ip
link命令又是怎么实现这个功能的呢？ip这个命令行工具来自<code>iproute2</code>包，搜索相关源码可以找到<a
href="https://github.com/iproute2/iproute2/blob/0c3400cc8f576b9f9e4099b67ae53596111323cd/ip/link_gre.c#L398"><code>link_gre.c</code></a>这里。可以发现在<code>linux/if_tunnel.h</code>这个内核头文件里有个flag叫<code>IFLA_GRE_PMTUDISC</code>。这里操纵的是<code>struct nlmsghdr</code>结构体，</p>
<p>那边netifd也是一样，但是使用了<a
href="https://www.infradead.org/~tgr/libnl/doc/core.html">libnl</a>库。<a
href="https://docs.kernel.org/userspace-api/netlink/intro.html">内核文档</a>和<a
href="https://www.infradead.org/~tgr/libnl/doc/core.html#core_msg_format">libnl文档</a>都描述了netlink消息的细节。</p>
<p>然而，<a
href="https://github.com/openwrt/netifd/blob/f01345ec13b9b27ffd314d8689fb2d3f9c81a47d/system-linux.c#L4012">这里</a>可以看到，仅对IPv4的隧道支持了<code>ignore-df</code>选项。在<a
href="https://man7.org/linux/man-pages/man8/ip-tunnel.8.html">ip命令的帮助</a>里可以发现，ignore-df选项仅忽略IPv4的Dont
Fragment包。</p>
<p><a
href="https://www.reddit.com/r/ipv6/comments/pmxg2m/ipv6_mtu_issue_with_hosts_behind_mikrotik_router/">这里</a>和<a
href="https://forum.vyos.io/t/ip6gre-and-fragmentation/11710">这里</a>提到了，在IPv6里根本没有分包，必须由中间节点发icmp6消息提醒发送端减少MTU。很可能这个问题是无解的，只能改自己本地MTU？</p>
<p>这个<a
href="https://www.rfc-editor.org/rfc/rfc7588.html">RFC文档</a>提到了一些实现，有些厂商为了解决这个问题而手动实现了分包。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title>X11转发-从docker到WSL</title>
    <url>/2023/X11%E8%BD%AC%E5%8F%91-%E4%BB%8Edocker%E5%88%B0wsl/</url>
    <content><![CDATA[<p>X11转发-从docker到WSL</p>
<span id="more"></span>
<p>随着WSL-g的普及，只需要在WSL2中去SSH连接远程服务器时带上-X或者-Y，就能够把服务器上的图形界面程序转到Windows本机，这在过去需要本机是Linux电脑。</p>
<p>如果远程服务器上装了docker，想在docker里再跑图形界面程序则更加复杂。需要从docker转到服务器，然后再通过SSH转到本地WSL。为了更好地使用这些高级的操作，有必要学习相关的原理。</p>
<h3 id="ssh-x11-转发">SSH X11 转发</h3>
<p>XSOCK环境变量负责告诉图形界面程序，怎么去连接X11服务器，从而显示图像。在通常的ubuntu
desktop系统中，往往图形服务器使用的是<code>/tmp/.X11-unix</code>。参考<a
href="https://unix.stackexchange.com/questions/196677/what-is-tmp-x11-unix">这里</a>。</p>
<p>SSH连接服务器如果带上了-X，则会设置DISPLAY和XAUTHORITY，DISPLAY通常指定为<code>hostname:10.0</code>。此时用的就是普通的tcp的端口，即<code>6000+10=6010</code>。</p>
<p>此外，一般这个端口只允许localhost的连接，由sshd_config里的<code>X11UseLocalhost no</code>控制。</p>
<h3 id="xauth-和-.xauthority">XAUTH 和 <code>.Xauthority</code></h3>
<p>TODO。不过根据<a
href="https://dzone.com/articles/docker-x11-client-via-ssh">这里</a>，把<code>.Xauthority</code>文件挂载进去就好了:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--volume=&quot;$HOME/.Xauthority:/root/.Xauthority:rw&quot;</span><br></pre></td></tr></table></figure>
<h3 id="docker-x11-ssh-x11要挂载tmp.x11-unix吗">docker X11 + SSH
X11：要挂载<code>/tmp/.X11-unix</code>吗？</h3>
<p>场景是，笔记本使用windows，连接服务器，服务器上在docker里运行图形界面程序，直接转发到笔记本显示。</p>
<p>在<a
href="https://github.com/GrammaTech/retypd-ghidra-plugin">这里</a>介绍的转发方法使用了下面的挂载：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xhost +si:localuser:root</span><br><span class="line">docker run -it --privileged \</span><br><span class="line">    --network=host \</span><br><span class="line">    -e DISPLAY \</span><br><span class="line">    -v /tmp/.X11-unix:/tmp/.X11-unix:ro \</span><br><span class="line">    retypd-image \</span><br><span class="line">    bash</span><br></pre></td></tr></table></figure>
<ul>
<li>挂载了<code>/tmp/.X11-unix</code>目录，这意味着假设x11转发走的是这里面的unix
socks（一般本机需要是linux系统才会用这个）</li>
<li><code>--network=host</code>使用本机网络，<code>-e DISPLAY</code>把当前的DISPLAY变量传进去。</li>
</ul>
<p>但是我们是ssh的x11转发，所以和<code>/tmp/.X11-unix</code>没关系，可以放心地去掉这个挂载，最后我们得到下面几个flag：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--network=host \</span><br><span class="line">-e DISPLAY \</span><br><span class="line">--volume=&quot;$HOME/.Xauthority:/root/.Xauthority:rw&quot; \</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title>Openwrt构建</title>
    <url>/2023/Openwrt%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<p>Openwrt构建</p>
<span id="more"></span>
<h3 id="编译环境搭建">编译环境搭建</h3>
<p>一些<a
href="https://hackmd.io/@gtknw/building_guide">常用命令</a></p>
<ul>
<li>跟着<a
href="https://openwrt.org/docs/guide-developer/toolchain/install-buildsystem">install-buildsystem</a>安装一堆包</li>
<li>跟着<a
href="https://openwrt.org/docs/guide-developer/toolchain/use-buildsystem">use-buildsystem</a>克隆源码</li>
<li>跟着<a
href="https://openwrt.org/docs/guide-developer/toolchain/use-buildsystem#using_official_build_config">using_official_build_config</a>构建一个路由器能用的镜像。下载config.buildinfo文件到.config。
<ul>
<li>我手头的路由器是AX6S，ROM的下载链接是：<code>http://downloads.openwrt.org/releases/23.05.0/targets/mediatek/mt7622/openwrt-23.05.0-mediatek-mt7622-xiaomi_redmi-router-ax6s-squashfs-factory.bin</code>，所以我就执行：<code>wget https://mirror-01.infra.openwrt.org/releases/23.05.0/targets/mediatek/mt7622/config.buildinfo -O .config</code>
和
<code>wget https://mirror-01.infra.openwrt.org/releases/23.05.0/targets/mediatek/mt7622/feeds.buildinfo -O feeds.conf</code></li>
</ul></li>
<li>构建GRE、netifd包：<code>make package/network/config/netifd/compile V=s</code>
（加上了<code>V=s</code>可以看到使用的相关命令）</li>
</ul>
<p><strong>重新构建一切</strong></p>
<p><code>make dirclean defconfig download clean world</code></p>
<h3 id="包编译的细节">包编译的细节</h3>
<ul>
<li>首先源码的压缩包，会被下载：<code>openwrt/dl/netifd-2023-09-19-7a58b995.tar.xz</code></li>
<li>然后被解压：<code>openwrt/build_dir/target-aarch64_cortex-a53_musl/netifd-2023-09-19-7a58b995</code></li>
<li>在上面文件夹里进行编译</li>
<li>被安装：<code>openwrt/build_dir/target-aarch64_cortex-a53_musl/netifd-2023-09-19-7a58b995/ipkg-install/usr/sbin/netifd</code></li>
<li>打包</li>
</ul>
<h3 id="单个包的开发">单个包的开发</h3>
<ul>
<li><a
href="https://openwrt.org/docs/guide-developer/toolchain/use-buildsystem#creating_a_local_feed">在feed中增加<code>src-link</code></a>，关联本地源码。</li>
</ul>
<h3 id="给核心仓库提交代码">给核心仓库提交代码</h3>
<ul>
<li><a href="https://openwrt.org/submitting-patches">Submitting
patches</a>页面，提到了核心包可以通过Github PR或者邮件列表提交。</li>
<li><a
href="https://lists.openwrt.org/pipermail/openwrt-devel/2024-January/041977.html">这个Patch</a>先出现在邮件列表，然后<a
href="https://git.openwrt.org/?p=project/netifd.git;a=commit;h=4219e99eeec7514657f5838eb4b4b5eb28ee1271">commit</a>才出现在netifd的列表里，说明他们还是在用mailing
list的，可以考虑直接写patch交patch。</li>
</ul>
<h3 id="给包增加patch">给包增加Patch</h3>
<p>https://openwrt.org/docs/guide-developer/toolchain/use-patches-with-buildsystem</p>
<p>quilt import
https://github.com/am009/mosdns/commit/4f90490dc7c56c94880f09b5bf2542ac65d97530.patch</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title>SMTSolver与程序合成</title>
    <url>/2023/SMTSolver%E4%B8%8E%E7%A8%8B%E5%BA%8F%E5%90%88%E6%88%90/</url>
    <content><![CDATA[<p>SMTSolver与程序合成。如何合成命令式语言？</p>
<span id="more"></span>
<h2 id="smt-solver">SMT Solver</h2>
<h3 id="相关资料">相关资料</h3>
<p>搜索Many-sorted logic SMT 找到一些直接相关的课。</p>
<ol type="1">
<li>《面向计算机科学的数理逻辑系统建模与推理》.pdf
这本书可以快速入门必要的逻辑学知识，而且本来就是讲SAT solver的。</li>
<li>https://users.aalto.fi/~tjunttil/2020-DP-AUT/notes-smt/part1.html</li>
<li>Z3支持的逻辑：http://theory.stanford.edu/~nikolaj/z3navigate.html
http://smtlib.cs.uiowa.edu/logics.shtml</li>
</ol>
<p>熊英飞 《软件分析》课里也提到了相关的知识，从<a
href="https://liveclass.org.cn/cloudCourse/#/courseDetail/8mI06L2eRqk8GcsW">第12节课</a>开始:</p>
<ul>
<li>第12课：SMT，基于SAT开始，把一系列理论结合起来。类似算数，数组，位向量就是一个理论。</li>
<li>第13课末尾：简单介绍了SMT-lib</li>
</ul>
<h3 id="sat和合取范式">SAT和合取范式</h3>
<ul>
<li><p>1.4.1
前面介绍了基本的逻辑推理是什么，命题之间可以有哪些组合关系（合取，析取，蕴含，取反），有哪些公理去推导。这一节介绍了真值表，基于命题的语法树可以遍历根据子命题的真值得到整个命题的真值</p></li>
<li><p>1.4.3 证明真值表求值和自然演绎的推理规则，语义上是一致的</p></li>
<li><p>1.5.1 <span class="math display">\[\phi \rightarrow \psi \equiv
\neg \phi \vee \psi\]</span>
利用这个规则，可以将所有的命题转换为不带假设和推导的。进一步，都可以转换为CNF
合取范式。合取范式中都是先and，再or，再not，再其他命题。</p>
<p>其次，对于合取范式，能够很有效地直接判断它是否恒为真（有效）。需要判断每一个and的规则为真，然后看这些由or组合的命题，是否存在q
or (not
q)的这种形式。（注：所有变量都是可以随意取值的，不然就可以直接代入化简了）。</p>
<p>为什么要判断有效性？因为本质上和可满足是紧密相关的。如果想证明命题Q是可满足的，即存在某种取值使得Q为真，只需要证明Q不会一定为假，即not
Q不是恒为真（有效）。</p>
<p>如何转换为CNF等价公式？如果能列出完整的真值表就可以转换，但也因为要真值表，所以很难。我们对于真值表里每个为false的项，构造False
or False or
False...这种形式，长度等价于自由命题变量的个数。然后把每个False替换为q或者not
q，根据q是否为真。最后把所有这种项目and起来即可。</p>
<p>即使都是CNF，它们之间也有相互等价的命题。比如p和 p and (p or
q)就是等价的，且都是CNF。可以编写一个算法，利用结构递归，基于推导消除，and和or交换顺序的分配律，not下降到子句的分配律，可以把任何命题转换为CNF。但是这个CNF并不是最简的，很可能很长。</p></li>
</ul>
<p><strong>零阶逻辑和一阶逻辑的区别是什么？</strong>
一阶逻辑引入了全程量词，for all 和 exist 这种复杂的东西。</p>
<p><strong>什么是合取范式？</strong>
合取范式中都是先and，再or，再not，再其他命题。</p>
<h3 id="smt-solver-1">SMT Solver</h3>
<p><strong>算术运算转换为SAT</strong>：逻辑门可以转化为SAT约束。bitVector的运算可以基于加法和乘法电路，转换为SAT问题。但是有性能开销，16bit的乘法就有几万个变量。</p>
<p><strong>SAT的应用</strong>：电路设计时，可以应用SAT证明电路的等价性。把两个电路异或起来，证明输出总是0。密码分析的时候，可以用于破译密码。</p>
<h2 id="syntax-guided-synthesis">Syntax-Guided Synthesis</h2>
<h3 id="相关的paper和项目">相关的paper和项目</h3>
<p><strong><a href="https://sygus-org.github.io/">SyGuS: Syntax-Guided
Synthesis</a></strong>
它总结出了现有的大量的程序合成的共性，提出了通用的问题框架，涵盖了之前研究的很多子问题。</p>
<p><strong>相关Solver</strong>：可以在<a
href="https://sygus-org.github.io/comp/2019/">这个benchmark页面</a>看到参与了比赛的solver：
- <a
href="https://github.com/cvc5/cvc5">CVC4</a>：可以通过<code>cvc4 --lang=sygus</code>调用</p>
<p><strong><a href="https://www.semgus.org/">SemGuS: Semantics-Guided
Synthesis</a></strong> 它基于SyGuS，通过转化为Constrained Horn
Clause，支持任意的语义表达，包括命令式语言的循环和赋值等语句。它也是一个程序合成框架，而不是具体的solver。它提供了对程序合成任务描述的统一格式（它们把自己类比为LLVM
IR，作为各种工具的兼容层），鼓励各种相关工具支持它这种格式，同时提供一些benchmark用来测试合成工具性能。</p>
<p>在描述合成任务的树语法文件中，它需要描述想要生成程序的语法，语义。</p>
<p><strong>相关Solver</strong></p>
<ul>
<li><a
href="https://github.com/SemGuS-git/Semgus-Messy">Semgus-Messy</a></li>
<li><a href="https://github.com/kjcjohnson/ks2-mono">The ks2 synthesizer
suite</a></li>
</ul>
<p><strong>相关资料</strong></p>
<ol type="1">
<li>Sygus相关课程
<ol type="1">
<li>SyGus的简介：https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm</li>
<li>https://people.eecs.berkeley.edu/~sseshia/219c/lectures/SyGuS.pdf</li>
<li>https://web.stanford.edu/class/cs357/lecture15.pdf</li>
<li>https://simons.berkeley.edu/sites/default/files/docs/17371/andrewreynoldstfcssynthesisslides.pdf</li>
<li>https://synthesis.to/presentations/introduction_to_program_synthesis.pdf
程序合成+二进制分析</li>
</ol></li>
</ol>
<p><strong>其他</strong></p>
<p><a
href="https://people.eecs.berkeley.edu/~sseshia/pubdir/synth-icse10.pdf">Oracle-Guided
Component-Based Program Synthesis</a>
第一个提出程序合成可以用于反混淆的工作。虽然其实并没有特别直接达到这个目标。</p>
<h3 id="摘抄">摘抄</h3>
<p>https://arxiv.org/pdf/2008.09836.pdf &gt; Program synthesis has been
studied from a variety of perspectives, which have led to great
practical advances in specific domains [Feser et al. 2015; Gulwani 2011;
Phothilimthana et al. 2019].</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
      </tags>
  </entry>
  <entry>
    <title>SSA-for-decompilation读后感</title>
    <url>/2023/SSA-for-decompilation%E8%AF%BB%E5%90%8E%E6%84%9F/</url>
    <content><![CDATA[<p>SSA-for-decompilation
读后感。反编译这一块不是很成体系。在这里整理一下。</p>
<span id="more"></span>
<h3 id="总体">总体</h3>
<ol type="1">
<li>静态分析和人分析还是不一样的。部分增加可读性的操作可以忽略。</li>
<li>分类法：按类型信息的来源-传递（运算）。</li>
<li>从另一头看，需要学习和观察静态分析的问题。静态分析如何处理引用。</li>
</ol>
<h3 id="结构体分析">结构体分析</h3>
<blockquote>
<p>结构体类型通常只能从基本指令的上下文中发现，例如在循环中执行的基本操作，或在指针的固定偏移处执行的一些基本操作。</p>
</blockquote>
<p>结构体类型，比如结构体和数组，确实，似乎只能从循环中识别出来。而且这相关的似乎完全没有被retypd提到。似乎retypd直接使用了ghidra的结构体划分。这一块的识别需要单独做。</p>
<blockquote>
<p>用索引编写的程序可能会被优化编译器转换为操作指针的等效代码</p>
</blockquote>
<p>是否可以用一个分析把这个过程逆向转回去。不过我们静态分析不知道更需要哪种？</p>
<ol type="1">
<li>用运行指针遍历数组</li>
<li>用运行指针，复杂终止条件遍历数组：无法预知数组大小</li>
<li>用运行指针，访问结构体数组。</li>
</ol>
<blockquote>
<p>类型分析是少数可以用数据流术语表达的问题之一，并且是真正双向的。 1.
定义的类型影响使用的类型 1. 使用的类型影响定义的类型： 1.
库函数调用（看作使用）影响之前的定义，已知返回值类型的赋值影响之前的定义。引用参数调用影响之前的定义。</p>
</blockquote>
<blockquote>
<p>仅考虑单个指令本身（至少在某些情况下）不足以分析聚合类型。要么必须在约束系统之外添加一些辅助规则，要么可以将表达式传播与高级类型模式结合使用。</p>
</blockquote>
<p>如何判断数组？可能可以通过，取数组下标的是变量，来表示。</p>
<h3 id="多种可能的解">多种可能的解</h3>
<p>反编译可行解过多怎么办？用更高层次的lattice值表示？</p>
<p>例如下面这个很难的例子</p>
<blockquote>
<p><span class="math inline">\(m[1000_1] := m[1000_2] +
1000_3\)</span></p>
<p>三种可能的结果是：</p>
<ul>
<li><span class="math inline">\(T (1000_1) = int*\)</span> and <span
class="math inline">\(T (1000_2) = int*\)</span> and <span
class="math inline">\(T (1000_3) = int\)</span></li>
<li><span class="math inline">\(T (1000_1) = α**\)</span> and <span
class="math inline">\(T (1000_2) = α**\)</span> and <span
class="math inline">\(T (1000_3) = int\)</span></li>
<li><span class="math inline">\(T (1000_1) = α**\)</span> and <span
class="math inline">\(T (1000_2) = int*\)</span> and <span
class="math inline">\(T (1000_3) = α*\)</span></li>
</ul>
</blockquote>
<p>对于这种不知道什么类型的指针，可以在lattice上用void*临时表示一下？</p>
<p>约束求解是否不可避免？即如何让加法，减法做出三种选择（数字+指针，指针+数字，数字+数字）中的一种？</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Decompile</tag>
      </tags>
  </entry>
  <entry>
    <title>SSA-for-decompilation-5</title>
    <url>/2023/SSA-for-decompilation-5/</url>
    <content><![CDATA[<p>《Static Single Assignment for Decompilation》 第五章 类型分析</p>
<p>划词翻译+人工校对</p>
<span id="more"></span>
<h1 id="类型分析">5 类型分析</h1>
<p>SSA 形式支持基于稀疏数据流的类型分析系统，非常适合反编译。</p>
<p>编译器执行类型分析以在软件开发过程的早期拒绝无效程序，避免以后进行更昂贵的纠正（例如在调试时或部署后）。某些源语言（例如
C 和
Java）需要所有变量的类型定义。对于这些语言，编译器在称为类型检查的过程中检查在编译时具有类型含义的语句的相互一致性。由于反编译源代码的编译器需要很多类型信息，而典型的机器代码程序中不存在显式类型信息，因此机器代码反编译器需要做大量工作来恢复变量的类型。这个过程称为反编译器的类型分析。</p>
<p>其他语言，如 Self、C/C++ 和 Smalltalk
需要很少的类型定义，变量可以在整个程序中包含不同的类型，并且大多数类型检查是在运行时执行的。这些语言是动态类型检查的。这些语言通常仍会执行静态（编译时）类型分析，以发现变量在运行时可以采用哪些类型进行优化。这个过程称为类型推断或类型重建，对于编译器来说比类型检查
[KDM03] 更难。由于类 C
语言更为常见，因此这里将不再考虑这种更复杂的情况</p>
<p>反编译器的类型分析问题是将每条数据与一个高级类型相关联。可以合理地期望该程序没有类型错误，即使某些语言（例如
C）允许从一种类型转换为几乎任何其他类型。各种不同的数据需要分析类型：已初始化和未初始化的全局数据、局部变量、堆分配变量和常量。</p>
<p>类型分析在概念上是在数据流分析之后和控制流分析之前进行的，如图5.1所示。</p>
<figure>
<img src="image-20230516151123785.png" alt="image-20230516151123785" />
<figcaption aria-hidden="true">image-20230516151123785</figcaption>
</figure>
<p>从编译器的角度来看，（编译器那边的）类型分析甚至比数据流分析在文献中的讨论要多得多。此处详细考虑了机器代码程序中类型的性质，以及反编译器输出中类型的要求。</p>
<p>机器代码程序中存在的类型信息可以看作是一组要解决的约束，或者是一组要处理的操作，类似于数据流分析。本章介绍了基于静态单一赋值形式（SSA
形式）的稀疏数据流类型分析。由于类型信息可以与每个定义（和常量）一起存储，因此每次使用一个位置时都可以随时访问当前类型。（因为只需要为每个定义存储类型而不是为每个程序点存储？）这种稀疏表示节省的内存是相当可观的。</p>
<p>每个生成三个约束的加法和减法指令在基于数据的类型分析系统中需要不同的方法。类似地，任意表达式的类型在这样的系统中值得特别注意，因为没有地方可以存储中间表达式结果的类型。</p>
<p>在任何用于机器代码反编译器的类型分析系统中，都有数量惊人的多种内存表达式，它们表示从简单变量到数组和结构成员的数据对象。</p>
<ul>
<li>5.1 节列出了构成本章基础的先前工作。</li>
<li>5.2
节从机器代码的角度介绍了类型的本质，以及它们为何如此重要。类型信息的来源在第
5.3 节中列出。常量需要类型和位置，如第 5.4 节所示。</li>
<li>5.5
节讨论了将类型分析作为约束满足问题来解决的局限性。加法和减法指令的特殊要求在第
5.6 节中讨论，并在第 5.7.4 节中重新讨论。</li>
<li>第 5.7 节提出了一种基于迭代数据流的解决方案，SSA 版本的优点在第
5.7.2 节中给出。</li>
<li>5.8
节列举了大量的内存位置模式。反编译器需要处理数据和代码，这个过程与类型分析密切相关，如第
5.9 节所述。</li>
<li>5.10 节提到了一些在类型分析中有用的特殊类型，5.11
节讨论了相关工作，5.12 节列出了未来需要做的工作。最后，第 5.13 节总结了
SSA 形式对类型分析的贡献。</li>
</ul>
<h2 id="现有工作">5.1 现有工作</h2>
<p>Mycroft 和 Reps
等人的工作。有一定的局限性，但为机器码反编译中的类型分析奠定了基础。</p>
<p>Mycroft 的论文 [Myc99] 是第一个认真考虑反编译类型分析的论文。他认识到
SSA
形式的有用性，可以用于“反-”寄存器着色优化，即分离同位变量。他指出了由数组索引引起的问题，其中编译器为数组元素访问生成了不止一条指令。第
5.5.1 节讨论了这个限制。</p>
<p>Mycroft
的工作还有许多其他限制，例如似乎没有考虑全局数组。然而，本章中的工作很大程度上受到了
Mycroft 论文的启发。</p>
<p>Reps 等人描述 x86 可执行文件的分析框架 [RBL06,
BR05]。他们的目标是生成一个 IR，该 IR 类似于可以从源代码生成的
IR，但具有对安全分析很重要的低级元素。他们最终使用旨在读取源代码的工具来进行浏览和安全查询。图
5.2 给出了一个概览。</p>
<p>声明的目标之一是类型信息，但除了简要提及从库函数传播信息外，论文没有详细说明这些信息的来源。他们的论文提到反编译是一种潜在的应用，但这不是他们主要感兴趣的领域之一。</p>
<p>使用了三种主要分析：Value-set
Analysis（VSA），一种值分析；仿射关系分析 (ARA) 和结构体识别 (ASI)。 VSA
发现一个位置在给定程序点可能采用的值的过高估计。 ARA
是作者修改的用于可执行程序的源代码分析。它找到位置之间的关系，例如索引变量和运行指针。
ASI 恢复聚合的结构，例如结构和数组，包括结构的数组。</p>
<p>作者报告的结果是合理的，特别是与大多数分析可执行程序中复杂数据结构的工具完全失败相比。然而，只有
55% 的虚函数被成功分析 [BR06]，并且 60%
的测试程序具有一个或多个无法分析的虚函数 [BR06、BR05]。 72%
的堆分配结构被正确分析（即计算出的结构与编译器的调试信息一致），但对于
20% 的程序，只有 12% 或更少是正确的
[BR05]。正如稍后将展示的，表示对数据项（尤其是聚合元素）的访问的内存表达式的形式非常复杂。特别是，不清楚他们的分析是否可以将原始指针与偏移指针分开（第
19 页第 1.5.3
节）。希望考虑到所有各种可能的内存表达形式的分析能够正确分析更大比例的数据访问，同时还能为每个数据项找到类型。</p>
<h2 id="机器代码的类型分析">机器代码的类型分析</h2>
<p>类型信息封装了很多区分低级机器代码和高级源代码的信息。</p>
<p>下一节将从机器代码的角度考虑类型的性质和用途。</p>
<h3 id="类型的作用角色">类型的作用（角色）</h3>
<p>类型是断言；它们划分程序语义域，并将数据划分为不同的对象。</p>
<p>当程序员在静态类型检查语言中将变量声明为整数类型或类 Customer
时，会断言变量可以取什么值，以及可以对它们执行什么操作。程序语义的部分域适用于整数类型的变量（例如左移
2 位），而其他域（例如调用方法 getName()）适用于类 Customer
的对象。当发现程序对变量应用了错误的语义时，可以表明该程序违反了语言的类型规则，因此可以在编译时发出错误消息。</p>
<p>类型包括有关数据对象大小的信息。类型将数据部分从字节块划分为具有已知属性的不同对象集。</p>
<p>在机器代码程序中，类型声明通常已被编译器删除。
（一个例外是调试信息，在软件开发过程中插入，在某些情况下可能仍然存在。）因此，在反编译程序时，变量在某个点左移两位的事实强烈表明它应该是类型为整数，而不是类
Customer。</p>
<p>类似地，当四个字节的数据用作整数时，这四个字节与数据部分中的其他数据对象不同。这四个字节不太可能是另一个数据对象的一部分，例如一个字符串，恰好在数据部分中位于它之前。这样，反编译器可以有效地重建从地址到原始编译器符号表中存在的类型的映射。</p>
<p>将类型视为断言的观点导致了为每个变量生成约束的想法，只要它在暗示其类型的上下文中使用。并非所有使用都暗示完整的类型信息。例如，一条
32
位复制（寄存器到寄存器移动）指令只约束类型的大小，而不约束它是整数、浮点数还是指针。以上假定指针的大小为
32
位。程序通常对指针使用一种大小，这可以通过检查二进制文件格式找到。本章中的示例将采用
32 位指针；显然可以容纳其他尺寸。</p>
<p>一些操作隐含基本类型，例如整数，但没有类型的详细信息，例如它的符号性（有符号与无符号）。左移运算符就是一个例子。右移算术等运算符暗示基本类型（整数）和符号性（在本例中为带符号）。某些类型信息的部分性质导致了类型层次或格的概念。类型
unsigned short 比短整数（符号未知）更精确，而它比 size16
更精确，而后者又比 <span
class="math inline">\(\top\)</span>（根本没有类型信息）更精确。</p>
<p>在面向对象的程序中，一组重要的类型是类类型。例如，希望知道某个指针是
Customer* 类型还是 Employee*
类型。这样的类型信息不是直接来自单个指令的语义，而是来自类层次结构分析</p>
<p>用高级语言表达的程序必须包含一些类型声明以满足该语言的规则。然而，在最trivial的层面上可能不使用类型系统。例如，考虑一个二进制翻译器，它不尝试理解它正在翻译的程序，而是将原始程序的数据部分复制为一个非结构化字节的整体块。还假设它使用
C 语言作为目标机器独立的汇编程序； UQBT 二进制翻译器以这种方式运行
[CVE00, CVEU+99, UQB01]。翻译器发出的这种低级 C
将包含与类型相关的结构，因为 C
语言要求每个变量定义都用类型声明，但所有变量都声明为整数，并根据需要插入强制转换以重现原始程序。内存由
<code>*(&lt;type&gt; *)(&lt;address expression&gt;)</code>
形式的表达式引用。</p>
<p>诸如此类的代码本质上是用高级语言表达的低级反汇编。这种代码缺少的主要特征之一是数据的真实类型信息。</p>
<p>（注：这里“高级语言表达的低级反汇编”说得很好。很多时候遇到人不懂lifter和decompiler产生的IR的区别，比如觉得都是转LLVM
IR，转出来不就可以了。经常不知道怎么反驳。。。）</p>
<h3 id="高级语言中的类型">高级语言中的类型</h3>
<p>类型对于以高级语言表达程序是必不可少的：它们有助于提高可读性、封装知识、将指针与数字常量分开，并支持面向对象。</p>
<p>从上面的讨论中可以清楚地看出，类型是用高级语言编写的代码的一个基本特征，没有它们，可读性将非常差。指针和数字常量的分离隐含在决定变量的类型中。指令中的立即数（在反汇编中可以表示内存中某个结构的地址、整数或浮动点数）显然是指针或常量，一旦分配了类型。回想一下
1.5 节，将指针与数字常量分开是从机器代码进行逆向工程的基本问题之一。</p>
<p>机器代码程序与其高级语言等效程序之间的差异之一是空指针检查和数组边界检查等功能通常由编译器隐式应用。换句话说，它们存在于机器代码级别，但一个好的反编译器应该删除它们。此删除需要进行类型分析；要删除空指针检查，分析必须发现变量是指针。同样，在删除数组边界检查之前，必须识别数组和数组索引。有人可能会争辩说，如果空指针或数组边界检查被反编译器删除但存在于原始源代码中，那么反编译程序仍然是正确的。</p>
<p>递归类型指的是类型表达式的一部分引用自身的类型。例如，链表可能有一个名为
Next
的元素，它是指向同一链表的另一个元素的指针。处理此类类型时必须小心。例如，将类型打印为字符串的简单算法如下：遇到指针时，发出星号并递归指针类型的孩子。这适用于非递归类型，但不适用于链表示例（它将尝试产生无限的星）。这个问题当然不是反编译器独有的</p>
<h3 id="基本和聚合类型">基本和聚合类型</h3>
<p>虽然基本类型从单个指令的语义中出现，但聚合类型有时必须通过间距分析（stride
analysis）来发现。</p>
<p>大多数机器指令处理基本（简单）类型。这些类型包括整数和浮动点数。枚举和函数指针在机器代码级别表示为整数。聚合类型是基本类型的组合：数组、结构体和基本类型的union类型。</p>
<p>其他主要类型（基本类型和聚合类型除外）是指针。这些将在接下来的部分中更详细地考虑。</p>
<p>聚合类型通常在机器代码级别一次处理一个元素。处理聚合类型的少数机器指令，例如块移动或块设置指令，可以在循环中分解为更基本的指令。虽然机器指令语义通常会确定基本数据项的类型，但聚合类型通常只能从基本指令的上下文中发现，例如在循环中执行的基本操作，或在指针的固定偏移处执行的一些基本操作。</p>
<p>图 5.3 显示了使用基本类型和聚合类型的源代码和机器代码。请注意在 Intel
x86 等复杂指令集上，基本类型的对象如何使用简单的寻址模式（如
m[r1）访问，而聚合类型使用更复杂的寻址模式，如
<code>m[r1+r2*S]</code>（寻址模式 (r1,r2,S)） 和
<code>m[r1+K]</code>（r1 和 r2 是寄存器，S 和 K 是常量）。</p>
<figure>
<img src="image-20230516164938196.png" alt="image-20230516164938196" />
<figcaption aria-hidden="true">image-20230516164938196</figcaption>
</figure>
<h3 id="变化的指针running-pointer">变化的指针（Running Pointer）</h3>
<p>虽然变化的指针和数组索引在大多数情况下是等效的，但运行指针在初始化数组的情况下会产生问题。</p>
<p>C
程序员知道可以使用索引或通过数组递增指针来访问数组。通常，指针比索引更有效；因此，用索引编写的程序可能会被优化编译器转换为操作指针的等效代码。这意味着反编译器可以自由地以任何一种方式表示数组处理代码。用户可能更喜欢一种表示而不是另一种表示。可以争论的是，表示可以安全地留给运行时选项或交互式用户选择。或者，总是可以产生一种表示，并且如果需要另一种表示，则使用后反编译转换阶段。</p>
<p>在数组上使用运行指针对于恢复预初始化数组具有重要意义。期望看到数组索引语义的简单类型分析（例如
[Myc99]）可能会正确地反编译程序的代码部分，但无法恢复数组的初始值。图
5.4 说明了这个问题。</p>
<p>在图5.4(a)中，类型分析发现了一个数组，为了正确声明数组，提示分析数组的大小。如果它在二进制文件的只读部分中，它的大小和类型可用于声明数组的初始值（示例中未显示）。在图5.4(b)中，p的类型是char<em>，常量的类型也是char</em>。地址
10 000 用作 char 的事实可能会提示将一个 char
声明为字符，并且如果在二进制文件的只读部分中，它可能会被赋予一个初始值。请注意，没有提示将其他九个值声明为
char 类型。更糟糕的是，常量 10 010 被用作 char*
类型，可能提示类型分析将地址 10010 处的对象声明为 char
类型，而实际上这只是数据段中数组 a
之后的下一个数据项。该对象可以是任何类型，也可以是未使用的。这表明每当常量
K 与类型 Y* 一起使用时，它并不总是遵循位置 K*（即 m[K]）与类型 Y
一起使用。</p>
<figure>
<img src="image-20230516165158780.png" alt="image-20230516165158780" />
<figcaption aria-hidden="true">image-20230516165158780</figcaption>
</figure>
<p>以 5.4(a) 风格编写的程序可以由编译器转换为 5.4(b)
风格的机器代码程序。</p>
<p>图 5.4(a)
中数组的大小比较容易确定。在其他情况下，可能很难或不可能确定数组的长度。例如，可以使用一个特殊值来终止循环。循环终止条件可以任意复杂，实际上需要执行程序才能找到终止条件。即使执行程序也可能无法确定数组的完整大小，因为对于每次执行，可能只会访问数组的一部分。在这些情况下，类型分析可能会确定存在已初始化的数组，但无法计算数组的长度。</p>
<figure>
<img src="image-20230516165337787.png" alt="image-20230516165337787" />
<figcaption aria-hidden="true">image-20230516165337787</figcaption>
</figure>
<p>图 5.5：从同一指针引用两种不同类型的程序。</p>
<p>另一种情况是使用运行指针遍历结构数组，如图 5.5(a)
所示。这里的结构包含一个整数和一个浮点数；在循环内部，指针交替引用一个整数和一个浮点数。原始编译器重新安排了代码，在每次引用后将指针递增整数的大小和浮点数的大小，从而使机器代码更加紧凑和高效。如图
5.5(b) 所示，指针的类型现在是
void*，因为它被用作两个不兼容的指针类型。</p>
<p>如果数组未初始化，如图 5.4(b) 和 5.5(b)
所示的程序可读性较差但正确（假设适当的转换并在适当的地址分配内存）。然而，如果数组被初始化，使它们正确的唯一方法是使用二进制翻译技术：强制数据访问到原始地址，如果源机器和目标机器的字节序不同，则反转数据部分。不用说，结果远非可读，并且翻译到具有不同指针大小（以及其他重要特征）的机器根本不可行。</p>
<p>为了避免这种极端的不可读性，有必要分析包含基于指针的代码的循环，并找出指针的范围。</p>
<p>这里不考虑反编译器的指针范围分析；分析，例如 Reps
等人的VSA分析。可能是合适的 [RBL06]。</p>
<h2 id="类型信息的来源">类型信息的来源</h2>
<p>类型信息来自机器指令opcode，来自库函数的签名，在一定程度上来自某些常量的值，偶尔来自调试信息。</p>
<p>机器代码程序中类型信息的最佳来源之一是对库函数的调用。通常，库函数的签名是已知的，因为库函数的目的是执行已知和记录的功能。签名由函数名称、参数的数量和类型以及函数的返回类型（如果有）组成。此信息可以存储在从解析头文件派生的签名数据库中，由函数名称（如果动态链接）或通过模式匹配静态链接代码
[FLI00，VE98] 获得的标识符进行索引。</p>
<p>有限的类型信息来自于一些常量的值。在许多架构中，某些值可以被排除为指针（例如，小于
0x100
的值）。类型分析的主要决定之一是常量是否为指针，因此此信息可能很有价值。</p>
<p>类型信息的第三个来源是单个机器指令的语义。所有机器指令都将暗示每个非立即操作数的大小。寄存器有确定的大小，所有内存操作都有一个编码到指令操作码中的大小。对于某些加载、存储和移动指令等指令，除了大小之外没有关于类型的信息，并且源和目标的类型通过T(dest)≥T(src)相关。
（T (x) 表示 x
的类型。不等式只出现在类指针中；目标可以指向至少与源一样多的东西）。相同的指针大小的移动指令可用于移动指针、整数、游标点值等。因此，需要有一种类型的表示，其唯一信息是大小，例如任何
16 位数量的 size16。</p>
<p>在某些机器代码程序中，有运行时类型信息（有时称为 RTTI
或运行时类型标识）。这通常在原始程序使用 C++ dynamic_cast
操作或类似操作的情况下可用。即使原始源代码没有显式使用此类操作，某些库（例如
Microsoft 基础类 (MFC)）的使用也可能会隐式引入 RTTI
[VEW04]。当输入程序中存在 RTTI
时，类的名称和层次结构都可用。类层次结构提供类型信息；例如，如果 A 类是
B 类的父类，则 T (A) &gt; T (B)。</p>
<p>最后，输入程序可能包含调试信息或符号。调试信息通常在程序开发期间打开以帮助调试。在某些情况下，调试信息可能仍然存在于反编译器可用的机器代码中。当调试信息在输入程序中可用时，所有过程的名称以及参数的名称和类型通常都是可用的。函数返回和局部变量的类型也可能可用，具体取决于存在的调试信息的详细信息。</p>
<p>大多数类型信息从被调用者传递到调用者，这对于反编译很方便，因为大多数其他信息（例如关于参数和返回的信息）也从被调用者传递到调用者。然而，一些类型信息以相反的方向传播。参数/参数和返回/结果之间存在对称性，值从参数发送到参数并返回到结果。上面讨论的源类型信息的传播方向取决于库函数、常量、机器指令等是否驻留在调用者或被调用者中。</p>
<p>考虑一个返回其两个 32
位（指针大小）参数之和的函数的简单示例。单独来看，关于这个函数的参数和返回值的唯一已知类型信息，参数和返回都是
32
位大小，而且不是任何浮动点类型。换句话说，指针和整数的多种组合都是可能的。如果为调用者的实际参数或结果找到了类型，则类型信息将从调用者流向被调用者。</p>
<p>这个例子也突出了类型分析的一个普遍问题：可能有几种可能的解决方案，但都是有效的。用于添加指针和整数、整数和指针以及两个整数的程序都可以编译为相同的机器代码程序。然而，这个问题对于小过程最为严重，因为随着考虑更大的过程，遇到暗示特定类型的使用的机会增加。</p>
<p>类型分析被认为是一个双向问题
[KDM03]。换句话说，如果实现为数据流问题，则流图的正向或反向遍历都不会显着提高性能。双向性的根源在于大多数类型定义操作都会影响目的地（定义）和一些操作数（使用）。定义的类型效果会影响该定义的使用；用途的类型影响回溯到这些用途的定义。库函数调用同样具有双向效果。按值调用库调用的实际参数是对先前定义的位置的使用（类型信息向后流动）。返回值类型和引用参数调用是类型向前影响的定义。因此，类型分析是少数可以用数据流术语表达的问题之一，并且是真正双向的。</p>
<p>比较操作导致可能不直观的类型约束。相等关系运算符（= 和
!=）仅表示被比较的变量的类型是可比较的。
（如果两个类型是可比较的，则意味着它们在 C 意义上是兼容的；int 和 char*
不兼容，因此无法比较它们。）任一操作数的类型都可以大于或等于操作数的类型另一个操作数，因为等式关系是可交换的，如图
5.6 所示。</p>
<figure>
<img src="image-20230516165932660.png" alt="image-20230516165932660" />
<figcaption aria-hidden="true">image-20230516165932660</figcaption>
</figure>
<p>相比之下，诸如 ≤
之类的非交换关系运算符表示统一类型对象的数组，因为高级语言不允许假设其他对象的相对地址。图
5.7(b) 显示了一个示例，其中常量 a+10 的类型应为
int*，即使相同的数字常量可能是在其他地方被用作浮点数 f
的地址。因此，这些运算符意味着操作数的类型是相等的。</p>
<figure>
<img src="image-20230516170012790.png" alt="image-20230516170012790" />
<figcaption aria-hidden="true">image-20230516170012790</figcaption>
</figure>
<p>一些关系运算符暗示操作数的符号性（例如，符号小于或等于）。编译器通常会忽略整数操作数的符号不匹配，因此不应将有符号整数、无符号整数和未知符号的整数视为不同类型。相反，整数类型的符号是一种属性，变量的最终声明符号可以通过启发式方法确定，例如统计上最常用的类型（
the statically most commonly used variant）。</p>
<p>通常，在比较整数和浮点数时会使用不同的比较运算符，因此这些运算符隐含了基本类型。定点数通常由整数运算符（例如比较运算符、加法和减法）进行操作，只有少数操作（例如固定点乘法）将操作数识别为固定点。因此，可以将整数提升为固定点数，即<span
class="math inline">\(fixpoint \sqsubset integer\)</span>。</p>
<h2 id="类型约束">5.4 类型约束</h2>
<p>常量与内存位置一样具有类型，并且由于具有相同数值的常量不一定相关，因此常量被必须独立设置类型。</p>
<p>在高级语言中，常量具有隐含类型。比如2.0的类型是double； 'a'
是字符，0x61
是整数，依此类推。但是，在反编译中，这并不适用。常量和位置一样需要输入。根据常量的类型，相同的立即值（机器语言常量）可能最终在反编译代码中作为
1084227584、5.000000、&amp;foo、ENUM_40A00000
或可能的其他表示形式发出。重要的是要认识到每个常量都必须独立类型化。例如，在下面的语句中，每个值为
1000 的常量都可以是不同的类型：</p>
<p><span class="math inline">\(m[1000_1] := m[1000_2] +
1000_3\)</span></p>
<p>三种可能的结果是：</p>
<ul>
<li><span class="math inline">\(T (1000_1) = int*\)</span> and <span
class="math inline">\(T (1000_2) = int*\)</span> and <span
class="math inline">\(T (1000_3) = int\)</span></li>
<li><span class="math inline">\(T (1000_1) = α**\)</span> and <span
class="math inline">\(T (1000_2) = α**\)</span> and <span
class="math inline">\(T (1000_3) = int\)</span></li>
<li><span class="math inline">\(T (1000_1) = α**\)</span> and <span
class="math inline">\(T (1000_2) = int*\)</span> and <span
class="math inline">\(T (1000_3) = α*\)</span></li>
</ul>
<p>其中每个 α 表示任意类型，但 α 的每次出现都暗示与其他 α
相同的任意类型。在第三个例子中，<span
class="math inline">\(1000_3\)</span> 是一个指向 α
的指针，它被一个整数（在内存地址 1000 处找到）加，产生一个指向 α
的指针，它覆盖了临时位于位置 1000
的整数。必须使用转换才能使第三个方案有效，并且需要反映在反编译输出中。</p>
<p>另请注意，寄存器中的值可以是没有类型的中间值，例如在以下 SPARC
代码中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sethi 0x10 000, %o0</span><br><span class="line">add %o0, 0x500, %o1 // %o1 used later as char*, value 0x10 500</span><br><span class="line">add %o0, 0x600, %o2 // %o2 used later as integer, value 0x10 600</span><br></pre></td></tr></table></figure>
<p>寄存器 %o0 中的值 0x10 000
没有标准类型，尽管它似乎被用作两种不同类型（char*
和整数）的一部分。它不得出现在反编译输出中。中间值来源于 RISC
机器的一个共同特征：由于 RISC
指令的长度通常是一个字，因此需要两条指令来产生大多数字长常量。 SSA
形式促进了常量传播和死代码消除，通过删除中间常量很容易解决这个问题。</p>
<h2 id="类型约束满足">5.5 类型约束满足</h2>
<p>在反编译输出中查找变量和常量的类型可以视为约束满足问题；它的具体特征表明了一种充分利用约束传播的算法。</p>
<p>可以将类型分配给反编译变量视为约束满足问题 (CSP) [VH89,
Bar98]。类型变量的域比较小：</p>
<ul>
<li><p>基本类型（在第 5.2.3 节中列举）</p></li>
<li><p>指向 α 的指针（其中 α 是任何类型，包括另一个指针）</p></li>
<li><p>α 的数组（其中 α 是任何类型，包括另一个数组）</p></li>
<li><p>结构或类</p></li>
<li><p>枚举类型</p></li>
</ul>
<p>图 5.8 显示了源代码中的程序片段、机器代码（带有 SSA
转换）、生成的约束以及约束的解决方案。</p>
<p>在第二条指令中，寄存器 r1a（寄存器 r1 的第一个 SSA 值）被设置为
0。由于零可以用作整数，也可以用作 NULL 指针，约束条件是 r1a
可以是整数（t1a = int ) 或指向某物的指针，称其为 α1 (t1a = ptr(α1))。
add指令产生的约束条件比较复杂，反映了三种可能：指针+整数=指针，整数+指针=指针，整数+整数=整数。约束通常使用标准约束求解器算法来求解，但是图
5.8
中的简单问题的一部分可以通过肉眼求解。例如，加载指令的约束只有一种可能性，t0b
= ptr(mem(0: t2a)（意味着 r0b 指向内存中类型为 t2a 的结构，位于 r0b
指向的偏移量 0 处）。这可以是代入标签为 3F2: 的指令的约束中，因此 t0a 和
t0c 的类型必须与此相同。</p>
<p>继续约束求解，找到两个解。在大多数情况下，不会有不止一种解决方案。</p>
<p>因为常量是独立类型的（上一节），并且表达式（包括常量）必须根据约束来表达，所以有必要以某种方式区分常量。例如，常量可以被下标，就像
SSA 变量被重命名一样，例如<span class="math inline">\(1000_3\)</span>
正如已经看到的那样。常量 1000
的每个版本的类型都需要被视为一个单独的变量。</p>
<p>类型常量（常量类型变量的值）很常见。例如，xor
指令意味着整数操作数和结果； sqrt 指令表示游标点操作数和结果； itof
指令意味着整数操作数和浮动点结果。库函数调用会导致每个参数（如果有）和结果（如果有）的类型常量。</p>
<p>为类型变量选择一个值（在 CSP
术语中）通常隐含在约束中。例如图5.8的add指令，add
r2a,r1b,r1c，结果为约束：</p>
<p><img src="image-20230516172503569.png"
alt="image-20230516172503569" /> <span class="math display">\[
\begin{align}
t2a = ptr (α_3), t1b = int, t1c = ptr(α_3) ∨ \\
t2a = int, t1a = ptr (α_4), t1c = ptr (α_4) ∨ \\
t2a = int, t1b = int, t1c = int
\end{align}
\]</span></p>
<p>在这里，约束表示为连词的disjunction（或-ing）（一些术语 and
在一起；这里的逗号表示 and）。通过选择三个连词之一，同时查找 t2a、t1b 和
t1c
的值。通常通过拒绝与其他约束冲突的合取来做出选择。希望在流程结束时，有一组约束代表类型分析问题的解决方案。</p>
<p>一些约束求解器基于约束传播（例如前向检查技术）。其他更多地依赖于检查冲突（例如简单的回溯或生成和测试）。综上所述，上述因素（小域大小、常量和等式很常见，等等）表明约束传播将快速修剪搜索树中会导致失败的分支。因此，约束传播技术似乎更适合类型约束满足问题，因为它比另一组技术更适用于反编译。</p>
<p>基于约束的类型分析算法的一个弱点是一些这样的算法是不完整的，即给定的算法可能找到一个或多个解决方案，或者证明约束无法解决（证明它们不一致），或者这两个都做不到。</p>
<h3 id="数组和结构体">数组和结构体</h3>
<p>基于约束的类型分析需要额外的规则才能正确处理数组。</p>
<p>Mycroft
提出了一种基于约束的类型分析系统，用于反编译机器代码程序（以寄存器传输语言形式或
RTL）[Myc99]。他为单个指令生成约束，并解决约束以给被反编译程序的变量创建类型。他假定双寄存器寻址模式指令的可用性和使用来指示数组的使用。例如，在他论文的第
4 节中，</p>
<figure>
<img src="image-20230516172844425.png" alt="image-20230516172844425" />
<figcaption aria-hidden="true">image-20230516172844425</figcaption>
</figure>
<p>但是，某些机器架构不支持双寄存器索引，即使支持，编译器也可能出于各种原因决定对加载或存储指令单独执行加法。因此，上述指令可以作为两条指令发出，具有如图
5.9 所示的约束。</p>
<figure>
<img src="image-20230516172857092.png" alt="image-20230516172857092" />
<figcaption aria-hidden="true">image-20230516172857092</figcaption>
</figure>
<p>图 5.9：上述两个指令版本的约束。来自 [Myc99] 的示例。</p>
<p>由于 r1
在第二条指令中用作指针，因此立即删除第一条指令的最后一个（带下划线的）条件句。最终约束现在是根据
ptr (t3)，而不是 ptr (array(t3))。这些在 C
意义上是等价的，但涉及数组的事实并不明显。换句话说，仅考虑单个指令本身（至少在某些情况下）不足以分析聚合类型。要么必须在约束系统之外添加一些辅助规则，要么可以将表达式传播与高级类型模式结合使用。
（在他论文的第 4.3 节中，Mycroft
似乎建议成对地考虑指令来解决这个问题。）这是另一个可以使用第 3 章和第 4
章中描述的表达式传播和简化的领域。</p>
<h2 id="加法和减法操作">加法和减法操作</h2>
<p>编译器隐式地使用指针大小的加法指令来访问结构成员，这导致将一个整数与
α* 类型的指针相加会产生另一个 α* 类型的指针的一般规则出现异常。</p>
<p>指针大小的加法和减法指令是类型分析的一种特殊情况，因为它们可以用于指针或整数。
Mycroft [Myc99] 将指令 add a,b,c（其中 c 是目的地，即 c := a +
b）的类型约束声明为：</p>
<figure>
<img src="image-20230516174842091.png" alt="image-20230516174842091" />
<figcaption aria-hidden="true">image-20230516174842091</figcaption>
</figure>
<p>其中 T (x) 再次表示 “x 的类型”（Mycroft 使用 tx ）并且 ptr(α)
表示指向任何类型的指针，类型变量 α 表示该类型。Mycroft 使用 C
指针算术规则，其中将整数与 α* 类型的变量相加将始终得到 α*
类型的指针。但是，C 定义并不总是适用于机器代码级别。编译器发出 add
指令以在源程序中实现加法运算符，但也用于其他两个目的：数组索引和结构成员访问。对于数组索引，C
指针规则适用。 α 类型元素数组的基是 α*
类型，（可能缩放的）索引是整数类型，结果是指向索引元素的指针，它是 α*
类型。</p>
<p>但是，结构成员访问不遵循 C 规则。考虑一个类型为 Σ 的结构，其在偏移 K
的地方包含类型为 ε 的元素。结构的地址可以是类型
Σ*（指向结构的指针）或类型 ε0*（指向结构的第一个元素 0
的指针），具体取决于关于它是如何使用的。在机器代码级别，Σ 和 Σ.0
具有相同的地址并且除了它们的使用方式外无法区分。 K
被添加到这个指针以产生一个指向元素 的指针，它是类型 ε*，通常是与 Σ* 或
ε0* 不同的类型。</p>
<p>不幸的是，在类型分析完成之前，不知道任何特定指针是否会变成结构指针。图
5.10 给出了一个例子。</p>
<figure>
<img src="image-20230516174950921.png" alt="image-20230516174950921" />
<figcaption aria-hidden="true">image-20230516174950921</figcaption>
</figure>
<p>图
5.10：一个程序片段说明了指针如何最初看起来不是结构指针，但后来用作结构指针。</p>
<p>最初，参数 p 仅被认为是一个指针。在处理完过程的第一条语句后，p 与类型
int* 一起使用，因此 T (p) 被设置为
int<em>。在第二个语句中（通常，任意时间之后），发现 p
指向一个结构，其中一个 int 位于 oset 0 处，一个 oat 位于 oset 4
处。如果使用 C 规则，则 p 的总和（然后type int</em>) 和 4 产生一个与 p
类型相同的指针，然后在第二个语句中 p 被有效地用作 int* 类型和 oat*
类型。这可能导致 p 被声明为 int* 和 oat* 的联合。</p>
<p>请注意，其他通用 C
规则的例外仅涉及添加结构指针和常量整数；编译器知道结构成员的集合，并将此信息保存在结构的符号表中。因此，如果整数不是常量，则可以将结果类型和输入指针的类型限制为相等，即适用
Mycroft 的限制条件。</p>
<p>为了避免这个问题，Mycroft 的约束可以重写如下：</p>
<figure>
<img src="image-20230516175122620.png" alt="image-20230516175122620" />
<figcaption aria-hidden="true">image-20230516175122620</figcaption>
</figure>
<figure>
<img src="image-20230516175132852.png" alt="image-20230516175132852" />
<figcaption aria-hidden="true">image-20230516175132852</figcaption>
</figure>
<p>这里，void*，表示一个已知为指针的变量，但指向的类型未知（输出）或被忽略（输入）。如果
void* 和 α* 之间存在冲突，则优先使用
α*。请注意，这已经暗示了类型的层次结构，void* 优于无类型，但任何 α* 优于
void*。</p>
<p>编译器不会隐式地执行指针减法或指针减法，因此可以导出指针大小减法运算的类似
Mycroft 的约束。对于 c := a - b:</p>
<figure>
<img src="image-20230516175205361.png" alt="image-20230516175205361" />
<figcaption aria-hidden="true">image-20230516175205361</figcaption>
</figure>
<h2 id="基于数据流的类型分析">基于数据流的类型分析</h2>
<p>对输出语言进行静态类型检查的反编译器的类型分析，由于使用了 SSA
形式，使得稀疏数据流算法变得可能。</p>
<p>类型可以被认为是变量的可能值的集合。可能值的集合越小，类型信息就越精确和有用。这些集合形成一个自然的层次结构：所有可能值的集合、所有可能的
32 位值的集合、有符号或无符号 32 位整数的集合、有符号的 32
位整数的集合、有符号整数的子范围，
等等。机器指令的作用通常是限制可能值的范围，例如从所有 32 位值到 32
位整数，或从 32 位整数到无符号 32 位整数。</p>
<p>该效应表明，调和位置类型的各种限制和约束的自然方法是使用迭代数据流框架
[MR90，KU76]。欠缺的数据是类型限制和约束，结果是在给定这些限制和约束的情况下程序中位置的最精确类型。</p>
<p>基于数据流的类型分析比第 5.5
节中概述的基于约束的类型分析有一些优势。由于在程序的正常中间表示之外没有要解决的显式约束，因此无需区分恰好具有一致值的常量。约束很难求解，有时候有不止一种解法，有时候根本就没有解法。相比之下，数据流方程的求解通常非常简单。这种简单性的两个例外是整数加法和减法指令；正如将要显示的那样，这些指令比其他指令更复杂，但复杂度适中。</p>
<h3 id="类型格">类型格</h3>
<p>由于类型是分层的并且某些类型对是不相交的，因此类型之间的关系形成了一个格。</p>
<p>类型可以被认为是可能值的集合，例如整数类型可以被认为是所有可能整数的无限集。在本章中，这两个视图将互换使用。整数集是无符号整数集（计数）的超集。整数集合中的元素多于无符号整数集合，即整数⊃无符号整数。因此，整数集在某种意义上大于无符号整数集；因此有一个类型的顺序关系。</p>
<p>然而，顺序关系并不完整，因为某些类型对是不相交的，即它们无法进行有意义的比较。例如，浮动点数、整数和指针在机器代码级别彼此不兼容，因此被认为是相互不兼容的（即不可比较）。这些基本类型中没有一个比其他类型包含更多信息。为了表示排序是部分排序，使用了常用集合运算符符号的方形版本：⊂、⊃、∩和∪分别变为
<span class="math inline">\(\sqsubset\)</span>、<span
class="math inline">\(\sqsupset\)</span>、<span
class="math inline">\(\sqcap\)</span> 和 <span
class="math inline">\(\sqcup\)</span>。因此 “int <span
class="math inline">\(\sqsupset\)</span> unsigned int” 或 “int 是
unsigned int 的超类型”。</p>
<p>尽管数学数字 1027
是一个整数，它也是一个实数，并且它可以用作内存中某个对象的地址，但这些类型在机器代码级别是不兼容的。浮点数与整数有不同的位表示，因此用途不同。指针变量只能由加载和存储指令（包括包含加载和/或存储的复杂指令）或比较/测试指令使用。整数变量应类似地由整数指令（整数加法、移位、按位或）使用，而浮点变量应仅由浮点指令（浮动点加法、平方根等）使用。</p>
<p>这种将类型与指令类巧妙分离的两个例外是整数加法和减法指令。在大多数机器中，这些指令可用于整数变量和指针变量。第
5.6
节更详细地讨论了此例外情况的含义。事实上，不同类型的对象通常必须与不同的指令类一起使用，这使得避免类型错误变得如此重要。</p>
<p>在反编译中，除了计算机语言中使用的类型外，还会考虑其他类型，例如
size32（一个 32
位的量，其基本类型尚不清楚，但大小已知），或指针或整数类型。这些是临时类型，应该在反编译结束前删除。作为一个人为的例子，考虑一个由三个指令引用的位置：符号位的
32
位测试、整数加法指令和算术右移。在test指令之前，根本不知道该位置的任何信息。类型系统可以为它分配一个特殊的值，称为<span
class="math inline">\(\top\)</span>（top）。 <span
class="math inline">\(\top\)</span> 代表所有可能的类型，或通用集 <span
class="math inline">\(\cup\)</span>，或等效地，没有类型信息（因为一切都是
<span class="math inline">\(\cup\)</span>
的成员）。test指令后，只知道它是一个32位有符号数，所以类型分析可以赋予它临时类型signed32。在
add
指令后，已知它是一个指针或一个整数：pointer-or-int。算术右移指令仅适用于整数变量，因此该位置可以分配为
int 类型。</p>
<p>到目前为止，类型层次结构可以被认为是一个有序列表，一端是 <span
class="math inline">\(\top\)</span>，另一端是
int。位置的类型最好朝一个方向移动（有一个例外，如下所述），朝向最受约束的类型（可能值较少的类型，远离
<span
class="math inline">\(\top\)</span>）。之后出现的信息也有可能与当前已知的类型发生冲突。例如，假设第四条指令使用该位置作为指针。从逻辑上讲，这可以用另一个特殊值
⊥（bottom）表示，表示过度约束或类型冲突，或可能值的空集
∅。这可能是由于原始程序中真正的不一致（例如，由于类型的联合或类型转换）或类型分析系统的某些限制而导致的。</p>
<p>实际上，对于反编译，最好永远不要将值 ⊥
分配给变量的类型；这相当于完全放弃分析这个位置的类型。相反，反编译器将保留当前类型
(int)
或分配新类型（指针），并且位置的冲突使用将以这样一种方式进行标记，即强制转换或联合将被体现到反编译输出中。
（如果在输出语言中不允许强制转换或联合，警告注释可能是最好的选择。某些语言比其他语言更适合作为反编译器的输出语言。）</p>
<p>继续引用位置的示例三个指令，类型列表可以垂直表示，<span
class="math inline">\(\top\)</span> 和类型 size32、pointer-or-int 和 int
依次向下延伸，如图 5.11(a) 所示。</p>
<figure>
<img src="image-20230518155630693.png" alt="image-20230518155630693" />
<figcaption aria-hidden="true">image-20230518155630693</figcaption>
</figure>
<p>图 5.11：说明glb(the greatest lower bound)</p>
<p>由于代替 add 指令的另一条指令（例如平方根指令）会确定该位置为 float
类型，因此有一条路径从size32到float，并且没有从 int 到 oat
的路径，因为它们是不兼容的。</p>
<p>到目前为止，当一个位置被用作两种类型 a 和 b
时，格中两种类型中较低的一种成为该位置的新类型。但是，请考虑一个位置是否已与类型
pointer-or-int 和 float-or-int 一起使用。
（后者可以通过分配一个已知对指针无效的值来实现）。结果类型不能是迄今为止使用过的任何一种类型
(pointer-or-int 或 float-or-int),，但实际上应该是新类型 int，它是小于
pointer-or-int 和 float-or-int
的最大类型。换句话说，使用类型为a和b的位置的一般结果是a和b的最大下界(greatest
lower bound)，也称为a和b的meet，记为a <span
class="math inline">\(\sqcap\)</span> b。.</p>
<p>注意与集合交叉符号∩的相似性。满足类型 a 和 b 的结果基本上是 a ∩
b，其中 a、b 和结果被认为是可能值的集合。例如，如果当前类型是
?signed-int（未知符号的整数），它可以被认为是集合 {sint,
uint}。如果此类型遇到 unsigned-int ({uint})，则结果为 {sint, uint} ∩
{uint} = {uint} 或 unsigned-int。</p>
<p>图 5.11(b)
显示了为什么它是所需的<strong>最大</strong>下界。当遇到类型 a 和 c
时，结果应该是 d 或 e，它们是 a 和 c 的下界。事实上，它应该是
d，最大的下界，因为没有理由（只考虑 a 和 c 的meet操作）选择更特殊的类型
e。例如，如果结果稍后遇到 b，则结果必须是 d，因为类型 b 和 e
在格中不可比较（这意味着它们在高级语言中是不兼容的类型）。</p>
<figure>
<img src="image-20230518160535675.png" alt="image-20230518160535675" />
<figcaption aria-hidden="true">image-20230518160535675</figcaption>
</figure>
<p>图 5.12：用于反编译的简化类型格。</p>
<p>图 5.12 显示了一个更实用的类型格，显示了数值的类型关系</p>
<p>前面提到，在考虑程序中位置的类型时，类型并不总是在格中从上到下移动。这些例外涉及指向面向对象语言（如
C++）中的类对象的指针。</p>
<figure>
<img src="image-20230518160708098.png" alt="image-20230518160708098" />
<figcaption aria-hidden="true">image-20230518160708098</figcaption>
</figure>
<p>图 5.13：类指针和引用</p>
<p>考虑图 5.13
中显示的示例类层次结构和网格。类层次结构和指向这些类的指针层次结构之间的相似性是显而易见的。一个指针可以在程序的一部分中被分配为
Sender* 类型，而在另一部分中被分配为 Receiver*
类型。如果这两个部分存在控制流合并，则指针将同时用作 Sender* 和
Receiver*。到目前为止的规则将产生 Transceiver* 类型，它是一个指向从类
Sender 和 Receiver 多重继承的类型的指针。但是，如果程序仅引用Sender和
Receiver 共有的那些方法和/或成员，即共同祖先 Communicator
的方法和成员，则这可能有点矫枉过正。此外，多重继承相对不常见，因此在许多程序中没有继承自多个类的类，并且在反编译输出中生成一个是不正确的。</p>
<p>这个例子说明有时关联两种类型的结果比所涉及的类型更高。在这些情况下，关联类型
α* 和 β* 导致类型 (α <span class="math inline">\(\sqcup\)</span>
β)*，其中 <span class="math inline">\(\sqcup\)</span> 是join运算符，而 α
<span class="math inline">\(\sqcup\)</span> β 得到 α 和 β
的最小上界（lub, least upper bound）。注意与集合并集运算符符号 ∪
的相似性</p>
<p>此行为仅发生在对类或结构对象的指针和引用中。对于指向其他类型对象的指针，指针或引用的类型与所引用的变量的类型必须在类型上完全对应。</p>
<p>类和结构指针和引用带来了额外的差异。在 a := b 这样的复制语句中，如果
a 和 b 不是这样的指针或引用，则 a 和 b 的类型相互影响；两者的类型都是 a
的类型与 b 的类型。但是，对于 p := q，其中 p 和 q
都是类或结构指针或引用，p 可能指向比 q 更大的对象集，并且 p
类型的这种扩展不会影响 q。因此，在这样的赋值之后，p 的类型变成了指向 p
的基类型和 q 的基类型的连接的指针，但是 q
的类型不受影响。只有这种形式的赋值才有这种例外，并且只有当涉及的变量是指针或类或结构的引用时。</p>
<p>出于类型分析的目的，过程参数在每次调用过程时由所有相应的实参表达式有效分配。该参数可以采用来自任何实际参数表达式的值。对于类型不是类或结构指针或引用的参数，所有参数的类型和参数的类型必须相同。但是，如果参数的类型是这样的指针或引用，则参数的类型必须是所有相应参数类型的join。</p>
<p>有关格的更多详细信息，参阅 [DP02]。</p>
<h3 id="基于-ssa-的类型分析">5.7.2 基于 SSA 的类型分析</h3>
<p>SSA
形式把使用连接到定义，允许在赋值节点中对类型信息进行稀疏表示。</p>
<p>在 5.7
节的开头，有人指出反编译器类型恢复问题可以作为数据流问题来解决，就像编译器可以通过这种方式对静态检查语言进行类型检查一样。可以使用传统的数据流分析，通常使用bit
vector实现
[ASU86]。但是，这涉及为程序的每个基本块（甚至每个语句，取决于实现）存储有关所有活动变量的信息。假设反编译器将为静态类型语言生成代码，每个
SSA 变量将保留相同的类型，因此更稀疏的表示是可能的。 SSA
位置的每次使用都链接到它的静态唯一定义，因此存储变量类型信息的逻辑位置是在与该定义关联的赋值语句中。对于没有显式赋值的参数和其他位置，可以在中间表示中插入隐式赋值。</p>
<p>这个框架是稀疏的，因为类型信息主要只位于需要的地方（对每个定义或常量创建一个类型变量，而不是对每个变量(或常量)和每个基本块）</p>
<p>基于数据流的类型分析的 SSA
形式是流不敏感的，因为计算类型是为整个程序总结的。但是，由于假定位置的类型在整个程序中都是相同的，因此这不是一个限制。换句话说，使用
SSA 形式允许以流不敏感的算法实现相同的结果精度，使用更少的开销。</p>
<h3 id="给表达式创建类型">5.7.3 给表达式创建类型</h3>
<p>在稀疏中间表示中，不存储子表达式的类型，因此必须根据表达式叶节点的需要，计算这些类型。</p>
<p>在反编译过程的早期，赋值通常采用简单的形式，例如 c := a <span
class="math inline">\(\odot\)</span> b，其中 <span
class="math inline">\(\odot\)</span> 是二元运算符，c 是位置，a 和 b
是位置或常量。然而，有些指令比这更复杂，并且在传播之后，表达式可以变得任意复杂。图
5.14 显示了一个简单的例子。</p>
<figure>
<img src="image-20230518161755702.png" alt="image-20230518161755702" />
<figcaption aria-hidden="true">image-20230518161755702</figcaption>
</figure>
<p>图 5.14：为一个简单的表达式创建类型。</p>
<p>表达式树的叶子总是位置或常量（赋值的目的地除外，它总是一个位置）。在反编译器的稀疏类型分析系统中，位置和常量具有与其关联的类型变量。然而，没有地方可以存储子表达式的类型，例如
a[2000] 或 s.b，除非所有子表达式都存储一个类型并且失去了稀疏性。</p>
<p>在这个例子中，从其他语句中唯一知道的类型信息是 a
是一个字符指针数组（即 a 当前的类型为
char*[]）。表达式的类型分析从表达式树的底部开始，称为
ascend-type的过程。在本例中，算法以子表达式 a[2000] 开始。 array-of
运算符是少数几个运算符之一，其中一个操作数的类型（这里是 a，而不是 2000
），如果已知，会影响结果，而结果的类型，如果已知，会影响该操作数。由于a的类型已知，所以可以计算出a[2000]的类型；在这种情况下它是
char*。此子表达式类型没有被存储；它是按需计算的。整数加法运算符是一种特殊情况，如果已知一个操作数是指针，则结果是指针类型，因为将指针和整数相加会得到指针。因此，整个表达式的类型被计算为
void*。 （将一个整数添加到一个 char* 并不总是会产生另一个
char*，因此结果的类型为 void*）。同样，不存储此类型。无法从 s、b 或 s.b
获得任何类型信息，因为 s 和 b 的类型当前未知。</p>
<p>接下来，第二阶段开始，称为descend-type。现在类型信息沿着表达式树向下流动，从根到叶。为了找到在加法运算符右侧的表达式树下推的类型，在其左侧操作数上调用
ascend-type。这将导致 char*
类型，如前所述。此类型与加法结果的类型一起用于查找加法右子表达式的类型。因为指针加上整数等于指针，所以找到的类型是整数。结构成员运算符，如
array-of
运算符，可以向上或向下传输表达式树的类型信息。在这种情况下，它会导致 b
的类型被设置为整数，而 s 的类型被设置为具有整数成员的结构。</p>
<p>当对 add 节点的左子表达式重复该过程时，结果为类型 void*，这意味着 a
的类型为 void*[ ]。然而，当遇到更精确的现有类型 char*[ ] 时，a
的类型仍为 char*[ ]。常量 2000
的类型设置为整数（数组索引始终为整数）。</p>
<p>在上面的示例中，位置 a
的初始类型来自程序中其他地方的类型信息。与位置相反，常量与程序的其他部分没有联系，如第
5.4 节所示。因此，常量仅由第二阶段被赋类型，descend-type。</p>
<p>通常，类型信息必须在表达式树中向上传播，然后再向下传播，分两次分开进行。</p>
<p>表 5.1
显示了各种运算符和常量的操作数和结果之间的类型关系。大多数运算符属于第一组，其中操作数和结果类型是固定的。对于其他不太常见的运算符和常量，需要
ascend-type 和 descend-type 的完整循环</p>
<p>在图 5.14 的示例中，<code>a[2000]</code>
的类型被计算了两次；期间一次ascend-type，再次descend-type。对于更复杂的表达式，descend-type
可能会在表达式树的重要部分多次调用 ascend-type。图 5.15 (a)
显示了具有四级二元运算符的表达式的最坏情况示例。在叶子节点，检查位置的类型（如果存在）可以被认为是一个操作。这个表达式树有
16 个叶节点，总共有 16
个操作。在树的上一级，使用来自两个子节点的信息检查父节点的类型，总共进行了三个操作。有八个这样的父节点，在这个级别总共有
24 个操作。类似地，在顶层，31 个操作（将近 2h+1，其中 h
是表达式树的高度）由 descend-type 执行。</p>
<figure>
<img src="image-20230518162635863.png" alt="image-20230518162635863" />
<figcaption aria-hidden="true">image-20230518162635863</figcaption>
</figure>
<p>表 5.1：表达式运算符和常量的类型关系。</p>
<figure>
<img src="image-20230518162656184.png" alt="image-20230518162656184" />
<figcaption aria-hidden="true">image-20230518162656184</figcaption>
</figure>
<p>图 5.15：上升和下降类型算法的复杂性。</p>
<p>图 5.15(b) 显示了一个包含所有三元运算符（例如 C 的 ?:
运算符）的树。这样的树在现实世界的例子中永远不会出现，但它说明了下降型算法在最坏情况下的复杂性。这里，执行了
3h+1
次操作。这种潜在的成本抵消了稀疏存储类型信息的空间节省（仅在定义时，而不是在使用时）。</p>
<h3 id="加法和减法">5.7.4 加法和减法</h3>
<p>从指针大小的加法和减法指令推断出的类型在基于数据流的类型分析中需要特殊的类型函数。</p>
<p>5.6 节展示了 Mycroft
约束的修改，它考虑了将常量添加到结构指针所导致的异常。为了在基于数据流的分析中表示
Mycroft 的约束，需要一些额外的类型和运算符。让 π
在格中为指针或整数或更高。希望所有出现的 π
最终都将被替换为更低（更精确）的类型，例如整数或特定的指针类型。int被认为与指针大小相同。在图
5.12 的格中，π 的值可以是指针或整数、size32 或 &gt;。与 add a, b, c
相关的数据流方程（即 c=a+b），结构指针例外，可以重述为： <span
class="math display">\[
\begin{align}
T (a) = Σ_a(T (c), T (b)) \qquad (5.1) \\
T (b) = Σ_a(T (c), T (a)) \qquad (5.2) \\
T (c) = Σ_s(T (a), T (b)) \qquad (5.3)
\end{align}
\]</span> 其中 Σa 和 Σs（a 代表加数或被加数，s
代表总和）是特殊函数，定义如下（译者注：第一行代入运算结果c的类型，然后左边第一列代入其中一个运算数的类型。图中只标了一行或者一列，但是是这个意思。比如行那边标T(c)
= xx
表示该行查找和的类型，在a+b=c这个等式中。）（注2：由于是数据流分析，所有格变量最开始都有初始类型π，代表不知道是数字还是指针，因此只要加法运算任意一方因为外部原因被更新，其他两个格变量都可以被更新。）</p>
<figure>
<img src="image-20230518163304404.png" alt="image-20230518163304404" />
<figcaption aria-hidden="true">image-20230518163304404</figcaption>
</figure>
<p>（译者注：这里可以观察到，上边的表中，当运算结果(行)为指针，其中一个参与数（列）不知道类型(var-π)，此时结果依然为var-π。表示放弃了考虑这个约束。）</p>
<p>为简洁起见，ptr(α) 记为 α*。如果操作数分别是位置或常量，则类型变量 T
(a)、T (b) 和 T (c) 被初始化为 var-π 或 const-π。 178 反编译器的类型分析
例如，考虑 p = q+r，已知 q 的类型为 char*，并且需要 r 的类型。由于 p
的类型尚不清楚，因此 p 的类型保持其初始值 var-π。 p、q 和 r 分别代替等式
5.2 的 c、a 和 b。该等式使用上面左表中定义的函数 Σa。由于 T (c) =
var-π，因此使用第三列，并且由于 T (other) = α* 其中 α =
char，因此使用第一行。第三列和第一行的交集包含 var-int，因此 T (b) = T
(r) = int。</p>
<p>类似地，与sub a, b, c（即 c=a-b）相关的数据流方程可以重述为： <span
class="math display">\[
\begin{align}
T (a) = ∆_m(T (c), T (b)) \qquad (5.4) \\
T (b) = ∆_s(T (c), T (a)) \qquad (5.5) \\
T (c) = ∆_d(T (a), T (b)) \qquad (5.6)
\end{align}
\]</span> 其中，Δm、Δs 和 Δd（m 代表被减数（被减去的项目），s
代表减数（被减去的项目），d 代表差值（结果））是如下定义的特殊函数：</p>
<figure>
<img src="image-20230518163517707.png" alt="image-20230518163517707" />
<figcaption aria-hidden="true">image-20230518163517707</figcaption>
</figure>
<p>如前所述，编译器不使用减法来引用结构成员，因此这次无需区分 var-int 和
const-int，或 var-π 和 const-π。</p>
<h2 id="类型模式">5.8 类型模式</h2>
<p>一小组高级模式可用于表示全局变量、局部变量和聚合元素访问。 5.8
类型模式 179
用于访问全局、局部或堆变量、数组元素或结构元素的一系列机器指令通常会产生一个内存表达式，该表达式可以用以下范式表示：</p>
<figure>
<img src="image-20230518163605241.png" alt="image-20230518163605241" />
<figcaption aria-hidden="true">image-20230518163605241</figcaption>
</figure>
<p>其中：</p>
<ul>
<li>m[x] 表示地址x 处的内存。</li>
<li>m[...] 中加法的各项只需要存在一个。</li>
<li>[ a ｜ b ] 表示可选的a 或b 但不是两者。</li>
<li><span class="math inline">\(sp_0\)</span>
表示过程开始时堆栈指针寄存器的值。</li>
<li>pl
是用作指针的非常量位置（虽然非常量，但它可以在运行时采用几个常量值之一）。</li>
<li><span class="math inline">\(S_j\)</span>
是比例常数，其中一些可以等于1。</li>
<li>这里*代表乘法。</li>
<li><span class="math inline">\(ie_j\)</span>
是不包含堆栈指针寄存器的非常量整数表达式，并且已知不是 x+C 的形式，其中
x 是一个位置，C 是一个常量。常量可以出现在 <span
class="math inline">\(ie_j\)</span> 的其他地方，例如它可能是
4*r1*r2。</li>
<li>K 是常数（整数或指针常数）。</li>
</ul>
<p>必要时应用分配律，例如在尝试匹配上述等式之前，m[4*(r1+1000)] 被转换为
m[r1*4 + 4000]。如第 3
章所述，表达式传播、简化和规范化可用于为高级模式匹配准备中间表示。</p>
<p>m[...]
中项的总和必须是定义的指针表达式。指针不能相加，两个或多个整数相加不会得到指针，指针和整数相加的结果是指针。因此，恰好有一项是指针，其余项必须是整数。由于<span
class="math inline">\(sp_0\)</span>永远是指针，<span
class="math inline">\(sp_0\)</span>和pl不能同时出现，如果<span
class="math inline">\(sp_0\)</span>或pl都存在，K就不能是指针。</p>
<p>可以认为，由于 pl 或 K 可能为负，因此 sp0、pl 和 K
的所有三个可以同时存在，两个指针相互减去，得到一个常量。然而，这样的组合需要指针的相减，这在真实程序中从未出现</p>
<p>最初，可能无法将 pl 与 <span class="math inline">\(S_j =1\)</span> 的
<span class="math inline">\(ie_j\)</span>
区分开来，因此可能需要临时表达式，例如 <span class="math inline">\(m[l_1
+ K]\)</span> 或 <span class="math inline">\(m[l_1 + l_2 +
K]\)</span>，直到弄清楚 <span class="math inline">\(l_1\)</span>、 <span
class="math inline">\(l_2\)</span>和K中哪个是指针。如果存在，<span
class="math inline">\(sp_0\)</span>
表示内存表达式表示堆栈分配的变量、数组元素或结构体元素。</p>
<figure>
<img src="image-20230518164428872.png" alt="image-20230518164428872" />
<figcaption aria-hidden="true">image-20230518164428872</figcaption>
</figure>
<p>表 5.2：类型模式和讨论它们的命题。</p>
<p>表 5.2
显示了在传播和死代码消除之后可以在中间表示中找到的一系列模式，以及在接下来的几页中讨论它们的命题。很明显，有很多可能的模式，区分它们并非易事。这种区分的大部分留作未来的工作。</p>
<p><strong>命题 5.8</strong>：（<span
class="math inline">\(ie_j\)</span>存在）将非常量整数表达式添加到指针意味着数组访问。</p>
<p>数组是相同元素的集合，并且可以被索引。结构是任何类型元素的集合，类型不一定相同，因此无法进行索引。因此，数组可以使用常量或变量索引表达式进行索引；索引表达式是整数类型。只能使用常量偏移访问结构元素。</p>
<p>因此，非常量整数表达式唯一可以出现的地方是作为数组索引。因此，当存在时，<span
class="math inline">\(ie_j\)</span>
指示数组索引，并且整个内存表达式引用数组元素。对于具有 m 维且其中 n
为非常量的数组元素访问，将至少有 n 个这样的项。
（一个或多个索引表达式可以是 j+k 的形式，其中 j 和 k 是位置，因此 n
是最小值。）</p>
<p>对于元素占用超过一个字节的一维数组，会涉及到一个尺度。缩放可以实现为移位操作、自我加法或乘以常数，但表达式的规范化会将所有这些更改为乘法操作。多维数组通常实现为子数组的数组，因此高阶索引表达式按子数组的大小缩放。数组和子数组的大小是常数，因此对于任何特定数组，Sj
都是常数。两次数组访问之间 Sj
的变化表明正在访问不同的数组，或者在索引表达式的至少一种情况下似乎正在缩放的部分。</p>
<p><strong>命题 5.9：</strong>（存在 K）当存在时，方程 5.7 的常数 K
可以表示以下各项的总和：</p>
<ol type="1">
<li>全局数组、全局结构或全局变量的地址（sp0 和 pl 不存在）。 K
的这个组件可能是有界的：反编译器的前端可能能够对落在只读或读/写数据部分内的地址提供限制。</li>
<li>从初始堆栈指针值到局部变量、数组或结构（存在
sp0）的（可能为零）偏移量。</li>
<li>一个或多个可能缩放的常量数组索引。</li>
<li>由数组索引表达式中的常数项产生的常数。例如，如果在一个10×10的4字节整数数组中，索引表达式为a*b+4和c*d+8，则数组元素的奥集表达式为(a*b+4)*
40 + (c*d+8)*4，这将规范化为 40*a*b + 4*c*d +
192。在没有其他常数的情况下，K 将是 192，这部分来自常数索引表达式中的 4
和 8，以及元素的大小 (<span class="math inline">\(S_2\)</span>=4)
和子数组的大小 (<span class="math inline">\(S_1\)</span>=40)。</li>
<li>数组下界产生的下标不为零（例如，a: array [-20 .. -11] of real
）。如果多维数组的不止一维具有非零的数组下界，则几个这样的偏移将集中在一起。在
C 语言中，数组总是从索引 0
开始，但是可以构造指向数组中间或数组范围之外的指针，以实现类似的效果，如图
5.16 所示。请注意，在图 5.16(b) 中，可以将 a0+100
传递给另一个函数，该函数使用从 -100 到 -91 的索引访问数组 a0。</li>
<li>父结构内变量、数组或结构的结构成员集。在存在嵌套结构的情况下，可以将多个结构成员
offset 集中在一起，以生成从提供的对象的开始到所涉及的结构成员的开始的
offset。例如，在 <span class="math inline">\(s.t.u[i]\)</span> 中，K
将包括从 s 的开始到 u 的开始的 offsets，或者等效地从 s 的开始到 t
的开始以及 t 的开始以及从t的开始 到u的开始的offset。</li>
</ol>
<figure>
<img src="image-20230518170122323.png" alt="image-20230518170122323" />
<figcaption aria-hidden="true">image-20230518170122323</figcaption>
</figure>
<p>图 5.16：用于访问具有非零索引下限的数组的第一个元素的源代码。</p>
<p>许多组合是可能的；例如如果在具有至少一个常量索引的结构中访问数组，则可以组合选项
(d) 和 (f)，例如s.a[5] 或 s.b[5, y] 其中 s 是一个结构体，a 是一个数组，b
是一个二维数组。</p>
<p><span class="math inline">\(ie_j\)</span>
项表示索引表达式的可变部分，索引表达式的常量部分将 off 拆分为 K
的一部分，如上文选项 5.9(d) 所示。为了节省空间，诸如 ie represents the
variable part of the index expression 之类的语句将缩短为 ie represents
the index expression，理解为索引表达式的常量部分实际上与其他项一起合并到
K 中。</p>
<p>很明显，在要类型化的程序的 IR
中可能会遇到许多模式，并且这些模式对所涉及的各种子表达式的类型做出不同的断言。以下命题总结了可能遇到的模式。</p>
<p><strong>命题 5.10：</strong>m[K]
表示全局变量、全局结构成员或具有常量索引的全局数组元素，可能在全局结构中</p>
<p>K 是选项 5.9(a) 和 5.9(c)-(f) 的总和。如第 83 页的第 3.4.4
节所述，假设体系结构为全局变量访问保留了单独的寄存器，并通过基于该寄存器的偏移访问全局变量，该寄存器由反编译器前端初始化为常量值，以确保所有全局变量访问（在不断传播之后）就是这种形式。由于此模式可以表示全局变量、结构元素或具有固定
offset(s)
的数组元素，因此可以将基本类型提升为结构或数组元素。为了将其纳入类型概念的格中，可以通过稍微滥用术语将此观察表示为
ξ(array(int)) v int。这里的符号 ξ(array(α)) 表示其元素类型为 α
的数组的一个元素。这种关系可以理解为类型“int 数组的元素”是类型“variable
of int”的子类型或等于类型（前者出现频率较低，在某种意义上
比后者更受约束).这同样适用于结构元素；类型为 β 的结构 σ 的元素记为
ξ(σ)(β)，其中结构类型未知或未指定，记为
ξ(structure-containing-β)。这些想法导致以下命题：</p>
<p><strong>命题 5.11：</strong>ξ(array( α)) <span
class="math inline">\(\sqsubseteq\)</span> α，以及
ξ(structure-containing-α) <span
class="math inline">\(\sqsubseteq\)</span> α。</p>
<p>下面将对上述命题进行改进。需要注意的是类型 α 和 ξ(array(α))
严格来说是相同的类型，所以<span
class="math inline">\(\sqsubseteq\)</span> 关系实际上是
=（相等），但是这样表达 α
的各种形式可以让这些形式成为一部分类型的格。当找到各种触发器时（例如，K
在程序的其他地方用作指向数组的指针），可以将与位置关联的类型向下移动格子（例如，从
α 到
ξ(array(α))）。这使得数组和结构成员的处理与类型分析的整个过程更加统一。</p>
<p><strong>命题 5.12：</strong>m[sp0 + K]
表示基于堆栈的局部变量、局部结构成员或具有常量索引的局部数组元素，可能在局部结构中。</p>
<p>K 代表选项 5.9(b)-(f) 的总和。</p>
<p><strong>命题 5.13：</strong>m[l + K]
表示聚合（数组或结构）元素访问。</p>
<p>这里，l 是一个位置，它可以是一个 ie
表示一个未缩放的数组索引，或者一个 pl 表示一个指向聚合的指针。如果 l
在其他地方用作整数或指针，则可以将此表达式重新定义为以下模式之一。由于l+K用作指针，加上两项意味着两项中一项是整数，另一项是指针，那么如果K的值不能是指针，则K必须是整数而
l 是一个指针。正如 5.4
节中指出的，常量是独立的，因此在其他地方使用同一常量不会影响 l 或 K
是否为指针。因此，影响 l 或 K 是 m[l + K] 中的指针的唯一因素是 l
是否在其他地方用作指针或整数，以及 K 是否具有阻止它成为指针的值。</p>
<p>​ <strong>命题 5.14：</strong>m[ie + K] 表示全局数组元素访问。此处 ie
已知用作整数。
K表示选项5.9(a)和5.9(c)-(f)之和，即可能缩放的索引表达式。多维数组可以有其他索引表达式，都是常量</p>
<p><strong>命题 5.15：</strong>m[pl + K]
表示具有常量索引的结构元素访问或数组元素访问。</p>
<p>这里 pl 是指向数组或结构（全局、局部或堆分配）的指针，K 表示选项
5.9(c)-(f) 的总和。例如，m[pl + K] 可以表示 s.m，其中 s
是结构类型的变量（用 pl 表示），m 是 s 的成员（K 表示从 s 开始到 m
的偏移集）。它还可以表示 a[C]，其中 a 是数组类型的变量（用 pl 表示），C
是一个常量，其值为 <span
class="math inline">\(\frac{K}{sizeof(a[0])}\)</span>。除非在别处发现非常量数组访问，否则无法区分这两种表示。</p>
<figure>
<img src="image-20230519101057542.png" alt="image-20230519101057542" />
<figcaption aria-hidden="true">image-20230519101057542</figcaption>
</figure>
<p>图 5.17：使用表示法 m[pl + K] 的等价程序。</p>
<p>m[pl + K] 的两种表示是等价的，如图 5.17
所示。因此，这两种表述都不正确。结构表示看起来更自然，因此可以将此模式视为结构引用，除非并且直到找到具有非常量索引的数组引用。在任何一种情况下，由于可以随时在其他地方找到具有非常量索引的数组引用，因此数组元素在某种意义上比结构元素更受约束。再次滥用术语，这可以表示为
ξ(array(α)) <span class="math inline">\(\sqsubseteq\)</span> ξ(structure
containing α。</p>
<p>将其与命题 5.11 结合并注意到数组可以包含在结构中得到以下命题：</p>
<p>​ <strong>命题 5.16:</strong> ξ(structure-containing-ξ(array(α)))
<span class="math inline">\(\sqsubseteq\)</span> ξ(array(α)) <span
class="math inline">\(\sqsubseteq\)</span> ξ(structure-containing-α)
<span class="math inline">\(\sqsubseteq\)</span> a.</p>
<p>这得到图 5.18 中所示的格片段。</p>
<p>上面的例子说明了这一点，即用于反编译的类型格至少部分不是基于源语言或程序的编写方式，而是基于在类型分析过程中如何发现信息。</p>
<figure>
<img src="image-20230519101330101.png" alt="image-20230519101330101" />
<figcaption aria-hidden="true">image-20230519101330101</figcaption>
</figure>
<p>图
5.18：与包含数组元素、数组元素、结构成员和普通变量的结构相关的类型格片段</p>
<p><strong>命题5.17：</strong><span class="math inline">\(m[sp_0 + ie +
K]\)</span>表示局部数组元素访问</p>
<p>ie 是数组索引表达式，K 将选项 5.9(b)-(f) 合并在一起。</p>
<p>没有模式 <span class="math inline">\(m[sp_0 + pl + K]\)</span> 因为
<span class="math inline">\(sp_0\)</span> 和 pl
都是指针，并且假设指针永远不会和指针相加。</p>
<p>其中 <span class="math inline">\(l_1\)</span> 和 <span
class="math inline">\(l_2\)</span> 是位置的模式 <span
class="math inline">\(m[l_1 + l_2 + K]\)</span>
很有趣，因为两个位置都可以匹配 ie 或 pl。在发现 <span
class="math inline">\(l_1\)</span> 或 <span
class="math inline">\(l_2\)</span>
的其他用途提供有关位置的类型信息之前，不知道哪个位置或 K 是指针。</p>
<p><strong>命题 5.18：</strong><span class="math inline">\(m[l_1 + l_2 +
K]\)</span> 表示数组元素访问。如果 <span
class="math inline">\(l_1\)</span> 或 <span
class="math inline">\(l_2\)</span> 在别处用作指针，或者 K
的值不能是指针并且 <span class="math inline">\(l_1\)</span> 或 <span
class="math inline">\(l_2\)</span>
在别处用作指针或整数，则可以将此表达式重新定义为以下模式：</p>
<p>​ <strong>命题 5.19：</strong><span class="math inline">\(m[ie + pl +
K]\)</span> 表示数组元素访问。
ie是索引表达式，pl是指向数组的指针（全局、局部或堆分配），K代表选项5.9(c)-(f)的总和.</p>
<p>如果 l1 和 l2 在别处都作为整数使用，那么命题 5.18
可以重新定义为以下模式：</p>
<p>​ <strong>命题 5.20：</strong><span class="math inline">\(m[ie_1 +
ie_2 + K]\)</span> 表示全局数组元素访问。非常数索引表达式为<span
class="math inline">\(ie_1 +
ie_2\)</span>，K表示选项5.9(a)和(c)-(f)之和。</p>
<p>命题 5.18 中模式的另一个特例是 K=0。 <span
class="math inline">\(l_1\)</span> 和 <span
class="math inline">\(l_2\)</span>
之一必须是整数，另一个必须是指针。根据命题
5.8，这意味着整数表达式表示数组索引。如果 <span
class="math inline">\(l_1\)</span> 或 <span
class="math inline">\(l_2\)</span>
之一在其他地方用作指针或整数，则此模式可以重新定义为以下模式。</p>
<p>​ <strong>命题 5.21：</strong><span class="math inline">\(m[ie +
pl]\)</span> 表示数组元素访问。 ie 是可能缩放的索引表达式，而 pl
是指向数组的指针。</p>
<p><strong>命题 5.22：</strong><span class="math inline">\(m[S_1*ie_1 +
S_2*ie_2 + ... + S_n*ie_n + K]\)</span> 表示 m 维全局数组元素访问。这里
<span class="math inline">\(ie_j\)</span> 是索引表达式，<span
class="math inline">\(S_1..S_n\)</span> 是比例常数，K 将选项 5.9(a) 和
5.9(c)-(f) 合并在一起。如果有多个位置的索引表达式，则 m 可能小于
n。如果存在常量索引表达式，则 m 可能超过
n。这两个因素可以抵消或不存在，在这种情况下 m = n。</p>
<p><strong>命题 5.23：</strong><span class="math inline">\(m[pl +
S_1*ie_1 + S_2*ie_2 + ... + S_n*ie_n + K]\)</span> 表示一个 m
维数组元素访问。</p>
<p>这里 pl 指向数组或包含数组的结构，<span
class="math inline">\(ie_j\)</span> 是索引表达式，<span
class="math inline">\(S_1.. S_n\)</span> 是缩放常数，K 将选项 5.9(a) 和
5.9(c)-(f) 合并在一起。</p>
<p><strong>命题 5.24：</strong><span class="math inline">\(m[sp_0 +
S_1*l_1 + S_2*l_2 + ... + S_n*l_n + K]\)</span> 表示一个 m
维局部数组元素访问。</p>
<p>这里 <span class="math inline">\(l_i\)</span> 是索引表达式，<span
class="math inline">\(S_1..S_n\)</span> 是缩放常数，K 将选项 5.9(b)-(f)
组合在一起。</p>
<p><strong>命题
5.25：</strong>假定其他表达式是指针表达式的间接寻址。</p>
<p>C 语言中的示例包括 <span class="math inline">\((*p)[i]\)</span> 和
<span
class="math inline">\(*(ptrs[j])\)</span>，其中上述表达式已应用于整个表达式的一部分以生成数组索引。</p>
<h2 id="划分数据段">5.9 划分数据段</h2>
<p>反编译器需要一个类似于编译器符号表（将符号映射到地址和类型）的数据结构来将地址映射到符号和类型。</p>
<p>第 155 页上的第 5.2.3
节指出，通常使用一系列机器代码指令而不是单个指令来操作聚合类型。例如，要对数组的内容求和，通常会使用循环。如果一个结构有
5 个基本类型的元素，通常至少有 5
段单独的代码来访问所有元素。换句话说，聚合类型的某些方面（例如元素数量和总大小）是许多指令的结果，而不是单个指令的结果。这与基本类型的类型和大小不同，后者通常可从单个指令获得。</p>
<p>因此，需要一个数据结构来构建数据部分如何组成的图景。这个过程可以被认为是将数据部分划分为各种类型的各种变量。这种数据结构在某种意义上相当于编译器或汇编器中最初为数据分配地址的符号表。在编译器或汇编器中，符号表本质上是一个从符号名到类型和数据地址的映射。在反编译器中，可以称为数据映射的适当数据结构是从数据地址到符号名称和类型的映射。</p>
<p>至少需要考虑两个地址空间：包含全局变量的全局地址空间和包含局部变量的堆栈局部地址空间。还有堆地址空间，其中变量（通常是聚合）是使用语言关键字（如
new）或调用堆分配库函数（如
malloc）创建的。但是，堆对象的分配通常一次只分配一个对象，并且设计的地址不会重叠。每个地址映射将使用单独的数据映射</p>
<h3 id="并置变量colocated-variables">5.9.1 并置变量(Colocated
Variables)</h3>
<p>需要逃逸分析来确定分离共置变量的有效性。</p>
<p>作为一种节省空间的优化，编译器可以将多个变量分配给同一地址。一旦确定这是安全的，这种托管对编译器来说就没有什么成本；它只是在符号表中有一些条目具有相同或重叠的数据地址值。然而，对于反编译器，问题要复杂得多。数据地址并不唯一标识数据映射条目，如图
5.19 所示。</p>
<figure>
<img src="image-20230519103443826.png" alt="image-20230519103443826" />
<figcaption aria-hidden="true">image-20230519103443826</figcaption>
</figure>
<p>图 5.19：一个变量的活跃范围的各种可能</p>
<p>在图5.19(a)和(b)中，虽然变量有多种定义，但变量的定义和使用是通过φ-functions统一起来的。在情况
(c) 和 (d)
中，变量有多个活跃范围，从一个活跃范围到下一个活跃范围的数据流间断可以证明这一点。如果一个变量有多个活跃期，并且生存期中变量的类型不同，则必须生成两个或更多变量，因为编译器显然已将不相关的变量并置，并且每个命名变量只能有一种类型。</p>
<p>尽管必须生成多个名称，但仍然可以选择将这些名称的地址联合起来（例如使用
C
Union），或者将它们分离为独立变量，生成代码的编译器可以将其分配给不同的地址。</p>
<p>然而，在各种活跃范围的类型一致的情况下，通常无法确定编译器是否将碰巧具有相同类型的不相关变量放在一起，或者原始源代码是否在多个活跃范围中使用了一个变量.后者可能发生的一个例子是数组索引在程序的第二个循环中被重新使用。始终将活动范围分成多个变量可能会使生成的源代码因过多的变量声明而变得混乱。当变量被赋予有意义的名称时，永远不将活动变量分成单独的变量可能会导致混淆。对一个活跃范围有意义的名称可能对其他活跃范围不正确。在这种情况下，专家用户可能会覆盖默认的反编译器行为。尽管可能会降低可读性，但这里没有不可避免地出现错误输出的情况。</p>
<p>有时，中间表示将有效地获取变量或聚合元素的地址。在高层，这可能是显式的，如
C 中的 &amp; 一元运算符，或隐式的，如在 Java
中引用对象时（引用是字节码级别的指针）。获取地址可能与最终使用该变量或聚合元素相去甚远。变量或聚合元素地址的类型模式与第
5.8 节相同，但外部 m[. . .]
操作已删除。在某些情况下，这些将是非常常见的表达式，例如 K 或 ie +
K。显然，并非所有此类模式都表示全局变量的地址或聚合元素的地址。</p>
<p>因此，这些模式在类型分析之后被应用，并且仅在类型分析显示模式（不包括
m[...]）是指针类型时使用。显然，第 5.8 节的模式带有 m[...]
保证内部表达式用作指针。</p>
<p>获取变量地址时，会引用该变量，但不会直接定义或使用它。数据流信息最终来自定义或使用，但当引用传递给库函数时，使用信息通常被浓缩为指定类型的常量引用或非常量引用。常量引用意味着所引用的位置已使用但未定义。一个非常量引用可能意味着各种定义和使用场景，所以保守的总结是可以定义和可以使用。库函数的目的可能比其原型携带更多的数据流信息。例如，CString::CString()
的 this 参数（字符串类的构造函数过程）在定义它之前不使用引用位置
(*this)。这个额外的信息可以帮助分离变量的生命范围，这些变量的存储与其他对象位于同一位置。虽然使用类型来帮助分离位于同一位置的变量可能很诱人，但原始程序使用强制类型转换的可能性使得类型对于此目的的可靠性降低。在
CString
构造函数的情况下，总是会启动一个新的活跃范围，但构造函数过程的原型中并未捕获这一事实。</p>
<figure>
<img src="image-20230519103918965.png" alt="image-20230519103918965" />
<figcaption aria-hidden="true">image-20230519103918965</figcaption>
</figure>
<p>图 5.20：带有并置变量并获取地址的程序。</p>
<p>获取与其他变量位于同一位置的变量的地址可能会导致不清楚获取的是哪个对象的地址。例如，考虑图
5.20(a) 的机器码程序。位置 m[esp-16]
有三个独立的变量共享该位置。假设已知 proc1 和 proc2 保留且不使用 edi。用
proc2 的地址定义 m[esp-16]
完全杀死了整型变量的有效范围，但在程序早期获取的地址在程序的后期被使用，此时只有
char 定义是居住。 m[esp-16] 的定义不会终止单独变量 edi
的范围，它继续保持值 esp-16。 esp-16 代表什么的解释随着 m[esp-16]
的定义而改变，从 &amp;i 到 &amp;proc2 再到一个字符的地址。
edi的类型信息通过address taking操作链接到 m[esp-16]的数据流信息</p>
<p>在这种情况下，如果没有其他用途的 edi 并且没有其他指令获取 m[esp-16]
的地址，则三个变量可以在反编译输出中分开，如图 5.20(b) 所示。然而，如果
m[esi-16] 的地址逃脱了过程（例如 edi 被传递给
proc1），这种分离通常是不安全的。例如，可能不知道地址转义到的过程（这里是proc1）是否定义了原始变量。如果它只使用原始变量，那么它将作为一个整数来使用，参考图
5.20(b) 中的
i。但是，它可以定义和使用任何类型的位置。最后，它可以将地址复制到一个全局变量，该变量在变量超出范围之前被调用的某个过程使用。在这种情况下，传递给
proc1 的类型取决于实际使用该位置时哪个并置变量是活动的。
（编译器必须非常聪明才能安全地安排它，但这是可能的。）因此，如果地址逃逸，保守的方法是将三个变量声明为联合，就像
eect
中的机器代码所做的那样。这种逃逸分析通常由编译器执行，以确保优化的有效性；反编译器需要它来确保分离并置变量的有效性。</p>
<p>如果图 5.20 示例中的 proc1 是对 m[esp-16]
是非常量引用参数的库函数的调用，则会出现同样的歧义。参数的类型将是一个很大的线索，但由于存在强制转换的可能性，使用类型信息可能会导致反编译错误。因此，虽然库函数是类型信息的极好来源，但它们并不是可以帮助分离并置变量的数据流信息的良好来源。这可能是一种，至少部分反编译库函数有用的情况。</p>
<p>并置变量是一种原始程序地址代表多个原始变量的情况。第 20 页的图 1.6
显示了一个程序，其中使用相同的立即值（一个原始指针和两个偏移指针）在机器代码级别访问三个数组。这是一种不同的情况，尽管三个变量位于不同的地址，但使用相同的立即数常量来引用具有不同范围的索引的这些变量。它说明了公式
5.7 的常数 K 如何具有许多内部成分的问题，特别是命题 5.9(e) 的常数 K</p>
<p>图 5.21 显示了三个嵌套结构的声明。第一个元素的地址可以引用
large、large.medium、large.medium.small 或 large.medium.small.a
中的任何一个。其中每一个的类型都是不同的，因此可以使用类型分析来决定需要哪些可能的引用。</p>
<figure>
<img src="image-20230519104959738.png" alt="image-20230519104959738" />
<figcaption aria-hidden="true">image-20230519104959738</figcaption>
</figure>
<p>图 5.21：嵌套结构体</p>
<h2 id="特殊类型">5.10 特殊类型</h2>
<p>需要一些特殊类型来满足某些机器语言细节，例如upper（float64）。</p>
<p>除了基本类型、聚合和指针之外，一些特殊类型在反编译中也很有用。显然不需要类型信息（&gt;
在类型格中，或 C 类型 void），并且可能过度约束（在类型格中为
⊥）。许多机器使用成对的位置（两个寄存器，或两个字大小的内存位置）实现双字类型。因此，定义
upper(τ) 和 lower(τ) 可能很有用，其中 τ 是类型变量，分别指代 τ
的上半部分或下半部分。对于较大的类型，这些可以组合，例如lower(upper(float128))
对于 128 位浮动点类型的位 64 到 95。例如，size32 将与 upper(float64)
兼容。在适当的情况下，成对的上层和下层类型可以合并成更大的类型，例如其中双字值在机器语言级别在两个字大小的位置传递给函数，这可以用一个变量替换（例如double类型）</p>
<h2 id="相关工作">5.11 相关工作</h2>
<p>大多数相关工作都是面向编译器的，因此没有解决机器代码反编译引起的一些问题。</p>
<p>许多作者都讨论过使用迭代数据流方程来解决编译器问题，首先是 Allen 和
Cocke [All70, AC72] 以及 Kildall [Kil73]。 Kam 和 Ullman [KU76]
证明了这些系统的理论性质</p>
<p>Khedker、Dhamdhere 和 Mycroft
主张更复杂的数据流分析框架，但他们试图解决动态类型语言 [KDM03]
的类型推断这一更困难的问题。</p>
<p>Guilfanov [Gui01] 讨论了通过可执行程序的 IR
从库函数传播类型的问题。但是，他没有尝试推断指令中固有的类型</p>
<p>通过为每个变量构建一个独特的评估图 [CCF91]，可以以比 SSA
形式支持的更稀疏的方式解决数据流问题。然而，这种方法受到为每个变量生成评估图以及该框架所需的一些其他表的空间和时间成本的影响。</p>
<p>Guo等，报告了汇编语言的指针分析，他们建议可以将其扩展以在运行时使用
[GBT+05]。在处理加法指令时，他们假设数组和结构元素访问的地址表达式的形式为
r2 + i × l + c，其中 i 是一个非常量（索引）值，l 是大小数组元素的个数，c
为常量。这与公式 5.7
的更复杂的表达式形成对比。后者比较复杂，主要是为了表达多维数组，例如a[x][y]
例如m[r1 * 40 + r2 * 4] + 8。但是，后者可以归一化为 m[(r1 * 10 + r2) *
4] + 8，表示 a[x*10+y]，其中
10是行中的元素数。机器代码数组似乎可以像这样分析，并在稍后阶段转换回
a[x][y] 或 a[x, y] 格式。</p>
<h2 id="未来工作">5.12 未来工作</h2>
<p>虽然已经取得了很好的进展，但在机器代码反编译器的类型分析成熟之前，还有很多工作要做。</p>
<p>本章中提出的大部分想法至少已在 Boomerang 反编译器 [Boo02]
中部分实现。诸如基于迭代数据流的类型分析问题解决方案等基本原则足以用于类型化简单的程序。然而，类型分析的几个更高级的方面需要实验验证，包括</p>
<ul>
<li>更不寻常的情况涉及指针大小的加法和减法指令（第 177 页第 5.7.4
节）；</li>
<li>将 K 的值拆分为其各种可能的来源（第 181 页的命题
5.9），这可能需要对指针和索引变量进行范围分析；</li>
<li>分离并置变量和逃逸分析（第 187 页第 5.9.1 节）；和</li>
<li>划分数据段（第 186 页第 5.9 节）</li>
</ul>
<p>指针的范围分析对于初始化聚合数据也很重要，如第 5.2.4 节所述</p>
<p>当前对数组的处理假定多维数组的数组实现类 C
数组。应该可以修改高层的模式以适应其他实现</p>
<p>C++
等面向对象的语言引入了更多需要考虑的元素，例如成员指针、类层次结构等。其中一些功能将在下一章中讨论</p>
<h2 id="ssa-的作用">5.13 SSA 的作用</h2>
<p>在 SSA
形式下，表达式传播与内存表达式简化相结合，为高级模式分析打下基础，并且
SSA 形式允许类型信息的稀疏表示。</p>
<p>第 178 页第 5.8
节的高级模式需要将整数常量与其他整数表达式区分开来。这很容易通过基于SSA的表达式传播和简化的组合来实现。这些还消除了
RISC 编译器生成的部分常量，这在任何类型分析系统中处理起来都很尴尬。</p>
<p>SSA 形式还允许在位置定义处对类型信息进行稀疏表示。每个 SSA
定义一种类型存储与每个基本块每个活动变量一种类型存储的要求形成对比，这是传统的基于bit
vector的迭代框架所要求的。</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Decompile</tag>
      </tags>
  </entry>
  <entry>
    <title>自动机与程序分析</title>
    <url>/2023/%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>自动机与程序分析</p>
<span id="more"></span>
<p>最早在程序分析中遇到自动机，是在学IFDS的时候（比如<a
href="https://www.cnblogs.com/LittleHann/p/16381920.html#_label2">这里</a>），里面需要根据call和return指令，做类似括号匹配的操作。</p>
<h2 id="自动机基础">自动机基础</h2>
<p>参考 《形式语言与自动机导论%20%20（原书第三版）_11454864.pdf》</p>
<h3 id="下推自动机push-down-automata-pda">下推自动机（Push Down
Automata, PDA）</h3>
<p>背景知识是，编译原理中，有限状态自动机和正则表达式的知识。另外，也需要一些上下文无关语言的知识。</p>
<p>下推自动机，在有限状态自动机上，额外增加了一个栈，每次转换状态的时候，允许向栈上压入，或弹出元素。</p>
<p>这里介绍一个例子，我们想要匹配偶数长度的，包含a,b两种字符的回文字符串。可以定义一个语法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">R -&gt; aRa | bRb | ε</span><br></pre></td></tr></table></figure>
<p>同时，我们可以定义一个下推自动机(来自这个<a
href="https://www.youtube.com/watch?v=BxA-aI2dyRo&amp;list=PLBlnK6fEyqRgp46KUv4ZY69yXmpwKOIev&amp;index=89">youtube视频</a>)。自动机包含四个状态：</p>
<ul>
<li>初始状态q1：读入ε空字符（不读入字符），同时把开始符号Z0压到栈中，可以转换到状态q2</li>
<li>q2：读入字符a，或字符b，同时把字符压入栈中，可以转换到状态q2（不变）。或者直接转换到状态q3。</li>
<li>q3：读入字符a，或字符b，同时弹出相应字符，可以转换到状态q3（字符和栈操作绑定，必须完整执行，否则不能转换）。弹出栈顶Z0符号后可以转换到结束状态q4</li>
<li>如果字符串走到了q4状态，且输入结束了，则表示自动机接受了这个输入。</li>
</ul>
<p>这里是不确定性下推自动机，按规则走时有多条路径。只要有可能走到结束，则说明该字符串被接受。其他情况是有可能走不下去的。</p>
<figure>
<img src="自动机1.png" alt="一个自动机的例子" />
<figcaption aria-hidden="true">一个自动机的例子</figcaption>
</figure>
<p><strong>下推自动机和上下文无关语言的一致性</strong>：</p>
<p>这里称上下文无关语言为Context Free Grammar, CFG。下推自动机被称为Push
Down Automata, PDA。</p>
<p>如何把CFG转为PDA？ -
在CFG根据规则替换非终结符的时候，我们约定每次仅替换最左侧的终结符。 -
对于每个状态正在推导的CFG，它包含终结符和非终结符的混合序列。我们从最左侧开始扫描，遇到的所有终结符放在PDA的输出上，剩下的放在PDA的栈里。
-
我们每次看栈上最左侧的非终结符，然后看它有哪些规则，比如<code>R -&gt; aRa</code>，我们对应此时有PDA的状态转换规则，即将这个非终结符替换成对应规则应用后的结果，即此时对当前状态有规则，弹出栈上的<code>R</code>，压入<code>aRa</code>，转换到下一个状态。
-
如果栈上是终结符，此时允许读入相同的终结符，弹出栈顶上的这个终结符。</p>
<figure>
<img src="CFG转PDA.png" alt="CFG转PDA" />
<figcaption aria-hidden="true">CFG转PDA</figcaption>
</figure>
<p>对于CFG，我们有时候不知道用哪个推导规则合适，这个正好对应上不确定性的自动机中，有多种状态转移，不知道转移为哪一种最后能到终态。因此，虽然有这种转换，但是并不代表能够高效解决确定字符串是否属于语言的问题。</p>
<h2 id="什么是-cfl-reachability-problem">什么是 CFL Reachability
Problem</h2>
<p>阅读《Interconvertibility of Set Constraints and Context-Free
Language Reachability》</p>
<p>我们知道普通的有向图的可达问题。但是这种图可达性太简单了。比如，多个函数的控制流图，它首先把每个函数的控制流图放上来，然后对于call指令，增加call指令到被调用函数开头的调用边，以及被调用函数结束时，返回call指令继续执行的边。这样构建出来的图会发现存在一个问题，即没有考虑到返回的时候要根据调用栈返回的情况。返回的时候，由于边就是连着的，直接看可达性的话我可以返回到任意调用点之后继续执行，然而实际情况是只会根据之前call是从哪里过来的，然后返回那边执行。</p>
<p>CFL Reachibility问题，就是结合CFG，给图可达性问题增加一些限制。</p>
<p>首先，我们允许对有向图上每一条边上都标上CFG里的终结符或者非终结符。对于每一条路径，把边上标记的符号连起来就是一个字符串。如果这个字符串属于某个CFG语言，即这个字符串能从CFG的开始符号S，通过CFG语法规则推导得到，则我们称这条路径属于S-Path。</p>
<p>all pair版本的图可达问题，就是求出所有的这样顶点对 v1,
v2，使得v1能走到v2。我们定义all
pair版本的S-Path问题为，找出所有的顶点对，使得存在一条v1到v2，且属于S-Path的路径。</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>StaticAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机专业入门应该做什么</title>
    <url>/2023/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E5%85%A5%E9%97%A8%E5%BA%94%E8%AF%A5%E5%81%9A%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<p>仔细回顾我这些年，也有很多做得不够好的地方。希望有一些经验能帮到其他人。我觉得开始应该多接触一些操作系统，计算机组成原理，编译原理的知识，把整个计算机学科的基础打好。</p>
<span id="more"></span>
<h2 id="总结">总结</h2>
<p>我觉得刚上来最重要的是开阔一下视野，感觉的那时候，说到计算机就想到算法竞赛了，但是后来才发现，计算机领域里算法其实只是一小部分。(不过如果想清楚确实要专心搞算法竞赛，也挺好的。)</p>
<p>我觉得我那时候对我非常有用的事情是，去图书馆看了很多计算机导论的书，把计算机的几个学科之间的关系弄清楚了。那时候虽然不懂，但是也知道计算机几门核心的基础课：数据结构与算法，操作系统，计算机网络，计算机组成原理，数据库。它们具体是做什么的，什么关系也不太明白。那时候本来就对计算机感兴趣，经常周末去图书馆借书，没课的下午或晚上在图书馆找本书看，感觉就是看科普书。过了几个星期之后，尤其是理解了<strong>计算机芯片怎么从门电路到汇编语言到操作系统到上层应用</strong>之后，感觉视野开阔了很多，每个方向都很有意思，值得探索。</p>
<p>首先当然可以多接触一些新的编程语言，多“重新入门”几次编程。可以感受到JavaScript的事件性，Go语言的并发性，Rust语言的所有权带来的安全性。同时可以思考解释型语言和编译型语言的区别。</p>
<p>还可以学习电脑装机，磁盘格式，多安装一些新的操作系统，尤其是Ubuntu，同时熟悉Linux的终端界面和SSH连接服务器。</p>
<p>其次可以入门的是Web开发。Web开发的资源很多，就和Python编程入门一样。首先它反馈性很强，学会了立刻可以给自己搞个个人网站，而且用途也很广，以后无论是课程项目套GUI，给自己写小项目，甚至未来就业都非常有用。同时它也是入门计算机网络的绝佳路径。学习路径一般是从
HTML/CSS 到
JavaScript，然后学计网和HTTP协议，写简单后端。当你把握了计网和协议，Web开发的精髓之后，各种Web框架都能很快上手了。后续学Web安全也离不开这些知识。</p>
<p>稍微提一句GUI，图形界面编程看似离我们很近，可以直接入门，不过在计算机领域里其实只是操作系统里图形界面环境的一小部分内容。不过也还是值得学习的，但是建议不要拘泥于某一种语言，而是不被语言限制，走到大路上。比如Windows图形界面大可以从C#开始入门，不需要先去接触C++
Qt。然后可以尝试简单的Android开发，用Java或者Kotlin。这些都可以在图书馆借到书，在看书的过程中就有代入感了，能了解到开发调试的全流程。</p>
<p>总结：</p>
<ul>
<li>学习路线上，为了避免缺乏基础知识，绕过了前置知识，可以从以下几个方面入门：
<ul>
<li>找更多计算机导论相关数据，进一步入门主要学科（计算机组成原理，操作系统），直到了解了计算机芯片怎么从门电路到汇编语言到操作系统到上层应用的全流程。</li>
<li>学习更多编程语言：Javascript，Golang，Rust</li>
<li>学习更多操作系统与开发平台
<ul>
<li>前端开发，计算机网络基础，后端开发。</li>
<li>Android、iOS移动开发</li>
<li>Windows GUI图形界面编程，C#</li>
</ul></li>
</ul></li>
</ul>
<p>入门之后自然知道之后怎么学了。</p>
<p>多看书，多写代码。不能过度纠结怎么写代码，该搞什么项目，而是要动手做起来。找到正反馈。</p>
<h2 id="相关的比赛">相关的比赛</h2>
<p>如果要为大学阶段设立目标的话，这些比赛是不错的选择。</p>
<p>最近几年出现了很多新的活动和比赛，比如OSPP和计算机系统能力大赛。国内相关的学习环境确实在不断变好。不得不说，现在互联网时代，学习资源越来越多，但是也意味着必须要坚定自学的信念。</p>
<p>首先是一些网课。这些网课不得不说都有难度，但是也学得深入。做好长线学习的准备。我在学ucore的时候，放弃了好几次，后面又重新回来。学习可能就是这样，挺正常的。</p>
<p>毕竟自己之后也要学这些课，提前学一学，后面更轻松。学习就是这样，看不懂也没关系，继续往后看，先把能看懂的都看了。下次回来再看的时候，能看懂的更多了。多看几遍之后就可以动手做实验，写作业代码了。</p>
<ul>
<li>值得学的网课
<ul>
<li>清华大学
向勇、陈渝老师的操作系统课：老师也积极组织开源社区，rcore也经常会有夏令营活动。
<ul>
<li>UCore</li>
<li><a
href="https://rcore-os.cn/rCore-Tutorial-deploy/docs/pre-lab/env.html">RCore-Tutorial</a>
从零学习</li>
</ul></li>
<li><a
href="http://wjk.moe/2022/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E8%B5%9B/">编译器相关的资料</a>
<ul>
<li>北航mini-sysY实验教程：<a
href="https://github.com/BUAA-SE-Compiling">Github</a> <a
href="https://buaa-se-compiling.github.io/miniSysY-tutorial/">实验指导书</a>
这个教程依然是偏前端的，时候早期学习完词法分析，语法分析后实践加深理解。</li>
<li>北大编译课实践教程：这个是参加比赛时久仰大名的 邢其正 大佬的教程。<a
href="https://pku-minic.github.io/online-doc/">pku-minic</a> <a
href="https://github.com/pku-minic/online-doc">Github</a>
在当时大量教程止步于前端到中端就结束的时候，只有这个教程讲到了后端。</li>
</ul></li>
<li>计算机组成原理：<a
href="https://www.bilibili.com/video/BV1jJ411m7Hr">自己动手画CPU</a>
这个课讲清楚了，从逻辑电路是怎么实现CPU的，关键就在于这个时序电路和寄存器，构成的每个CPU周期，每次执行不同的运算。</li>
</ul></li>
</ul>
<p>还有很多比赛，可以作为自己的目标而奋斗，让自己更有学习动力。其次，每个比赛作为关键词去搜，都能搜出很多相关的学习资源。</p>
<ul>
<li><a href="https://compiler.educg.net/#/">计算机系统能力大赛</a>
<ul>
<li>操作系统赛：深入操作系统原理，借助CPU的硬件支持，调度进程，使用外设，管理整个计算机系统。</li>
<li>编译系统赛：深入编程语言原理，实现一个编译器，从高级语言转换为汇编语言。</li>
<li>龙芯杯，一生一芯项目：深入计算机硬件设计，设计CPU。</li>
</ul></li>
</ul>
<p>当你把视野仅仅放在国内，某种意义上都还是狭隘的。如果语言不是障碍，那么可以放眼全球的顶尖大学，他们很多课件和课程都是公开的，也是绝佳的学习资源。</p>
<p>最后是开源。开源是一种理念，当你发现一个软件有问题的时候，你可以从用户转变为开发者，直接debug修复，然后让原来的开发者审核合并你的修改。而且每一次这样的参与你都可以写进简历。</p>
<ul>
<li>开源开发：
<ul>
<li>Google Summer of Code &amp; Google Summer of Docs</li>
<li><a
href="https://summer-ospp.ac.cn/">OSPP</a>：国内的类似GSOC的活动。</li>
<li>Linux内核：LFX Mentorship</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>学术论文写作总结</title>
    <url>/2023/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>学术论文写作总结</p>
<span id="more"></span>
<h2 id="概述">概述</h2>
<p>写一篇论文大致要经过下面几个步骤:</p>
<ol type="1">
<li>基本idea: 有基本的idea，技术路线。基本的内容。</li>
<li>搭建论文的最基本的框架列出大标题。写出基本的内容。</li>
<li>画出架构图，给出例子作为图。给出实验数据的图。</li>
<li>写出主要内容，并基于图介绍。</li>
<li>改进图表，更加紧凑，更加逻辑清晰。</li>
<li>改进叙事逻辑：叙事思路上逻辑需要清晰，更易懂。</li>
<li>不断完善和改进论文细节。</li>
</ol>
<p>语言上，关注这两个问题：</p>
<ol type="1">
<li>是否容易看懂？</li>
<li>是否有更准确的说法？是否别人根据我的说法就可以复现？</li>
<li>必要的铺垫和呼应 vs. 无意义的重复。向前引用，而非重新描述。</li>
</ol>
<h2 id="资料和工具">资料和工具</h2>
<ul>
<li>How to Write a Good Scientific Paper 作者：Chris. A. Mack.</li>
<li><a href="https://simon.peytonjones.org/great-research-paper/">How to
Write a Great Research Paper</a> Simon Peyton Jones</li>
<li><a
href="https://github.com/am009/git-latexdiff-web">git-latexdiff-web</a>：上传两个overleaf压缩包，运行git-latexdiff，返回一个可以看出有哪些修改的pdf。可以在其他人帮改paper后得到反馈。</li>
</ul>
<h2 id="英语写作">英语写作</h2>
<p>不要尝试自己写了，容易有语法错误。只需要提升英语阅读能力，知道一段文字比另外一段好。使用大模型翻译，比如：<a
href="https://poe.com/TranslatingChinese">Poe翻译机器人</a>：直接输入中文，内置提示词会让ChatGPT将内容直接翻译为英文。</p>
<ul>
<li>先写出中文、或者垃圾英文，然后让大模型按照这个思路翻译润色。</li>
<li>修改时：直接用中文修改，然后让大模型翻译润色这个中英混杂片段。</li>
<li>问大模型这个怎么说比较好，让他按要求改成想要的说法。</li>
<li>润色：Act as a language expert, Paraphrase the text using more
academic and scientific language. Polish the writing to meet the
academic style, improve the spelling, grammar, clarity, concision and
overall readability. When necessary, rewrite the whole sentence.
Furthermore, list all modification and explain the reasons to do so in
markdown table.</li>
<li>找语法错误：Proofread the following text for spelling and
grammatical errors and rewrite it with corrections.</li>
</ul>
<h2 id="找idea">找idea</h2>
<ul>
<li>Generate 10 academic research questions about</li>
<li>Suggest novel applications</li>
<li>Identify gaps in the literature</li>
<li>Identify potential areas for future research. Find a research topic
for a PhD in this area, Write a detailed proposal on the following
research topic.</li>
</ul>
<h2 id="论文结构">论文结构</h2>
<p>Good Logic: -
总体结构上，都是形成了模式的。就像填模板一样，不需要要有格式上的创新。 -
宏观是逻辑是一条线下来，微观上段落都是总分的结构。 -
多找其他人看一看自己写的好不好。</p>
<p><strong>写Abstract、Introduction可以留到最后。</strong>
Abstract需要考虑让没有背景的人也能看懂。Introduction也不需要写得太细节，即使能很好地概况你的内容。写清楚是正文approach的事情。最最早的时候，可以把内容都当做introduction写。然后，将内容整理分开为Backround，Challenge，Method三部分，然后Challenge后续可能扩写为Motivating
Example部分。 最开始写的时候跳过Abstract，</p>
<p>常见的论文结构 - Introduction - Background - Methodology - Evaluation
- Related Work</p>
<p>根据需要调整： - 通常都会有一个Motivating
Example。直接在例子上解释整个流程。如果方便写的话一定要写，例子是最容易懂的。
- Background和Related work可以合并放到前面。 - 如果没有Motivating
Example导致内容不多，也可以Method前面有单独的Challenge一章，为Challenge编号，后续在Method引用。</p>
<h3 id="abstract">Abstract</h3>
<p>为下面的内容写一份论文摘要，不要超过250词，分别按顺序讲述：背景、工作重要性、挑战、解决方案、实验结果。</p>
<ul>
<li><strong>不该写什么：</strong>
<ul>
<li>未来工作： 绝对不要出现在摘要里。</li>
<li>空洞的吹嘘：
避免“本文提出了一种开创性的方法”这类无实质内容的自我评价，用事实（结果）说话。</li>
<li>图表、公式、引用： 摘要应自成一体，无需引用其他部分或文献。</li>
</ul></li>
</ul>
<h3 id="introduction">Introduction</h3>
<p>One clear sharp idea，不要混合多个问题，有多个idea就写多个paper。Make
certain that the reader is in no doubt what the idea is.</p>
<ul>
<li><strong>使命：</strong>
解释你研究的问题，然后说明你的贡献，不要太复杂。直接举例子也很好。The
list of contributions drives the entire paper:</li>
<li>Introduction解释问题的时候，直接make
claim，或者挑明Challenge，然后引用后面的章节。</li>
<li>讲一个好故事，让读者相信你研究的问题既重要又有趣，并且目前还没有完美的解决方案，从而为你的方法登场做好铺垫。</li>
<li><strong>该写什么：</strong>
<ol type="1">
<li><strong>背景与重要性：</strong> 宽泛地介绍研究领域及其重要性。</li>
<li><strong>问题聚焦：</strong> 将范围缩小到你所研究的具体问题。</li>
<li><strong>现状与不足：</strong>
综述现有工作（高度概括），并明确指出其存在的<strong>关键缺口</strong>
或<strong>未解决的问题</strong>。这是引言的灵魂！</li>
<li><strong>你的贡献：</strong>
明确提出本文为解决上述缺口所做的事情。最好用条目列表列出你的主要贡献，清晰明了。</li>
<li><strong>论文结构：</strong>
最后一段概述本文后续章节的组织结构。</li>
</ol></li>
<li><strong>不该写什么：</strong>
<ul>
<li><strong>过于详细的背景：</strong>
引言是“导游图”，不是“教科书”。细节留给Background/Related Work章节。</li>
<li><strong>冗长的文献综述：</strong>
对现有工作的详细分析应放在“相关工作”章节，引言中只需点出最关键、最相关的不足。</li>
<li><strong>方法细节：</strong>
不要在这里描述算法的具体步骤。只说高层的核心思想。</li>
<li><strong>实验结果的详细数据：</strong>
可以提一句“实验证明了我们方法的有效性”，但不要给出具体数字。</li>
</ul></li>
</ul>
<h3 id="background-related-work">3. Background / Related work</h3>
<p>推荐不要让related
work阻挡别人读paper，不需要看related也应当能看懂你的paper。</p>
<ul>
<li><strong>使命：</strong>
提及相关的工作。从当前工作的视角提及现有工作的不足。从专业的视角对当前领域提出一些insight。</li>
<li><strong>该写什么：</strong>
<ul>
<li><strong>背景：</strong>
提供理解你方法所必需的理论基础（如公式、定义）。</li>
<li><strong>相关工作：</strong>
对现有工作进行<strong>分类、梳理和总结</strong>。例如，将方法分为A、B、C三类，分别阐述其思想、优势和局限性。</li>
<li><strong>与本文的关联：</strong>
在讨论每一类工作时，都要巧妙地将其与你的工作联系起来（例如，“我们的方法借鉴了A类的思想，但解决了其……的问题”）。</li>
</ul></li>
<li><strong>不该写什么：</strong>
<ul>
<li><strong>简单的罗列：</strong>
避免“A做了X，B做了Y，C做了Z”这种流水账。要有批判性思考和有机的组织。</li>
<li><strong>攻击性语言：</strong>
批评要客观、公正，用“可能无法处理”、“对……场景敏感”等句式，而不是“他们的方法很糟糕”。</li>
<li><strong>忽略重要文献：</strong>
必须引用并讨论最相关、最重要的文献，否则会被认为调研不充分。</li>
</ul></li>
</ul>
<h3 id="方法">4. 方法</h3>
<p>Conveying the intuition is primary, not secondary。</p>
<ul>
<li><strong>使命：</strong>
易懂、语言准确、完整地描述你做了什么，让同行能够复现你的工作。</li>
<li><strong>该写什么：</strong>
<ul>
<li><strong>总体框架：</strong>
先用一张“框图”和高层文字描述整个方法的流程和组成部分。</li>
<li><strong>前提假设：</strong> 明确说明你的方法基于哪些假设。</li>
<li><strong>符号定义：</strong> 清晰定义将使用的数学符号。</li>
<li><strong>细节分解：</strong>
分小节详细描述每个组件的设计、算法流程、公式推导。<strong>每一部分都应回答“是什么”和“为什么”</strong>，但“为什么”要简洁地关联到引言中提出的挑战。</li>
<li><strong>伪代码：</strong>
如果适用，提供清晰的伪代码并配以解释。</li>
</ul></li>
<li><strong>不该写什么：</strong>
<ul>
<li><strong>重复引言中的动机：</strong>
不要大段复述“为什么做这个研究”，要用“为了解诀第1节提到的X问题，我们设计了Y模块”这种方式快速衔接。</li>
<li><strong>讨论结果：</strong>
方法部分只讲“怎么做”，结果好坏留给实验部分。</li>
<li><strong>描述实现细节：</strong>
避免“我们使用了PyTorch框架，在一台RTX
4090显卡上运行”这类信息，这些应放在实验部分的“实现细节”小节。</li>
</ul></li>
</ul>
<h3 id="实验">5. 实验</h3>
<ul>
<li><strong>使命：</strong>
通过严谨的、可重复的实验设计，令人信服地证明你的方法优于其他方案，并深入分析其优缺点。</li>
<li><strong>该写什么：</strong>
<ol type="1">
<li><strong>实验设置：</strong>
数据集介绍、评估指标、基线方法、实现细节（超参数等）。确保可复现性。</li>
<li><strong>主实验：</strong>
与基线方法的定量比较（表格、曲线），并辅以定性比较（图片示例）。</li>
<li><strong>消融实验：</strong>
证明你方法中各个组件的必要性。这是体现你工作价值的关键！</li>
<li><strong>分析与讨论：</strong>
分析结果背后的原因，展示方法的失败案例，讨论其局限性。</li>
</ol></li>
<li><strong>不该写什么：</strong>
<ul>
<li><strong>只展示好的结果：</strong>
诚实是科学的第一准则，讨论局限性能增加可信度。</li>
<li><strong>不合理的比较：</strong>
比较的基线方法必须具有代表性和可比性，并在相同的实验设置下进行。</li>
<li><strong>空洞的结论：</strong>
不要说“从表1可以看出我们的方法更好”，而要说“我们的方法在指标Y上平均提升了Z%，这主要归功于我们设计的X模块对……问题的有效解决”。</li>
</ul></li>
</ul>
<h3 id="结论与未来工作">6. 结论与未来工作</h3>
<ul>
<li><strong>使命：</strong>
总结全文，再次强调核心贡献，并指出未来的研究方向。</li>
<li><strong>该写什么：</strong>
<ul>
<li><strong>总结：</strong>
用不同于摘要的话言，再次概括研究问题、方法和主要发现。</li>
<li><strong>重申贡献：</strong>
再次强调你的核心贡献，但要基于实验结果的支撑。</li>
<li><strong>未来工作：</strong>
基于当前研究的局限性，提出具体、可行的未来研究方向。</li>
</ul></li>
<li><strong>不该写什么：</strong>
<ul>
<li><strong>引入新内容：</strong>
结论中不应出现前文未提及的新概念、新结果或新引用。</li>
<li><strong>过度夸大：</strong> 结论应稳健，避免不切实际的断言。</li>
<li><strong>简单的重复：</strong> 不要只是把摘要复制粘贴过来。</li>
</ul></li>
</ul>
<h3 id="evaluation-assessment">Evaluation / Assessment</h3>
<ul>
<li>几个Assessment的角度：
<ul>
<li>解释数据</li>
<li>展示了方法的什么限制？</li>
<li>得出什么推论？对未来发展方向的指导？</li>
</ul></li>
<li>总分的结构，先总结，然后分析推理数据，然后提出推论。</li>
<li>最后可以用加粗或者框总结并强调最后的结论。</li>
<li>描述的时候必须要定量，给出数据。不能说多了很多这种。</li>
<li>要写的非常直接，不要觉得图上隐含。</li>
<li>用一般现在时。过去时会让人觉得现在不成立。</li>
</ul>
<h3 id="rebuttal-revision">Rebuttal &amp; Revision</h3>
<p>最直接的想法当然是，针对review提出的问题，直接列表一个个回答便是。但是，review经常会，完全不记得问题的上下文。因此这种方式容易导致review想不起来之前的问题。因此要注意重新介绍一下相关的上下文。</p>
<ol type="1">
<li>reviewer可能忘了自己之前说什么，最好不要有太多引用文章或者rebuttal的地方，而是复述一下。</li>
<li>rebuttal的时候最好不要对其他没有提到意见的地方有太大修改。因为理论上应该在投paper之前，paper应当被打磨完毕。</li>
</ol>
<h2 id="从审稿人的思维考虑">从审稿人的思维考虑：</h2>
<p>审视论文是否实验部分看上去还有足够的内容。比如添加Ablation
study。</p>
<p>审视论文的说法是否可能被攻击。比如，你的工具识别出来了X个，你检查了它们是正确的。审稿人可能说你没有看ground
truth有多少个。</p>
<p>注意自己对deadline的过度的乐观倾向。有时候你觉得进度好像还可以，实际上可能根本来不及。</p>
<h2 id="心态">心态</h2>
<p>没有不能克服的困难。写paper看似很难，实际上是由一些没那么难的事情组合而成。</p>
<ul>
<li>Good paper = Good Research + Good
Writing。一般过于忽视了好的写作的重要性。好的写作和好的Research同等重要。不需要注重词语，不建议写很长句子。
<ul>
<li>Good Research:
<ul>
<li>Good Idea: 提出问题/解决问题？</li>
</ul></li>
<li>Good Writing
<ul>
<li>English:
大模型帮助很大，但是依然要注重提升英语水平。不要用太多复杂的词。
<ul>
<li>同时准备雅思/托福等英语考试。</li>
</ul></li>
<li>Good Logic:
<ul>
<li>总体结构上，都是形成了模式的。就像填模板一样，不需要要有格式上的创新。</li>
<li>宏观是逻辑是一条线下来，微观上段落都是总分的结构。</li>
<li>多找其他人看一看自己写的好不好。</li>
</ul></li>
<li>Reader Oriented:</li>
<li>Correct and Succinct:</li>
<li>Clear with Good Logic: 把自己的逻辑先列出来，然后再理清楚。</li>
<li>Reproducible:
重视实验结果的可复现性。写作上指写出来的东西是可复现的，要把关键的点写出来。</li>
</ul></li>
</ul></li>
</ul>
<h3 id="重要注意事项">重要注意事项</h3>
<p><strong>方法上</strong>：</p>
<ul>
<li>是否尽早开始写paper。
<ul>
<li>没有很好的idea也可以写，可以更好地帮助自己找到idea。</li>
<li>写paper可以理清思路，明确自己不懂的地方。</li>
<li>是否没有将自己的东西发给其他人看：将现有的内容发给其他人看，促进交流合作，尽早发现潜在的问题。</li>
</ul></li>
<li>找到自己的Key Idea
<ul>
<li>One clear, sharp idea. Idea是否clear,
sharp。有很多idea就写很多paper，而不是混在一起。</li>
</ul></li>
</ul>
<p><strong>写作上：</strong></p>
<ul>
<li>使用主动语态，使用一致的词。</li>
</ul>
<h2 id="文字细节">文字细节</h2>
<h3 id="标点符号">标点符号</h3>
<ul>
<li>ref和cite前要用<a
href="https://tex.stackexchange.com/questions/468726/cite-is-the-tie-actully-recommended">波浪线替代空格</a>。</li>
<li>不能用缩写：不能用Can't, I'm, It's等。</li>
<li>逗号表示列举：两个物体不需要用逗号，直接用and或or连接。三个及以上需要使用两个引号，即在and/or前要加逗号。想象自己读句子的时候在and前也会停顿。</li>
<li>冒号：必须在完整的句子后使用冒号。比如<code>The tasks contain: \n - xxx\n - xxx</code>这种是错误的，需要加上对应的宾语：<code>The tasks contain three steps: ...</code>
<ul>
<li>即使在句子内也是： You can bring the following things: a book, a
pen, and a laptop. 必须是完整的句子</li>
</ul></li>
<li>连字符Hyphen: 名词前的复合形容词。或者某些数字（"twenty-one"）</li>
<li>引号
<ul>
<li>引用：引用别人的话</li>
<li>特殊含义：提及行话，或者特殊意义的词</li>
<li>如果涉及到书，paper标题，起到类似书名号的作用。</li>
</ul></li>
<li>footnote写在标点符号后面</li>
<li>引用Paper的时候的<a
href="https://academia.stackexchange.com/questions/213673/first-et-al-many-authors-with-same-surname-and-ieee-citations">两种方法</a>：<code>In [1], the authors xxx</code>，以及基于<a
href="https://www.scribbr.com/citing-sources/et-al/">姓氏+et
al.的引用</a></li>
</ul>
<h3 id="数字的使用">数字的使用</h3>
<p>总体思想：不能有歧义，全文要一致。</p>
<ul>
<li>带单位，或者有运算时，用阿拉伯数字。数字和单位之间使用空格，且使用不分割的空格。
<ul>
<li>word里使用<code>Ctrl+Shift+Space</code></li>
<li>latex里使用<code>~</code></li>
</ul></li>
<li>具体的数字不要加近似词限定：<del>Approximately</del> 17 samples
...</li>
<li>1到9的数字（不带单位），序数词通常写单词，而不是阿拉伯数字。0都可以。</li>
<li>大于9的数字写阿拉伯数字，序数词同理：50th xxx, 21st century</li>
<li>拉丁或者希腊符号，往往用斜体。latex里加了数学模式自然会斜体。单位不斜体。</li>
<li>当数字较大时，每三个数字使用分隔符
<ul>
<li>US风格，增加逗号</li>
<li>欧洲风格：使用不分割空格</li>
</ul></li>
<li>使用近似词的时候，单位需要写全称：tens of kilometers</li>
<li>近似描述较大的词的时候，使用million，billion，trillion。</li>
<li>句首不能有阿拉伯数字，此时改成数字的单词写法，或者换说法。</li>
<li>使用近似的数字时，也需要上述格式。“Approximately 70~000 people”</li>
<li>常见图标的引用描述：
<ul>
<li>Figure 7 / Fig. 7</li>
</ul></li>
<li>数字连接在一起的时候，交替使用避免歧义。<code>twenty 20-mm xxx</code></li>
<li>表示范围的时候
<ul>
<li>使用dash破折线，而不是hyphen减号。此时两边都加单位防止歧义。</li>
<li>但是如果有负数的话，就不要用dash，而是to 或through</li>
<li>from和between和to使用，不要和dash混合使用。</li>
</ul></li>
<li>hyphen复合词：
<ul>
<li>复合成为形容词：
<ul>
<li>数字加单位复合</li>
</ul></li>
<li>21到99的数字用单词表示时（例如在句首）。</li>
<li>单词分数的时候：two-thirds</li>
<li>Fold相关：大于9： 20-fold 小于等于9： threefold</li>
</ul></li>
</ul>
<p><strong>大小对比</strong></p>
<ul>
<li>避免有歧义的比例：不要用几倍小几倍大(one-fourth smaller, 10 times
smaller)，而是用<code>two times as much/many as</code></li>
<li>正确描述大小关系
<ul>
<li>测量出来的值：less than, more than, amount of</li>
<li>数出来的值：fewer than, greater than, number of</li>
<li>维度：smaller than, larger than</li>
</ul></li>
</ul>
<h3 id="图表">图表</h3>
<ul>
<li>保证图表单独能被直接看懂</li>
<li>坐标轴是否正确标注了单位</li>
<li>表格内保证数据精度完全一致，比如全文都保留两位小数。</li>
<li>表格内文字首字母大写是否一致，比如都只首字母大写。</li>
<li>加粗是否使用规范。</li>
<li>推荐右对齐，使得小数点末尾对齐。百分号可以提到表头。</li>
<li>底部如果字太长可以斜过来</li>
<li>位置：图表放到顶部或底部，从而防止两图之间文字太少。图表不能跨页。如果实在太长，用continue
table的方式说明。图表和文字之间至少有两行间距。</li>
<li>如果用bar graph/折线图描述平均值，可以带上error bar。</li>
<li>折线图如果点标出来了可以根据情况选择趋势线而不是直接连接。</li>
<li>如果散点图有趋势，可以画一个趋势线。</li>
<li>violin plot是box plot的升级版，进一步展示数据分布趋势。</li>
</ul>
<p><strong>描述图表</strong></p>
<ul>
<li>如果只是描述某个图展示了什么，没有什么意义。描述图表的时候建议直接描述直接吸引读者注意力，然后用括号引用到表。
<ul>
<li>Germination rates were significantly higher after 24h in running
water than in controls (Figure 4)</li>
</ul></li>
</ul>
<p>配色选择网站：colorbrewer2.org 勾选print
friendly选项可以保证灰度时也可读。</p>
<h3 id="引用">引用</h3>
<ul>
<li>不要后面去补引用，而是一边写就一边增加引用。</li>
<li>Google
Scholar的引用，即使bibtex也可能不全。而是使用ACM/IEEE网站，或者DBLP的bibtex。</li>
<li>引用Section的时候用<code>\S</code>替代以节约空间，例如<code>\S~\ref&#123;sssec:xxx&#125;</code></li>
</ul>
<h2 id="latex相关问题">Latex相关问题</h2>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 段内编号</span></span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\one</span>&#125;&#123;(&#123;<span class="keyword">\em</span> i&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\two</span>&#125;&#123;(&#123;<span class="keyword">\em</span> ii&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\three</span>&#125;&#123;(&#123;<span class="keyword">\em</span> iii&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\four</span>&#125;&#123;(&#123;<span class="keyword">\em</span> iv&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\five</span>&#125;&#123;(&#123;<span class="keyword">\em</span> v&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\six</span>&#125;&#123;(&#123;<span class="keyword">\em</span> vi&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\seven</span>&#125;&#123;(&#123;<span class="keyword">\em</span> vii&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\eight</span>&#125;&#123;(&#123;<span class="keyword">\em</span> viii&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\nine</span>&#125;&#123;(&#123;<span class="keyword">\em</span> ix&#125;<span class="keyword">\/</span>)<span class="keyword">\xspace</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 工具或框架的名字可以定义为单独命令，使用textsc</span></span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\framework</span>&#125;&#123;<span class="keyword">\textsc</span>&#123;MyTool&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Answerbox的使用</span></span><br><span class="line"><span class="keyword">\usepackage</span>[breakable]&#123;tcolorbox&#125;</span><br><span class="line"><span class="keyword">\newcommand</span>&#123;<span class="keyword">\answerbox</span>&#125;[1]&#123;</span><br><span class="line"><span class="keyword">\begin</span>&#123;tcolorbox&#125;[leftrule=0.5mm,toprule=0mm,bottomrule=0mm,left=0.7pt,right=0.7pt,top=0.2pt,bottom=0.2pt, breakable]</span><br><span class="line"><span class="keyword">\em</span> <span class="params">#1</span></span><br><span class="line"><span class="keyword">\end</span>&#123;tcolorbox&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 修改autoref的缩写。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>如果因为断词的问题，某一行特别长，可以插入Soft
hypen：<code>\-</code></li>
<li>有加粗字的段落可以都不缩进
<code>\noindent \textbf&#123;xxx&#125;: xxx</code></li>
<li>标号也可以用<a
href="https://tex.stackexchange.com/questions/7032/good-way-to-make-textcircled-numbers">带圆圈的数字</a>。
<ul>
<li>另外一种方法：基于 <code>\ding&#123;172&#125;</code>
表示带圆圈的1。要几就递增一下。<code>\usepackage&#123;pifont&#125;</code>
里面有黑底和白底的圆圈数字。</li>
</ul></li>
</ul>
<p><strong>Revision时给文字增加高亮</strong></p>
<ul>
<li>文字高亮：使用蓝色：<code>\textcolor&#123;blue&#125;&#123;&#125;</code></li>
<li>图片增加蓝色边框，使用textcolor+frame：<code>\textcolor&#123;blue&#125;&#123;\frame&#123;\includegraphics[width=xxx]&#123;xxx.pdf&#125;&#125;&#125;</code></li>
</ul>
<p><strong>ACM模板移除Copyright</strong></p>
<p>这篇<a
href="https://shantoroy.com/latex/acm-remove-copyright-information-from-first-page/">文章</a>介绍了。其中<a
href="https://fr.overleaf.com/learn/latex/Headers_and_footers#LaTeX_page_styles">pagestyle</a>是和header和footer有关的设置，我加上好像没什么变化。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 加在use的package后面</span></span><br><span class="line"><span class="keyword">\setcopyright</span>&#123;none&#125;</span><br><span class="line"><span class="keyword">\settopmatter</span>&#123;printacmref=false&#125; <span class="comment">% Removes citation information below abstract</span></span><br><span class="line"><span class="keyword">\renewcommand</span><span class="keyword">\footnotetextcopyrightpermission</span>[1]&#123;&#125; <span class="comment">% removes footnote with conference information in first column</span></span><br><span class="line"><span class="comment">% \pagestyle&#123;plain&#125;% removes running headers</span></span><br></pre></td></tr></table></figure>
<p><strong>hyperref与链接颜色：</strong></p>
<p>不加上<code>hyperref</code>包之前，各种链接都无法点击，包括<code>\url&#123;https://...&#125;</code>和表格和图的<code>Fig.~\ref&#123;xxx&#125;</code>。直接引入<code>hyperref</code>后会使得链接外面有个浅蓝色边框。使用<code>\usepackage[hidelinks]&#123;hyperref&#125;</code>可以消除边框。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;hyperref&#125;</span><br><span class="line">\AtEndPreamble&#123;</span><br><span class="line">	\usepackage&#123;hyperref&#125;</span><br><span class="line">	\hypersetup&#123;</span><br><span class="line">		colorlinks = true,</span><br><span class="line">		linkcolor = brown,</span><br><span class="line">		anchorcolor = brown,</span><br><span class="line">		citecolor = brown,</span><br><span class="line">		filecolor = brown,</span><br><span class="line">		urlcolor = brown</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用autoref可以免去写<code>Figure. 1</code>前面的<code>Figure.</code>部分。</p>
<p><strong>IEEE 表Caption是大写</strong></p>
<p><a
href="https://tex.stackexchange.com/questions/166814/table-caption-in-uppercase-i-dont-know-why">IEEE模板确实要求表的标题是Small
Caps格式</a>的。但是，当你<a
href="https://tex.stackexchange.com/questions/387133/my-table-is-not-conforming-to-the-ieeetran-caption-table-format">引用了<code>\usepackage&#123;subcaption&#125;</code>之后会变成正常格式</a>。如果要提交到期刊，这是一个容易犯的错误。但是确实有很多paper的table的格式因为这个而不对。有一个<a
href="https://tex.stackexchange.com/questions/154435/ieee-template-and-caption-false-option-for-subcaption-package">方法</a>（<a
href="https://liuzhiguang.wordpress.com/2018/01/05/get-ieeetran-to-work-with-the-subcaption-package/">这里</a>也提到）可以绕过这个问题而正常使用subcaption包。</p>
<ul>
<li><strong>在Caption中使用footnote</strong>：<a
href="https://tex.stackexchange.com/questions/10181/using-footnote-in-a-figures-caption">这里</a>说需要先使用<code>\protect\footnotemark</code>生成脚标标记，然后在表后增加一个<code>\footnotetext&#123;xxxx&#125;</code>。此外，建议此时同时使用<code>\caption[short description]&#123;long description&#125;</code>的格式。有的论文会在结尾生成一个list
of figures/tables目录，此时short description会被用到。</li>
</ul>
<h3 id="图表-1">图表</h3>
<p>基础样式的表格：基于 https://www.tablesgenerator.com/
生成，选择Booktabs table
style，仅选择三个横线（表顶部底部和表头）和内部竖线。</p>
<ul>
<li>图表说明是否需要句号？</li>
<li>引用图表时使用不换行空格：<code>Fig.~\ref&#123;fig:xxx&#125;</code>。波浪线代表不换行空格。</li>
</ul>
<p><strong>节约空间</strong></p>
<p>调paper空间要注意Latex的块结构。如果有个块是一个整体，比如一些RQ的Answer块，正好卡在了页面边缘，那么除非你能删改出整个块的空间，不然空间布局是不会变的。</p>
<ul>
<li>可以让列表没有左边距<code>\begin&#123;itemize&#125; [leftmargin=*]</code></li>
<li>如果有一些段落最后就一两个单词，可以看看怎么缩上去，节约空间。</li>
<li>如果某段结尾只有一个单词，可以段落结尾加一个<code>\looseness=-1</code>，从而增加单词之间的间距填充满这个多出来的整行。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\addtolength&#123;\floatsep&#125;&#123;-2mm&#125;</span><br><span class="line">\addtolength&#123;\dblfloatsep&#125;&#123;-4mm&#125;</span><br><span class="line">\addtolength&#123;\textfloatsep&#125;&#123;-4mm&#125;  % single column figure margin</span><br><span class="line">\addtolength&#123;\dbltextfloatsep&#125;&#123;-3mm&#125;  % double column figure margin</span><br><span class="line">\addtolength&#123;\abovecaptionskip&#125;&#123;-2mm&#125;</span><br><span class="line">\addtolength&#123;\belowcaptionskip&#125;&#123;-2mm&#125;</span><br></pre></td></tr></table></figure>
<p><strong>表太宽或太窄</strong></p>
<p>不推荐使用resize，用的话也是用<code>\resizebox&#123;\columnwidth&#125;&#123;!&#125;&#123;....&#125;</code>（<a
href="https://tex.stackexchange.com/a/387166/308917">出处</a>）</p>
<h3 id="引用-1">引用</h3>
<ul>
<li>作者名字的引用，可以 1 仅姓氏， 2 名字首字母加姓氏 比如F. Wang 3
全名。</li>
<li>单个作者直接称呼姓氏？两个作者直接用and连接</li>
<li>三个及以上作者的，使用第一个人的姓氏+et al. 比如： Wang et al.
suggested ... [1].
<ul>
<li>如果多个作者有重复的姓氏，则考虑名字首字母加姓氏：F. Wang et al.
suggested ...</li>
<li>或者直接避开
<ul>
<li>In [1], the authors</li>
<li>the authors in [1]</li>
</ul></li>
</ul></li>
</ul>
<blockquote>
<p>as shown by Brown [4], [5]; as mentioned earlier [2], [4]–[7], [9];
Smith [4] and Brown and Jones [5]; Wood et al. [7]</p>
<p>NOTE: Use et al. when three or more names are given for a reference
cited in the text.</p>
<p>or as nouns:</p>
<p>as demonstrated in [3]; according to [4] and [6]–[9].</p>
</blockquote>
<p>(摘自<a
href="https://ieeeauthorcenter.ieee.org/wp-content/uploads/IEEE-Reference-Guide.pdf">IEEE
Reference Guide</a>)</p>
<p>但最好不要将引用数字作为句子的成分，而是改为提作者名字，或代词指代。</p>
<h3 id="缩写">缩写</h3>
<ul>
<li>对于容量，可以直接用全大写的MB，虽然MiB更精确，但是实际上都行。</li>
</ul>
<h3 id="matplotlib">matplotlib</h3>
<p><a
href="https://stackoverflow.com/questions/42097053/matplotlib-cannot-find-basic-fonts">安装字体</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="comment"># 防止type 3字体的出现</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;pdf.fonttype&#x27;</span>] = <span class="number">42</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;ps.fonttype&#x27;</span>] = <span class="number">42</span></span><br><span class="line"><span class="comment"># 设置默认字体</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&quot;font.family&quot;</span>] = <span class="string">&quot;Times New Roman&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="其他">其他</h2>
<p>先写中文是有帮助的。能够清楚地知道自己往往遇到的是逻辑问题，而不是英语表达能力的问题。速度就是质量，真正好的文章是改出来的，如果不能以很快的速度进行这个过程，那么就很可能不能在自己可接受的时间范围内写出“还看得过去”的paper内容，自己也会非常折磨。可以在文档中自己分两栏，比如用个两列的列表，左边放中文，右边放英文。每次同时修改两边内容。</p>
<p>在分离了语言这个困难后，其次是讲求逻辑，有明确的逻辑关系。优先看自己是不是完全写清楚了，其次是考虑篇幅等其他问题。往往会发现越写越多，然后超出内容，然后开始精简，这也是写paper的必经之路。后面再删，删的时候优先选择必要的逻辑，次要的注释掉。</p>
<p>最后，需要注意，语言是一种艺术。必须要让自己的语言能够以最简单的方式被看懂。首先，任何逻辑上复杂的弯都最好理顺，①进一步增加自己paper的受众，让更多人能看懂，②很有可能reviewer在看你paper的时候很累，思维也并不是很清晰。其次，为了段落结构的清晰，可以通过调整句子，让自己每个段落想表达什么都明确出来。比如，介绍自己paper主要思想时，我们往往并不会写：“The
main idea of our paper is that
xxxx.”，但是我们却可以刻意改成这样，从而极度明确地让人知道这个段落的主要内容。从另外一方面想，把段落组织起来，利用开头句作为索引，也是方便知识查找和索引的一种方式。语言也是一种艺术，你很难知道这些句子在别人脑子里能否和得到你形成一样的想法。就像艺术要追求美一样，我们要追求逻辑上的清晰，简洁易懂。</p>
<h3 id="年7月19日">2025年7月19日</h3>
<p>如何优化paper： 1.
行文的结构逻辑上理清楚，然后能简化都简化。如果没有站在读者角度考虑简化，那么肯定是要改的。
2. 把对工具的修改放到discussion里面？ 3.
介绍表除了带上具体数字，要带上具体行号 4. 多加交叉应用。指向别的段落 5.
评价其他工作的时候要客观而具体。不要说他们做得不好，可以说具体的方面，struggle
with。</p>
<h3 id="年1月24日">2024年1月24日</h3>
<ul>
<li>表格的<code>\extracolsep</code>填满整个页，会导致边框有gap，rotate之后不对齐到中间。</li>
<li>引用网页时，使用<code>@misc&#123;&#125;</code>项目，如果写<code>url = &#123;&#123;xxx&#125;&#125;</code>则在后面不会显示链接。写<code>howpublished  = &#123;\url&#123;xxx&#125;&#125;</code>才会显示。<a
href="https://tex.stackexchange.com/questions/171441/url-not-showing-in-references">这里</a>有个相关的问题。可能<code>@online</code>和<code>url</code>搭配，而<code>@misc</code>和<code>howpublished</code>搭配使用。</li>
</ul>
<h3 id="年12月9日">2023年12月9日</h3>
<p>注意小节开头的句子和之前的连贯性。</p>
<ul>
<li>research做不可数名词。Some research shows that xxx</li>
</ul>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Scientific</tag>
      </tags>
  </entry>
  <entry>
    <title>大语言模型学习笔记</title>
    <url>/2024/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>大模型学习笔记</p>
<span id="more"></span>
<h3 id="什么是stepbatch-sizeepoch">什么是step，batch size，epoch</h3>
<p>一般来说，会同时跑batch
size个样本，然后把梯度平均一下，然后根据这个梯度更新参数。</p>
<ul>
<li>step: 模型一次step代表了一次更新参数的过程。</li>
<li>batch的设置：batch
size使得单次遍历数据集所更新的参数次数减少了，因此通常似乎认为batch
size是为了增加训练速度，所以batch
size越小越好。但是实际上并不一定。如果数据集很多样，则最好让模型多看一些数据，使得数据能够比较好地代表整个数据集，然后再更新参数。</li>
<li>batch size与显存：batch
size越大，占用的显存也越大。但是有时候想要batch
size大一些但是显存不够，此时需要增加gradient
accumulation。将多次的梯度聚集起来再做参数更新（step）。</li>
<li>然而，梯度聚集虽然能够显著减少显存使用，但随着梯度聚集的值增加，显存占用还是会增长不少。gradient_checkpointing_enable参数可以使用checkpoint技术进一步减少显存占用，但是会增加20%左右的训练开销。</li>
</ul>
<h3 id="大模型的训练阶段">大模型的训练阶段</h3>
<ul>
<li><p><a href="https://deci.ai/blog/dpo-preference-tuning-llms/">Is DPO
Always the Better Choice for Preference Tuning LLMs?</a></p></li>
<li><p><a
href="https://medium.com/@bijit211987/the-evolution-of-language-models-pre-training-fine-tuning-and-in-context-learning-b63d4c161e49">Empowering
Language Models: Pre-training, Fine-Tuning, and In-Context Learning</a>
解释了PreTraining的特点（无监督，填空），和Fine-Tuning的特点（转移学习，根据梯度优化参数）。</p></li>
<li><p>PreTraining 预训练：一般是无监督学习类似填空这样的任务。</p></li>
<li><p>Supervised Fine-Tuning
有监督微调：直接让模型学习输出对应的东西。</p></li>
<li><p>RLHF
基于人类反馈的大模型微调过程。首先收集人类反馈，然后基于反馈训练奖励模型(Rewarding
Model)，代替人类做出实时反馈。基于奖励模型，使用“Proximal Policy
Optimization”（PPO）这种强化学习算法，使这个过程更加稳定。最终大模型的输出被训练为最大化奖励模型的奖励。</p></li>
<li><p>DPO:
一种和RLHF类似，但是更为简化和稳定的方法：基于大模型生成的输出对，直接标注哪个更好。使用这些输出优化大模型的参数。</p></li>
</ul>
<h3 id="什么是rope-scaling">什么是RoPE scaling</h3>
<p>现有的大模型存在上下文长度的问题：当输入的上下文长度超过了训练时的上下文时，会出现困惑度（基于模型输出时概率分布，衡量模型是否确信自己的输出的指标。）猛增的情况。</p>
<p><strong>RoPE</strong>：位置编码是 Transformer
里一个重要组成部分。通过生成一些位置向量，加到词向量上，使模型知道每个词之间的位置信息。否则模型无法知道词之间的位置关系。RoPE是LLaMA模型引入的一种新的生成位置向量的方法，不使用加法，而是给向量增加一些旋转。</p>
<ul>
<li><a href="https://nn.labml.ai/transformers/rope/index.html">RoPE
explanation with code</a></li>
<li><a
href="https://medium.com/@jain.sm/position-interpolation-extending-context-window-sizes-in-large-language-models-ef19d0209a9f">RoPE
interpolation paper explanation</a></li>
</ul>
<p><strong>Linear RoPE scaling</strong>：最初，Meta（和<a
href="https://kaiokendev.github.io/context#random-positional-encoding">reddit</a>/kaiokendev同时发现）提出了<a
href="https://arxiv.org/abs/2306.15595">RoPE
interpolation</a>方法提升上下文长度。它基于插值。打个比方，例如训练的时候是360上下文，此时RoPE可以比作给每个向量旋转1度编码位置关系。此时我们想输入720长度的文字，则我们在原来的360度中分720段，每个字旋转0.5度，从而让大模型更适应长上下文。</p>
<p>Reddit上有人提出了两个重要的RoPE
scaling方法（是的，没有论文，论文也引用的reddit）： - <a
href="https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/">NTK-Aware
RoPE scaling</a> 引入了neural tangent kernel - <a
href="https://www.reddit.com/r/LocalLLaMA/comments/14mrgpr/dynamically_scaled_rope_further_increases/">Dynamically
Scaled RoPE</a> 根据当前上下文位置，动态调整线性或者NTK方法的参数。</p>
<p>基于这些方法，可以零微调直接提升上下文长度，或者让大模型在长上下文中进行进一步微调，更大地提升上下文长度。</p>
<ul>
<li><a href="https://arxiv.org/abs/2310.05209">“Scaling Laws of
RoPE-based Extrapolation”</a> 深入地研究了这个方面：
<ul>
<li>文中发现，RoPE原文中选取的base参数10000居然是最差的值？无论变大还是变小都能有效提升上下文长度。</li>
</ul></li>
<li><a href="https://arxiv.org/abs/2309.00071">YaRN: Efficient Context
Window Extension of Large Language Models</a>
提出了新的修改和改进。</li>
</ul>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>如何写一篇好的学术论文综述</title>
    <url>/2024/%E5%A6%82%E4%BD%95%E5%86%99%E4%B8%80%E7%AF%87%E5%A5%BD%E7%9A%84%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>如何写一篇好的学术论文综述</p>
<span id="more"></span>
<p>文献综述是对大量最近发表的学术文章的技术审查结果进行分析、总结、组织和呈现新结论的过程。学习怎么写综述非常重要，即使不专门去写综述，通常的文章中也有需要写类似综述的内容的场景。</p>
<ul>
<li><strong>文献综述的形式</strong>
<ul>
<li>独立研究论文</li>
<li>研究论文中的一个章节</li>
<li>学位论文中的一个章节</li>
</ul></li>
<li><strong>综述文章的意义</strong>：
<ul>
<li>将每项工作置于其对研究问题的贡献的背景下</li>
<li>描述每项工作与其他正在考虑的工作之间的关系</li>
<li>识别解读先前研究的新方法</li>
<li>揭示文献中存在的任何空白点</li>
<li>解决看似矛盾的先前研究之间的冲突</li>
<li>识别先前学术研究的领域，以避免工作重复</li>
<li>指明满足额外研究需求的方向</li>
<li>在现有文献背景下定位你自己的研究</li>
<li>与你的观众建立融洽关系</li>
<li>帮助你避免意外抄袭</li>
<li>锐化你的研究焦点</li>
</ul></li>
<li><strong>综述的不同类型：</strong>
<ul>
<li>辩论性评论：对给定立场提出相反观点</li>
<li>综合性评论：对给定主题进行检验和批判性分析，以引出新研究的需要</li>
<li>历史性评论：按时间顺序评估所有学术研究的历史记录</li>
<li>方法论评论：审查分析方法</li>
<li>系统性评论：包括与明确制定的研究问题相关的现有证据的概述</li>
<li>理论性评论：检视关于一个议题、概念、理论、现象积累的理论文献汇编</li>
</ul></li>
<li><strong>编写综述的步骤</strong>
<ul>
<li>搜索和收集文献</li>
<li>阅读评估并批评文献</li>
<li>写综述</li>
</ul></li>
</ul>
<p><strong>写综述</strong></p>
<ul>
<li>向从未阅读过该论文的读者解释内容
<ul>
<li>在一个针对某个领域专业人士的非常专注的会议或期刊中，可以假设读者具有扎实的背景知识</li>
</ul></li>
<li>以连贯的方式解释相关要点
<ul>
<li>你应该将你的调研焦点只放在论文中提到的某些主题上</li>
</ul></li>
<li>使用适当的引用，以便读者始终知道信息的来源</li>
<li>清楚地将你自己的评论和结论与原文区分开</li>
</ul>
<p><strong>综述文章的主要部分</strong>：综述需要很好地体现对这个领域知识的分类，并体现在标题上，所以有一个“实际内容部分”。</p>
<ul>
<li>标题与作者</li>
<li>摘要</li>
<li>关键词</li>
<li>引言</li>
<li>综述方法：描述如何收集文章
<ul>
<li>使用到的关键词</li>
<li>论文的统计信息，包括一些图表</li>
<li>做一篇新的综述的必要性</li>
</ul></li>
<li>概念定义
<ul>
<li>描述概念的意思</li>
<li>可能有竞争关系的定义</li>
<li>可能导致误解和混淆的概念</li>
<li>可能的方法和途径</li>
</ul></li>
<li>实际内容（配以适当标题）
<ul>
<li>列表整理分类总结现有的工作</li>
</ul></li>
<li>结论
<ul>
<li>最重要的发现和结论</li>
<li>对未来研究的建议</li>
<li>明确区分自己的论证与其他人的工作</li>
</ul></li>
<li>参考文献</li>
</ul>
<p><strong>如何写一个好的相关工作章节</strong></p>
<p>直接罗列出各种相关算法，然后说它们的优缺点：是一种常见但是错误的做法</p>
<p>主要点可能包括： -
说服读者你的方法具有创新性（例如，指出它与传统方法的不同之处） -
说服读者你的方法是合理的（例如，提供采用类似方法的成功案例；或者暗示当前方法的先前成果）
- 描述你的工作所基于的先前方法 -
说服读者你对这个领域的问题和方法足够熟悉，能够撰写论文</p>
<ul>
<li>我需要涵盖所有文献吗？对于那些与我的假设相悖的文献该怎么办？
<ul>
<li>除非你是在写一篇文献综述论文，否则你无需涵盖所有的文献。</li>
<li>你需要涵盖那些支持你研究并与之相关的文献——包括正面和负面的。</li>
</ul></li>
<li>所谓“负面”的文献，指的是在你的特定领域中，与你的假设、方法和发现不一致的任何文献。你的目标是不让评审员发表如下评论：
<ul>
<li>作者的文献回顾仅限于那些支持他们假设的论文，而没有涵盖与本研究相关的所有文献。</li>
</ul></li>
<li>一个好的相关研究部分应该包括以下内容
<ul>
<li>是否解决了核心问题</li>
<li>是否解决了相关的问题</li>
<li>是否识别出了问题</li>
<li>是否为类似问题使用了相同的方法论</li>
<li>是否你的工作受到了它们的启发</li>
</ul></li>
<li>相关工作部分通常按照以下顺序回答以下问题。
<ul>
<li>在我的主题上有哪些开创性工作？我需要提到这些吗？</li>
<li>自从这些开创性工作以来取得了哪些进展？</li>
<li>哪些工作最为相关？提到这些工作的最佳顺序是什么？</li>
<li>这些近期工作的成就和局限性是什么？</li>
<li>这些局限性揭示了哪些差距？</li>
<li>我的工作打算如何填补这个差距？</li>
</ul></li>
<li>在相关工作中，我应该怎样开始我的文献综述？
我应该怎样构建它，以展示历年来的进展？</li>
<li>从上一个例子中学到的建议结构：
<ul>
<li>主题介绍</li>
<li>文献支持</li>
<li>小结</li>
<li>下一个主题的介绍。依此类推。</li>
</ul></li>
<li>最清晰的方式来提及其他作者是什么？
我应该关注作者本人还是他们的观点？</li>
<li>这取决于你的关注点是什么：
<ul>
<li>作者本人</li>
<li>研究成果</li>
<li>论文/研究本身</li>
</ul></li>
<li>引用其他作者的各种风格
<ul>
<li>Style 1: Blinco [5] found that Japanese elementary school children
showed …</li>
<li>Style 2: In the previous study [5], Blinco found that Japanese
elementary school children showed …</li>
<li>Style 3: A study of the level of persistence in school children is
presented by Blinco [5].</li>
<li>Style 4: A greater level of persistence has been noticed in Japan
[5]</li>
</ul></li>
</ul>
<p>我应该如何以建设性和合理的方式谈论现有工作的局限性以及我们工作的创新之处？
- 如果提出的是前所未有的方法 - As far as we know, there are no studies
on ... - To [the bese of our knowledge], the literature has not
discussed - We believe that this is the first time that xxx has been
applied to ... - 如果想提及现有工作的局限性 - Generally speaking xxxx
are <em>seldom</em> considered - Results often appear to conflict with
each other ... - So far X <em>has nerver been applied</em> to Y. -
Moreover, no attention has been paid to ... - These studies have only
dealt with the situation in X, <em>whereas</em> our study focuses on the
situation in Y</p>
<p>问自己以下问题：</p>
<ul>
<li>我是否显示出自己对当前研究现状的了解？</li>
<li>我是否只提到了读者需要具体了解的内容？</li>
<li>我是否避免了只提及支持我假设的文献？</li>
<li>我提到的论文逻辑顺序是否合理？</li>
<li>我选择这些论文而不选择其他的理由是否清楚？</li>
<li>我是否选择了来自我国的不成比例数量的论文？</li>
<li>我是否确保参考文献中没有引用论文中没有提到的文章，反之亦然？</li>
<li>我是否遵循了期刊/会议关于引用文献的指示？</li>
<li>我在报道文献时是否去除了任何冗余内容？</li>
<li>我是否正确使用了时态？</li>
</ul>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Scientific</tag>
        <tag>Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>生活和效率</title>
    <url>/2023/%E7%94%9F%E6%B4%BB%E5%92%8C%E6%95%88%E7%8E%87/</url>
    <content><![CDATA[<p>如何乐观和高效。</p>
<span id="more"></span>
<h2 id="方法论">方法论</h2>
<h3 id="相关视频及其观点">相关视频及其观点</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=R5i8alK5hPo">4 ONE-MINUTE
Habits That Save Me 20+ Hours a Week - Time Management For Busy
People</a>
<ul>
<li>专心：专心，沉浸是高效的基础。
<ul>
<li>工作前，想象自己要去看电影。记得提前完成常见分心动作：上厕所喝水，手机开勿扰。</li>
</ul></li>
<li>批处理：把零散的工作累积起来。把类似的工作积累起来。</li>
<li>做事情前想一想，自己要做的事情能不能避免或者更高效地做/减少工作量。</li>
<li>同时用脑和身体：比如锻炼时可以听一些有声读物。</li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=cfiw3lwrkp0">《How I stay
productive 98% of every day》</a>
<ul>
<li>做事情必须要有极其明确的目标，并计时。</li>
</ul></li>
<li><a href="https://www.youtube.com/watch?v=y1oFxKxAmWE">Why I'm able
to work 12 hours a day with 100% focus - 6 ONE-MINUTE Habits</a>
<ul>
<li>计时，在计时访问内沉浸工作，想象自己去看一部电影。</li>
<li>给自己deadline，在真正的deadline之前完成工作。
<ul>
<li>Hofstadter的法则说，事情总是花比想象中更多的时间，即使你考虑到了它会花更多时间。</li>
<li>提早deadline可以给自己减轻压力，同时有时间进一步完善。</li>
</ul></li>
<li>考虑环境的作用：环境对心态的潜在影响。</li>
<li>感受到快乐是重要的，不能感到厌烦，否则效率不高。（但不是最重要的）</li>
<li>设置一个每天没有商量必须做的事情。</li>
<li>在每天结束的时候计划第二天。让你不需要记住。之后也更放松。之后回来也更快。</li>
</ul></li>
</ul>
<h3 id="总结">总结</h3>
<h2 id="生活">生活</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=snAhsXyO3Ck">《The
Spaceship You》</a>
<ul>
<li>《Thinking About Lockdowns》里<a
href="https://youtu.be/SVmEXdGqO-s?t=613">提到</a>，里面提到：“《The
Spaceship
You》不只是一个关于疫情居家的视频。而是一个关于如何生活的视频。其中一些道理我花了好几年才弄清楚，想要写给过去的自己。”
（注：不是我说的，是视频里他说的。）</li>
</ul></li>
</ul>
<h3 id="已知有效的规律">已知有效的规律</h3>
<p>85%的重要性放在自己身体方面（睡眠、运动、饮食）。</p>
<ul>
<li>睡眠，运动
<ul>
<li>熬夜的坏处：第二天精神不好。胃更容易受损。</li>
</ul></li>
<li>更健康的食物</li>
<li>如果身体不舒服，以至于无法继续学习，则应当做些体育运动。之后就会发现不舒服缓解了。</li>
</ul>
<h3 id="其他可能有效的规律">其他可能有效的规律</h3>
<ul>
<li>逐渐减少自己的刺激，习惯学习。
<ul>
<li>游戏，食物，社交媒体</li>
</ul></li>
<li><a
href="https://youtu.be/ALaTm6VzTBw?t=69">生产力会随时间下滑？</a>，效率在一天/周内随着时间递减。</li>
</ul>
<h2 id="心态">心态</h2>
<ul>
<li><strong>不想干活</strong>：放松，然后就会发现那些负面想法其实是一种形成的心理的坏习惯。放松，然后想到了什么就做什么，不要浪费了自己想到的东西。</li>
<li>被学习的目标是固定的，只要坚持，总有一天能够学会。</li>
</ul>
<h3 id="rebt">REBT</h3>
<p><a
href="https://en.wikipedia.org/wiki/Rational_emotive_behavior_therapy">Rational
emotive behavior therapy (REBT)</a>
是一种认知行为疗法。它用逻辑去挑战悲观的观念，意识到这些观念都是不成立的，为更健康的念头空出空间。人们不是因为外部事情的发生而悲观，而是因为对这些外部事情的想法而悲观。</p>
<p><a
href="https://en.wikipedia.org/wiki/Rational_emotive_behavior_therapy#Core_beliefs_that_disturb_humans">一些对生活产生影响的核心念头：</a></p>
<ul>
<li>我<strong>必须</strong>，无论在任何条件，任何场景下，都要表现得很好，赢得其他人的支持。如果我在这些重要的，神圣的方面失败了，那么我就是一个坏的，不完整的，没有价值的人。我之后总是会继续失败，并非常痛苦。
<ul>
<li>这个念头会增加焦虑，恐慌，抑郁，绝望，失去自我价值</li>
</ul></li>
<li>和我有关系的任何其他人，<strong>必须</strong>在任何条件，任何场景下，对我很好，考虑很周到，公平。否则，这是一个非常差的事情，他们也是坏的，迂腐，不值得信任的人，不值得有个很好的生活，应当因为对我不够好而被严重惩罚。
<ul>
<li>这个念头使人产生愤怒，狂躁，感到受害。</li>
</ul></li>
<li>我的生活环境在任何情况<strong>必须</strong>是非常好的，安全的，无害的，让人愉悦的。如果不是这样，那么它就是让人难受，恐怖的，无法忍受。完全不能让自己享受，生活下去是不可能的，不值得的。
<ul>
<li>这个念头使人倾向于沮丧，不安，忍耐力差，自我怜悯，愤怒，抑郁。容易造成拖延，逃避，上瘾，无助。</li>
</ul></li>
</ul>
<p><a
href="https://en.wikipedia.org/wiki/Rational_emotive_behavior_therapy#Other_insights">REBT的三个观点</a>：</p>
<ul>
<li>有悲观倾向的人会因为“触发事件”而导致突然的悲观，这潜在地受到之前经历过的强烈负面经历的影响，但这些都不是核心。触发事件导致悲观的核心，在于人们对触发事件的不合理的念头或推断。</li>
<li>当人们因为不合理的念头，被一件事触发了悲观之后，他们会倾向于继续保持这种不合理的念头并继续悲观。不仅仅是因为他们之前一直这样做，而是因为他们在当前依然无意识地有着不合理的念头，并还在继续巩固，表现得像是这些念头依然成立。</li>
<li>无论他们对上面两点的理解有多深，对自己悲观的理解有多深，这几乎不能让他们不再受到悲观的影响。他们可能仅仅会在知道的时候感觉好一些，但帮助不大。而是要，在持续的努力下不断寻找自己的不合理理念，积极地，充满能量地，科学地阻止它们。将这些绝对的“必须”换成更灵活的倾向，将自己的不健康的感觉替换成健康，自我帮助的感觉。并且坚定地反对自己不合理的害怕和冲动。只有通过联合的认知，情绪和行为，持续和强力地攻击自己的严重情绪问题，一个人才可能显著地改进或消除这种念头。</li>
</ul>
<p>REBT强调患者必须努力变得更好，在疗法中这包括在生活中大量的每天的日常练习，家庭作业。其中可能包括直面自己害怕的事情。最终使得患者改变，评估自己，他人，和生活的哲学方式，最终实现无条件的自我接受，对他人的接受，以及对生活的接受，并不断努力过上一个自我满足和幸福的生活。</p>
<h3 id="logotherapy">Logotherapy</h3>
<p>Logotherapy，意义疗法，基于一种假设，即人主要动力来源于找寻生活的意义。</p>
<ul>
<li>生活无论在什么情况下都有意义，即使在最悲惨的情况下也如此。</li>
<li>我们生活的主要动力就是找寻生活的意义。</li>
<li>我们能自由地在，自己做的事情，经历的事情中找寻意义。（但要警惕享乐注意，物质主义。）</li>
</ul>
<p>Frankl提到人生的意义可以从，创造事情或从事工作，经历事情或者鼓舞他人中寻找。</p>
<p>当人过于关注自己的焦虑，进入恶性循环的生活，需要尝试分心，关注其他事情。</p>
<h3 id="通过写日记改变心态">通过写日记改变心态</h3>
<p>坚持写日记是面对不良心态的重要应对措施。只要记住，乐观的本质就在于关注那些积极的事情，忘记那些消极的事情。如果今天过得高兴，就多记录下来自己为什么高兴，强化一下高兴的记忆。</p>
<p>任何习惯，包括思维习惯都是很难短时间内改变的。但是做任何事情本质上都分为两部分，具体的行动和背后的心态都同等重要。做到正确的心态就成功了一半。而如果想要做到，就得先意识到什么是正确的心态。复盘是向正确心态靠近的重要努力。</p>
<p>另外一方面，如果有难以释怀的事情，就进行复盘。</p>
<ul>
<li>经历事情的时候，往往就是非常自信地认定自己是对的。复盘前觉得自己也许还是一样的想法，甚至有时候就是想写一写继续痛斥别人做的不对。</li>
<li>在重新给自己描述一遍的时候，很多事情往往就有了不同的角度和看法，这一点是不到写的时候完全意识不到的。
<ul>
<li>就像做数学题，不可能什么题上来第一次就能做对，很多时候复盘一下经常发现自己想的不对。</li>
</ul></li>
<li>很多难以释怀的地方，最后也能放下来。
<ul>
<li>自己吃亏也不一定是坏事。</li>
<li>别人也不一定会在意自己，什么事情最后都会被忘记。</li>
</ul></li>
</ul>
<!-- 我记得有著名作家还是谁，提到自己经常记录每天让自己痛苦的事情，晚年经常出现不明原因的头疼。而如果能够积极看待事情，即使处于最差的环境，依然能保持乐观。 -->
<p>每个的经历都不一样，很难找到一个完全理解自己的人，因此往往都需要靠自己去引导自己。也许写日记这样的事情才是真正的解决方案。如果有人经常过于悲观，我都会推荐他去多写日记。</p>
<h2 id="结语">结语</h2>
<ul>
<li>在看过不少相关的资料后，这里尝试总结出一些和效率关联最大的因素。我认为人与人之间的差异一般不能作为这些因素失效的原因。</li>
<li>这些都不是规则，因为生活过于复杂，任何规则都有不适合的时候。它更像是一个靶子，一个目标，并不总是正中中心，但是需要我们瞄准并对齐。</li>
</ul>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>英语标准发音教程笔记</title>
    <url>/2024/%E8%8B%B1%E8%AF%AD%E6%A0%87%E5%87%86%E5%8F%91%E9%9F%B3%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>之前很早就买了王式仁的《英语标准发音教程》和王桂珍的《英语语音语调教程》这两本书</p>
<span id="more"></span>
<h2 id="第二章">第二章</h2>
<ul>
<li>发/s,z/这两个齿龈音，用平舌就不好听，如果舌面形成一条沟导引气流泄出，就很地道。</li>
</ul>
<h3 id="发音图">发音图</h3>
<p>发音主要有三个方面：。 - 口腔开度/舌位高低： -
舌位的降低和抬高同口腔的开闭（即开口度的大小有关），舌位越高开口度越小，舌位越低开口度越大。
- <a
href="https://www.baike.com/wikiid/776383084178444608">舌位</a>：舌头是否放平，或者贴近上面。
- 唇形：圆唇和非圆唇</p>
<p>舌位可以看下图：图左边纵坐标是口腔开闭情况（舌面高低），横坐标是元音前后，即左图的舌位。</p>
<figure>
<img src="舌位.png" alt="舌位" />
<figcaption aria-hidden="true">舌位</figcaption>
</figure>
<figure>
<img src="元音.png" alt="元音" />
<figcaption aria-hidden="true">元音</figcaption>
</figure>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>AFLplusplus的动态dict生成与cmplog插桩</title>
    <url>/2025/AFLplusplus%E7%9A%84%E5%8A%A8%E6%80%81dict%E7%94%9F%E6%88%90%E4%B8%8Ecmplog%E6%8F%92%E6%A1%A9/</url>
    <content><![CDATA[<p>AFL++的动态dict生成与cmplog插桩</p>
<span id="more"></span>
<h2 id="cmplog模式的使用">CmpLog模式的使用</h2>
<p>正常的Fuzzing模式是编译插桩后的二进制，然后使用afl-fuzz程序指定路径启动fuzz。</p>
<p>使用cmplog模式后，除了普通的插桩二进制，还需要额外编译一份cmplog插桩的二进制。通过编译的时候指定<code>AFL_LLVM_CMPLOG=1</code>启动这种特殊的插桩。然后在fuzz的过程中，使用<code>-c path-to-cmplog-binary</code>指定第二个二进制程序。在fuzz过程中会执行该二进制，通过插桩记录下所有的比较指令，以及字符串比较。</p>
<h3 id="cmplog模式的插桩">CmpLog模式的插桩</h3>
<p>AFL++采用了cmplog，和动态dict在功能上有所重合。这篇文章<a
href="https://arxiv.org/pdf/2211.08357.pdf">《Improving AFL++ CmpLog:
Tackling the bottlenecks》</a>介绍了cmplog当前实现的不足。</p>
<p>不像honggfuzz使用clang的标准插桩，AFL++使用了自己的自定义的Pass进行插桩。</p>
<p>字符串比较函数相关的插桩逻辑如下</p>
<ul>
<li>根据函数签名是否像strcmp函数，即两个指针参数（isPtrRtn）。像memcmp函数，两个指针加上一个整数（isPtrRtnN）。整数需要是32或者64位大小。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> isPtrRtn = FT-&gt;<span class="built_in">getNumParams</span>() &gt;= <span class="number">2</span> &amp;&amp;</span><br><span class="line">                !FT-&gt;<span class="built_in">getReturnType</span>()-&gt;<span class="built_in">isVoidTy</span>() &amp;&amp;</span><br><span class="line">                FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>) == FT-&gt;<span class="built_in">getParamType</span>(<span class="number">1</span>) &amp;&amp;</span><br><span class="line">                FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>)-&gt;<span class="built_in">isPointerTy</span>();</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> isPtrRtnN = FT-&gt;<span class="built_in">getNumParams</span>() &gt;= <span class="number">3</span> &amp;&amp;</span><br><span class="line">                 !FT-&gt;<span class="built_in">getReturnType</span>()-&gt;<span class="built_in">isVoidTy</span>() &amp;&amp;</span><br><span class="line">                 FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>) == FT-&gt;<span class="built_in">getParamType</span>(<span class="number">1</span>) &amp;&amp;</span><br><span class="line">                 FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>)-&gt;<span class="built_in">isPointerTy</span>() &amp;&amp;</span><br><span class="line">                 FT-&gt;<span class="built_in">getParamType</span>(<span class="number">2</span>)-&gt;<span class="built_in">isIntegerTy</span>();</span><br></pre></td></tr></table></figure>
<ul>
<li>主要区分的核心函数，isMemcmp isStrcmp
isStrncmp。根据函数名判断，收集常见的函数名以及其他的类似封装<code>xmlStrcmp</code>。<code>isPtrRtnN</code>直接看作是一种Memcmp</li>
</ul>
<table>
<colgroup>
<col style="width: 52%" />
<col style="width: 22%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr>
<th>插桩函数名</th>
<th>变量名</th>
<th>被插桩的函数组</th>
</tr>
</thead>
<tbody>
<tr>
<td>__cmplog_rtn_hook</td>
<td>cmplogHookFn</td>
<td>其他未归类的签名类似的函数</td>
</tr>
<tr>
<td>__cmplog_rtn_llvm_stdstring_stdstring</td>
<td>cmplogLlvmStdStd</td>
<td>llvmStdStd</td>
</tr>
<tr>
<td>__cmplog_rtn_llvm_stdstring_cstring</td>
<td>cmplogLlvmStdC</td>
<td>llvmStdC</td>
</tr>
<tr>
<td>__cmplog_rtn_gcc_stdstring_stdstring</td>
<td>cmplogGccStdStd</td>
<td>gccStdStd</td>
</tr>
<tr>
<td>__cmplog_rtn_gcc_stdstring_cstring</td>
<td>cmplogGccStdC</td>
<td>gccStdC</td>
</tr>
<tr>
<td>__cmplog_rtn_hook_n</td>
<td>cmplogHookFnN</td>
<td>Memcmp 和未归类的同签名函数</td>
</tr>
<tr>
<td>__cmplog_rtn_hook_strn</td>
<td>cmplogHookFnStrN</td>
<td>Strncmp</td>
</tr>
<tr>
<td>__cmplog_rtn_hook_str</td>
<td>cmplogHookFnStr</td>
<td>Strcmp</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>相关的插桩函数的实现在<code>instrumentation/afl-compiler-rt.o.c</code>：</p>
<p>插桩的共享内存相关的数据结构主要在<a
href="https://github.com/AFLplusplus/AFLplusplus/blob/c1e4b8f7f6f1f95a94c2340de4f57a998c90f094/include/cmplog.h"><code>cmplog.h</code></a>里。包括两个数组。用具体哪个下标是通过hash函数处理得到的，然后拿着这个下标访问headers和log两个结构体数组。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmp_map</span> &#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">cmp_header</span>   headers[CMP_MAP_W];</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">cmp_operands</span> log[CMP_MAP_W][CMP_MAP_H];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>首先会在headers里面设置一些信息。包括 hits
击中次数。shape，对比的两边的大小。type，对比的两大类类型，cmp表示一些cmp指令，比较整数，rtn表示一些memcmp或者strcmp这种内存比较。attribute
属性，比如是switch还是什么strcmp。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmp_header</span> &#123;  <span class="comment">// 16 bit = 2 bytes</span></span><br><span class="line"></span><br><span class="line">  <span class="type">unsigned</span> hits : <span class="number">6</span>;       <span class="comment">// up to 63 entries, we have CMP_MAP_H = 32</span></span><br><span class="line">  <span class="type">unsigned</span> shape : <span class="number">5</span>;      <span class="comment">// 31+1 bytes max</span></span><br><span class="line">  <span class="type">unsigned</span> type : <span class="number">1</span>;       <span class="comment">// 2: cmp, rtn</span></span><br><span class="line">  <span class="type">unsigned</span> attribute : <span class="number">4</span>;  <span class="comment">// 16 for arithmetic comparison types</span></span><br><span class="line"></span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure>
<p>然后在log里面存入两个被对比的值。由于256bit大小的数字大多都能支持，这里留了两个256bit数字的大小。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmp_operands</span> &#123;</span><br><span class="line"></span><br><span class="line">  u64 v0;</span><br><span class="line">  u64 v0_128;</span><br><span class="line">  u64 v0_256_0;  <span class="comment">// u256 is unsupported by any compiler for now, so future use</span></span><br><span class="line">  u64 v0_256_1;</span><br><span class="line">  u64 v1;</span><br><span class="line">  u64 v1_128;</span><br><span class="line">  u64 v1_256_0;</span><br><span class="line">  u64 v1_256_1;</span><br><span class="line">  u8  unused[<span class="number">8</span>];  <span class="comment">// 2 bits could be used for &quot;is constant operand&quot;</span></span><br><span class="line"></span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure>
<p>对于rtn这种字符串比较的类型，则会将log数组的项目重新强制类型转换为cmpfn_operands类型。存储两个最长32字节的字符串，以及他们的长度。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmpfn_operands</span> &#123;</span><br><span class="line"></span><br><span class="line">  u8 v0[<span class="number">32</span>];</span><br><span class="line">  u8 v1[<span class="number">32</span>];</span><br><span class="line">  u8 v0_len;</span><br><span class="line">  u8 v1_len;</span><br><span class="line">  u8 unused[<span class="number">6</span>];  <span class="comment">// 2 bits could be used for &quot;is constant operand&quot;</span></span><br><span class="line"></span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure>
<p>总之，插桩代码会用上面的方式，在cmplog共享内存中存储关于程序的比较的信息，用于后续Fuzz算法使用。</p>
<h3 id="cmplog模式的fuzz算法">CmpLog模式的Fuzz算法</h3>
<p>主要的入口是在<code>src/afl-fuzz-redqueen.c</code>文件的<code>input_to_state_stage</code>函数中。</p>
<ol type="1">
<li>执行colorization阶段，更新buf
<ol type="1">
<li>在保证执行路径完全相同（coverage
map完全相同），且执行时间大致不变的情况下，尽量替换输入中的字节。</li>
</ol></li>
<li>在原始输入和colorized输入上，运行待测程序得到两份cmplog。(由于coverage
map完全相同，可以假设cmplog完全按顺序一一对应。)
<ol type="1">
<li>cmplog数据分别存在afl-&gt;orig_cmp_map和afl-&gt;shm.cmp_map</li>
</ol></li>
<li>处理每个log项目
<ol type="1">
<li>如果是cmp类型则执行cmp_fuzz函数中的逻辑</li>
<li>如果是rtn类型则执行rtn_fuzz函数中的逻辑</li>
</ol></li>
<li>如果定义了CMPLOG_COMBINE，则更新virgin_bits。</li>
</ol>
<p>its_fuzz函数是对执行fuzz（common_fuzz_stuff）的封装，而common_fuzz_cmplog_stuff则是会执行额外指定的cmplog插桩的binary。</p>
<blockquote>
<p>CmpLog状态的第一步是着色阶段。在着色过程中，输入的每个字节都被替换为同一类型的另一个字节，一系列被替换的字节称为一个Taint区域。最初，整个输入被视为一个Taint区域，这个着色后的输入被传递给目标程序。当执行路径的结果哈希与原始执行路径的哈希不同时，Taint区域会被分成两半并分别处理，否则该区域会被保存。着色后的结果是一个着色输入，其中每个Taint区域中的字节都被替换为同一类型的另一个字节，并且执行路径的哈希等于原始输入。对于哈希的构建，使用了“trace_bits”和“map_size”。</p>
</blockquote>
<blockquote>
<p><code>rtn_extend_encoding()</code>
函数替换复制值的第一个字节，并使用这个修改后的输入执行目标。这将持续进行，直到达到Taint区域长度的最后一个字节，并且只要比较的另一侧的值等于将要被替换的输入字节。其背后的想法是，如果操作数值与该输入字节具有
I2S（input-to-state） 关系，则值应该相等。对于 INS
比较，这必须同时适用于原始输入和着色输入。对于 RTN
类型，这只需要适用于其中之一。请注意，只有在禁用转换时才会执行此 I2S
检查，因为当转换启用时，此检查不再适用。</p>
</blockquote>
<p>这里主要关注的是什么条件下会增加dict：在cmp_fuzz或者rtn_fuzz的结尾的判断中，</p>
<ul>
<li>对于cmp，严格一些，需要o（colorized之后的cmplog项目中的v0/v1）和orig_o（原始输入中的cmp项目中的v0/v1）相等，<strong>且</strong>没有发现新的崩溃（<code>!found_one</code>），或者是纯文本的buffer。调用的是<code>try_to_add_to_dict</code>。</li>
<li>对于rtn，宽松一些。需要o和orig_o相等，<strong>或</strong>没有发现新的崩溃（<code>!found_one</code>）或者是纯文本的buffer。调用的是<code>maybe_add_auto</code>。</li>
</ul>
<p>由于没有发现新的崩溃是很常见的，所以对于rtn，基本上都会调用maybe_add_auto。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
        <tag>Read</tag>
      </tags>
  </entry>
  <entry>
    <title>AlgebraticSubtyping</title>
    <url>/2025/AlgebraticSubtyping/</url>
    <content><![CDATA[<p>读论文：《Algebraic Subtyping》 -- Dolan</p>
<span id="more"></span>
<h2 id="intro-代数先于语法原文-第一章">Intro: 代数先于语法（原文
第一章）</h2>
<p>类型为什么和代数有关系呢？因为如果引入了子类型这样的特性之后，类型之间就会出现运算，最简单的运算就是判断类型的相等。其次就是引入子类型关系之后，判断类型之间是否兼容（判断子类型关系，一个类型是否是另外一个类型的子类型）。这就相当于抽象代数里面的成员和运算所构成的比如群、环、域之类的东西。通常设计一个语言的时候，可能会优先去找出最简单的描述类型的语法，然后再去尝试基于它构建一个代数类型。比如说我们在引入子类型这个特性的时候。类型通常就会构成一个lattice格。</p>
<p>然而，随着各种各样的类型特性被引入，比如说子类型特性。结构体类型，函数类型。这些类型的复杂交互，甚至可能会导致最终的类型运算在一些复杂的情况不好定义，甚至出现矛盾。在一段时间以内。研究者们可能想了很久，也不知道如何解决这种矛盾。</p>
<p>因此，Dolan提出，首先要找到最简单的兼容这些类型运算的代数系统，然后再基于该类型系统，设计描述类型的语法。（让我想起了物理学里面那种感觉：怎么测光速都不变的时候反过来把光速不变作为基础。）</p>
<h3 id="矛盾的情况-原文-1.4-failures-of-extensibility">矛盾的情况 （原文
1.4 Failures of extensibility）</h3>
<p>一个最简单的情况是。我们知道通常的类型系统里面有bool类型，函数类型以及结构体类型。但是他们这几个类型之间是不相交的，比如说一个类型不可能同时是布尔类型，又是函数类型。因此这些类型之间是独立的格，而不能够形成一个更大的格。一种非常简单的想法就是引入新的top类型和bottom类型。让它作为这些类型的公共父类型和公共子类型。然而这样形成的整体的格运算发现在实际中会出现严重的问题，甚至无法得出一些非常简单的子类型属性。</p>
<p>最简单的例子就是，如果一个类型同时是函数类型，又同时是结构体类型，那么根据上面的格，他是bottom类型，那么它也是布尔类型的子类型。即可以用作布尔类型。虽然这种情况在常规的编程语言中一开始不存在，但是随后他们可通过比如说C语言的union类型等方式加入了进来。Python这种动态类型的语言也存在这种情况。</p>
<p>为了解决这种情况有几种选择：</p>
<ol type="1">
<li>coproduct of
lattices，比如可以同时维护集合表示可能存在的bool类型，函数类型和结构体类型，如果内部的元素同时有子类型，则说明合并的类型也是子类型。</li>
<li>a coproduct of posets or plain
sets。这里简单地加入top和bottom就是直接整个类型集合看作一个元素，弄一个格结构。这样是不对的。</li>
</ol>
<p>基本概念背景 -
<strong>余积（Coproduct）</strong>：在范畴论中，余积是范畴中的一种泛构造，是积（product）的对偶概念。对于不同的范畴（如集合、偏序集、格），余积的具体实现方式不同。
-
<strong>偏序集（Poset）</strong>：带有偏序关系（自反、反对称、传递）的集合。
-
<strong>格（Lattice）</strong>：一种特殊的偏序集，其中任意两个元素都有唯一的最小上界（并）和最大下界（交）。</p>
<p>Kleene 代数是正则表达式和有限自动机的代数</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>StaticAnalysis</tag>
        <tag>Decompile</tag>
      </tags>
  </entry>
  <entry>
    <title>如何编写可维护的跑实验代码</title>
    <url>/2024/%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99%E5%8F%AF%E7%BB%B4%E6%8A%A4%E7%9A%84%E8%B7%91%E5%AE%9E%E9%AA%8C%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>当你实现了一个工具，需要在不同配置下跑实验的时候，跑实验的代码很可能变得越来越复杂，以至于难以维护。</p>
<span id="more"></span>
<h3 id="python-dict转array">Python dict转array</h3>
<p>比如你有一个实验数据表示不同工具的时间消耗<code>&#123;"tool A": [1.1, 2.0, 3.9, ...], "tool B": [...], "tool C": [...]&#125;</code>。然后你想要画一个散点图。但是散点图需要直接传入内部数据的数组，此时，似乎自然而然地就会直接<code>list(data.values())</code>。</p>
<p>血和泪的教训。。。实验数据可能会产生错位！！！因为<code>.values()</code>调用不会保证顺序！！还是要按照自己图上的label，从dict里好好一个个取出，才能正确地按顺序得到list。</p>
<h3
id="善于cache减少重复运算">善于<code>@cache</code>减少重复运算。</h3>
<p>基于Jupyter
notebook分块运行python代码非常方便。将实验数据收集划分为不同的函数，然后加上<code>@cache</code>修饰，使得重跑时不会重复运行代码。</p>
<p>如果用python，首先定义一个实验数据类，指定每个实验结果文件夹，然后定义一些获取实验数据的成员函数，需要参数的用<code>@cache</code>修饰，不需要参数的用<code>@cached_property</code>修饰，这样无需考虑反复调用获取的复杂度问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NSStats</span>:</span><br><span class="line">    native_methods = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, result_path:<span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.result_path = result_path</span><br><span class="line"></span><br><span class="line"><span class="meta">    @cached_property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">time</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> match_unix_time_file(<span class="string">f&quot;<span class="subst">&#123;self.result_path&#125;</span>/docker_stderr.txt&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>然后可以利用类似defaultdict的思想，自动在取dict的时候实例化我们这个类。只需要直接拿结果文件夹路径访问这个dict，然后访问参数直接得到对应的实验数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NSDataDict</span>(<span class="title class_ inherited__">dict</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__missing__</span>(<span class="params">self, key</span>):</span><br><span class="line">        self[key] = NSStats(key)</span><br><span class="line">        <span class="keyword">return</span> self[key]</span><br><span class="line"></span><br><span class="line">ns_data_dict = NSDataDict()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> folder <span class="keyword">in</span> os.listdir(xxx):</span><br><span class="line">    st = ns_data_dict[<span class="string">f&#x27;<span class="subst">&#123;BASE&#125;</span>/<span class="subst">&#123;folder&#125;</span>&#x27;</span>]<span class="comment"># type: NSStats</span></span><br><span class="line">    time = st.time</span><br></pre></td></tr></table></figure>
<h3 id="如何测量内存和时间">如何测量内存和时间</h3>
<p>建议优先使用<a
href="https://stackoverflow.com/a/774601/13798540"><code>/usr/bin/time -v</code></a>。如果实验在docker里运行，则修改docker容器，在docker内部使用<code>/usr/bin/time</code></p>
<p>我之前实验在docker里运行，于是开始搜索是否有监控docker容器运行的内存和时间的工具，发现没有之后就开始用python脚本自己写了一个。写起来很折磨，因为其实考虑清楚细节挺复杂的。最后选择了监控docker
stats的输出的方式，统计每个容器的时间和内存。最让人沮丧的事情是，最后分析实验数据的时候发现，自己测出来的时间不准！！最后很让人崩溃</p>
<h3 id="如何控制命令运行超时">如何控制命令运行超时</h3>
<p>使用<code>timeout</code>命令，同时加上<code>--kill-after=60s</code>防止命令因为卡死不退出的情况。即使使用了docker，也不要使用docker
kill等命令，而是修改docker镜像，在内部使用timeout。</p>
<p>结合测量时间和内存的话，通常需要在运行实验的命令前加上一长串（<code>/usr/bin/time -v /usr/bin/timeout --kill-after=60s $TIMEOUT ...</code>）。虽然一开始可能感觉奇怪，但实际上相比其他的方案会简单很多。我也在python脚本里集成了监控运行的docker容器，超时调用docker
kill的功能，最后导致复杂度的暴增，有时也无法有效地停止卡死的容器。</p>
<p>一个可能的问题是，如果强行终止程序，即使有了一些结果程序也没保存下来。这时候建议同时设置这个硬超时，和程序命令行里的软超时（略小于硬超时时间）。</p>
<h3
id="如何多进程并行运行实验同时控制并行数量">如何多进程并行运行实验，同时控制并行数量</h3>
<p>使用python脚本将需要运行的命令打印出来，需要顺序运行的命令之间可以用分号隔开。使用<code>\x00</code>作为并行运行命令的分隔符，并通过管道传给<a
href="https://stackoverflow.com/a/19618159/13798540">xargs命令</a>（例如：<code>python cmds_print.py | xargs -0 -I CMD --max-procs=1 bash -c CMD</code>）。即使是用docker运行，也应该把docker
run命令打印出来然后用该方案运行。</p>
<p>这种方案的另外一个好处是，可以先将需要运行的命令收集起来，然后按照想要的方式打印出来作为执行顺序。有时候会发现，自己运行的实验命令是一个二维的情况，生成的时候按照参数配置生成方便，但是如果运行的时候按照数据集运行，则便于自己在实验没完全跑完时手动分析处理。此时可以将运行的命令矩阵<a
href="https://stackoverflow.com/a/8421412/13798540">转置</a>一下（<code>list(*zip(arr))</code>），再打印出来。</p>
<p>之前没有发现这个方案，又自己写并行运行的方案。写出来也很复杂。。</p>
<h3 id="如何在文件数据集的子集上分析">如何在文件数据集的子集上分析</h3>
<p>为这个数据集创建新的文件夹，内部使用软链接的方式，链接到原数据集文件夹。通过转换为在一个新的数据集上分析的问题，复用分析单个文件夹的逻辑。</p>
<h3 id="如何给实验数据画图">如何给实验数据画图</h3>
<p>（最好想好自己要画的图的类型）将需要画图的数据转换为简单的格式，如json/csv。然后将数据文件发送给GPT4，说明需求，让GPT4的code
interpreter功能为自己画图。</p>
<p>不得不说，我在matplotlib
seaborn等画图库上调试和debug的时间很多。数据可视化已经是GPT4能干得不错的事情。</p>
<h3
id="实验数据如何存储pickel序列化存数据库">实验数据如何存储，pickel序列化？，存数据库？</h3>
<p>使用tee命令或者输出重定向的方式，将实验的相关原始输出都记录下来，包括/usr/bin/time
-v的输出。数据完全不存储数据库，而是按需直接访问对应实验文件夹，在输出中匹配得到。</p>
<p>本质上实验数据输出的原始文件夹，也可以看作一种“数据库”。如果还要单独存一份的话，那一方面要维护一个实验数据提取脚本，一方面要维护从数据库读取然后转换画图的脚本。时刻警惕复杂度的上升，不然它会成为软件工程的灾难和自己的噩梦。</p>
<h3 id="善用环境变量传递参数">善用环境变量传递参数</h3>
<p>当整个实验环境被打包，在复杂的模块套模块的情况里，如果要通过最外层命令行设置里面模块的参数，则需要将参数一直保持和传递，极大地增加了复杂性。然而可以通过环境变量传递参数，在最外层设置环境变量，在内部模块则可以直接获取到（例如python，<code>os.environ['XXX']</code>）。</p>
<h3
id="标记正常运行完成而不是被杀或者超时">标记正常运行完成，而不是被杀或者超时</h3>
<p>在跑实验的脚本里使用touch创建对应的文件，例如 touch XXX_FINISHED
表示已经完成，通过检测对应文件是否存在判断是否运行完成。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Scientific</tag>
      </tags>
  </entry>
  <entry>
    <title>SoftwareFoundations学习笔记</title>
    <url>/2024/SoftwareFoundations%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>SoftwareFoundations学习笔记。</p>
<span id="more"></span>
<p>不得不说，还是应该跟着各种课程，好好的去重新学习一下编程语言理论相关的知识。首先，我在问过很多大佬之后，他们提到的学习资源也就是这些东西。第二，奢求其他人耐心的给你讲解基础知识基本上是不可能的，所以这些东西都需要靠自己自学。最近完全没有耐下心来去好好学习，从现在开始冲刺还来得及。而且，这种基础知识类的东西，无论什么时候学，都是好处远大于投入。学了之后，基本马上就能用到。不学，只能浪费更多的时间自己推理。</p>
<p>https://coq.inria.fr/tutorial/</p>
<p>https://blog.vero.site/ref/coq</p>
<h2 id="常用命令与环境配置">常用命令与环境配置：</h2>
<p>手动命令行命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 最好先运行make编译每个.v为.vo文件</span><br><span class="line">coqc -Q . LF Basics.v</span><br><span class="line">coqc -Q . LF BasicsTest.v</span><br><span class="line">coqtop -Q . LF # 进入交互式模式。退出使用 `Quit.`</span><br><span class="line">ledit coqtop -Q . LF # 直接使用coqtop 会无法使用左右箭头，上下翻历史等功能。搜了发现需要先`opam install ledit`然后用ledit执行coqtop</span><br></pre></td></tr></table></figure>
<p>然后执行 <code>From LF Require Export Induction.</code>
导入当前在读的章节。</p>
<p>最基本的做题环境设置：VSCode下面开两个分屏的终端，上面看代码（即同时也是看书）。每次做题目就把上面的定理复制到下面coqtop。然后在下面手动证明。做好了把答案整理上去。</p>
<p>更好用的配置，首先安装vscoq插件并配置好，然后在要做题的地方使用快捷键Alt
+
右箭头。插件会解释代码到文件当前位置。同时在右侧展示当前Goal。不断写语句并查看右侧。</p>
<h2 id="逻辑基础-basics">1 逻辑基础 Basics</h2>
<p>声明（Declaration），将一个名字和规范（specification）对应起来，有三种规范：logical
propositions, mathematical collections, and abstract types。 -
Hypothesis 假设，一个返回Prop（bool）类型值的logical propositions， -
Definition 定义，就是给个别名。Definition double (m : nat) := plus m m.
- Inductive
递归的定义，即定义里面可以用当前正在定义的类型。类似Fixpoint，但是Fixpoint更复杂。
- Fixpoint 递归函数定义，可以函数体内用这个函数。 Coq 要求每个 Fixpoint
定义中的某些参数必须是“递减的”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Fixpoint evenb (n:nat) : bool :=</span><br><span class="line">  match n with</span><br><span class="line">  | O ⇒ true</span><br><span class="line">  | S O ⇒ false</span><br><span class="line">  | S (S n&#x27;) ⇒ evenb n&#x27;</span><br><span class="line">  end.</span><br></pre></td></tr></table></figure>
<ul>
<li>Check 类型检查。如果不加类型则打印类型。</li>
<li>Example / Theorem /Lemma / Fact / Remark
都是表示一个需要证明的定理？</li>
</ul>
<h3 id="数据结构">数据结构</h3>
<p>有参数的构造函数： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Inductive color : Type :=</span><br><span class="line">  | black</span><br><span class="line">  | white</span><br><span class="line">  | primary (p : rgb).</span><br></pre></td></tr></table></figure></p>
<p>模式匹配：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Definition isred (c : color) : bool :=</span><br><span class="line">  match c with</span><br><span class="line">  | black ⇒ false</span><br><span class="line">  | white ⇒ false</span><br><span class="line">  | primary red ⇒ true</span><br><span class="line">  | primary _ ⇒ false</span><br><span class="line">  end.</span><br></pre></td></tr></table></figure>
<p>元组：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Inductive nybble : Type :=</span><br><span class="line">  | bits (b(0) b(1) b(2) b(3) : bit).</span><br></pre></td></tr></table></figure>
<p>定义的数组的表示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Notation &quot;x :: y&quot; := (cons x y)</span><br><span class="line">                     (at level 60, right associativity).</span><br><span class="line">Notation &quot;[ ]&quot; := nil.</span><br><span class="line">Notation &quot;[ x ; .. ; y ]&quot; := (cons x .. (cons y []) ..).</span><br><span class="line">Notation &quot;x ++ y&quot; := (app x y)</span><br><span class="line">                     (at level 60, right associativity).</span><br></pre></td></tr></table></figure>
<h3 id="证明模式">证明模式：</h3>
<p>https://www.cs.cornell.edu/courses/cs3110/2018sp/a5/coq-tactics-cheatsheet.html#induction</p>
<ul>
<li>intro
H：将条件成立的定理的条件移入到局部的假设，假设命名为H。intros：反复应用intro，自动取假设的名字。</li>
<li>Symmetry 交换等式左右两边。</li>
<li>Apply H:
H是一个条件成立的定理，且结果和待证明目标相同。想要应用H，则需要满足H的条件。接下来只需要证明H的条件，即可证明待证明的目标。</li>
<li>Exact HA: 待证明目标就是假设HA。不需要证明/直接完成证明。</li>
<li>Assumption:
当前需要证明的目标，直接可以由已有的假设得到。尝试在上下文中查找完全匹配目标的前提
H。 如果找到了，那么其行为与 apply H 相同。</li>
<li>assert：引入一个子目标，先证明它然后把它加入假设。例如：<code>assert (H : n * m * n = n * n * m). &#123; rewrite mul_comm. apply mult_assoc. &#125;</code></li>
<li>Qed.: 检查当前的证明并保存。</li>
<li>rewrite -&gt; H
：基于相等的某个前提，把等式一边的东西改写成另外一边的东西。右箭头表示从左往右改写</li>
<li>Destruct n as [| n'] eqn:E :
根据结构体结构解构，引入多个子目标。这里方括号内用|分割，是给每个构造函数的参数取的变量名字。然后后面用标号依次证明每个子目标。减号和加号
星号，或者它们的重复都可以。也可以花括号。
<ul>
<li>这里的eqn，表示用E表示引入的等价关系。比如这里将n解构为<code>0</code>或者<code>S n1</code>，这里E就分别代表<code>n = 0</code>或者
<code>n = S n1</code>。</li>
</ul></li>
<li>unfold 展开定义。有时候定义会阻止simpl.简化。</li>
<li>induction：归纳法，证明基础的，证明传递保持的。和destruct类似，引入多个子目标。</li>
<li>injection：利用构造子的单射性，比如把<code>S n = S m</code>的两边都移除构造子，<code>injection H as Hnm</code>，得到假设<code>Hnm</code>
即<code>n = m</code>。</li>
<li>discriminate
理由构造子的不相交性，对一个假设说这个是不可能成立的。因此直接停止证明。因为错误的假设可以推出任何东西。</li>
<li>transitivity 连续的应用等式，利用等式的传递性。</li>
<li>f_equal 可以将结论外面相同的函数脱去。
<ul>
<li>如果每个参数依次等价，则相同形式的构造器/函数等价。对一个<code>f a1 ... an = g b1 ... bn</code>的场景应用该定理，得到多个子目标：<code>[f = g], [a1 = b1], ..., [an = bn]</code>。</li>
</ul></li>
<li>inversion
和上面类型，但是应用在假设上，把假设里相同的构造器脱去。</li>
<li>specialize
将一个通用的假设，用一个情况特化。比如假设<code>H : forall m : nat, m * n = 0</code>
然后执行<code>specialize H with (m := 1).</code>，这个假设变成<code>H : 1 * n = 0</code>。可以specialize一个外面的定理进来，得到新的假设，控制apply的工作方式。</li>
<li>generalize dependent
可以将变量重新放回forall的量词。在想要给量词顺序换位置的时候有用。</li>
</ul>
<p>直接使用这些Tactics都是反向证明，使用<code>apply xx in H</code>这种带in的Tactics则可以进行前向证明。即，不断变换前提条件，最后直接在某个假设中得到结论，Apply一下即可完成证明。</p>
<ul>
<li>clear H：从上下文中删除前提 H。</li>
<li>subst x：对于变量 x，在上下文中查找假设 x = e 或 e = x，
将整个上下文和当前目标中的所有 x 替换为 e 并清除该假设。</li>
<li>subst：替换掉'所有'形如 x = e 或 e = x 的假设（其中 x
为变量）。</li>
<li>rename... into...：更改证明上下文中前提的名字。例如，
如果上下文中包含名为 x 的变量，那么 rename x into y 就会将所有出现的 x
重命名为 y。</li>
<li>contradiction：尝试在当前上下文中查找逻辑等价于 False 的前提 H。
如果找到了，就解决该目标。</li>
<li>constructor：尝试在当前环境中的 Inductive
定义中查找可用于解决当前目标的构造子 c。如果找到了，那么其行为与 apply c
相同。</li>
</ul>
<h3 id="连接不同的证明">连接不同的证明：</h3>
<ul>
<li><code>T(1) ; T(2) (read T(1) then T(2))</code>
先应用T1，出现了多个需要证明的子目标时，对所有子目标应用T2</li>
<li><code>T; [T(1) | T(2) | ... | T(n)]</code>
先应用T，出现了多个需要证明的子目标时，对每个子目标按顺序应用T1 T2 ...
Tn</li>
</ul>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
      </tags>
  </entry>
  <entry>
    <title>BTIGhidra和BinSub代码解析</title>
    <url>/2025/BTIGhidra%E5%92%8CBinSub%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<p>BTIGhidra和BinSub代码解析</p>
<span id="more"></span>
<h3 id="运行与调试环境搭建">运行与调试环境搭建</h3>
<p>想要舒服地阅读代码肯定需要良好的调试环境。本次使用的代码是<a
href="https://github.com/trailofbits/BTIGhidra/tree/28dee6a31d00d171ef37765f933d22a44ae95998">这个commit</a></p>
<ol type="1">
<li>安装Ghidra 10.3.3并设置环境变量 <code>GHIDRA_INSTALL_DIR</code>.
<ol type="1">
<li>修改ghidraRun脚本里面bg改为fg，在控制台前台运行，从而能够看到更多的输出。</li>
</ol></li>
<li>安装Java 17 openjdk</li>
<li>安装Rust环境</li>
<li>安装just工具：cargo install just</li>
<li>执行just build。构建插件</li>
<li>找到<code>/BTIGhidra/plugin/dist/ghidiaplugin.zip</code>，启动Ghidra，选择安装插件，选择这个zip包。</li>
</ol>
<!-- 3. (如果想要调试Java) 安装IntelliJ IDEA -->
<p><strong>调试rust部分</strong></p>
<p>在<a
href="https://github.com/trailofbits/BTIGhidra/blob/28dee6a31d00d171ef37765f933d22a44ae95998/plugin/src/main/java/binary_type_inference/BinaryTypeInferenceRunner.java#L110">BinaryTypeInferenceRunner</a>尝试增加代码打印执行<code>binary_to_types</code>的命令。然后创建一个项目，尝试运行一下插件。初始分析的时候记得额外勾选decompiler
param ID。然后在Analysis-&gt;one Shot-&gt;Type
inference这里执行插件。</p>
<p>然后vscode安装好rust开发环境，codeLLDB插件。需要用vscode直接打开内部的rust项目文件夹，language
server的提升和跳转才会正常。然后基于上面打印的执行命令，先执行测试一下，然后增加Launch的debug选项。只需要把运行的程序路径改为构建后debug版本的可执行文件路径。参数就是打印出来的参数。比如我的是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;type&quot;: &quot;lldb&quot;,</span><br><span class="line">    &quot;request&quot;: &quot;launch&quot;,</span><br><span class="line">    &quot;name&quot;: &quot;Launch mooosl&quot;,</span><br><span class="line">    &quot;program&quot;: &quot;/sn640/BTIGhidra/binary_type_inference/target/debug/binary_to_types&quot;,</span><br><span class="line">    &quot;args&quot;: [&quot;/sn640/BTIGhidra/binary_type_inference/test_data/mooosl&quot;, &quot;/tmp/1738839619485-0/ir.json&quot;, &quot;/tmp/1738839619485-0/lattice.json&quot;, &quot;/tmp/1738839619485-0/additional_constraints.pb&quot;, &quot;/tmp/1738839619485-0/interesting_tids.pb&quot;, &quot;--out&quot;, &quot;/tmp/1738839619485-0/ctypes.pb&quot;, &quot;--debug_out_dir&quot;, &quot;/tmp/1738839619485-0&quot;],</span><br><span class="line">    &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<h2 id="代码架构">代码架构</h2>
<p>整体架构如图所示</p>
<p><img src="BTIGhidra架构.drawio.png" /></p>
<p><strong>BTIGhidra的Java插件</strong></p>
<p>当点击Ghidra菜单的type
inference按钮的时候，首先BTIGhidra的Ghidra插件部分会导出各种信息，准备传递给Rust部分的主体分析代码。</p>
<p>从脚本的<a
href="https://github.com/trailofbits/BTIGhidra/blob/5253fd83baf89baf32efab9bc8b24cd7f674b22e/plugin/src/main/java/binary_type_inference/BinaryTypeInference.java#L476">main函数</a>可以看出这里主要分为三步：</p>
<ul>
<li>produceArtifacts：提取约束，导出相关的文件，准备执行Rust那边可执行文件<code>binary_to_types</code>。可以参考rust那边的<a
href="https://github.com/trailofbits/binary_type_inference/blob/94918fa010b5d2fe0bb7589ebf3efe72ae5d9322/src/bin/binary_to_types.rs#L25">命令行参数</a>。
<ul>
<li>GetBinaryJson：<a
href="https://github.com/trailofbits/BTIGhidra/blob/b5fba911f9237ce1d8e7c46762fed73cc6d1706d/plugin/src/main/java/binary_type_inference/GetBinaryJson.java#L66">调用</a>CWEChecker的PcodeExtractor插件里的脚本，导出一个pcode的json表示。</li>
<li>createTypeLattice：生成类型的格（偏序集）表示</li>
<li>生成额外的约束文件</li>
</ul></li>
<li>getCtypes：调用<a
href="https://github.com/trailofbits/BTIGhidra/blob/main/plugin/src/main/java/binary_type_inference/BinaryTypeInferenceRunner.java">BinaryTypeInferenceRunner</a>，运行rust那边的类型分析逻辑，生成最终类型导出的文件。</li>
<li>applyCtype：在Ghidra中设置并创建导出的类型。目前似乎只设置了函数参数和返回值类型，以及全局变量类型。</li>
</ul>
<p><strong>Rust代码部分</strong></p>
<p>从可执行文件<code>binary_to_types</code>的<a
href="https://github.com/trailofbits/binary_type_inference/blob/94918fa010b5d2fe0bb7589ebf3efe72ae5d9322/src/bin/binary_to_types.rs#L24">main函数</a>开始。所有的输入首先被封装为<code>JobDefinition</code>，然后进一步生成<code>InferenceJob</code>类，并调用<code>infer_ctypes</code>函数生成结果。最后将结果导出为文件。</p>
<p>这里如果对基础理论不懂，想要深入研究的可以看我上一篇博客对retypd论文的解读，找里面相关的部分。</p>
<p><code>infer_ctypes</code>的主要函数调用：</p>
<ul>
<li><code>infer_labeled_graph</code>
<ul>
<li><code>get_simplified_constraints</code>
生成每个函数的summary，即如果有其他函数调用它，它的返回值类型和参数类型会有什么关系。即summary表示了这个函数调用对类型的影响，避免反复重复递归进去分析。
<ul>
<li>首先从CWE_Checker那边拿到函数的调用图。因为summary之间也有依赖关系，提取调用者的summary的时候要应用依赖于被调函数的summary。因此我们采用拓扑排序的思想，按照调用图的拓扑排序顺序去依次分析得到summary。（如果调用边形成了环形依赖，即强联通分量，则把所有环上的函数看作一个大的函数进行分析。）这里和retypd论文中一致。</li>
<li>然后创建<code>scc_constraint_generation::Context</code>并调用那边的生成约束逻辑。进一步调用那边的<a
href="https://github.com/trailofbits/binary_type_inference/blob/94918fa010b5d2fe0bb7589ebf3efe72ae5d9322/src/solver/scc_constraint_generation.rs#L670"><code>get_simplified_constraints</code></a>函数。多次转调调用<a
href="https://github.com/trailofbits/binary_type_inference/blob/94918fa010b5d2fe0bb7589ebf3efe72ae5d9322/src/solver/scc_constraint_generation.rs#L510"><code>Context::simplify_scc</code></a>
<ul>
<li><a
href="https://github.com/trailofbits/binary_type_inference/blob/94918fa010b5d2fe0bb7589ebf3efe72ae5d9322/src/solver/scc_constraint_generation.rs#L546"><code>instantiate_callee_signatures</code></a>应用调用的其他函数的summary。</li>
<li><code>infer_pointers</code>:
处理区分指针和数字类型的问题。通过一些加法减法运算，判断它们是数字加减还是指针加减。进一步推理那些变量是指针。</li>
<li><a
href="https://github.com/trailofbits/binary_type_inference/blob/94918fa010b5d2fe0bb7589ebf3efe72ae5d9322/src/solver/constraint_graph.rs#L1021"><code>simplify_graph</code></a>:
<ul>
<li>首先执行Saturate算法，算是核心的类型推断了，和retypd论文应该一致。简单来说，如果结构体指针A是结构体指针B子类型，则A在不同偏移位置的成员，也应当是B对应成员的子类型。此时saturation算法就会增加一条额外的子类型边给这两个成员节点。</li>
<li><code>intersect_with_pop_push</code>:
这里涉及自动机理论，具体对应retypd论文里<code>D.4 Shadowing</code>的第二段（里面轻描淡写的一句）。把图看作自动机，创建一个新的图（自动机）保留原图的路径，仅去掉不允许先走pop边然后走push边的路径。把类型看作自动机之后，这里本质上是应用了自动机理论里语言相交的算法，节点数量为两边自动机状态数相乘。但是因为那边不允许pop+push的语言只需要两个自动机即可描述，节点只增加了一倍。</li>
<li><code>generate_recursive_type_variables</code>：这里和后续的<code>walk_constraints</code>函数相关。这里涉及自动机转正则表达式的算法。因为retypd原文中用文本形式表示约束，同时允许一种递归的约束形式，因此本质上就是正则表达式。retypd原文在Algorithm
D.1推荐的是Tarjan’s path expression algorithm。《A Unified Approach to
Path Problems》这篇。</li>
<li><code>walk_constraints</code>
见上面的描述。首先需要标记参数和返回值节点，作为interesting的节点，然后生成interesting节点之间的所有路径组合成的正则表达式。因为路径只允许先push一些边，然后再pop一些边，对应的就是约束两边的label，所以最后的表达式就是一系列constraint。这个最后也就是summary。</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><code>lower_labeled_sketch_graph</code>：
<ul>
<li><code>get_labeled_sketch_graph</code>：将节点转换为具体的类型。
<ul>
<li><a
href="https://github.com/trailofbits/binary_type_inference/blob/94918fa010b5d2fe0bb7589ebf3efe72ae5d9322/src/lowering/mod.rs#L550"><code>build_type</code></a>
递归访问节点，转换为C类型。涉及类型的图表示和语法树表示之间的对应关系。</li>
</ul></li>
</ul></li>
</ul>
<h3 id="类型的图表示">类型的图表示</h3>
<p>常规的类型往往都是语法树的形式。但是有时候会出现递归的数据结构。在代码里都是先声明，然后成员可以引用没有定义完的结构体类型。而在语法树上，可以发现树的子节点反向应用了之前的节点，这似乎使得树（有向无环图）形成了环，泛化为了一般的图。因此，我们直接使用图表示类型。对应retypd论文中的<code>Sketch</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">A</span> <span class="title">Ptr</span>*;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>CTF</tag>
        <tag>Decompile</tag>
      </tags>
  </entry>
  <entry>
    <title>Fuzzbench架构</title>
    <url>/2025/Fuzzbench%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<p>Fuzzbench的代码架构解析</p>
<span id="more"></span>
<h2 id="fuzzbench">Fuzzbench</h2>
<p>使用流程：</p>
<ul>
<li>根据教程创建好虚拟环境，并安装好python的包</li>
<li>调用make执行相关的debug和test-run</li>
<li>填写yaml，然后使用脚本运行实验</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> .venv/bin/activate</span><br><span class="line">PYTHONPATH=. python3 experiment/run_experiment.py \</span><br><span class="line">--experiment-config ./fuzzbench.yaml \</span><br><span class="line">--benchmarks mbedtls_fuzz_dtlsclient lcms_cms_transform_fuzzer libpcap_fuzz_both libxml2_xml \</span><br><span class="line">--experiment-name <span class="variable">$BENCHNAME</span> \</span><br><span class="line">--fuzzers libafl aflplusplus</span><br></pre></td></tr></table></figure>
<h2 id="运行相关的make命令">运行相关的Make命令</h2>
<ul>
<li><strong>生成Makefile</strong>：首先根目录的makefile会检查是否docker/generated.mk不存在，或者需要更新，然后使用docker/generate_makefile.py生成makefile，然后再include进来。</li>
</ul>
<h2 id="fuzzer的三大文件">Fuzzer的三大文件</h2>
<ul>
<li>builder.Dockerfile 负责下载和构建Fuzzer</li>
<li>fuzzer.py 提供两个函数，分别用于构建和运行fuzzer。</li>
<li>runner.Dockerfile 负责准备Fuzzer的运行环境</li>
</ul>
<h2 id="fuzzing相关的docker镜像">Fuzzing相关的Docker镜像</h2>
<p>各个镜像的构建方式是由上面生成的Makefile命令决定的。每个镜像都在makefile里面有个target。</p>
<p><img src="Fuzzbench-docker-arch.drawio.png" /></p>
<p><strong>1 基础镜像</strong></p>
<ul>
<li><strong>base-image镜像</strong>：最基础的镜像，由于不知道的原因，每个benchmark都是基于硬编码SHA的base-image，从gcr.io下载。</li>
<li><strong>dispatcher-image</strong>：用于。之后会将docker挂载进去，因此下载了docker-client，然后安装了llvm-cov等工具。最后复制了启动脚本startup-dispatcher.sh，它调用<code>src/experiment/dispatcher.py</code>。</li>
<li><strong>worker-image</strong>：它的启动命令是<code>rq worker $EXPERIMENT --url redis://$REDIS_HOST:6379</code>，本地跑似乎不会用到这个镜像。</li>
</ul>
<p><strong>2 Fuzz镜像</strong></p>
<ul>
<li><strong>bench-builder镜像</strong>：每个Benchmark提供的基础的bench-builder镜像里面负责存储项目的源码，并放好相关的构建脚本<code>$SRC/build.sh</code>。</li>
<li><strong>builder-intermediate镜像</strong>（Fuzzer的<strong>builder.Dockerfile</strong>）：<code>fuzzers/xxx/builder.Dockerfile</code>：每个Fuzzer提供的两个dockerfile之一。它开头是固定的通过参数传入Paren
Image。该镜像负责在原有的bench-builder镜像中<strong>构建好fuzzer自身</strong>，然后得到builder-intermediate镜像。</li>
</ul>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ARG</span> parent_image</span><br><span class="line"><span class="keyword">FROM</span> $parent_image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译并准备好fuzzer</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>builder镜像</strong>：基于builder-intermediate镜像，使用统一的dockerfile（<code>docker/benchmark-builder/Dockerfile</code>），开始<strong>用Fuzzer的插桩去构建Target</strong>。它安装了fuzzbench需要的python3，用于运行Fuzzer提供的三大文件之一的fuzzer.py。最后提供了一个fuzzer_build脚本，内部主要运行的是<code>python3 -c "from fuzzers import utils; utils.initialize_env(); from fuzzers.$FUZZER import fuzzer; fuzzer.build()"</code>，而给fuzzers提供的编译Target的接口<code>utils.build_benchmark</code>内部就是用bash执行<code>$SRC/build.sh</code>
这个就是最早bench-builder镜像放好的构建脚本。</li>
</ul>
<p>最终编译好的Target的相关文件会被放到<code>OUT=/out</code>。同时fuzzer.py也要将Fuzzer自身的binary放过去。</p>
<ul>
<li><p><strong>intermediate-runner镜像</strong>（Fuzzer的<strong>runner.Dockerfile</strong>）：从最基础的Base镜像，使用runner.Dockerfile构建，给fuzzer准备一些辅助的环境，比如安装一些包，设置一些环境变量。对于简单的fuzzer，这里是可以是空的。由于从Base重新构建，这里面不含任何Target和Fuzzer的东西。</p></li>
<li><p><strong>runner镜像</strong>：使用<code>docker/benchmark-runner/Dockerfile</code>统一构建。将builder镜像里面构建好的Fuzzer和Target复制到intermediate-runner镜像，然后复制了一些fuzzbench的源码进去，最后设置了entry
point为<code>docker/benchmark-runner/startup-runner.sh</code>。使用docker的multi-stage
build特性。</p></li>
</ul>
<p><strong>相关的debug target</strong></p>
<ul>
<li><strong>builder-debug镜像</strong>：在builder镜像的基础上增加了个<code>--build-arg debug_builder=1</code>。</li>
<li><strong>debug-builder-xxx
Target</strong>：在builder-debug镜像上给shell。</li>
<li><strong>debug-xxx Target</strong>：在runner镜像上给一个shell
<code>--entrypoint "/bin/bash"</code></li>
<li><strong>test-run
Target</strong>：在runner镜像基础上设置<code>SNAPSHOT_PERIOD=10</code>，<code>MAX_TOTAL_TIME=20</code></li>
</ul>
<p><strong>特殊的Fuzzer</strong></p>
<ul>
<li><strong>Coverage镜像</strong>：有个特殊的fuzzer叫做Coverage，内部其实是一个LLVM的Libfuzzer(LLVM的那个fuzzer)。它负责测量实验过程中的coverage：实验过程中提取所有的queue里的种子，然后拿这个插桩的binary跑一遍得到coverage信息。</li>
</ul>
<h2 id="启动一次实验">启动一次实验</h2>
<p>主要的入口是<code>experiment/run_experiment.py</code>。在运行前会把源码打包tar.gz到实验目录的<code>input/src.tar.gz</code>，然后再启动runner的时候解压到<code>/work/src</code>。这也是为什么每次跑实验都会打印一遍所有源码文件路径，因为是tar在解压。</p>
<p>实验的docker数量 = benchmark数量 * Fuzzer数量 * 重复数量 + 1</p>
<p>这里我们称某个（benchmark，fuzzer，trial）是一个pair，对应一个docker。</p>
<p><strong>Docker架构</strong>：处理跑实验的fuzzer容器，还有负责总体管理的dispatcher容器。就这两部分。</p>
<p><strong>Runner容器</strong></p>
<p>主要逻辑在<code>experiment/runner.py</code>。python主线程，首先启动runner线程跑具体的fuzzer，然后就不断sleep等待每个cycle，然后遍历<code>/out/corpus</code>文件夹，把修改日期更新的文件压缩一下，存放到<code>corpus-archives</code>文件夹。</p>
<p><strong>Dispatcher容器</strong></p>
<p>主要逻辑在<code>experiment/dispatcher.py</code>。会挂载docker
socks进去，所以能够启动docker镜像。会把experiment folder和report
folder按照主机完全一致的路径挂载进去。</p>
<ul>
<li><strong>构建镜像</strong>根据上面镜像的构建流程，得到最终runner镜像。具体就是使用docker依次构建Fuzzer，使用Fuzzer的Toolchain构建Fuzz
Target，最后将构建好的Target放到Fuzzer一起准备运行。</li>
<li>然后会将相关的参数转存并启动dispatcher-image，执行dispatcher.py。
<ul>
<li>dispatcher容器内部会启动scheduler_loop_thread</li>
<li>dispatcher容器内部会启动measurer进程。</li>
</ul></li>
<li>然后一边等待实验结束，一边生成临时的report。</li>
</ul>
<p>Scheduler和Measurer进程</p>
<p>两个进程的输出都是打印到stdout里的，即dispatcher的输出，或者说整个运行脚本的输出。但是里面的</p>
<ul>
<li><strong>scheduler</strong>：它会不断获取相关的需要运行的某个pair，然后执行启动流程（start_trials）。内部创建一个专门的脚本（render_startup_script_template），启动对应的runner。</li>
<li><strong>Measurer</strong>：主函数执行measure_manager_inner_loop，负责发送请求给measurers_cpus数量的子进程。子进程接受到请求就拉取queue然后测量coverage。这里有一个DEFAULT_SNAPSHOT_SECONDS=900s，以这个为周期编号，每隔这么久，那边Runner就会保存一下最新的种子到压缩包。然后这边Measurer就会从数据库找没有测量的周期，然后生成任务给worker，即尝试去拉取所有的fuzzer的coverage压缩包，解压并运行，测量一下Coverage。Coverage测量完直接存入数据库。</li>
</ul>
<p><strong>数据库相关</strong></p>
<ol type="1">
<li>Experiment表: 存储实验信息</li>
<li>Trial表: 存储每个试验的信息 (fuzzer + benchmark组合)</li>
<li>Snapshot表: 存储测量快照数据
(第812行的measured_snapshots就是这些对象)</li>
<li>Crash表: 存储崩溃信息</li>
</ol>
<p><strong>Coverage的测量原理</strong></p>
<p>首先用插桩过的binary跑输入，生成profraw文件，然后合并
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">llvm-profdata merge -sparse /work/measurement-folders/sqlite3_ossfuzz-honggfuzz_latest/trial-23/reports/data.profdata -o /work/measurement-folders/sqlite3_ossfuzz-honggfuzz_latest/merged.profdata</span><br><span class="line">llvm-cov export -format=text -num-threads=1 -region-coverage-gt=0 -skip-expansions /work/coverage-binaries/sqlite3_ossfuzz/ossfuzz -instr-profile=/work/measurement-folders/sqlite3_ossfuzz-honggfuzz_latest/merged.profdata</span><br><span class="line">cp /work/coverage/data/sqlite3_ossfuzz/honggfuzz_latest/covered_branches.json /xxx/experiment-data/debug16/coverage/data/sqlite3_ossfuzz/honggfuzz_latest/covered_branches.json</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>Fuzzing-MOpt-Mutator</title>
    <url>/2025/Fuzzing-MOpt-Mutator/</url>
    <content><![CDATA[<p>Fuzzing-MOpt-Mutator。再次阅读这篇paper《MOpt: Optimized Mutation
Scheduling for Fuzzers》</p>
<span id="more"></span>
<h3 id="主要思想">主要思想</h3>
<p>这里解决的问题是fuzzing过程中各种mutator的概率应该设置为多少比较好。这篇Paper引入了粒子群优化（Particle
Swarm Optimization, PSO）。</p>
<p><strong>主要思想</strong>：一个很简单的思想就是根据fuzzing过程中的结果去动态调整。先给一个基础的概率，然后在Fuzzing的过程中观察。众所周知，Fuzz过程中,会不断选取种子，随机使用mutator进行变异。如果当前的种子并没有覆盖额外的全局边，那么该种子将会直接被抛弃。如果产生了好的种子则会加入Corpus。如果当前Fuzz循环产生了好的种子，记录此时用到的mutator都是哪些，那么说明这些mutator肯定是更好的，应该增加他们的概率。</p>
<p><strong>为什么有粒子？</strong>：但是具体增加多少呢？反正得朝那个方向调整。如果我们把这个从零到一的一维的概率空间，上面某个mutator被使用的可能性看作一个粒子，那我们调整概率本质上就是调整这个粒子的位置。那么我们可以采用速度和加速度的办法调整概率，根据上面统计出来的好的mutator的情况。把好的mutator对应的粒子给他增加一个向概率增加方向的速度或者加速度（具体怎么做需要学习粒子群优化算法）。</p>
<p><strong>局部优化方案与全局优化方案</strong>：一方面，我们可以根据最近的固定数量的Fuzz尝试（最近的表现，局部表现），里面每个mutated的表现去调控，这对应了论文里面的Local
Best
Position。另外一方面，我们也可以统计整个fuzz过程的Mutated表现（全局表现）调控，对应了论文里面的Global
Best
Position。最后，论文尝试同时，维护这两个粒子群，选出表现比较好的用来调控mutator的概率。</p>
<h2 id="粒子群算法">粒子群算法</h2>
<p>推荐阅读这里 <a
href="https://zhuanlan.zhihu.com/p/398856271">《数学建模：非常通俗易懂的粒子群算法（PSO）入门》</a>
以及<a
href="https://www.usenix.org/sites/default/files/conference/protected-files/sec19_slides_lyu.pdf">论文的slides</a>的关键的两页</p>
<p>粒子群算法背后的直觉和原理请看上面的文章。我们这里详细解析MOpt是怎么应用过来的。</p>
<p>粒子群算法的核心公式如下（借用知乎文章的比喻，每个例子是一只鸟）：</p>
<p>这只鸟第d步的速度=上一步自身的速度惯性+自我认知部分+社会认知部分</p>
<p><span class="math display">\[
v_i^d = w v_i^{d-1} + c_1 r_1 (pbest_i^d - x_i^d) + c_2 r_2 (gbest^d -
x_i^d)
\]</span></p>
<p>鸟的新位置 = 鸟在上一轮的位置 + 鸟当前轮的速度
(因为每一步运动的时间t一般取1)</p>
<p><span class="math display">\[
x_i^{d+1} = x_i^d + v_i^d
\]</span></p>
<p>和论文PPT里的说明一致：</p>
<figure>
<img src="PSO.png" alt="alt text" />
<figcaption aria-hidden="true">alt text</figcaption>
</figure>
<h2 id="为fuzzing改进的粒子群算法">为Fuzzing改进的粒子群算法</h2>
<figure>
<img src="Fuzz-PSO.png" alt="alt text" />
<figcaption aria-hidden="true">alt text</figcaption>
</figure>
<p>每个鸟对应了一个Mutator。所在的位置对应了概率。因此，一开始随机分布位置的时候，让他们位置加起来等于1。整个粒子群就对应了所有mutator的概率分布。</p>
<p>w是惯性权重。如果惯性太高，会到处冲去搜索解空间，容易找到全局最优解，但是收敛更慢。而r对应的是个体学习因子和社会学习因子的学习权重。反正后面会有多个粒子群，这里可以随机取？</p>
<p>关键是怎么评判哪里是更优的解。根据最近的固定数量的Fuzz尝试，mutator的表现被定义为Local
Best Position，整个fuzz过程的Mutated表现，对应了论文里面的Global Best
Position。</p>
<p>局部最优位置
LBest：在一次iteration中，某个mutator的效率被定义为，有趣的测试用例的数量，除以调用这个mutator的次数。而LBest是历史上效率最高的时候的所在位置（概率）。</p>
<p>全局最优位置
GBest：在所有swan（群）中，该粒子（变异操作）得到的有趣测试用例数目。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>C指针分析基础</title>
    <url>/2025/C%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<p>C指针分析基础。</p>
<span id="more"></span>
<h2 id="什么是c语言指针分析">什么是C语言指针分析？</h2>
<p>首先你要比较了解C语言的指针。</p>
<h2 id="稀疏指针分析">稀疏指针分析</h2>
<p>我们都知道LLVM那种SSA形式是半-SSA，因为还是有内存中的变量。其中的道理是，内存通过指针访问，指针存储导致的定义点不明确。</p>
<p>如果存入某个指针，有两种情况： 1.
指针只可能指向一个地方：此时一定是为那个内存地址定义了新的变量。 1.
指针可能同时指向多个地方：此时可能为不同的内存地址定义变量，而且后续的load也会“有可能”访问某些变量，不知道具体访问的谁。</p>
<p>总之造成了定义-使用（Use-Def）关系的混乱。</p>
<p><strong>流敏感指针分析和SSA的关系</strong>：因为现有SSA，LLVM
IR都是不完善的SSA。所以只有表层变量是SSA。因此，这样分析下来，内存中变量因为没有分版本，本质上还是流非敏感的。only
context-sensitive for top-level variables</p>
<p><strong>流敏感指针分析的三大挑战</strong>：</p>
<ul>
<li>保守的传播：基于传统的CFG的传播方式，所有的指针指向信息都得传播到每个块上，即使这个块不会用到。因为算法是遍历基本块，极大增加了时间复杂度和内存需求。</li>
<li>复杂的转换函数：每个基本块要做gen/kill等集合的交集并集操作，复杂度随着集合大小线性增加。</li>
</ul>
<p><strong>流敏感指针分析的优化方法</strong>：</p>
<ul>
<li>优先级队列：按照CFG节点划分优先级worklist，优先处理靠上的CFG节点，使得前面先迭代，后面的块获取的就是更靠近最终结果的的IN信息，节约迭代时间。</li>
<li>函数调用时过滤有用的信息：被调函数能影响到的范围就是传入的对象，以及全局对象。其他无关的对象不用传入函数里面。</li>
</ul>
<h3 id="基于memory-ssa的稀疏指针分析">基于Memory SSA的稀疏指针分析</h3>
<h2 id="指针访问的ssa表示">指针访问的SSA表示</h2>
<h2 id="参考文献">参考文献</h2>
<h3 id="最简单的指针分析">最简单的指针分析</h3>
<ul>
<li>Anderson的指针分析论文</li>
<li>《Points-to Analysis in Almost Linear Time》 Bjarne Steensgaard
1996：最经典的基于unification的指针分析。</li>
</ul>
<h3 id="指针访问的ssa表示-1">指针访问的SSA表示</h3>
<ul>
<li>Effective representation of aliases and indirect memory operations
in SSA form.</li>
</ul>
<h3 id="指针分析">指针分析</h3>
<h2 id="两阶段的稀疏指针分析">两阶段的稀疏指针分析。</h2>
<ul>
<li>Semi-Sparse Flow-Sensitive Pointer Analysis</li>
<li>the ant and the grasshopper: fast and accurate pointer analysis for
millions of lines of code PLDI07</li>
</ul>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>StaticAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title>SVF-LLVM指针分析框架</title>
    <url>/2025/SVF-LLVM%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<p>本文解析SVF的代码框架。</p>
<span id="more"></span>
<h2 id="svf">SVF</h2>
<p>SVF是一个C++指针分析框架。</p>
<h2 id="whole-program-analysis">Whole Program Analysis</h2>
<ul>
<li>构建了LLVMModuleSet，包含了一系列Module，以及函数集合等。</li>
<li><a
href="https://github.com/SVF-tools/SVF/blob/45597fc4c7fe44ff798db73dde5e7097cb3af444/svf-llvm/lib/SVFIRBuilder.cpp#L54">构建SVFIR</a>：
<ul>
<li>处理外部函数节点，全局变量节点</li>
<li>转换类型：LLVM的类型被转换为了SVFType。</li>
<li>构建SVFIRCallGraph</li>
<li><a
href="https://github.com/SVF-tools/SVF/blob/45597fc4c7fe44ff798db73dde5e7097cb3af444/svf-llvm/lib/SVFIRBuilder.cpp#L1004">处理不同的指令</a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>StaticAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title>AFLplusplus的enhancedDeterministicMode</title>
    <url>/2025/AFLplusplus%E7%9A%84enhancedDeterministicMode/</url>
    <content><![CDATA[<p>AFL++的<a
href="https://github.com/AFLplusplus/AFLplusplus/pull/1972">Enhanced
Deterministic mode</a>的实现解析</p>
<span id="more"></span>
<p>deterministic
mode是最开始的时候AFL就有的一个和havoc并列的mutate阶段。而后续AFL++则进一步改进了这一阶段，增加了效率。本文介绍相关的内容。</p>
<h2 id="之前的deterministic-mode">之前的deterministic mode</h2>
<p><a
href="https://www.usenix.org/system/files/woot20-paper-fioraldi.pdf">《AFL++:
Combining Incremental Steps of Fuzzing Research》</a>
里面提到了AFL++的mutation分为两个主要部分，分别是这里解析的确定性变异（deterministic）和havoc。确定性变异阶段，AFL++会对种子进行单次的确定性的变异。使用的mutation通常包括bit
blips, addition, 用常见的整数值，比如INT_MAX,
-1等进行替换（substitution）。</p>
<p><a
href="https://blog.adacore.com/advanced-fuzz-testing-with-aflplusplus-3-00">这个网站</a>提到，deterministic策略会尝试bit
flip每个test-case的bit。</p>
<p>这一确定性的过程比较花时间，所以在fuzz初期的覆盖率上，开了会比不过关闭deterministic
mode。但是如果关闭deterministic
mode会直接缺失一部分的mutator，所以最后coverage收敛后，开启deterministic模式会高一点。</p>
<h3 id="effect-map">Effect Map</h3>
<p>如果某个字节，完全翻转（fully
flipped）都不会对执行的路径造成影响，则跳过对这些字节的deterministic阶段。</p>
<p>比如，如果一个值被用作for循环的循环次数，那么翻转了肯定是影响执行路径的，此时在deterministic阶段使用一些int_max或者-1这种值进行mutate就很有用，但是如果是普通的无关执行路径的值，那么浪费时间在上面也没有意义。</p>
<p>原版的AFL中就有了Effect map机制，在<a
href="https://github.com/ThePatrickStar/AFL-Original/blob/d09714865d3a211a9c1a682eaa9bb8b00327e842/afl-fuzz.c#L5421">这里</a>。</p>
<h2 id="enhanced-deterministic-mode">Enhanced deterministic mode</h2>
<p>原始的Pull Request:
https://github.com/AFLplusplus/AFLplusplus/pull/1972</p>
<p>在2024年1月份左右，有人提交了PR改进了deterministic模式，跳过了很多不必要的mutation。增加了总体的效率。在fuzzbench上的表现有所提升。在openthread_ot-ip6-send-fuzzer上提升很大。在sqlite3_ossfuzz，freetype2_ftfuzzer，woff2_convert_woff2ttf_fuzzer上略有提升。</p>
<p>这个Patch里面最核心的文件<code>afl-fuzz-skipdet.c</code>里面的最核心的函数是<code>skip_deterministic_stage</code>。在fuzz-one里面插入了对skip_deterministic_stage的调用，该函数设置了skip_eff_map(初始都为0)，然后正常执行deterministic
mode的时候，如果当前mutate的字节在skip_eff_map里面的值是0，则会直接跳过该字节。</p>
<h3 id="skip_deterministic_stage">skip_deterministic_stage</h3>
<h4 id="should_det_fuzz">should_det_fuzz</h4>
<p>首先，使用<code>should_det_fuzz</code>函数做初步的判断：</p>
<ul>
<li>如果种子不是favored，则直接跳过deterministic
stage（<code>!q-&gt;favored</code>）</li>
<li>基于coverage
map和virgin_det_bits进行考虑。virgin_det_bits是全局的一个数据结构，和coverage
map大小一样。如果当前的种子的coverage map
的某个bit是1，而全局的这个virgin_det_bits对应的地方不是1，则给new_det_bits加1。如果new_det_bits大于undet_bits_threshold则</li>
</ul>
<p>undet_bits_threshold是一个动态的阈值，每隔一段时间（20分钟），如果大于2，会乘以0.75。</p>
<h4 id="推理阶段inference-stage">推理阶段（Inference Stage）</h4>
<p>首先，在队列的每个种子的数据结构里，增加了<code>skipdet_entry</code>成员：
- <code>u8 continue_inf</code> - <code>u8 done_eff</code> -
<code>u32 undet_bits</code> - <code>u32 quick_eff_bytes</code> -
<code>u8 *skip_eff_map</code>
最重要的map，如果设置某个字节为0，则表示跳过。 -
<code>u8 *done_inf_map</code>：</p>
<p>首先这个节点会把skip_eff_map都设置为1，表示默认不跳过。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>LLVM的SROA解析</title>
    <url>/2025/LLVM-SROA/</url>
    <content><![CDATA[<p>LLVM的<a
href="https://llvm.org/docs/Passes.html#sroa-scalar-replacement-of-aggregates">SROA（Scalar
Replacement of Aggregates）</a>的实现解析</p>
<span id="more"></span>
<p>FCA: First Class Aggregate（第一类聚合体，如结构体或数组）</p>
<h2 id="总体思路">总体思路</h2>
<p>SROA是一个Function Pass，输入是单个函数。</p>
<ul>
<li><a
href="https://github.com/llvm/llvm-project/blob/e188aae406f3fecaed65a1f7e6562205f0de937e/llvm/lib/Transforms/Scalar/SROA.cpp#L4722"><code>SROAPass::runImpl</code></a>
里面的主体while函数包含了如下的步骤：</li>
</ul>
<ol type="1">
<li><strong>提前promote简单alloca</strong>：首先遍历entry基本块内的alloca指令。如果某个Alloca指令可以直接被Promote（<a
href="https://github.com/llvm/llvm-project/blob/e188aae406f3fecaed65a1f7e6562205f0de937e/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp#L65"><code>isAllocaPromotable</code></a>），简单来说仅被load和store，则提前给promote掉，用Mem2Reg相关的SSA构建函数。否则就加入工作队列中依次分析处理。</li>
<li><strong>runOnAlloca</strong>：处理剩下的每个alloca指令
<ul>
<li>维护了PromotableAllocas队列，存储可以被提升的Alloca指令。在循环结尾提升并清理。</li>
<li>维护了DeadInsts，存储等待被删除的指令，由函数deleteDeadInstructions删除</li>
<li>维护了DeletedAllocas，从DeletedAllocas里</li>
</ul></li>
</ol>
<h3
id="处理每个alloca指令runonalloca">处理每个alloca指令（runOnAlloca）</h3>
<ol type="1">
<li>如果没有任何User，或者是Array形式的alloca指令（即alloca的第二个操作数不是1）则直接不处理。</li>
<li>使用<code>AggLoadStoreRewriter</code>处理带有extractvalue指令的复杂的结构体的load和store。将结构体的load和store拆分为每个成员的load和store，然后再用extractvalue/insertvalue分开或者拼在一起。</li>
<li><strong>构建AllocaSlices</strong>，如果认定该alloca为escaped，则放弃</li>
<li>删掉没有User的一些地址的引用，比如bitcast（DeadUser）和DeadOp（即Alloca被Gep指令的使用，但是这个operand不可能被取到）</li>
<li>调用<strong>splitAlloca</strong>，基于计算得到的Alloca Slice分割。
<ol type="1">
<li><strong>presplitLoadsAndStores</strong>将过大的批量内存复制给分割开。</li>
<li>如果某个Slice和别的Slice要么不相交，要么互为包含关系就还好，如果出现了交替重叠则标记为无法split。</li>
<li>排序后依次调用<strong>rewritePartition</strong>重写每个分区。如果重写成功就放到Fragments。
<ol type="1">
<li>确定拆分后的Alloca的具体类型。找不到就用相关的整数或者i8数组</li>
<li>创建新的Alloca。</li>
<li><strong>AllocaSliceRewriter</strong>
访问每个Slice重写访问，同时判断是否Promotable。</li>
<li>可以提升则提升，不可以提升则回退相关结果然后返回</li>
</ol></li>
<li>修复每个Fragment的DebugInfo。</li>
</ol></li>
</ol>
<p>对于一个很大的alloca，会尽量将内部标记为unsplittable的</p>
<h3
id="allocaslicesalloca能否被拆分的判断"><strong>AllocaSlices</strong>：Alloca能否被拆分的判断</h3>
<p><code>AllocaSlices</code>的构造函数里调用了用于构建的<code>AllocaSlices::SliceBuilder</code>，它继承了<code>PtrUseVisitor</code>，递归遍历指针的Use树，分析指针的escaped
Flag和aborted
Flag。如果遇到了指针难以处理的情况，指针会标记为escaped。每次Visit某个Use时，会将成员变量<code>Use* U</code>设置，然后再把User
cast为指令然后访问。</p>
<ul>
<li>alloca可以被store和load读写。但是alloca自身的地址不能被store到别的地方。根据Load和Store的边界会分割Slice。</li>
<li>可以被Gep指令计算，但是如果计算得到了未知偏移的地址，则放弃处理。</li>
<li>遇到内存转移指令，memcpy/memmove，会根据复制点分割出Slice。</li>
</ul>
<p>继承后拓展的逻辑里，，额外维护了alloca的分割点，并创建Slice，partition等数据结构：</p>
<ul>
<li><code>Slice</code>表示一个Alloca的位置中的一个部分<code>[BeginOffset, EndOffset)</code>同时有一个<code>Use*</code>成员和一个isSplittable
Flag。这里的<code>Use*</code>存入的user一般是Load/Store指令。</li>
<li><code>Partition</code>是一种特殊的Slice数组的iterator，将相同范围内的Slice聚合起来一起返回。</li>
</ul>
<p><strong>已知偏移的维护</strong>：相关的逻辑在<code>PtrUseVisitor</code>里面首先在工作队列里面，存储Use的同时也会存储该指令基于的偏移。访问的时候，根据是否是什么gep指令去增加偏移。然后需要进一步访问的时候会调用<code>enqueueUsers</code>函数，然后在将Users放入工作队列的同时会存入当前的Offset。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>LLVM</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>Ghidra反编译器原理与代码架构解析</title>
    <url>/2025/Ghidra%E5%8F%8D%E7%BC%96%E8%AF%91%E5%99%A8%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BB%A3%E7%A0%81%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<p>Ghidra反编译器原理与架构解析</p>
<p>Ghidra Sleigh Decompiler Internals and Code Architectures</p>
<span id="more"></span>
<p><strong>相关资源</strong></p>


	<div class="row">
    <embed src="/2023.assets/D1T2_Taking_Ghidra_to_The_Next_Level_Zhanzhao_Ding.pdf" width="100%" height="550" type="application/pdf">
	</div>



<ul>
<li><a
href="https://github.com/NationalSecurityAgency/ghidra/blob/5604178194cb55ddb8526f843466d485ed8a36e6/Ghidra/Features/Decompiler/src/decompile/cpp/coreaction.cc#L5363">Ghidra反编译器的C++源码</a>
在这层目录执行make doc会使用doxygen生成HTML格式的<a
href="https://lemuellew.github.io/Ghidra-Decompiler-Analysis-Engine-Document/">文档</a>。</li>
<li><a
href="https://github.com/dannyquist/re/blob/master/ghidra/ghidra-getting-started.md">一个Ghidra的使用介绍</a></li>
<li><a
href="https://uwspace.uwaterloo.ca/bitstream/handle/10012/17976/Toor_Tejvinder.pdf?sequence=3&amp;isAllowed=y">一个Ghidra
PCode转LLVM的论文</a>和<a
href="https://github.com/toor-de-force/Ghidra-to-LLVM">代码</a></li>
<li><a
href="https://blog.grimm-co.com/2020/11/automated-struct-identification-with.html">Ghidra上的ASI结构体类型恢复</a></li>
</ul>
<h3 id="ghidra不是java写的吗">Ghidra不是Java写的吗？</h3>
<figure>
<img src="Ghidra的C++和Java代码关系.png"
alt="Ghidra的C++和Java代码关系" />
<figcaption aria-hidden="true">Ghidra的C++和Java代码关系</figcaption>
</figure>
<p>是的，但是反编译器是用C++写的。Java主要负责图形界面，反汇编器等外围数据结构，比如存储各种图形界面展示的信息。核心的反编译算法是用C++写的，并又Java进程启动子进程，中间似乎是通过一种特殊的XML格式通信（TODO）。</p>
<p>但是这个反编译器也自带一个简单的命令行，用于调试。Ghidra图形界面反编译结果右上角也可以生成一个xml格式的dump，包含了输入给C++反编译器进程的所有信息，用它可以复现某次反编译过程，便于调试。</p>
<h3 id="ghidra-反编译器简介">Ghidra 反编译器简介</h3>
<figure>
<img src="Ghidra反编译器内部模块.png" alt="Ghidra反编译器内部模块" />
<figcaption aria-hidden="true">Ghidra反编译器内部模块</figcaption>
</figure>
<p>反编译器内部，Protocol负责和Java进程通信，比如获取用户设置的变量名等。最关键的是Action，和LLVM的Pass类似。</p>
<figure>
<img src="反编译器内部流程.png" alt="反编译器内部流程" />
<figcaption aria-hidden="true">反编译器内部流程</figcaption>
</figure>
<p>这里参照<a
href="https://lemuellew.github.io/Ghidra-Decompiler-Analysis-Engine-Document/">文档</a>阅读，现有的反编译器都需要结合编译优化技术，因此往往也基于SSA的IR。然后就是一些特有的，比如逆向处理一些适合执行但是不适合分析的优化。最后是转表达式，然后CFG转if-else/while/for等AST控制流的结构恢复。</p>
<h3 id="阅读与调试">阅读与调试</h3>
<p><strong>代码阅读环境</strong>：尝试编译，并用bear等工具生成compile_commands.json。然后用VSCode打开有json的那层文件夹，然后使用clangd插件或者默认的C++插件，从而获得代码提示和跳转。</p>
<p><strong>代码调试环境</strong>：使用<code>make decomp_dbg</code>编译后，找到<code>cpp/decomp_dbg</code>可执行文件进行调试。<a
href="https://www.nccgroup.com/sg/research-blog/earlyremoval-in-the-conservatory-with-the-wrench-exploring-ghidra-s-decompiler-internals-to-make-automatic-p-code-analysis-scripts/">这里</a>也有相关的介绍</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;type&quot;: &quot;lldb&quot;,</span><br><span class="line">    &quot;request&quot;: &quot;launch&quot;,</span><br><span class="line">    &quot;name&quot;: &quot;Debug&quot;,</span><br><span class="line">    &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;/cpp/decomp_dbg&quot;,</span><br><span class="line">    &quot;args&quot;: [],</span><br><span class="line">    &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;,</span><br><span class="line">    &quot;env&quot;: &#123;&quot;SLEIGHHOME&quot;: &quot;/home/ubuntu/ghidra&quot;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="代码结构">代码结构</h3>
<p>最关键的分析在<a
href="https://github.com/NationalSecurityAgency/ghidra/blob/5604178194cb55ddb8526f843466d485ed8a36e6/Ghidra/Features/Decompiler/src/decompile/cpp/coreaction.cc#L5363"><code>universalAction</code></a>函数注册。上面的<code>buildDefaultGroups</code>给分析分组。</p>
<p>在启动的时候，会调用<code>ActionDatabase::resetDefaults</code></p>
<h3 id="sleigh-汇编转pcode-ir">SLEIGH 汇编转PCode IR</h3>
<p>TODO</p>
<h3 id="中端优化与类型恢复">中端优化与类型恢复</h3>
<p>TODO</p>
<h3 id="打印到语法树">打印到语法树</h3>
<p>数据结构上，Ghidra没有使用完善的C语法树节点，而是直接基于结构恢复算法的数据结构，以及PCode。直接在结构分析结束的时候打印为C代码。</p>
<p>结构分析是一个CFG转IF-ELSE/WHILE这种语法树形式的控制流的过程。使用的数据结构在最初的时候就是CFG，每个基本块里面的指令可以提前转为C代码，也可以之后转。在结构恢复过程中，会使用模式匹配，匹配IF-ELSE结构或者While循环，然后把相关的块折叠为一个线性执行的复合块（<a
href="https://github.com/NationalSecurityAgency/ghidra/blob/784540f1c0fc7df122f1c6591557edf608a8c1d1/Ghidra/Features/Decompiler/src/decompile/cpp/block.hh#L77"><code>FlowBlock</code></a>），或者说直接折叠为一个Statement，包含在其他基本块中。在分析结束的时候，整个函数就只有一个函数体的单个基本块。</p>
<p>这里Ghidra在结构分析结束的时候直接基于这个复合块打印。Ghidra对每种特殊的块都实现同一个emit虚函数，然后<a
href="https://github.com/NationalSecurityAgency/ghidra/blob/784540f1c0fc7df122f1c6591557edf608a8c1d1/Ghidra/Features/Decompiler/src/decompile/cpp/block.hh#L699">转调</a><code>printc.cc</code>里面<code>PrintC</code>的方法。</p>
<p>具体每个语句，即内部的表达式是<a
href="https://github.com/NationalSecurityAgency/ghidra/blob/e5969a613cdca59252cc0366254d005597c313a2/Ghidra/Features/Decompiler/src/decompile/cpp/printc.cc#L2716">直接基于PCode打印</a>的。具体是<a
href="https://github.com/NationalSecurityAgency/ghidra/blob/e5969a613cdca59252cc0366254d005597c313a2/Ghidra/Features/Decompiler/src/decompile/cpp/printc.cc#L2464"><code>PrintC::emitExpression</code></a>函数。这里有一个<code>RPN stack</code>逆波兰表示法。</p>
<p>其他反编译器是怎么做的？<a
href="https://github.com/uxmal/reko/blob/f9ff640ea95cbde1f2f4ce948339d42e392d5dab/src/Decompiler/Decompiler.cs#L315">reko的做法</a>类似</p>
<h3 id="decomp_dbg">decomp_dbg</h3>
<p><a
href="https://www.nccgroup.com/sg/research-blog/earlyremoval-in-the-conservatory-with-the-wrench-exploring-ghidra-s-decompiler-internals-to-make-automatic-p-code-analysis-scripts/">这里</a>的执行实例，可以总结出大致的流程：</p>
<ul>
<li>首先使用<code>SLEIGHHOME=/opt/ghidra_10.1.2 ./decomp_dbg</code>启动</li>
<li>使用<code>restore /tmp/mystery_printf_main.xml</code>命令加载某次反编译信息。
<ul>
<li>这里也可以用binary命令直接加载某个二进制？。</li>
</ul></li>
<li>然后执行<code>load function main.main</code></li>
<li><code>trace address 0x48e7c4</code>
追踪某个指令被每个优化怎么修改了。</li>
<li><code>decompile</code> 启动反编译</li>
</ul>
<p>decomp_dbg命令行处按Tab有如下的命令： - <code># % //</code> 表示注释
- addpath - adjust vma - analyze range - binary - break action - break
jumptable - break start - callgraph build - callgraph build quick -
callgraph dump - callgraph list - callgraph load - clear architecture -
closefile - codedata dump crossrefs - codedata dump hits - codedata dump
starts - codedata dump targethits - codedata dump unlinked - codedata
init - codedata run - codedata target - comment instruction - continue -
count pcode - deadcode delay - debug action - decompile - disassemble -
dump - duplicate hash - echo - execute test command - fixup apply -
fixup call - fixup callother - force datatype - force goto - force
varnode - global add - global registers - global remove - global spaces
- graph controlflow - graph dataflow - graph dom - history - isolate -
list action - list override - list prototypes - list test commands -
load addr - load file - load function - load test file - map address -
map convert - map externalref - map function - map hash - map label -
map unionfacet - name varnode - openfile append - openfile write -
option - override flow - override jumptable - override prototype - parse
file - parse line - pointer setting - prefersplit - print C - print C
flat - print C globals - print C types - print C xml - print actionstats
- print cover high - print cover varnode - print cover varnodehigh -
print extrapop - print high - print inputs - print inputs all - print
language - print localrange - print map - print parammeasures - print
raw - print spaces - print tree block - print tree varnode - print
varnode - produce C - produce prototypes - prototype lock - prototype
unlock - quit - read symbols - readonly - remove - rename - reset
actionstats -
restore：这个命令后面加导出的XML文件，就可以复现一次反编译过程了 -
retype - save - set context - set track - source - structure blocks -
trace address - trace break - trace clear - trace disable - trace enable
- trace list - type varnode - volatile</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>CTF</tag>
        <tag>Decompile</tag>
      </tags>
  </entry>
  <entry>
    <title>分析数据的相关性和因果性</title>
    <url>/2025/%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%92%8C%E5%9B%A0%E6%9E%9C%E6%80%A7/</url>
    <content><![CDATA[<p>分析数据的相关性和因果性</p>
<span id="more"></span>
<h2 id="资料">资料</h2>
<p>相关书籍：</p>
<ul>
<li>《统计因果推理入门-Judea-Pearl》</li>
<li>《数据挖掘导论》</li>
<li>《数据挖掘：概念与技术》</li>
<li><a
href="https://github.com/Doragd/Algorithm-Practice-in-Industry">这里</a>
搜索因果推理</li>
<li><a
href="https://cosx.org/2022/10/causality-statistical-method/">因果推断的统计方法</a></li>
<li><a
href="http://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&amp;mid=2247618221&amp;idx=1&amp;sn=bbbb4acd59fa304fd9941138d03a5b03&amp;chksm=fbd6bcc1cca135d72d19924659d0ba226d516409c975610d077e64705d351b2c0b82ee46da4f&amp;scene=27#wechat_redirect">因果推理主要技术思想与方法总结</a></li>
</ul>
<p>结构因果框架主要的文献：</p>
<ul>
<li>《统计因果推理入门》- Judea, Pearl</li>
<li>J. Pearl. Causality: models, reasoning and inference, volume 29.
Springer, 2000.</li>
<li>J. Pearl. <a
href="https://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf">Causal inference in
statistics: An overview</a>. Statistics surveys, 3:96–146, 2009.</li>
<li>https://blog.csdn.net/l8947943/article/details/128946593</li>
</ul>
<h2
id="相关性挖掘机器学习大数据数据挖掘">相关性挖掘（机器学习、大数据、数据挖掘）</h2>
<blockquote>
<p>实际上，在面对少量数据时关联分析并不难，可以直接使用统计学中有关相关性的知识，这也正是机器学习界没有研究关联分析的一个重要原因。</p>
<p>关联分析的困难其实完全是由海量数据造成的，因为数据量的增加会直接造成挖掘效率的下降，当数据量增加到一定程度，问题的难度就会产生质变，例如，在关联分析中必须考虑因数据太大而无法承受多次扫描数据库的开销、可能产生在存储和计算上都无法接受的大量中间结果等，而关联分析技术正是围绕着“提高效率”这条主线发展起来的。在R.
Agrawal等人首先对关联规则挖掘进行研究之后，大批学者投身到这方面的研究中并产生了很多成果，代表性工作有R.
Agrawal和R. Srikant的Apriori算法以及J. Han等人的FP-Growth算法等。</p>
<p>--- <a
href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/cccf07.pdf">《机器学习与数据挖掘》</a></p>
</blockquote>
<p>因此，分析数据的相关性和因果性，可以从下面两个角度：</p>
<ul>
<li>基于统计学的相关性：因果分析</li>
<li>针对大数据的算法</li>
</ul>
<h3 id="数据的相关性">数据的相关性</h3>
<ul>
<li><a
href="https://zhuanlan.zhihu.com/p/194254252">《数学建模笔记——相关系数》</a></li>
</ul>
<p><strong>Pearson 相关系数</strong></p>
<p>高中的时候我们都学过相关系数，对于两个二值的变量有一个表，然后根据公式可以有一个相关系数，从而判断是否存在线性关系。</p>
<p>φ = (ad - bc) / √((a+b)(c+d)(a+c)(b+d))</p>
<p>这个相关系数进一步拓展到连续变量就是Pearson 相关系数Pearson
相关系数表示为 <span class="math inline">\(\rho(X,Y) =
\sigma_{xy}/(\sigma_x\sigma_y)\)</span>，其中，<span
class="math inline">\(\sigma_{xy}\)</span> 是 <span
class="math inline">\(X,Y\)</span> 的协方差，<span
class="math inline">\(\sigma_x,\sigma_y\)</span> 分别是 <span
class="math inline">\(X,Y\)</span> 的标准差。</p>
<p>对于很多不同数据形成的一个表，我们可以列出数据之间两两的Pearson
相关系数，形成一个相关系数矩阵，方便我们进一步观察哪两个数据之间相关。</p>
<p><strong>斯皮尔曼秩相关系数</strong></p>
<p>然而，Pearson
相关系数假设变量之间关系大致呈线性，且数据最好服从二元正态分布（对大样本要求可放宽）。不符合假设的时候，我们可以使用<strong>斯皮尔曼秩相关系数</strong>。它衡量两个变量之间单调关系的强度和方向（无论是否为线性）。它的思想非常简单，为每个数据点在X和Y内部分配排名（秩），得到两个秩序列，然后对这两个配对好的秩序列直接套用皮尔逊公式。通过这种分配排名的方式，就可以更好地衡量非线性关系的同时，突出相关性。</p>
<h2 id="因果分析">因果分析</h2>
<p>统计学只能给出相关性的表示，而无法给出因果关系的表示。即使是数学表示上，也缺乏这种单向性。随着因果分析在近年来的发展，相关理论应当被更广泛地应用。</p>
<h3 id="背景">背景</h3>
<p><strong>重要性：辛普森悖论</strong></p>
<ul>
<li>数据总体上的结果，可能和内部<strong>每</strong>一小块细分数据相反！（辛普森悖论）</li>
<li>相关性不是因果关系。统计学知识通常只能分析出相关性。</li>
</ul>
<p><strong>样例1</strong></p>
<table>
<thead>
<tr>
<th>患者</th>
<th>患者服药情况</th>
<th></th>
<th>患者未服药情况</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>症状患者数</td>
<td>症状率/%</td>
<td>症状患者数</td>
<td>症状率/%</td>
</tr>
<tr>
<td>男性患者</td>
<td>81 例（共 87 例）</td>
<td>93</td>
<td>234 例（共 270 例）</td>
<td>87</td>
</tr>
<tr>
<td>女性患者</td>
<td>192 例（共 263 例）</td>
<td>73</td>
<td>55 例（共 80 例）</td>
<td>69</td>
</tr>
<tr>
<td>合计</td>
<td>273 例（共 350 例）</td>
<td>78</td>
<td>289 例（共 350 例）</td>
<td>83</td>
</tr>
</tbody>
</table>
<p>对于男性和女性各自有效，但是为什么合起来看就没有效果了呢？难道说，医生如果知道性别就可以开药，不知道性别就不能开药吗？</p>
<p>因为女性的激素让她们更不容易痊愈。而因为允许患者自由选择是否服药，导致数据中，女性更倾向于服药，男性倾向于不服药。导致整体的数据受到了数据分布的偏差。更进一步地，女性在服药中权重更大，因此整体的服药痊愈率被拉低到女性服药后的结果。整体的不服药痊愈率，被拉高到男性的结果。</p>
<p><strong>广告推荐，策略投放的应用</strong></p>
<p>因果推理的用途： -
探索变量之间的关系，即相关性。常规机器学习在应用中主要学习的就是变量之间的相关性。
-
研究实施某种干扰的效果，这一层次在营销领域使用得较多，典型的例子是uplift
model。举个例子，我们对某个地方或者某一群用户发放优惠券，我们考虑发多少优惠券、对哪些人发放优惠券，实施这一行为后产生的效果或者收益是否符合业务预期。这类方法被称为干扰或者干预。
-
结果考虑原因，被称为反事实推断，即如果我想得到某种结果我们应该做什么改变。现在大多数因果建模都是从这一层次来进行探索。</p>
<h3 id="因果分析的知识体系"><strong>因果分析的知识体系</strong></h3>
<p>因果分析有几个著名的框架：“潜在结果框架” potential outcome
framework和 结构因果框架 structural causal
model。它们是两种完全不同的范式。结构因果框架致力于从纯观测数据中发现因果关系，自动学习因果结构的骨架或方向。而潜在结果框架旨在精确估计一个特定干预或处理（Treatment）对某个结果（Outcome）的定量影响。它通常不关心整个系统的全图，而是聚焦于一对具体的因果关系。潜在结果模型主要用于估计变量之间一度相关的影响(i.e，只允许有一个因变量和一些自变量，不能估计间接影响的链路)。如何学习众多变量之间的链路和复杂关系，则需要用到另一个流派
结构因果框架 的结构因果模型方法。</p>
<p>基于因果网络模型方法主要可以检验和改进已知的网络，但弱点是，在实际中很难得到一个已知的因果网络。潜在结果模型的方法不需要一个已知的因果网络，但是需要可忽略处理分配假定或者工具变量假定。</p>
<h2 id="结构因果框架">结构因果框架</h2>
<p>控制随机试验是发现因果关系的首选方法。即使不能控制，在特定假设下，随机变量间的部分或完整因果关系可以从观测数据中还原
(Pearl,2009b)。</p>
<p>主要的假设 - Causal
Markov因果马尔可夫假设：该假设意味任何节点的条件分布仅基于其直接父节点。
- Causal Sufficiency
因果充分性假设：该假设等同于不存在无法观测的混淆变量。 - Causal
Faithfulness
因果忠诚性假设：该假设意味基于一些条件概率分布，一些节点之间是独立的（因此图可以被切割）。</p>
<p><strong>d-分离</strong></p>
<p><strong>前门准则</strong></p>
<p><strong>后门准则</strong></p>
<p><strong>因果网络学习</strong></p>
<p>因果网络学习又分为因果网络的参数学习和结构学习。因果网络结构学习有两类方法：基于条件独立检验的方法学习出所有满足faithfulness和causal
markov假设的因果图，即检验两个节点之间的条件分布是否独立。例如PC算法（Spirtes
and Glymour 1991）和IC算法（Verma and Pearl 1990）。</p>
<ul>
<li><strong>IC算法</strong>：Verma and Pearl (1990) 提出了 IC (inductive
causation) 算法，首先针对任意两个节点 <span
class="math inline">\(X_i\)</span> 和 <span
class="math inline">\(X_j\)</span> 尽力搜索是否存在分离集 <span
class="math inline">\(S_{ij}\)</span> 使得条件独立 <span
class="math inline">\(X_i \perp\!\!\!\perp X_j \mid S_{ij}\)</span>
成立；如果存在这样的 <span
class="math inline">\(S_{ij}\)</span>，则删去这两个节点间的边。然后利用两个不相邻的节点
<span class="math inline">\(X_i\)</span> 和 <span
class="math inline">\(X_j\)</span>，如果它们的公共邻居 <span
class="math inline">\(X_k\)</span> 不包含在它们的分离集 <span
class="math inline">\(S_{ij}\)</span> 中，则确定一个 V-结构 (<span
class="math inline">\(X_i \rightarrow X_k \leftarrow
X_j\)</span>)。最后确定其他边的方向，避免出现新的 V-结构和有向环。</li>
<li><strong>PC算法</strong>：在 IC 算法中穷尽搜索分离集 <span
class="math inline">\(S_{ij}\)</span>
的计算复杂度很高，并且对于大的分离集 <span
class="math inline">\(S_{ij}\)</span>，其条件独立检验功效低。为了改善 IC
算法的效率，Spirtes and Glymour (1991) 提出了 PC (Peter and Clark)
算法。PC
算法仍是将完全图作为初始骨架图，然后从空集开始逐步增大分离集的大小，不断删除骨架图中的边，使得每个结点的邻居数不断减少，寻找两个节点的分离集限定在它们的邻居集的子集范围内，目的是避免高维变量的条件独立检验。后续的研究对
PC
算法不断改进，克服了其在稳定性、潜在混杂变量处理、非线性因果关系处理、混合变量处理等方面的不足。Colombo
and Maathuis (2014) 提出了 Stable PC
算法，通过引入稳定骨架学习及固定定向规则的修改，降低了 PC
算法对随机变量的序列关系的敏感度，使其在高维变量的场景中仍能获得稳定的结构学习效果。FCI/RFCI
算法及其变体被提出 (Spirtes et al.,2000,1999;),
用以在未观测混杂变量和样本选择偏差存在的情况下学习因果结构，这些方法在
PC 邻接搜索的基础上，利用额外的条件独立性检验以处理潜在混杂变量。Zhang
et al.(2012)
提出基于核的独立性检验方式并给出条件独立零假设下的渐近分布构造方法，以支持非线性假设下的因果关系发现。Copula
PC(Cui et al.,2016)将 PC 算法中基于相关矩阵的独立性检验更新为基于高斯
copula
相关矩阵的独立性检验，以支持混合变量（连续和离散变量并存）下的因果结构学习。</li>
</ul>
<p>在所有可能生成的图中进行搜索是NP-Hard的问题。第二种方法，通过最优化定义的某种score来寻找和数据最匹配的图结构，避免了搜索所有可能的图。NOTEARS算法将离散搜索的问题转化成了连续搜索的问题。该算法极大提高了运算速度。但这个方法也存在着一定的局限性，例如假设所有变量的噪声必须是高斯分布。近年来也有越来越多的方法（如He
et al.2021）尝试改进这类方法的假设。</p>
<p>Copula PC(Cui et al.,2016)将 PC
算法中基于相关矩阵的独立性检验更新为基于高斯 copula
相关矩阵的独立性检验，以支持混合变量（连续和离散变量并存）下的因果结构学习。</p>
<p><strong>将因果网络进行参数化</strong></p>
<p>将因果网络进行参数化，利用结构方程模型（SEM）描述变量间的因果关系。将结果变量
<span class="math inline">\(Y\)</span> 与直接原因变量集合 <span
class="math inline">\(X\)</span> 和噪音项 <span
class="math inline">\(\varepsilon\)</span> 用结构方程 <span
class="math inline">\(Y = f(X, \varepsilon)\)</span> 联系起来，其中
<span class="math inline">\(X\)</span> 和 <span
class="math inline">\(\varepsilon\)</span>
相互独立。因果方向的可判定问题是 SEM 研究中的一项重要课题。Hoyer et
al.(2009); Shimizu et al.(2006)
的研究表明，当噪音项服从非高斯分布或者函数方程满足非线性约束时，由于原因变量和噪音项间的独立性仅在正确的因果方向下成立，使得变量间的因果方向是可判定的。</p>
<p>LINGAM (Shimizu et al., 2006)
是该研究方向的一个代表性模型，它建模连续随机变量间的因果关系，假设变量间线性关联且噪音项服从非高斯分布。独立主成分分析技术（ICA）被用于
LINGAM 的模型选择，由于超参数选择问题，ICA
算法常常陷入局部最优而无法收敛于最优解。为此，DirectLiNGAM 算法 (Shimizu
et al., 2011)
利用外部变量及非外部变量在其上的回归残差间的独立性信息求解变量间的因果结构，被证明可以收敛于最优。后续研究针对
LINGAM 在诸多方向上进行了扩展。例如，Hoyer et al.(2008)
将潜在混杂变量及其对观测变量的影响进行建模，并利用完备 ICA
算法实现模型选择。Henao and Winther (2011) 提出一种
方法来解带潜在线性因子的 LINGAM 模型。Lacerda et al.(2008) 和 Hyvarinen
and Smith (2013) 将 LINGAM
进行了有环化的扩展，并给出了模型可判定的充分条件。Zhang and Hyvarinen
(2009) 扩展 LINGAM
以处理随机变量间的非线性因果关系，并证明除个别非线性函数及数据分布外，其模型是可判定的。Zhang
et al.(2010) 对这些非线性模型进行扩展以处理潜在混杂变量。</p>
<p>噪音可加模型（additive noise model, ANM）将因果关系建模为 <span
class="math inline">\(Y = f(X) + \varepsilon\)</span>。Hoyer et
al.(2009) 的研究表明，当函数满足非线性约束时，该模型是可判定模型。Hoyer
et al.(2009)
利用目标变量与源变量在其上非线性回归的残差之间的独立性信息判定因果方向。Buhlmann
et al.(2013) 提出基于 评分准则的非线性 ANM 的模型选择算法。Mooij et
al.(2011) 致力于有环 ANM
的模型选择等。针对似然函数方法存在的马尔科夫等价类问题，Cai et
al.(2018a)
通过将结构方程模型引入到似然函数计算框架中，实现了似然函数方法和结构方程模型的有效结合较好地解决了马尔科夫等价类问题。Fei
and Yang (2017)
提出了一种结合探索性因子分析和路径分析方法推断存在隐变量情况下的因果关系，利用因子分析得到相对各自独立的隐变量，采用路径分析（PA）算法得到观测变量之间的因果方向与因果关系，扩展了隐变量以及它们与观测变量之间的线性因果关系。</p>
<p>还有一些研究将独立性检验和逻辑推理结合，以解决 PC
类算法的稳健性问题（不正确的独立性检验会导致连锁的定向错误）。该类方法的另一个优势在于易集成多种类别的先验知识，同时易于处理未观测的混杂因素及数据选择偏差。Claassen
and Heskes (2011)
将变量间的（条件）独立信息转换成逻辑命题，并给出了相应的逻辑推理算法以识别部分祖先图（PAG）。Hyttinen
et al.(2013)
提出使用一阶逻辑编码随机变量间的条件独立关系，从而将因果关系发现问题转换成骨干变量求解问题，并利用
SAT 处理器识别因果结构。Borboudakis and Tsamardinos (2016)
的工作更进一步定义了更多的逻辑项及规则对控制试验数据、非同源数据等信息进行编码及推理，实现了更泛化的因果结构学习。</p>
<h2 id="潜在结果框架">潜在结果框架</h2>
<p>参考资料： - <a
href="https://zhuanlan.zhihu.com/p/360837921">因果推断综述解析</a></p>
<p>识别因果效应的三个关键假设</p>
<p>权重分配方法、分层推理方法、基于匹配的方法、基于树的方法、基于表征的方法、基于多任务学习的方法和基于元学习的方法</p>
<p>放松上述三个假设的因果推断方法，以满足不同情况下的需求</p>
<h3 id="贝叶斯网络">贝叶斯网络</h3>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>Honggfuzz的DynamicFeedbackDict</title>
    <url>/2025/Honggfuzz%E7%9A%84DynamicFeedbackDict/</url>
    <content><![CDATA[<p>Honggfuzz的DynamicFeedbackDict机制</p>
<span id="more"></span>
<h2 id="实际场景的优势">实际场景的优势</h2>
<p>Honggfuzz实现了一套相比现有cmplog更简单的机制，却达到了很好的效果，甚至在proj4_proj_crs_to_crs_fuzzer这个benchmark上超越了其他的fuzzer。</p>
<figure>
<img src="honggfuzz-decdict.png"
alt="honggfuzz 禁用feedback dict后，效果大打折扣" />
<figcaption aria-hidden="true">honggfuzz 禁用feedback
dict后，效果大打折扣</figcaption>
</figure>
<p>可以看到图中，禁用feedback的hongfuzz-decdict，覆盖率降低了接近一半。正常的honggfuzz-orig，比AFL++效果还要好。</p>
<h2 id="clang的trace-cmp选项">Clang的trace-cmp选项</h2>
<p><a
href="https://clang.llvm.org/docs/SanitizerCoverage.html#tracing-data-flow">Clang可以增加<code>--trace-cmp</code>选项</a>，在代码中出现比较指令的时候，会调用提供的插桩函数。比如下面就是8字节比较会插入的插桩函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> __sanitizer_cov_trace_cmp8(<span class="type">uint64_t</span> Arg1, <span class="type">uint64_t</span> Arg2);</span><br></pre></td></tr></table></figure>
<p>honggfuzz提供的插桩函数在<code>/sn640/fuzzerlog/honggfuzz/libhfuzz/instrument.c</code>。</p>
<h3 id="honggfuzz的插桩逻辑">Honggfuzz的插桩逻辑</h3>
<p>Hongfuzz的feedback dict主要分为两部分，</p>
<ul>
<li>插桩部分负责将重要的内容存入dict数组，即生成dict关键词。</li>
<li>后续mutation中随机抽取数组中的词找个位置随机插入或者覆盖（即和普通的dict使用一致（虽然使用概率很高，大于50%）。</li>
</ul>
<p>因此主要介绍插桩部分。</p>
<p>首先是存储生成的dict的数组。结构如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> cnt;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">        <span class="type">uint8_t</span>  val[<span class="number">32</span>];</span><br><span class="line">        <span class="type">uint32_t</span> len;</span><br><span class="line">    &#125; valArr[<span class="number">1024</span> * <span class="number">16</span>];</span><br><span class="line">&#125; <span class="type">cmpfeedback_t</span>;</span><br></pre></td></tr></table></figure>
<p>这个结构在整个fuzzing过程中共享一个实例。其中第一个字段的cnt会随着fuzz过程不断增长。每个dict的值不能超过32字节大小，总数量不超过1024*16个。后面mutation的时候就是随机抽取valArr里的成员。所以我们重点关注valArr的使用。</p>
<p>以<code>__sanitizer_cov_trace_cmp8</code>为例，主要有以下几个插桩逻辑：</p>
<ul>
<li>每4095次才进入内部，即按概率随机抽取进入内部逻辑。</li>
<li><code>__builtin_bswap64</code>主要负责处理大小端的问题。</li>
<li><code>util_64bitValInBinary</code>很关键，仅过滤出binary中存在的内容，加入dict。因为比较运算的时候，经常是输入中的一个什么东西和程序里的常量比较。如果不加过滤，那么就是把fuzz自己得出的东西当做dict使用，意义不大。
<ul>
<li>在最开始的时候，honggfuzz会整理程序中的值存到values32InBinary数组中。这个数组在<code>collectValuesInBinary_cb</code>中被初始化。它使用libdl，遍历程序（非动态链接库）中readonly的段，就直接按32字节，64字节收集起来了。然后排序，方便后续二分查找。</li>
</ul></li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> __sanitizer_cov_trace_cmp8(<span class="type">uint64_t</span> Arg1, <span class="type">uint64_t</span> Arg2) &#123;</span><br><span class="line">    <span class="comment">/* Add 8byte values to the const_dictionary if they exist within the binary */</span></span><br><span class="line">    <span class="keyword">if</span> (globalCmpFeedback &amp;&amp; instrumentLimitEvery(<span class="number">4095</span>)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (Arg1 &gt; <span class="number">0xffffff</span>) &#123;</span><br><span class="line">            <span class="type">uint64_t</span> bswp = __builtin_bswap64(Arg1);</span><br><span class="line">            <span class="keyword">if</span> (util_64bitValInBinary(Arg1) || util_64bitValInBinary(bswp)) &#123;</span><br><span class="line">                instrumentAddConstMemInternal(&amp;Arg1, <span class="keyword">sizeof</span>(Arg1));</span><br><span class="line">                instrumentAddConstMemInternal(&amp;bswp, <span class="keyword">sizeof</span>(bswp));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (Arg2 &gt; <span class="number">0xffffff</span>) &#123;</span><br><span class="line">            <span class="type">uint64_t</span> bswp = __builtin_bswap64(Arg2);</span><br><span class="line">            <span class="keyword">if</span> (util_64bitValInBinary(Arg2) || util_64bitValInBinary(bswp)) &#123;</span><br><span class="line">                instrumentAddConstMemInternal(&amp;Arg2, <span class="keyword">sizeof</span>(Arg2));</span><br><span class="line">                instrumentAddConstMemInternal(&amp;bswp, <span class="keyword">sizeof</span>(bswp));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    hfuzz_trace_cmp8_internal((<span class="type">uintptr_t</span>)__builtin_return_address(<span class="number">0</span>), Arg1, Arg2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面插桩获取的都是大小为4或者8的值，此外，字符串比较也非常重要。这是通过<code>libhfuzz/memorycmp.c</code>里的插桩实现的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">__sanitizer_weak_hook_strcmp</span><br><span class="line">__sanitizer_weak_hook_strcasecmp</span><br><span class="line">__sanitizer_weak_hook_stricmp</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">instrumentAddConstStr</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* s)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!globalCmpFeedback) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!instrumentLimitEvery(<span class="number">127</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * if (len &lt;= 1)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (s[<span class="number">0</span>] == <span class="string">&#x27;\0&#x27;</span> || s[<span class="number">1</span>] == <span class="string">&#x27;\0&#x27;</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 关键的检查，地址要是程序内部的地址。</span></span><br><span class="line">    <span class="keyword">if</span> (util_getProgAddr(s) == LHFC_ADDR_NOTFOUND) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    instrumentAddConstMemInternal(s, <span class="built_in">strlen</span>(s));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于字符串比较，也存在可能把自己fuzz随机生成的东西抓过来的问题。这里通过判断<strong>值的地址是不是映射到二进制内部</strong>进行筛选。一般程序输入的值都在栈上或者堆上，然后和程序自带的字符串（位于不可变的内存区域）进行比较。如下面的代码所示，如果值太长就切断到32字节。同时也会遍历已有的map找是否已经这个值已经被插入了。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">instrumentAddConstMemInternal</span><span class="params">(<span class="type">const</span> <span class="type">void</span>* mem, <span class="type">size_t</span> len)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (len &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (len &gt; <span class="keyword">sizeof</span>(globalCmpFeedback-&gt;valArr[<span class="number">0</span>].val)) &#123;</span><br><span class="line">        len = <span class="keyword">sizeof</span>(globalCmpFeedback-&gt;valArr[<span class="number">0</span>].val);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 检查dict数组长度不能超过收集的最大数量</span></span><br><span class="line">    <span class="type">uint32_t</span> curroff = ATOMIC_GET(globalCmpFeedback-&gt;cnt);</span><br><span class="line">    <span class="keyword">if</span> (curroff &gt;= ARRAYSIZE(globalCmpFeedback-&gt;valArr)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果和现有的项目完全相同就跳过</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; curroff; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> ((len == ATOMIC_GET(globalCmpFeedback-&gt;valArr[i].len)) &amp;&amp;</span><br><span class="line">            hf_memcmp(globalCmpFeedback-&gt;valArr[i].val, mem, len) == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> newoff = ATOMIC_POST_INC(globalCmpFeedback-&gt;cnt);</span><br><span class="line">    <span class="keyword">if</span> (newoff &gt;= ARRAYSIZE(globalCmpFeedback-&gt;valArr)) &#123;</span><br><span class="line">        ATOMIC_SET(globalCmpFeedback-&gt;cnt, ARRAYSIZE(globalCmpFeedback-&gt;valArr));</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">memcpy</span>(globalCmpFeedback-&gt;valArr[newoff].val, mem, len);</span><br><span class="line">    ATOMIC_SET(globalCmpFeedback-&gt;valArr[newoff].len, len);</span><br><span class="line">    wmb();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="移植到afl上">移植到AFL++上</h3>
<p>AFL++采用了cmplog，和动态dict在功能上有所重合。这篇文章<a
href="https://arxiv.org/pdf/2211.08357.pdf">《Improving AFL++ CmpLog:
Tackling the bottlenecks》</a>介绍了cmplog当前实现的不足。</p>
<p>不像honggfuzz使用clang的标准插桩，AFL++使用了自己的自定义的Pass进行插桩。</p>
<p>字符串比较函数相关的插桩逻辑如下</p>
<ul>
<li>根据函数签名是否像strcmp函数，即两个指针参数（isPtrRtn）。像memcmp函数，两个指针加上一个整数（isPtrRtnN）。整数需要是32或者64位大小。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> isPtrRtn = FT-&gt;<span class="built_in">getNumParams</span>() &gt;= <span class="number">2</span> &amp;&amp;</span><br><span class="line">                !FT-&gt;<span class="built_in">getReturnType</span>()-&gt;<span class="built_in">isVoidTy</span>() &amp;&amp;</span><br><span class="line">                FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>) == FT-&gt;<span class="built_in">getParamType</span>(<span class="number">1</span>) &amp;&amp;</span><br><span class="line">                FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>)-&gt;<span class="built_in">isPointerTy</span>();</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> isPtrRtnN = FT-&gt;<span class="built_in">getNumParams</span>() &gt;= <span class="number">3</span> &amp;&amp;</span><br><span class="line">                 !FT-&gt;<span class="built_in">getReturnType</span>()-&gt;<span class="built_in">isVoidTy</span>() &amp;&amp;</span><br><span class="line">                 FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>) == FT-&gt;<span class="built_in">getParamType</span>(<span class="number">1</span>) &amp;&amp;</span><br><span class="line">                 FT-&gt;<span class="built_in">getParamType</span>(<span class="number">0</span>)-&gt;<span class="built_in">isPointerTy</span>() &amp;&amp;</span><br><span class="line">                 FT-&gt;<span class="built_in">getParamType</span>(<span class="number">2</span>)-&gt;<span class="built_in">isIntegerTy</span>();</span><br></pre></td></tr></table></figure>
<ul>
<li>主要区分的核心函数，isMemcmp isStrcmp
isStrncmp。根据函数名判断，收集常见的函数名以及其他的类似封装<code>xmlStrcmp</code>。<code>isPtrRtnN</code>直接看作是一种Memcmp</li>
</ul>
<table>
<colgroup>
<col style="width: 52%" />
<col style="width: 22%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr>
<th>插桩函数名</th>
<th>变量名</th>
<th>被插桩的函数组</th>
</tr>
</thead>
<tbody>
<tr>
<td>__cmplog_rtn_hook</td>
<td>cmplogHookFn</td>
<td>其他未归类的签名类似的函数</td>
</tr>
<tr>
<td>__cmplog_rtn_llvm_stdstring_stdstring</td>
<td>cmplogLlvmStdStd</td>
<td>llvmStdStd</td>
</tr>
<tr>
<td>__cmplog_rtn_llvm_stdstring_cstring</td>
<td>cmplogLlvmStdC</td>
<td>llvmStdC</td>
</tr>
<tr>
<td>__cmplog_rtn_gcc_stdstring_stdstring</td>
<td>cmplogGccStdStd</td>
<td>gccStdStd</td>
</tr>
<tr>
<td>__cmplog_rtn_gcc_stdstring_cstring</td>
<td>cmplogGccStdC</td>
<td>gccStdC</td>
</tr>
<tr>
<td>__cmplog_rtn_hook_n</td>
<td>cmplogHookFnN</td>
<td>Memcmp 和未归类的同签名函数</td>
</tr>
<tr>
<td>__cmplog_rtn_hook_strn</td>
<td>cmplogHookFnStrN</td>
<td>Strncmp</td>
</tr>
<tr>
<td>__cmplog_rtn_hook_str</td>
<td>cmplogHookFnStr</td>
<td>Strcmp</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>相关的插桩函数的实现在<code>instrumentation/afl-compiler-rt.o.c</code>：</p>
<p>插桩的共享内存相关的数据结构主要在<a
href="https://github.com/AFLplusplus/AFLplusplus/blob/c1e4b8f7f6f1f95a94c2340de4f57a998c90f094/include/cmplog.h"><code>cmplog.h</code></a>里。包括两个数组。用具体哪个下标是通过hash函数处理得到的，然后拿着这个下标访问headers和log两个结构体数组。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmp_map</span> &#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">cmp_header</span>   headers[CMP_MAP_W];</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">cmp_operands</span> log[CMP_MAP_W][CMP_MAP_H];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>首先会在headers里面设置一些信息。包括 hits
击中次数。shape，对比的两边的大小。type，对比的两大类类型，cmp表示一些cmp指令，比较整数，rtn表示一些memcmp或者strcmp这种内存比较。attribute
属性，比如是switch还是什么strcmp。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmp_header</span> &#123;  <span class="comment">// 16 bit = 2 bytes</span></span><br><span class="line"></span><br><span class="line">  <span class="type">unsigned</span> hits : <span class="number">6</span>;       <span class="comment">// up to 63 entries, we have CMP_MAP_H = 32</span></span><br><span class="line">  <span class="type">unsigned</span> shape : <span class="number">5</span>;      <span class="comment">// 31+1 bytes max</span></span><br><span class="line">  <span class="type">unsigned</span> type : <span class="number">1</span>;       <span class="comment">// 2: cmp, rtn</span></span><br><span class="line">  <span class="type">unsigned</span> attribute : <span class="number">4</span>;  <span class="comment">// 16 for arithmetic comparison types</span></span><br><span class="line"></span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure>
<p>然后在log里面存入两个被对比的值。由于256bit大小的数字大多都能支持，这里留了两个256bit数字的大小。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmp_operands</span> &#123;</span><br><span class="line"></span><br><span class="line">  u64 v0;</span><br><span class="line">  u64 v0_128;</span><br><span class="line">  u64 v0_256_0;  <span class="comment">// u256 is unsupported by any compiler for now, so future use</span></span><br><span class="line">  u64 v0_256_1;</span><br><span class="line">  u64 v1;</span><br><span class="line">  u64 v1_128;</span><br><span class="line">  u64 v1_256_0;</span><br><span class="line">  u64 v1_256_1;</span><br><span class="line">  u8  unused[<span class="number">8</span>];  <span class="comment">// 2 bits could be used for &quot;is constant operand&quot;</span></span><br><span class="line"></span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure>
<p>对于rtn这种字符串比较的类型，则会将log数组的项目重新强制类型转换为cmpfn_operands类型。存储两个最长32字节的字符串，以及他们的长度。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">cmpfn_operands</span> &#123;</span><br><span class="line"></span><br><span class="line">  u8 v0[<span class="number">32</span>];</span><br><span class="line">  u8 v1[<span class="number">32</span>];</span><br><span class="line">  u8 v0_len;</span><br><span class="line">  u8 v1_len;</span><br><span class="line">  u8 unused[<span class="number">6</span>];  <span class="comment">// 2 bits could be used for &quot;is constant operand&quot;</span></span><br><span class="line"></span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure>
<p>总之，插桩代码会用上面的方式，在cmplog共享内存中存储关于程序的比较的信息，用于后续Fuzz算法使用。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
        <tag>Read</tag>
      </tags>
  </entry>
  <entry>
    <title>基于对数期望的投资尺寸计算</title>
    <url>/2025/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%95%B0%E6%9C%9F%E6%9C%9B%E7%9A%84%E6%8A%95%E8%B5%84%E5%B0%BA%E5%AF%B8%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<p>基于对数期望的投资尺寸计算</p>
<span id="more"></span>
<p>根据<a
href="/2025/深入理解投资中的凯利公式/">上一篇文章</a>，我们知道了投入比例关键在于，最大化下面的函数：</p>
<p><span class="math display">\[
f(x) = p_1 \log (1+r_1x) + p_2 \log (1+r_2x) + p_3 \log (1+r_3x)
\]</span></p>
<p>其中多个概率 <span class="math inline">\(p\)</span>
表示不同回报场景出现的概率。回报率 <span
class="math inline">\(r\)</span>
的定义是，比如，回报率是0.1表示赚了投入的10%，回报率是-0.1表示亏了投入的10%。</p>
<p>我们需要考虑更复杂的问题：</p>
<ul>
<li>对于多个投资机会同时存在时，如何计算最优投资比例？</li>
<li>如何考虑投资机会的时间成本？比如通过折算夏普比率</li>
<li>如何考虑杠杆带来的成本？</li>
</ul>
<h2 id="完全独立的多个机会">完全独立的多个机会</h2>
<p>如果投资机会的分布完全独立，我们可以考虑两个机会所有可能结果的组合。</p>
<blockquote>
<p>巴菲特和芒格批评现代资产组合理论说分散风险是对无知的保护。他的意思是，如果不去做任何筛选，直接随意地进行分散风险投资，对于他们这种能够辨别优质投资机会的人来说，确实不好，因为买入了很多平庸的投资。如果经过筛选后，依然同时存在多个优质投资机会，然后将风险分散在其中，当然依然是更好的。所以和我们这里不冲突</p>
</blockquote>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Investing</tag>
      </tags>
  </entry>
  <entry>
    <title>多态类型推理SimpleSub和MLsub</title>
    <url>/2025/%E5%A4%9A%E6%80%81%E7%B1%BB%E5%9E%8B%E6%8E%A8%E7%90%86SimpleSub%E5%92%8CMLsub/</url>
    <content><![CDATA[<p>多态类型推理SimpleSub和MLsub</p>
<span id="more"></span>
<h2 id="简介">简介</h2>
<p>SimpleSub 和
MLsub是编程语言理论（PL）中的类型推理方向的，一系列支持多态子类型推理的算法框架。子类型（可以想象为继承和接口之类的）其实在现实编程中用得特别多，而多态类型（可以想象一下C++的模板）其实用的也多。这个算法可以让编译型语言也不用写很多类型标注，同时它在程序分析领域也可能有着很广泛的应用。</p>
<h2 id="资源总结">资源总结</h2>
<p>按时间线：</p>
<ul>
<li>2016 Dolan的PhD paper，提出了被称为<a
href="https://www.cs.tufts.edu/~nr/cs257/archive/stephen-dolan/thesis.pdf">MLsub</a>的系统，是最原始的资源。但是偏理论。到中间才介绍自动机和图等算法，最后的算法不涉及前几章的理论。（我反复看了，略懂一些，有问题可以发邮件问我）<a
href="https://github.com/stedolan/mlsub">代码</a>是OCaml写的。</li>
<li>2020 SimplSub <a
href="https://infoscience.epfl.ch/entities/publication/106da598-3385-4029-892b-27ea85194046">论文</a>和<a
href="https://github.com/LPTK/simple-sub">代码</a>和<a
href="https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html">博客</a></li>
<li>CubiML系列<a
href="https://blog.polybdenum.com/2020/07/04/subtype-inference-by-example-part-1-introducing-cubiml.html">博客</a>，以及系列代码<a
href="https://github.com/Storyyeller/cubiml-demo">CubiML</a> -&gt; <a
href="https://github.com/Storyyeller/IntercalScript">IntercalScript</a>
-&gt; <a
href="https://github.com/Storyyeller/polysubml-demo">polysubML</a>。</li>
</ul>
<p>入门优先看几篇博客，然后考虑看SimpleSub论文，这个论文作者专门希望没什么基础的人也能看懂，对着代码讲。然后可以考虑看看相关代码。MLsub原代码和论文比较难懂，优先级最低。</p>
<h2 id="introduction">Introduction</h2>
<p>简单来说： -
<strong>子类型</strong>：子类型的本质是，如果某个类型在任何情况下都能替代另外一个类型被使用，我们称这种情况下为子类型。这种替换关系很直接，也很核心。
-
<strong>多态</strong>：一段程序可以接受不同类型的变量，使得它在不同上下文中有着不同的类型。可以想象一下C++的模版。但是python通过动态检查对象的类型不属于这种情况。</p>
<p>应用的角度： -
<strong>新的编程语言</strong>：想象一下，比如C++语言，所有的引用和指针不需要声明类型，只需要写auto即可。现在的auto只支持明确有类型的地方，而且只根据定义的初始化的时候确定类型。而这个算法可以根据变量的使用去综合确定类型，比如直接写不带初始化的auto变量。总之，它可以让你使用更多的auto。如果类型出问题了，编译器会告诉你的。不过分配堆、栈上的结构体对象的时候还是得完整声明具体的类型。
- <strong>更深入的静态分析</strong>： -
<strong>基于类型的安全检查</strong>：比如Rust语言的生命周期就是一种可以在类型中表示的特性，而编译器需要推理出没有标注的地方的生命周期，使得程序不会出错。这个算法可以应用于这种情况，让语言编写者写出更多的基于类型的安全检查。
-
<strong>加速动态语言</strong>：比如pypy这种转译python的方式，通过深入的类型分析，说不定可以让更多的python程序直接被编译出来，极大增加速度。</p>
<p>从PL的角度来说， -
SimpleSub与MLsub<strong>不需要很深入的基础知识</strong>：现在的类型推理算法其实并没有进步很多，入门PL与类型系统的经典书籍《Types
and Programming Languages》
TaPL中就介绍了ML语言的基于unification的类型推理。 -
<strong>系统更加简单高效</strong>：后续很长一段时间的类型推理系统，它基于单独维护一个约束集合，和约束求解器那边有一些关联，效率低且复杂。这次的算法高效且简洁。</p>
<h2 id="mlsub">MLsub</h2>
<p>传统的 Hindley-Milner
类型推断是基于Unification算法的过程，该过程通过不断地强迫两个未知类型相等，直到达到矛盾或所有程序约束满足为止。在MLsub中，Dolan
提出了一个叫做biunification的过程。biunification的一个关键部分是极性类型系统。极性意味着类型被分为两种类型，传统上称为正类型（+）和负类型（-）。<a
href="https://blog.polybdenum.com/2020/07/11/subtype-inference-by-example-part-2-parsing-and-biunification.html">这个</a>里面说的很好，为了使理解更加容易，我称之为值类型（+）和用法类型（-）。为了避免导致半统一不可判定的无限循环，biunification将所有子类型约束限制为
v &lt;= u 的形式，其中 v 是值类型，u
是用法类型。这些约束可以自然地解释为要求程序值与其使用方式相兼容。</p>
<p><strong>类型变量</strong>：基本原则是，为每个表达式创建一个值类型（+，也称为正极性），为每个表达式操作数创建一个用法类型（-，也称为负极性），并在每个值类型（+）与其使用上下文（-）之间建立子类型约束，以确保一致性。我们将这些约束
v+ &lt;= u- 称为值流向其使用，它们是通过 TypeCheckerCore 中的 flow
方法创建的。</p>
<p>还有一个更复杂的方面——变量。变量由一对类型表示——值类型（+）和用法类型（-）。从概念上讲，值类型表示从变量读取的类型（），而用法类型表示分配给该变量的类型。自然，我们需要约束
v- &lt;=
v+，即对变量的每一次写入与对该变量的每一次读取都是兼容的。然而，这种类型的约束我们使用数据流边直接表示。它确保流关系的传递性。对于每个变量
(v1, u1)，以及每个流向 u1 的值类型 v2 和 v1 流向的每个用法类型
u2，我们添加约束 v2 流向
u2。本质上，变量（一对连接了数据流边的类型节点）在类型图中像小隧道或虫洞一样运作。无论从一端进入的是什么，都会从数据流另一端出来。直接把下界/上界类型约束沿着数据流边传递。</p>
<p><strong>位置约束</strong>
类型构成一种格（Lattice），我们有两种类型运算</p>
<ul>
<li>并类型（ <span class="math inline">\(\sqcup\)</span>
（Join），求两个类型的最小上界 least upper bound）</li>
<li>交类型 （ <span class="math inline">\(\sqcap\)</span>
（Meet），求两个类型的最大下界 greatest lower bound）</li>
</ul>
<p>我们要求交类型运算 <span class="math inline">\(\sqcap\)</span>
只出现在负极性处，并类型运算 <span class="math inline">\(\sqcup\)</span>
只出现在正极性处。</p>
<p>例如，下面的类型是不合法的：（例子取自MLsub论文的 5.2.3 节）</p>
<p><span class="math display">\[
\{\text{awake} : \text{bool}\} \sqcap α \rightarrow \{\text{awake} :
\text{bool}\} \sqcap α
\]</span></p>
<p>因为在返回值（正极性）的地方出现了交类型运算 <span
class="math inline">\(\sqcap\)</span> ，但是我们有</p>
<p><span class="math display">\[
\{\text{awake} : \text{bool}\} \sqcap α \rightarrow α \;\;\; \leq \;\;\;
\{\text{awake} : \text{bool}\} \sqcap α \rightarrow \{\text{awake} :
\text{bool}\} \sqcap α
\]</span></p>
<p>因此就直接会采取左边的表示方式。</p>
<h3 id="simplesub的三种简化方式">SimpleSub的三种简化方式</h3>
<p><strong>概述</strong>：其实结合SimpleSub代码，真正实现出来的简化操作按顺序总结如下：</p>
<ol type="1">
<li>CompactType
平坦化操作，将类型的上下界展开。这个阶段会把类型展开为特殊的表示，用新的数据结构CompactType存储。</li>
<li>Canonicalize 规范化，这个主要针对递归类型。</li>
<li>Co-occurrence 共现分析，这里涵盖了论文里的 去除极性变量
合并共现变量，以及和常量的共现，三种分析。</li>
<li>hash-consing
负责折叠完全相同的递归结构。这个阶段会和转换为用于打印的语法树类型结合，即将CompactType转换为最终的类型结构。</li>
</ol>
<p>这里我们先按照论文的顺序，先分析SimpleSub论文第4.3章里面提到的简化算法。CompactType和Canonicalize放到后面再介绍。</p>
<p><strong>背景</strong>：首先回忆一下，类型变量是干什么用的。类型变量通常给<strong>多态</strong>函数使用，对应的是数据流边。如果就是普通的类型的话，是不会有类型变量的。</p>
<ul>
<li>不是多态的函数，参数和返回值类型都是确定的，即使函数接受一个复杂的结构体类型，返回另外一个复杂的结构体类型，里面也不会出现变量。</li>
<li>多态函数的典型例子，比如id函数 <span class="math inline">\(\lambda
x.x\)</span>
，把参数原样返回，如果传入一个整数，返回的是整数类型，传入的是字符串，返回的是字符串类型。那么我们就不能简单给参数和返回值标记成具体的类型，标记为
<span class="math inline">\(int \rightarrow int\)</span> 或者 <span
class="math inline">\(str \rightarrow str\)</span>
都是错的。因此，我们引入类型变量 <span
class="math inline">\(\alpha\)</span> 表示参数x的类型，将它的类型标记为
<span class="math inline">\(\alpha \rightarrow \alpha\)</span>
。表示，假如参数给定的类型是 <span class="math inline">\(\alpha\)</span>
时，返回值的类型也是 <span class="math inline">\(\alpha\)</span> 。</li>
<li>类型推理的最后，类型变量表示的纯粹的未知类型，不会有约束，因为约束会通过替换操作表示到外面。
<ul>
<li>比如说同样是id函数 <span class="math inline">\(\lambda x.x\)</span>
，但是我在函数体里面访问了一下成员field1并当做int类型使用，但是最后还是返回x。此时，在类型推理时会生成约束
<span class="math inline">\(\alpha \leq \{f1: int\}\)</span> （其中
<span class="math inline">\(\alpha\)</span>
表示x的类型），它通过约束x是某个有f1成员的结构体类型，来约束x必须有这个成员。</li>
<li>既然说，<span class="math inline">\(\alpha\)</span>
表示x的类型了，那么，既然函数还是返回x，那么整个函数的类型依然还是 <span
class="math inline">\(\alpha \rightarrow \alpha\)</span>
？这个说法是错误的。因为类型推理解决这个约束的时候会产生一个替换， <span
class="math inline">\(\alpha^- \rightarrow \alpha^- \sqcap \{f1:
int\}\)</span> 最终推理出来的类型是 <span class="math inline">\(\alpha
\sqcap \{f1: int\} \rightarrow
\alpha\)</span>。这代表什么含义呢？这意味着<strong>类型变量如果有约束，总是会通过交类型或者并类型把约束单独表示，从而抽出身来变成没有约束的纯粹变量</strong>
（参考MLsub论文《Algebraic
Subtyping》的5.2.3节后半部分，这里涉及了一个细节，即类型使用产生的上界约束仅影响变量的负极性（上界）的使用点）</li>
</ul></li>
</ul>
<p><strong>简化1：去除极性变量</strong>
因为变量仅仅在正极性，或者负极性出现，则我们可以删掉它。因为变量表示的就只是参数到返回值之间的多态类型关系。这种仅在一个方面出现的变量无法表示数据流，因此可以去掉。比如对于类型
<span class="math inline">\(\alpha \sqcap \text{int} \rightarrow
\text{int} \sqcup \beta\)</span> ，直接简化成 <span
class="math inline">\(\text{int} \rightarrow \text{int}\)</span> 。</p>
<p><strong>简化2：共现分析</strong>：如果两个变量总是在相同极性位置同时出现，则我们可以将它们合并。这里同时出现的意思是，把类型中，用
<span class="math inline">\(\sqcap\)</span> 或 <span
class="math inline">\(\sqcup\)</span>
连接的部分看作一个槽位，里面可以同时存在被连接的多个变量。然后依次看正极性的所有槽位，和负极性的所有槽位，如果两个变量总是同时出现在某个槽位，则说明可以合并。</p>
<p>从最简单的角度理解，既然变量就已经抽身成单独的纯粹变量，那么多个变量其实就没有意义了。例如，比如说对于id函数
<span class="math inline">\(\lambda x.x\)</span> 它的类型是 <span
class="math inline">\(\alpha \rightarrow \alpha\)</span> 。
如果类型推理给出类型是 <span class="math inline">\(\alpha \sqcap \beta
\rightarrow \alpha \sqcup \beta\)</span>
这也是对的，可以化简成前面的类型。</p>
<p>但是，这里有一个坑点，<strong>两个极性下，任意一个极性下共现即可进行合并，即使另外一个极性不共现</strong>。例如，我们看论文里3.4章结尾提到的twice函数
twice = <span class="math inline">\(\lambda f. \lambda x. f(f
x)\)</span> 。初步得到的类型是 <span class="math inline">\(\alpha \sqcap
(\beta \sqcup \gamma \rightarrow \gamma \sqcap \delta) \rightarrow \beta
\rightarrow \delta\)</span>
接下来需要化简它。首先根据“简化1”去除只出现一次的 <span
class="math inline">\(\alpha\)</span>
变量，都只出现一次肯定只在一个极性出现。得到 <span
class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma \sqcap
\delta) \rightarrow \beta \rightarrow \delta\)</span>
。它是一个函数类型，第一个参数也是函数类型 <span
class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma \sqcap
\delta)\)</span> 第二个参数是 <span class="math inline">\(\beta\)</span>
返回值类型是 <span class="math inline">\(\delta\)</span> 。</p>
<p>首先我们需要区分极性。参数是负极性的，但是如果负极性的参数位置内部又是函数类型，里面的极性又要反过来。我们通过下划线标注负极性的位置，如下：
<span class="math inline">\((\beta \sqcup \gamma \rightarrow
\underline{\gamma \sqcap \delta}) \rightarrow \underline{\beta}
\rightarrow \delta\)</span> 。然后，我们不用区分 <span
class="math inline">\(\sqcap\)</span> 和 <span
class="math inline">\(\sqcup\)</span>
两个运算了，可以当做简单的集合连接符。比如表示成 <span
class="math inline">\((\{\beta, \gamma\} \rightarrow
\underline{\{\gamma, \delta\}}) \rightarrow \underline{\beta}
\rightarrow \delta\)</span>
总之就是四个槽位，然后每个位置可以有多个变量。</p>
<p><strong>标准解法</strong>：我们每次只看一个极性，看带下划线的负极性，此时，
<span class="math inline">\(\beta\)</span> 单独出现， <span
class="math inline">\(\gamma\)</span> 和 <span
class="math inline">\(\delta\)</span> 一起出现。因此 <span
class="math inline">\(\gamma\)</span> 和 <span
class="math inline">\(\delta\)</span> 可以合并。比如我们都合并成 <span
class="math inline">\(\gamma\)</span> ，把所有的 <span
class="math inline">\(\delta\)</span> 替换成 <span
class="math inline">\(\gamma\)</span> 即可。得到 <span
class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma)
\rightarrow \beta \rightarrow \gamma\)</span>。</p>
<p>论文的原文如下，和论文一样：</p>
<blockquote>
<p>this type can be compacted to α ⊓ (β ⊔ γ → γ ⊓ δ) → β → δ, and then
simplified to (β ⊔ γ → γ) → β → γ, since α occurs only negatively (thus
can be removed) and δ and γ co-occur negatively (thus can be merged into
a single variable).</p>
</blockquote>
<p>我们再看能不能进一步化简，这里 <span class="math inline">\((\beta
\sqcup \gamma \rightarrow \underline{\gamma}) \rightarrow
\underline{\beta} \rightarrow \gamma\)</span>
看带下划线的负极性，两个变量单独出现，因此不能化简。看正极性，虽然 <span
class="math inline">\(\beta \sqcup \gamma\)</span>
这里两个变量同时出现，但是 <span class="math inline">\(\gamma\)</span>
也会单独出现，所以不算是一直同时出现。</p>
<p><strong>标准解法2</strong>：如果我们先看正极性，可以发现其实也可以把
<span class="math inline">\(\beta\)</span> 和 <span
class="math inline">\(\gamma\)</span> 合并，此时得到的类型是： <span
class="math inline">\((\beta \rightarrow \beta \sqcap \delta)
\rightarrow \beta \rightarrow \delta\)</span>
这个简化方式也是正确的。</p>
<p><strong>共现分析：基于数据流的深入理解</strong></p>
<p>从数据流的角度，回忆MLsub论文，变量的本质就是连接数据流，只要数据流的边一致，类型就是一致的。如果某个变量在负极性槽位出现，然后又在正极性槽位出现，则我们认为存在一个从负极性槽位到正极性槽位的数据流。</p>
<p>比如，对于 <span class="math inline">\((\{\beta, \gamma\} \rightarrow
\underline{\{\gamma, \delta\}}) \rightarrow \underline{\beta}
\rightarrow \delta\)</span>
这里四个槽位标记为1到4，我们观察，对于下划线位置的变量，还在什么没有下划线的位置出现，得到下面的数据流</p>
<ol type="1">
<li>槽位2 -&gt; 槽位1 ( <span class="math inline">\(\gamma\)</span>
)</li>
<li>槽位2 -&gt; 槽位4 ( <span class="math inline">\(\gamma\)</span>
)</li>
<li>槽位3 -&gt; 槽位1 ( <span class="math inline">\(\beta\)</span>
)</li>
</ol>
<p>用同样的方式，给简化后的两种类型连接起来看看，得到下面的图：</p>
<p><img src="ML数据流示例.drawio.png" /></p>
<p>可以看到数据流完全一样！所以确实类型是一样的。</p>
<p>TODO 从数据流的角度，再次理解上面的简化。</p>
<p><strong>基于子类型定义的证明</strong></p>
<p>我们尝试基于定义，证明两个解法的类型是一致的。即尝试证明 <span
class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma)
\rightarrow \beta \rightarrow \gamma\)</span> 等价于 <span
class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma \sqcap
\delta) \rightarrow \beta \rightarrow \delta\)</span>
。我们通过证明两个类型互为对方的子类型，来证明类型等价。</p>
<p>首先回忆子类型的定义。MLsub中子类型的定义的，如果存在一个类型替换，使得类型A的变量在替换后，变成了类型B的子类型，则说明A是B的子类型。</p>
<ul>
<li>替换可以是变量替换为具体类型，比如说，类型 <span
class="math inline">\(\alpha \sqcap \text{int} \rightarrow \text{int}
\sqcup \alpha\)</span> 中，我们可以替换 <span
class="math inline">\(\alpha \rightarrow \text{int}\)</span> 得到 <span
class="math inline">\(\text{int} \sqcap \text{int} \rightarrow
\text{int} \sqcup \text{int}\)</span> 等价于 <span
class="math inline">\(\text{int} \rightarrow \text{int}\)</span>
。因此前者是后者的子类型。
<ul>
<li>注意到子类型关系也不仅仅局限于不带变量的具体类型，带变量的多态类型之间也可能存在子类型关系。即，无论变量怎么替换成具体类型，最终的实例之间依然保留子类型关系。</li>
</ul></li>
<li><strong>替换也可以是变量替换为变量！或者其他新的带新变量的类型表达式</strong>。比如我们尝试证明类型
<span class="math inline">\(\alpha \rightarrow \alpha \rightarrow
\alpha\)</span> 等价于 <span class="math inline">\(\alpha \rightarrow
\beta \rightarrow \alpha \sqcup \beta\)</span>
（参考MLsub论文《Algebraic Subtyping》4.2.1节）
<ul>
<li>对于后者，我们使用替换 <span class="math inline">\(\beta \rightarrow
\alpha\)</span> 得到前者，这很简单</li>
<li>对于前者，我们使用替换 <span class="math inline">\(\alpha
\rightarrow \beta \sqcup \gamma\)</span> 得到 <span
class="math inline">\(\beta \sqcup \gamma \rightarrow \beta \sqcup
\gamma \rightarrow \beta \sqcup \gamma\)</span> 而它 <span
class="math inline">\(\leq \gamma \rightarrow \beta \rightarrow \beta
\sqcup \gamma\)</span> 然后我们再把 <span
class="math inline">\(\gamma\)</span> 重命名为 <span
class="math inline">\(\alpha\)</span> 就得到后者了。</li>
</ul></li>
</ul>
<p>证明分两步：</p>
<ul>
<li>找一个替换，让 <span class="math inline">\((\beta \sqcup \gamma
\rightarrow \gamma \sqcap \delta) \rightarrow \beta \rightarrow
\delta\)</span> 变成 <span class="math inline">\((\beta \sqcup \gamma
\rightarrow \gamma) \rightarrow \beta \rightarrow \gamma\)</span>
<ul>
<li>TODO 好像有点难</li>
</ul></li>
<li>找一个替换，让 <span class="math inline">\((\beta \sqcup \gamma
\rightarrow \gamma) \rightarrow \beta \rightarrow \gamma\)</span> 变成
<span class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma
\sqcap \delta) \rightarrow \beta \rightarrow \delta\)</span>
<ul>
<li>TODO 好像有点难</li>
</ul></li>
</ul>
<p>同理，也可以证明 <span class="math inline">\((\beta \rightarrow \beta
\sqcap \delta) \rightarrow \beta \rightarrow \delta\)</span> 也等价于
<span class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma
\sqcap \delta) \rightarrow \beta \rightarrow \delta\)</span></p>
<p><strong>和常量的共现</strong>：比如，变量 <span
class="math inline">\(\alpha\)</span> 和 int
总是在负极性同时出现，同时也和int总是在正极性同时出现，则将这个变量替换为int类型。</p>
<p>因为，变量 <span class="math inline">\(\alpha\)</span> 和 int
总是在负极性同时出现，则其实对应的是，之前存在约束 <span
class="math inline">\(\alpha \leq \text{int}\)</span>
。同理，总是在正极性对应的是 <span class="math inline">\(\text{int} \leq
\alpha\)</span> 两个合起来，不就说明 <span
class="math inline">\(\alpha\)</span> 等价于int类型了。</p>
<p><strong>简化方法3：哈希合并（Hash
Consing）</strong>：这个方法是SimpleSub特有的，MLsub没有进行这一步。这个涉及递归类型。</p>
<p>原文如下：</p>
<blockquote>
<p>考虑以下递归项：</p>
<p><span class="math display">\[ \text{let } f = \lambda x. \{ L = x ; R
= f x \} \text{ in } f \]</span></p>
<p>为这个项推断出的合并类型将是：</p>
<p><span class="math display">\[ \alpha \rightarrow \{ L : \alpha; R :
\mu\beta. \{ L : \alpha; R : \beta \} \} \]</span></p>
<p>注意，这里有一个冗余的外部结构体层。我们希望推断出：</p>
<p><span class="math display">\[ \alpha \rightarrow \mu\beta. \{ L :
\alpha; R : \beta \} \]</span></p>
<p>这可以通过在 <code>coalesceType</code>
函数中对正在合并的类型执行哈希合并来完成：我们可以记住正在合并的整个类型表达式，而不仅仅是哪个
<em>变量</em>
正在被合并；当我们遇到一个已经在合并中的类型表达式时，我们会在这个位置引入一个递归类型变量，从而去除像上述那样冗余的外层类型。MLsub
当前并不执行类似的简化，因此在像上述示例中，Simple-sub
推导出更简单的类型。</p>
</blockquote>
<p>简单来说，就是在遇到递归类型的时候，可以多向外匹配一层，消除一层冗余。</p>
<p>首先我们复习递归类型：比如说有类型 <span
class="math inline">\(\mu\beta. \{ L : \alpha; R : \beta \}\)</span>
这里的 <span class="math inline">\(\mu\)</span> 是不动点算子。其中 <span
class="math inline">\(\beta\)</span> 等于这个类型，同时 <span
class="math inline">\(\{ L : \alpha; R : \beta \}\)</span>
也等于这个类型。总之我们得到等价关系 <span class="math inline">\(\beta =
\{ L : \alpha; R : \beta \}\)</span> 这意味着我们可以不断展开：</p>
<ul>
<li><span class="math inline">\(\beta\)</span></li>
<li><span class="math inline">\(\{ L : \alpha; R : \beta
\}\)</span></li>
<li><span class="math inline">\(\{ L : \alpha; R : \{ L : \alpha; R :
\beta \} \}\)</span></li>
<li><span class="math inline">\(\{ L : \alpha; R : \{ L : \alpha; R : \{
L : \alpha; R : \beta \} \} \}\)</span></li>
<li>......</li>
</ul>
<p>总之 <span class="math inline">\(\mu\)</span>
就是表示这种递归类型。例如我们常用的链表结构体，内部有指向自己的指针。</p>
<p>经过前面的简化之后，有下面的类型。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&#x27;o → &#123;self: &#x27;q; thing: &#x27;o&#125;)</span><br><span class="line">其中&#x27;q是递归类型：</span><br><span class="line">  &#x27;q = &#123;self: &#x27;q; thing: &#x27;o&#125;</span><br></pre></td></tr></table></figure>
<p>匹配的时候不仅会匹配变量，对于递归类型也会匹配相同的递归结构。即维护一个从CompactType到变量的映射。（对应代码中coalesceCompactType函数）比如对于上面的类型，我们进行递归访问。首先访问整体的函数类型，然后访问函数的参数类型（即<code>'o</code>），然后访问函数体了，放入map中<code>&#123;self: 'q; thing: 'o&#125;</code>。然后我们递归访问成员，访问self成员，访问到<code>'q</code>的时候，我们发现它是递归变量，因此我们访问它等价的递归类型。此时我们发现，又访问到了<code>&#123;self: 'q; thing: 'o&#125;</code>，和前面的一致！因此我们为它创建一个专门的递归变量，比如<code>μ0</code>。然后返回作为</p>
<h3 id="类型优化的具体细节">类型优化的具体细节</h3>
<p>具体到代码的话，其实还有一些论文中没有写出来的细节。
这里介绍CompactType和Canonicalize，即在优化之前的平坦化和规范化操作。</p>
<p><strong>类型平坦化：CompactType</strong>：当我们遇到类型：<code>&#123;x: A&#125; ∧ &#123;x: B; y: C&#125;</code>的时候，我们可以进一步合并结构体类型，变成
<code>&#123;x: A ∧ B; y: C&#125;</code>。它会让后续的共现分析更准确</p>
<p>下面是CompactType的定义：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Intermediate representation for simplification (Section 4.4)</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CompactType</span> &#123;</span><br><span class="line">  std::set&lt;SimpleType&gt; vars;                          <span class="comment">// type variables</span></span><br><span class="line">  std::set&lt;SimpleType, SimpleTypeValueCompare&gt; prims; <span class="comment">// primitive types</span></span><br><span class="line">  std::optional&lt;std::map&lt;std::string, std::shared_ptr&lt;CompactType&gt;&gt;&gt;</span><br><span class="line">      record; <span class="comment">// record fields</span></span><br><span class="line">  std::optional&lt;std::pair&lt;std::vector&lt;std::shared_ptr&lt;CompactType&gt;&gt;, std::shared_ptr&lt;CompactType&gt;&gt;&gt;</span><br><span class="line">      function; <span class="comment">// function type</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>CompactType本身可以看作一个很大的集合，里面归类放置了各种类型。我们回忆之前，SimpleType核心类型推理结构，它其实并不是我们常见的基于语法树的类型，而是有上下界指向其他类型。如果我们单看变量类型的一个界，比如上界，</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">VariableState</span> &#123;</span><br><span class="line">  std::vector&lt;SimpleType&gt; lowerBounds;</span><br><span class="line">  std::vector&lt;SimpleType&gt; upperBounds; <span class="comment">// CompactType即分类整理数组里的类型</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其实含义是，所有上界指向的类型，全部用类型交运算连接起来。那么就是把这个上界数组里的类型，分类整理了起来。保存成上面那种集合的样子。根据所处位置的极性，表示类型交运算或者并运算。</p>
<p>同理，因为我们会展开结构体和函数类型，比如<code>&#123;x: A&#125; ∧ &#123;x: B; y: C&#125;</code>展开成<code>&#123;x: A ∧ B; y: C&#125;</code>，所以这里对于结构体类型，并不是也保存成集合，而是保存为单独的CompactType，因为即使有很多结构体，也会合并起来变成一个，然后在结构体内部再用类型交运算或者并运算。</p>
<p>这样转换为Compact类型的过程也非常直接。
<!-- TODO 贴代码展示？ --></p>
<p><strong>类型规范化：Canonicalize</strong>：</p>
<h2 id="faq">FAQ</h2>
<p><strong>Q1:</strong>
比如我有一个函数，原始参数类型就是Animal。传递参数的两个时候是分别传入了Dog，传入了Cat。那么我是不是有
<code>func_in &lt;= Dog</code> 和
<code>func_in &lt;= cat</code>。那么为什么求交类型运算 <code>^</code>
只出现在负极性处，而不是并运算？（Dog 并 Cat = Animal，Dog 交 Cat =
Bottom）</p>
<p>Answer 1:</p>
<ul>
<li>参数类型之所以是 animal，是因为后面当 animal
用，而不是因为传进来什么，不用的话，甚至可以当 top。</li>
<li>参数是负极性，所以是看使用。如果后面返回了参数这个值，返回值就会因为数据流把这两个约束拿过来。</li>
</ul>
<p>MLsub
原文处理约束就是，把负极性到正极性的约束连成数据流，正极性到负极性的约束才看作约束。约束可以随便生成，但是求类型的时候，负极性顺着数据流收集，正极性逆着数据流收集，不管另外一个方向。另外一个方向，因为连了数据流，数据流是负极性到正极性的，会传给另一头。总结：负极性
顺着数据流收集上界。正极性逆着数据流收集下界。</p>
<p><strong>Q2: 类型的交和并怎么理解来着？</strong></p>
<p>Answer 2:
实际程序执行的时候都是具体的值，而类型对应的是所有可能的值的集合。比如说程序执行的时候都是具体的数字，而我们用int类型表示所有int类型能存的有具体数字的集合。然后子类型相比父类型更精确，即集合范围更小。比如我们根据上面的<code>Animal，Dog, Cat</code>创建类型：</p>
<ul>
<li>Top类型，它包含所有可能的值，甚至包括冲突的值，比如结构体类型，和整数，和浮点数。它的集合最大，是所有类型的父类型。</li>
<li>Animal类型，它表示所有动物的集合</li>
<li>Dog类型, Cat类型，它表示所有具体的猫和狗的集合。</li>
<li>Bottom类型，对应空集合，没有任何具体值的类型，通常不会出现。</li>
</ul>
<p>可以观察到：</p>
<ul>
<li>集合之间的子集关系，就是子类型关系。比如<code>Dot &lt;= Animal</code>，即Dog是Animal的子类型，对应Dog是Animal的子集</li>
<li>集合越小，越靠近子类型。</li>
<li>类型的并（Join, v），即求最小公共上界，会往父类型走。</li>
<li>类型的交（Meet, v），即最大公共下节，会往子类型走。</li>
</ul>
<p>但是要注意：</p>
<ul>
<li>类型的并集 对应 结构体成员的交集</li>
<li>类型的交集 对应 结构体成员的并集</li>
</ul>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>StaticAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title>投资策略与市场走势的概率分布</title>
    <url>/2025/%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5%E4%B8%8E%E5%B8%82%E5%9C%BA%E8%B5%B0%E5%8A%BF%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<p>投资策略与市场走势的概率分布</p>
<span id="more"></span>
<p>策略在不同市场上有不同的收益率。而且其实不会均衡。策略可以看作一个函数，输入市场走势，得到盈亏情况。</p>
<p>不能考虑永远不走的情况，假设固定轮数，然后结算。</p>
<p>策略和能盈利的市场走势是对应的。策略，某种意义上是对市场未来走势的某种预测？让某些分布下能赚钱，某些分布下亏钱。</p>
<ul>
<li>不投入，就是在任何市场场景下不赚不亏。调整投入的比例，则会放大或者缩小风险。</li>
<li>如果限制只能够买入，那么最优的策略就是捕获市场中所有的上涨。能参与的前提肯定是有涨的，一直跌的话，最优策略都会是不入场。如果允许卖空的话
就是捕获预判正确所有的走势，在涨之前买入，在走势反转后卖出。</li>
</ul>
<p>我们一般都是假设自己有信息优势的，但是往往会比较模糊。假如有一个内幕人员已经看过了市场的走势，怎样让它传递上尽可能少的信息，依然能够实现很大的盈利。预判每一个细微的走势是不现实的，这至少意味着
我们的熵有限制。</p>
<p>这也增加了我们投资策略的鲁棒性。</p>
<p>首先降一下熵，比如说只能看到平滑后的曲线。</p>
<p>比如说给最高点和最低点。</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Investing</tag>
      </tags>
  </entry>
  <entry>
    <title>代数子类型的精髓（双语交替版本）</title>
    <url>/2025/%E4%BB%A3%E6%95%B0%E5%AD%90%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%B2%BE%E9%AB%93%EF%BC%88%E5%8F%8C%E8%AF%AD%E4%BA%A4%E6%9B%BF%E7%89%88%E6%9C%AC%EF%BC%89/</url>
    <content><![CDATA[<p>一篇论文的中英文翻译版本：</p>
<p>《The Simple Essence of Algebraic Subtyping. Principal Type Inference
with Subtyping Made Easy (Functional Pearl)》 --- LIONEL PARREAUX, EPFL,
Switzerland</p>
<span id="more"></span>
<p>本文使用了 <a
href="https://tool.latexdiff.cn/">https://tool.latexdiff.cn/</a>
进行OCR与LLM翻译，然后放在这里不断校对和改进翻译。发现问题的话，请点击<a
href="https://github.com/am009/blog/edit/hexo/source/_posts/2025/%E4%BB%A3%E6%95%B0%E5%AD%90%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%B2%BE%E9%AB%93%EF%BC%88%E5%8F%8C%E8%AF%AD%E4%BA%A4%E6%9B%BF%E7%89%88%E6%9C%AC%EF%BC%89.md">这里</a>修改本文内容。下面是正文。</p>
<p>MLsub extends traditional Hindley-Milner type inference with
subtyping while preserving compact principal types, an exciting new
development. However, its specification in terms of
<em>biunification</em> is difficult to understand, relying on the new
concepts of bisubstitution and polar types, and making use of advanced
notions from abstract algebra. In this paper, we show that these are in
fact not essential to understanding the mechanisms at play in MLsub. We
propose an alternative algorithm called <em>Simple-sub</em>, which can
be implemented efficiently in under 500 lines of code (including
parsing, simplification, and pretty-printing), looks more familiar, and
is easier to understand.</p>
<p>MLsub在保留紧凑主类型的同时，扩展了传统的Hindley-Milner类型推断并引入了子类型，这是一个令人兴奋的新发展。然而，它在<em>biunification</em>方面的具体操作难以理解，依赖于bisubstitution和polar
types的新概念，并使用了抽象代数中的高级概念。我们在本文中展示，这些实际上并非理解MLsub中运作机制的必要条件。我们提出了一种替代算法，称为<em>Simple-sub</em>，它可以在不到500行代码（包括解析、简化和美化打印）的情况下高效实现，显得更加熟悉，且易于理解。</p>
<blockquote>
<p>译者注：这里的Hindley-Milner类型推理算法是一种针对ML语言的类型推理算法。ML语言是一个用于编程语言和类型系统学习和教学的语言。即，《Types
and Programming
Languages》TAPL这本书里就有相关的讲解。了解相关内容对理解本文有帮助，但不是必须的。</p>
</blockquote>
<blockquote>
<p>译者注：不太了解类型系统的，可能不太看得懂这个对MLsub的评价。类比一下的话，ML语言就像是课本里的C语言。子类型是一个非常常用的概念，比如说接口或者继承。MLsub还是很不错的，它在类型推理领域做到的事情，类比一下的话，类似于在编程语言里面引入了接口或者继承。</p>
</blockquote>
<p>We present an experimental evaluation of Simple-sub against MLsub on
a million randomly-generated well-scoped expressions, showing that the
two systems agree. The mutable automaton-based implementation of MLsub
is quite far from its algebraic specification, leaving a lot of space
for errors; in fact, our evaluation uncovered several bugs in it. We
sketch more straightforward soundness and completeness arguments for
Simple-sub, based on a syntactic specification of the type system.</p>
<p>我们对Simple-sub和MLsub在百万个随机生成的良好作用域表达式上的实验评估，展示了这两个系统的一致性。基于自动机的MLsub实现与其代数规范相距甚远，留下了许多出错的空间；实际上，我们的评估发现了其中的几个bug。我们基于类型系统的句法规范，简要概述了Simple-sub更直接的完善性和完备性论证。</p>
<p>This paper is meant to be light in formalism, rich in insights, and
easy to consume for prospective designers of new type systems and
programming languages. In particular, no abstract algebra is inflicted
on readers.</p>
<p>本文旨在保持形式上的简洁，提供丰富的见解，并易于新类型系统和编程语言潜在设计者消化。特别是，未对读者施加任何抽象符号的负担。</p>
<p>The ML family of languages, which encompasses Standard ML, OCaml, and
Haskell, have been designed around a powerful “global” approach to type
inference, rooted in the work of Hindley [1969] and Milner [1978], later
closely formalized by Damas and Milner [1982]. In this approach, the
type system is designed to be simple enough that types can be
unambiguously inferred from terms without the help of any type
annotations. That is, for any well-typed unannotated term, it is always
possible to infer a <em>principal type</em> which subsumes all other
types that can be assigned to this term. For instance, the term <span
class="math inline">\(\lambda x. x\)</span> can be assigned types <span
class="math inline">\(bool \rightarrow bool\)</span> and <span
class="math inline">\(int \rightarrow int\)</span>, but both of these
are subsumed by the polymorphic type <span class="math inline">\(\forall
\alpha. \alpha \rightarrow \alpha\)</span>, also written '<span
class="math inline">\(a \rightarrow &#39;a\)</span>, which is the
principal type of this term.</p>
<p>ML语言家族，包括Standard
ML、OCaml和Haskell，围绕一种强大的“全局”类型推断方法进行设计，这种方法源于Hindley
[1969]和Milner [1978]的工作，后来由Damas和Milner
[1982]进行了紧密的形式化。在这种方法中，类型系统的设计足够简单，以至于可以从术语中不借助任何类型注释不明确地推断出类型。也就是说，对于任何良构的未注释术语，总是可以推断出一个<em>主类型</em>，该主类型包含所有可以分配给该术语的其他类型。例如，术语<span
class="math inline">\(\lambda x. x\)</span>可以被分配类型<span
class="math inline">\(bool \rightarrow bool\)</span>和<span
class="math inline">\(int \rightarrow
int\)</span>，但是这两者都被多态类型<span class="math inline">\(\forall
\alpha. \alpha \rightarrow \alpha\)</span>所包含，也可以写作'<span
class="math inline">\(a \rightarrow
&#39;a\)</span>，这是该术语的主类型。</p>
<p>This “Hindley-Milner” (HM) type inference approach contrasts with
more restricted “local” approaches to type inference, found in languages
like Scala, C#, and Idris, which often require the types of variables to
be annotated explicitly by programmers. On the flip side, abandoning the
principal type property allows these type systems to be more expressive,
and to support features like object orientation and dependent types.
Even ML languages like OCaml and Haskell have adopted type system
features which, when used, break the principal type property<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> and sometimes require explicit type
annotations. Supporting principal types is a delicate tradeoff.</p>
<p>这种“Hindley-Milner”（HM）类型推断方法与更受限制的“局部”类型推断方法形成对比，后者在像Scala、C#和Idris这样的语言中常常需要程序员显式地注释变量的类型。另一方面，放弃主要类型属性使这些类型系统能够更加表达性，并支持像面向对象和依赖类型一样的特性，即使是像
OCaml 和 Haskell 这样的 ML
语言也采纳了类型系统的特性，当这些特性被使用时，会打破主类型属性<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>，有时需要显式的类型注释。支持主类型是一种微妙的权衡。</p>
<p><strong>Subtyping</strong> is an expressive approach allowing types
to be structured into hierarchies — usually a subtyping <em>lattice</em>
— with the property that types can be <em>refined</em> or
<em>widened</em> implicitly following this hierarchy. This lets one
express the fact that some types are more precise (contain more
information) than others, but still have a compatible runtime
representation, so that no coercions between them are needed. For
instance, in a system where the type ‘nat’ is a subtype of ‘int’, one
can transparently use a ‘nat list’ in place where an ‘int list’ is
expected, without having to apply a coercion function on all the
elements of the list. Subtyping can be emulated using somewhat heavy
type system machinery (which both OCaml and Haskell do, to some extent<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>), but first-class support for
subtyping gives the benefit of simpler type signatures and better type
inference.</p>
<p><strong>子类型化</strong>是一种表达能力强的方法，允许将类型结构化为层次——通常是一个子类型
<em>格</em>——其特性是类型可以在这个层次下被<em>细化</em>或<em>扩展</em>，而不需要显式转换。这让人们能表达某些类型比其他类型更精确（包含更多信息），但仍然具有兼容的运行时表示，这样就不需要在它们之间进行任何强制转换。例如，在一个类型‘nat’是‘int’的子类型的系统中，可以透明地在预期为‘int
list’的地方使用‘nat
list’，而无需对列表的所有元素应用强制转换函数。子类型化可以通过一些较复杂的类型系统机制进行模拟（OCaml
和 Haskell 在某种程度上都这样做<a href="#fn4" class="footnote-ref"
id="fnref4"
role="doc-noteref"><sup>4</sup></a>），但是对子类型化的第一类支持则带来了更简单的类型签名和更好的类型推断的好处。</p>
<p>While subtyping is a staple of object-oriented programming (being
used to mirror class inheritance hierarchies), it is by no means limited
to that paradigm, and has found vast domains of applications in
functional programming too, including refinement types for ML data types
[Freeman and Pfenning 1991], lightweight verification [Rondon et al.
2008; Rushby et al. 1998; Vazou et al. 2014], full dependent types
[Hutchins 2010], first-class modules [Amin et al. 2016; Rossberg 2015],
polymorphic variants [Castagna et al. 2016], XML transformations [Hosoya
et al. 2005], and higher-rank polymorphism [Dunfield and Krishnaswami
2013; Odersky and Läufer 1996].</p>
<p>虽然子类型是面向对象编程的基本概念（用于反映类继承层次），但这绝不是该范式的唯一应用，它在函数式编程中也找到了广泛的应用领域，包括
ML 数据类型的细化类型 [Freeman and Pfenning 1991]、轻量级验证 [Rondon et
al. 2008；Rushby et al. 1998；Vazou et al. 2014]、全依赖类型 [Hutchins
2010]、一类模块 [Amin et al. 2016；Rossberg 2015]、多态变体 [Castagna et
al. 2016]、XML 转换 [Hosoya et al. 2005] 和高阶多态 [Dunfield and
Krishnaswami 2013；Odersky and Läufer 1996]。</p>
<p>For a long time, it was widely believed that implicit subtyping got
in the way of satisfactory global type inference. Indeed, previous
approaches to inferring subtypes failed to support principal types, or
resulted in the inference of large types containing sets of unwieldy
constraints, making them difficult to understand by programmers.</p>
<p>长期以来，人们普遍认为隐式子类型妨碍了令人满意的全局类型推断。事实上，以前的推断子类型的方法未能支持主要类型，或者导致推断出包含一组难以处理的约束的大类型，使得程序员难以理解。</p>
<p><strong>MLsub</strong> was introduced by Dolan and Mycroft [2017] as
an ML-style type system supporting subtyping, polymorphism, and global
type inference, while still producing compact principal types. Here,
<em>compact</em> refers to the fact that the inferred types are
relatively simple type expressions without any visible constraints,
making them easy to read and understand. This was achieved by carefully
designing the semantics of the subtyping lattice using an
<em>algebra-first</em> approach, also referred to as <strong>algebraic
subtyping</strong> [Dolan 2017].</p>
<p><strong>MLsub</strong> 是由 Dolan 和 Mycroft [2017] 提出的 ML
风格类型系统，支持子类型、多态和全局类型推断，同时仍然生成紧凑的主类型。这里的
<em>compact</em>
指的是推断出的类型是相对简单的类型表达式，且没有任何明显的约束，使得它们易于阅读和理解。这是通过精心设计子类型格的语义，采用
<em>algebra-first</em> 方法实现的，这也被称为 <strong>algebraic
subtyping</strong> [Dolan 2017]。</p>
<p>However, the specification of MLsub’s type inference algorithm as
<em>biunification</em> is difficult to understand for experts and
non-experts alike. On the surface, it looks more complicated than the
<em>algorithm W</em> traditionally used for HM type systems, requiring
additional concepts such as bisubstitution, polar types, and advanced
notions from abstract algebra. Although its elegant presentation will
appeal to mathematically-minded researchers, experience has shown that
grasping an understanding of the approach complete enough to reimplement
the algorithm required reading Dolan’s thesis in full, and sometimes
more [Courant 2018].</p>
<p>然而，MLsub 的类型推断算法的规范被称为 <em>biunification</em>
对于专家和非专家来说都很难理解。从表面上看，它看起来比传统上用于 HM
类型系统的 <em>algorithm W</em> 更复杂，要求引入诸如
bisubstitution、polar types
和抽象代数中的高级概念等额外概念。尽管其优雅的呈现方式将吸引有数学思维的研究人员，但经验表明，要完全掌握该方法以重新实现算法，通常需要通读
Dolan 的论文，有时还需要更多的阅读 [Courant 2018]。</p>
<p>Thankfully, it turns out that the essence of algebraic subtyping can
be captured by a much simpler algorithm, <strong>Simple-sub</strong>,
which is also more efficient than biunification (or at least, than the
basic syntax-driven form of biunification used as a specification for
MLsub<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>). In this paper, we show that
inferring MLsub types is surprisingly easy, and can be done in under 300
lines of Scala code, with an additional 200 lines of code for
simplification and pretty-printing. Simple-sub is available online at <a
href="https://github.com/LPTK/simple-sub">https://github.com/LPTK/simple-sub</a>.
While the implementation we present is written in Scala, it is
straightforward to translate into any other functional programming
languages.</p>
<p>值得庆幸的是，代数子类型的本质可以通过一个更简单的算法<strong>Simple-sub</strong>来捕获，该算法在效率上也优于双一化（至少优于作为MLsub<a
href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>规范使用的基本语法驱动形式）。在本文中，我们展示了推导MLsub类型是出乎意料的简单，并且可以在不到300行的Scala代码中完成，另外再增加200行代码用于简化和美化输出。Simple-sub可以在<a
href="https://github.com/LPTK/simple-sub">https://github.com/LPTK/simple-sub</a>
在线获取。尽管我们提出的实现是用Scala编写的，但将其转换为其他功能性编程语言是非常简单的。</p>
<p><strong>Our main contribution</strong> is to recast MLsub into a
simpler mold and to disentangle its algebraic construction of types from
the properties actually needed by the type inference and type
simplification processes. We believe this will allow future designers of
type systems and programming languages to benefit from some of the great
insights of the approach, without having to delve too deeply into the
theory of algebraic subtyping. In the rest of this paper, we:</p>
<p><strong>我们的主要贡献</strong>
是将MLsub重新塑造为一个更简单的模型，并将其类型的代数构造与类型推理和类型简化过程实际需要的属性解开。我们相信将使未来的类型系统和编程语言设计者能够从这种方法的一些重要见解中受益，而无需深入研究代数子类型理论。在本文的其余部分，我们：</p>
<ul>
<li>present MLsub and the <em>algebraic subtyping</em> discipline on
which it is based (Section 2);</li>
<li>describe our new Simple-sub type inference algorithm (Section
3);</li>
<li>explain how to perform basic simplification on the types inferred by
Simple-sub (Section 4);</li>
<li>sketch the correctness proofs of Simple-sub through
<em>soundness</em> and <em>completeness</em> theorems, formalizing the
minimal subtyping relation needed to carry out these proofs. (Section
5);</li>
<li>describe our experimental evaluation: we verified that Simple-sub
and MLsub agreed on the results of type inference for over a million
automatically-generated programs (Section 6).</li>
</ul>
<hr />
<ul>
<li>介绍 MLsub 及其所基于的 <em>algebraic subtyping</em> 学科（第 2
节）；</li>
<li>描述我们新的 Simple-sub 类型推断算法（第 3 节）；</li>
<li>解释如何对由 Simple-sub 推断出的类型进行基本简化（第 4 节）；</li>
<li>通过 <em>完善性</em> 和 <em>完整性</em> 定理勾勒 Simple-sub
的正确性证明，形式化进行这些证明所需的最小子类型关系。（第 5 节）；</li>
<li>描述我们的实验评估：我们验证了 Simple-sub 和 MLsub
在超过一百万个自动生成的程序的类型推断结果上是一致的（第 6 节）。</li>
</ul>
<h1 id="algebraic-subtyping-and-mlsub">Algebraic Subtyping and
MLsub</h1>
<h1 id="代数子类型和mlsub">2 代数子类型和MLsub</h1>
<p>Let us first describe MLsub and the algebraic subtyping philosophy
that underlies its design.</p>
<p>让我们首先描述 MLsub 及其设计所依据的代数子类型哲学。</p>
<h2 id="background-on-algebraic-subtyping">2.1 Background on Algebraic
Subtyping</h2>
<h2 id="代数子类型的背景">2.1 代数子类型的背景</h2>
<p>There are at least three major schools of thought on formalizing
subtyping. <em>Syntactic approaches</em>, as in this paper, use direct
specifications (usually given as inference rules) for the subtyping
relationship, closely following the syntax of types. <em>Semantic
approaches</em> [Frisch et al. 2008] view types as sets of values which
inhabit them, and define the subtyping relationship as set inclusion
between these sets. <em>Algebraic approaches</em> [Dolan 2017] define
types as abstract elements of a distributive lattice, whose algebraic
properties are carefully chosen to yield good properties, such as
“extensibility” and principal types.</p>
<p>关于形式化子类型，至少有三种主要的思想流派。<em>语法方法</em>，如本文所述，使用直接的规范（通常以推理规则的形式给出）来描述子类型关系，紧密跟随类型的语法。<em>语义方法</em>
[Frisch et al. 2008]
将类型视为其所占用的值的集合，并将子类型关系定义为这些集合之间的集合包含关系。<em>代数方法</em>
[Dolan 2017]
将类型定义为分布格的抽象元素，其代数性质经过精心选择，以产生良好的性质，如“可扩展性”和主类型。</p>
<p>Syntactic approaches somehow pay for their simplicity by forcing type
system designers to consider the consequences and interactions of all
their inference rules, having to manually verify that they result in a
subtyping relationship with the desired algebraic properties.</p>
<p>句法方法在某种程度上因其简单性而付出了代价，使类型系统设计者必须考虑所有推理规则的后果和相互作用，手动验证它们是否产生具有所需代数性质的子类型关系。</p>
<p>The semantic approach is probably the most intuitive, and is also
very powerful; however, it suffers from difficulties related to
polymorphism – an understanding of type variables as <em>ranging</em>
over ground types can lead to paradoxes and a lack of extensibility
[Dolan 2017].</p>
<p>语义方法可能是最直观的，且也非常强大；然而，它受到与多态性相关的困难的困扰——将类型变量理解为<em>范围</em>在基础类型上可能导致悖论和缺乏可扩展性
[Dolan 2017]。</p>
<p>As a response to these perceived shortcomings, Dolan argues that
<em>algebra</em> (not <em>syntax</em>) should come first, in order to
guarantee from the start that type systems are well-behaved, as opposed
to ensuring it as a sort of afterthought. In particular, he emphasizes
the concept of <em>extensibility</em> of type systems, the idea being
that existing programs should remain well-typed when new type forms are
added. While the practical usefulness of this notion of extensibility is
unclear,<a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> the general approach of making the
subtyping lattice <em>distributive</em> does help simplify types
aggressively and construct algorithms for checking subsumption
effectively (i.e., checking whether one type signature is as general as
another).</p>
<p>作为对这些被认为的不足之处的回应，Dolan 认为 <em>algebra</em>（而不是
<em>syntax</em>）应该优先考虑，以确保从一开始就保证类型系统的良好行为，而不是将其视为一种事后考虑。尤其是，他强调了类型系统的
<em>extensibility</em>
概念，核心思想是当添加新的类型形式时，现有程序应该保持良好的类型。虽然这种可拓展性的实际有用性尚不明确，<a
href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a> 但使子类型格 <em>distributive</em>
的一般方法确实有助于有效地简化类型并构建检查包含关系的算法（即检查一个类型签名是否与另一个一样通用）。</p>
<p>In the rest of this section, we explain the basics of MLsub and its
static semantics, to set the stage for the presentation of Simple-sub in
Section 3.</p>
<p>在本节的其余部分，我们将解释 MLsub 的基础及其静态语义，为第 3 节中
Simple-sub 的介绍奠定基础。</p>
<h2 id="basics-of-mlsub">2.2 Basics of MLsub</h2>
<h2 id="mlsub基础">2.2 MLsub基础</h2>
<p>2.2.1 Term Language. The term syntax of MLsub is given in Figure 1.
We make some simplifications compared to the original MLsub
presentation: first, we omit boolean literals and if-then-else, as they
can easily be typed as primitive combiners; second, we use only one form
of variables x (MLsub distinguished between lambda-bound and let-bound
variables, for technical reasons).</p>
<p>2.2.1
项语言。MLsub的项语法如图1所示。与原始的MLsub介绍相比，我们进行了一些简化：首先，我们省略布尔字面量和if-then-else，因为它们可以很容易地被归类为原始组合子；第二，我们仅使用一种形式的变量x（MLsub在技术原因上区分了lambda绑定和let绑定的变量）。</p>
<p><span class="math display">\[t ::= x | \lambda x. t | t t | \{ l_0 =
t; \dots; l_n = t \} | t.l | \text{let rec } x = t \text{ in }
t\]</span></p>
<p><span class="math display">\[ t ::= x | \lambda x. t | t t | \{ l_0 =
t; \dots; l_n = t \} | t.l | \text{let rec } x = t \text{ in } t
\]</span></p>
<p>Fig. 1. Syntax of MLsub terms, for which we want to infer types.</p>
<p>图1. MLsub项的语法，我们希望推导其类型。</p>
<p>2.2.2 Type Language. The type syntax of MLsub, summarized in Figure
2, consists in primitive types (such as int and bool) function types,
record types, type variables, top <span
class="math inline">\(\top\)</span> (the type of all values — supertype
of all types), bottom <span class="math inline">\(\bot\)</span> (the
type of no values — subtype of all types), type union <span
class="math inline">\(\sqcup\)</span>, type intersection <span
class="math inline">\(\sqcap\)</span>, and recursive types <span
class="math inline">\(\mu\alpha.\tau\)</span>.</p>
<p>2.2.2 类型语言。MLsub 的类型语法如图 2 所示，包含基本类型（如 int 和
bool）、函数类型、结构体类型、类型变量、上界 <span
class="math inline">\(\top\)</span>（所有值的类型——所有类型的超类型）、下界
<span
class="math inline">\(\bot\)</span>（没有值的类型——所有类型的子类型）、类型并
$ $、类型交 $ $ 和递归类型 $ .$。</p>
<p><span class="math display">\[\tau ::= \text{primitive} | \tau \to
\tau | \{ l_0 : \tau; \dots; l_n : \tau \} | \alpha | \top | \bot | \tau
\sqcup \tau | \tau \sqcap \tau | \mu\alpha.\tau\]</span></p>
<p>Fig. 2. Syntax of MLsub types.</p>
<p>图 2. MLsub 类型的语法。</p>
<p>2.2.3 Type System. The declarative type system of MLsub is given in
Figure 3. It is mostly as presented by Dolan and Mycroft [2017]. We
support recursive let bindings explicitly for clarity, though recursion
could also be factored out into a combinator [Damas and Milner 1982]. We
write <span class="math inline">\(\overline{E}^i\)</span> for a
repetition of elements E indexed by i. Of particular interest are the
rules T-SUB, which takes a term from a subtype to a supertype implicitly
(without a term-level coercion), T-LET, which types x in its recursive
right-hand side in a monomorphic way, but types x in its body
polymorphically, and T-VAR, which instantiates polymorphic types using
the substitution syntax <span
class="math inline">\([\tau_0/\alpha_0]\tau\)</span>.</p>
<p>2.2.3 类型系统。MLsub 的声明性类型系统如图 3 所示。它大部分与 Dolan
和 Mycroft [2017] 的介绍相同。为了清晰起见，我们显式支持递归 let
绑定，尽管递归也可以被抽象为一个组合子 [Damas 和 Milner 1982]。我们用
<span class="math inline">\(\overline{E}^i\)</span> 表示索引为 i 的元素
E 的重复。特别值得关注的是规则
T-SUB，它隐式地将一个子类型的项转换为超类型（没有项级的强制转换），规则
T-LET，它以单一类型的方式类型化其递归右侧的
x，但在其主体中以多态的方式类型化 x，以及规则 T-VAR，它使用替换语法
<span class="math inline">\([\tau_0/\alpha_0]\tau\)</span>
实例化多态类型。</p>
<p>We appeal to the reader's intuition and leave the precise definition
of subtyping unspecified for now, as it requires some technicalities
around recursive types. In contrast to MLsub, which gives an algebraic
account of subtyping, we will present a syntactic subtyping system in
Section 5.1.</p>
<p>我们借用读者的直觉，目前暂时不对子类型的精确定义进行说明，因为这涉及到递归类型的一些技术细节。与
MLsub 提供的代数子类型描述相比，我们将在第 5.1
节中展示一个语法子类型系统。</p>
<p><span class="math display">\[
\text{T-LIT:} \quad \frac{}{\Gamma \vdash n : \text{int}}
\]</span></p>
<p><span class="math display">\[
\text{T-VAR:} \quad \frac{\Gamma(x) = \overline{\forall \alpha_i.\,
\tau}^i}{\Gamma \vdash x : [\tau_i / \alpha_i]^i \tau}
\]</span></p>
<p><span class="math display">\[
\text{T-ABS:} \quad \frac{\Gamma, x : \tau_1 \vdash t : \tau_2}{\Gamma
\vdash \lambda x.\, t : \tau_1 \to \tau_2}
\]</span></p>
<p><span class="math display">\[
\text{T-APP:} \quad \frac{\Gamma \vdash t_0 : \tau_1 \to \tau_2 \quad
\Gamma \vdash t_1 : \tau_1}{\Gamma \vdash t_0\, t_1 : \tau_2}
\]</span></p>
<p><span class="math display">\[
\text{T-RCD:} \quad \frac{\Gamma \vdash t_i : \tau_i^i}{\Gamma \vdash \{
l_i = t_i \}^i : \{ l_i : \tau_i \}^i}
\]</span></p>
<p><span class="math display">\[
\text{T-PROJ:} \quad \frac{\Gamma \vdash t : \{ l : \tau \}}{\Gamma
\vdash t.l : \tau}
\]</span></p>
<p><span class="math display">\[
\text{T-SUB:} \quad \frac{\Gamma \vdash t : \tau_1 \quad \tau_1 \leq
\tau_2}{\Gamma \vdash t : \tau_2}
\]</span></p>
<p><span class="math display">\[
\text{T-LET:} \quad \frac{\Gamma, x : \tau_1 \vdash t_1 : \tau_1 \quad
\Gamma, x : \overline{\forall \alpha_i.\, \tau_1}^i \vdash t_2 :
\tau_2}{\Gamma \vdash \mathbf{let}\ \mathbf{rec}\ x = t_1\ \mathbf{in}\
t_2 : \tau_2}
\]</span></p>
<p><span class="math display">\[
\begin{align*}
\text{succ} &amp;: \text{int} \to \text{int} \\
\text{iszero} &amp;: \text{int} \to \text{bool} \\
\text{true} &amp;: \text{bool} \\
\text{false} &amp;: \text{bool} \\
\text{if} &amp;: \forall \alpha.\, \text{bool} \to \alpha \to \alpha \to
\alpha
\end{align*}
\]</span></p>
<p>Fig. 3. Declarative typing rules of MLsub (and Simple-sub).</p>
<p>图 3. MLsub（和 Simple-sub）的声明性类型规则。</p>
<h2 id="informal-semantics-of-types">2.3 Informal Semantics of
Types</h2>
<h2 id="类型的非正式语义">2.3 类型的非正式语义</h2>
<p>While most MLsub type forms are usual and unsurprising, two kinds of
types require our special attention: set-theoretic types (especially
unions and intersections), and recursive types.</p>
<p>虽然大多数 MLsub
类型形式是常见且不令人惊讶的，但有两种类型需要我们特别关注：集合论类型（尤其是并集和交集）和递归类型。</p>
<h3 id="set-theoretic-types.">2.3.1 Set-Theoretic Types.</h3>
<h3 id="集合论类型">2.3.1 集合论类型</h3>
<p>To a first approximation, union and intersection types can be
understood in set-theoretic terms: <span class="math inline">\(τ_0 ⊔
τ_1\)</span> (resp. <span class="math inline">\(τ_0 ⊕ τ_1\)</span>)
represents the type of values that are either (resp. both) of type <span
class="math inline">\(τ_0\)</span> or (resp. and) of type <span
class="math inline">\(τ_1\)</span>.</p>
<p>初步来看，联结类型和交集类型可以用集合论术语来理解：<span
class="math inline">\(τ_0 ⊔ τ_1\)</span>（分别为 <span
class="math inline">\(τ_0 ⊕
τ_1\)</span>）表示的值的类型要么是（分别是）<span
class="math inline">\(τ_0\)</span> 类型，要么是（分别是）<span
class="math inline">\(τ_1\)</span> 类型。</p>
<p>MLsub uses these types to indirectly constrain type variables: When a
type variable <span class="math inline">\(α\)</span> is supposed to be a
<em>subtype</em> of some type <span class="math inline">\(τ\)</span>
(i.e., values of type <span class="math inline">\(α\)</span> may be used
at type <span class="math inline">\(τ\)</span>), MLsub substitutes all
occurrences of <span class="math inline">\(α\)</span> in input position
with <span class="math inline">\(α ⊔ τ\)</span>, making sure that any
arguments passed in as <span class="math inline">\(α\)</span> values are
also <span class="math inline">\(τ\)</span> values. Similarly, when
<span class="math inline">\(α\)</span> is supposed to be a
<em>supertype</em> of some <span class="math inline">\(τ\)</span> (i.e.,
values of type <span class="math inline">\(τ\)</span> may be used at
type <span class="math inline">\(α\)</span>), MLsub substitutes all
occurrences of <span class="math inline">\(α\)</span> in output position
with <span class="math inline">\(α ⊔ τ\)</span>, making sure that
results returned as <span class="math inline">\(α\)</span> values are
also <span class="math inline">\(τ\)</span> values.</p>
<p>MLsub 使用这些类型来间接约束类型变量：当一个类型变量 <span
class="math inline">\(α\)</span> 应该是某类型 <span
class="math inline">\(τ\)</span> 的 <em>子类型</em> 时（即，类型为 <span
class="math inline">\(α\)</span> 的值可以在类型 <span
class="math inline">\(τ\)</span> 中使用），MLsub 会用 <span
class="math inline">\(α ⊔ τ\)</span> 替换输入位置中所有 <span
class="math inline">\(α\)</span> 的出现，确保作为 <span
class="math inline">\(α\)</span> 值传入的任何参数也是 <span
class="math inline">\(τ\)</span> 值。类似地，当 <span
class="math inline">\(α\)</span> 应该是某个 <span
class="math inline">\(τ\)</span> 的 <em>超类型</em> 时（即，类型为 <span
class="math inline">\(τ\)</span> 的值可以在类型 <span
class="math inline">\(α\)</span> 中使用），MLsub 会用 <span
class="math inline">\(α ⊔ τ\)</span> 替换输出位置中所有 <span
class="math inline">\(α\)</span> 的出现，确保作为 <span
class="math inline">\(α\)</span> 值返回的结果也是 <span
class="math inline">\(τ\)</span> 值。</p>
<p>As an example, one type inferred for the term <span
class="math inline">\(λx. \{ L = x - 1; R = x \}\)</span> could be <span
class="math inline">\(α ⊕ int → \{ L : int; R : α \}\)</span>, assuming
operator <span class="math inline">\((-)\)</span> has type <span
class="math inline">\(int → int → int\)</span>. This type reflects the
fact that the original argument, of some type <span
class="math inline">\(α\)</span>, is returned in the R field of the
result record (as the input of the function ends up in that position),
but also that this argument should be able to be treated as an int,
expressed via the type intersection <span class="math inline">\(α ⊕
int\)</span> on the left-hand side of the function type. Keeping track
of the precise argument type <span class="math inline">\(α\)</span> is
important: it could be later substituted with a more specific type than
int, such as <span class="math inline">\(α = nat\)</span>, which would
give us <span class="math inline">\(nat → \{ L : int; R : nat
\}\)</span>. On the other hand, there may be type signatures where <span
class="math inline">\(α\)</span> becomes undistinguishable from int. For
instance, consider the term '<span class="math inline">\(λx. if true
then x - 1 else x\)</span>', whose simplified inferred type would be
just int → int, as the seemingly-more precise type <span
class="math inline">\(α ⊕ int → α ⊔ int\)</span> does not actually
contain more information (we expand on this in Section 4.3.1).</p>
<p>作为一个例子，术语 <span class="math inline">\(λx. \{ L = x - 1; R =
x \}\)</span> 推断出的一个类型可以是 <span class="math inline">\(α ⊕ int
→ \{ L : int; R : α \}\)</span>，假设运算符 <span
class="math inline">\((-)\)</span> 的类型为 <span
class="math inline">\(int → int →
int\)</span>。这个类型反映了一个事实，即原始参数，某个类型为 <span
class="math inline">\(α\)</span> 的值，被返回在结果结构体的 R
字段中（因为函数的输入最终位于这个位置），同时也表明这个参数应该能够被视为一个
int，通过函数类型左侧的类型交集 <span class="math inline">\(α ⊕
int\)</span> 表达。跟踪精确的参数类型 <span
class="math inline">\(α\)</span> 是重要的：它可以在后面用比 int
更具体的类型替代，例如 <span class="math inline">\(α =
nat\)</span>，这将给我们 <span class="math inline">\(nat → \{ L : int; R
: nat \}\)</span>。另一方面，可能存在某些类型签名，其中 <span
class="math inline">\(α\)</span> 变得与 int 无法区分。例如，考虑术语
'<span class="math inline">\(λx. if true then x - 1 else
x\)</span>，其简化后的推断类型将只是 int → int，因为看似更精确的类型
<span class="math inline">\(α ⊕ int → α ⊔ int\)</span>
实际上并未包含更多信息（我们将在第 4.3.1 节中对此进行扩展）。</p>
<p>The beauty of MLsub is that this sort of reasoning scales to
arbitrary flows of variables and higher-order functions; for instance,
the previous example can be generalized by passing in a function <span
class="math inline">\(f\)</span> to stand for the <span
class="math inline">\(· - 1\)</span> operation, as in <span
class="math inline">\(λf. λx. \{ L = f x; R = x \}\)</span> whose type
could be inferred as <span class="math inline">\((β → γ) → α ⊕ β → \{ L
: γ; R : α \}\)</span> and further simplified to <span
class="math inline">\((α → γ) → α → \{ L : γ; R : α \}\)</span>.
Applying this function to argument <span class="math inline">\((λx. x -
1)\)</span> yields the same type (after simplification) as in the
example of the previous paragraph.</p>
<p>MLsub
的美在于这种推理可以扩展到任意的变量流和高阶函数；例如，之前的例子可以通过传递一个函数
<span class="math inline">\(f\)</span> 来代表 <span
class="math inline">\(· - 1\)</span> 操作进行广义化，如 <span
class="math inline">\(λf. λx. \{ L = f x; R = x
\}\)</span>，其类型可以推断为 <span class="math inline">\((β → γ) → α ⊕
β → \{ L : γ; R : α \}\)</span>，进一步简化为 <span
class="math inline">\((α → γ) → α → \{ L : γ; R : α
\}\)</span>。将此函数应用于参数 <span class="math inline">\((λx. x -
1)\)</span> 产生与前一段示例相同的类型（经过简化后）。</p>
<h3 id="recursive-types.">2.3.2 Recursive Types.</h3>
<h3 id="递归类型">2.3.2 递归类型。</h3>
<p>A recursive type <span class="math inline">\(μα. τ\)</span>
represents a type we can unroll as many times as we want; for instance,
<span class="math inline">\(μα. (T → α)\)</span>, which we write just
<span class="math inline">\(μα. T → α\)</span>, is equivalent to <span
class="math inline">\(T → μα. T → α\)</span>, which is equivalent to
<span class="math inline">\(T → T → μα. T → α\)</span>, etc., and is the
type of a function that can be applied to any arguments (any subtypes of
<span class="math inline">\(T\)</span>) indefinitely. A recursive type
is conceptually infinite — if we unrolled the above fully, it would
unfold as an infinitely-deep tree <span class="math inline">\(T → T → T
→ ...\)</span></p>
<p>递归类型 <span class="math inline">\(μα. τ\)</span>
代表一个我们可以展开任意次的类型；例如，<span class="math inline">\(μα.
(T → α)\)</span>，我们简写为 <span class="math inline">\(μα. T →
α\)</span>，它等同于 <span class="math inline">\(T → μα. T →
α\)</span>，进一步等同于 <span class="math inline">\(T → T → μα. T →
α\)</span>，等等，这就是一个可以无限期应用于任何参数（T
的任何子类型）的函数的类型。递归类型在概念上是无限的——如果我们完全展开上述内容，它将展现为一个无限深的树
<span class="math inline">\(T → T → T → ...\)</span></p>
<p>If this sounds confusing, that's perfectly fine. We will get some
deeper intuition on recursive types and <em>why</em> we need them in
Section 3.4.1, and we will give them a formal treatment in Section 5.1.
The high-level idea is that recursive types are sometimes necessary to
give principal types to MLsub terms. The example given by Dolan [2017]
is that of the term <span class="math inline">\(Y(λf. λx. f)\)</span>
where <span class="math inline">\(Y\)</span> is the call-by-value <span
class="math inline">\(Y\)</span> combinator. This term represents a
function which ignores its parameter and returns itself. It can be given
type <span class="math inline">\(T → T\)</span> as well as <span
class="math inline">\(T → T → T\)</span>, and <span
class="math inline">\(T → T → T → T\)</span>, etc. Its principal type is
the recursive type shown in the previous paragraph.</p>
<p>如果这听起来让人困惑，那是完全可以理解的。我们将在第3.4.1节中深入理解递归类型以及<em>我们为什么需要它们</em>，并将在第5.1节中对它们进行正式处理。总体思路是，递归类型有时是必要的，以便为MLsub术语提供主类型。Dolan
[2017]给出的例子是术语<span class="math inline">\(Y(λf. λx.
f)\)</span>，其中<span class="math inline">\(Y\)</span>是按值调用的<span
class="math inline">\(Y\)</span>组合子。这个术语表示一个忽略其参数并返回自身的函数。它可以被赋予类型<span
class="math inline">\(T → T\)</span>以及<span class="math inline">\(T →
T → T\)</span>，还有<span class="math inline">\(T → T → T →
T\)</span>，等等。它的主类型是前一段中所示的递归类型。</p>
<h3 id="typing-surprises.">2.3.3 Typing Surprises.</h3>
<h3 id="类型意外">2.3.3 类型意外</h3>
<p>It is worth noting that inferring recursive types can lead to typing
terms which <em>appear</em> ill-typed, and would in fact not be
well-typed in ML.<a href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a> This kind of surprises can also
arise simply due to subtyping. For instance, in MLsub, the
strange-looking term <span class="math inline">\(\lambda x. x
x\)</span>, which takes a function in parameter and applies it to
itself, can be typed as <span class="math inline">\(\forall \alpha,
\beta. (\alpha \to \beta) \sqcap \alpha \to \beta\)</span>. Indeed, if
the input <span class="math inline">\(x\)</span> passed to the function
has type <span class="math inline">\((\alpha \to \beta) \sqcap
\alpha\)</span>, that means it has type <span
class="math inline">\(\alpha \to \beta\)</span> (a function taking an
<span class="math inline">\(\alpha\)</span> argument) and type <span
class="math inline">\(\alpha\)</span>, meaning that it can be passed as
an argument to itself.</p>
<p>值得注意的是，推断递归类型可能导致出现<em>看起来</em>类型不正确的术语，实际上在ML中并不会是良好类型的。<a
href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a>
这类意外也可能简单地源于子类型。例如，在 MLsub 中，奇怪的术语 <span
class="math inline">\(\lambda x. x
x\)</span>，它以一个函数作为参数并将其应用于自身，可以被类型化为 <span
class="math inline">\(\forall \alpha, \beta. (\alpha \to \beta) \sqcap
\alpha \to \beta\)</span>。事实上，如果传递给函数的输入 <span
class="math inline">\(x\)</span> 的类型是 <span
class="math inline">\((\alpha \to \beta) \sqcap
\alpha\)</span>，这意味着它具有类型 <span class="math inline">\(\alpha
\to \beta\)</span>（一个接受 <span class="math inline">\(\alpha\)</span>
参数的函数）和类型 <span
class="math inline">\(\alpha\)</span>，意味着它可以作为自身的参数传递。</p>
<h2 id="expressiveness">2.4 Expressiveness</h2>
<h2 id="表达能力">2.4 表达能力</h2>
<p>There is an important caveat to add to the definition of types we
gave above: these types cannot actually be used freely within type
expressions. The true syntax of MLsub is segregated between
<em>positive</em> and <em>negative</em> types. In particular, unions are
positive types (and may not appear in negative position) and
intersections are negative types (and may not appear in positive
position).</p>
<p>需要在上述类型定义中添加一个重要的警告：这些类型实际上不能在类型表达式中被自由使用。MLsub
的真实语法在 <em>正</em> 类型和 <em>负</em>
类型之间是分隔的。特别地，联合是正类型（不能出现在负位置），而交集是负类型（不能出现在正位置）。</p>
<h3 id="polarity-of-type-positions.">2.4.1 Polarity of Type
Positions.</h3>
<h3 id="类型位置的极性">2.4.1 类型位置的极性。</h3>
<p>Positive positions correspond to the types that a term
<em>outputs</em>, while negative positions correspond to the types that
a term <em>takes in</em> as input. For instance, in <span
class="math inline">\((\tau_0 \to \tau_1) \to \tau_2\)</span>, type
<span class="math inline">\(\tau_2\)</span> is in positive position
since it is the output of the main function, and the function type <span
class="math inline">\((\tau_0 \to \tau_1)\)</span> is in negative
position, as it is taken as an input to the main function. On the other
hand, <span class="math inline">\(\tau_1\)</span>, which is returned
<em>by the function taken as input</em> is in negative position (since
it is provided by callers via the argument function), and <span
class="math inline">\(\tau_0\)</span> is in positive position (since it
is provided by the main function when calling the argument
function).</p>
<p>正位置对应于一个术语 <em>输出</em> 的类型，而负位置对应于一个术语
<em>作为输入接收</em> 的类型。例如，在 <span
class="math inline">\((\tau_0 \to \tau_1) \to \tau_2\)</span> 中，类型
<span class="math inline">\(\tau_2\)</span>
位于正位置，因为它是主函数的输出，而函数类型 <span
class="math inline">\((\tau_0 \to \tau_1)\)</span>
位于负位置，因为它作为主函数的输入。另一方面，<span
class="math inline">\(\tau_1\)</span> 是由 <em>作为输入的函数返回</em>
的，所以它位于负位置（因为它是通过调用者提供的参数函数提供的），而 <span
class="math inline">\(\tau_0\)</span>
位于正位置（因为它是由主函数在调用参数函数时提供的）。</p>
<h3 id="consequence-of-the-polarity-restriction.">2.4.2 Consequence of
the Polarity Restriction.</h3>
<h3 id="极性限制的后果">2.4.2 极性限制的后果。</h3>
<p>These <em>polarity</em> restrictions mean that the full syntax of
types we saw above cannot actually be used as is; programmers cannot
write, in their own type annotations, types that violate the polarity
distinction. In fact, in MLsub, one <em>cannot</em> express the type of
a function which takes “either an integer or a string”: type
<code>int</code> <span class="math inline">\(\sqcup\)</span>
<code>string</code> <span class="math inline">\(\to\)</span> <span
class="math inline">\(\tau\)</span> is illegal because it has the
<code>int</code> <span class="math inline">\(\sqcup\)</span>
<code>string</code> union in negative position. On the other hand, MLsub
may assign the legal type <span class="math inline">\(\tau \to\)</span>
<code>int</code> <span class="math inline">\(\sqcup\)</span>
<code>string</code> to functions which may return either an integer or a
string... but this is not a very useful type, since one cannot do
anything useful with an <code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code> value in
MLsub.<a href="#fn11" class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a></p>
<p>这些 <em>极性</em>
限制意味着我们上面看到的类型的完整语法实际上无法按原样使用；程序员不能在自己的类型注释中编写违反极性区分的类型。事实上，在
MLsub 中，人们 <em>无法</em>
表达一个接受“整数或字符串”的函数的类型：类型 <code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code> <span
class="math inline">\(\to\)</span> <span
class="math inline">\(\tau\)</span> 是非法的，因为它在负位置上有
<code>int</code> <span class="math inline">\(\sqcup\)</span>
<code>string</code> 的并集。另一方面，MLsub 可以将合法类型 <span
class="math inline">\(\tau \to\)</span> <code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code>
分配给可能返回整数或字符串的函数……但这并不是一个非常有用的类型，因为在
MLsub 中，人们无法对 <code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code>
值进行任何有用的操作。<a href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a></p>
<p>What this all comes down to, perhaps surprisingly, is that the MLsub
language is fundamentally no more expressive<a href="#fn13"
class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>
than a “structurally-typed Java”, by which we mean a hypothetical Java
dialect with structural records and lower as well as upper bounds for
type variables. To understand this, consider the following function:</p>
<p>这一切归结起来，也许令人惊讶的是，MLsub
语言在表达能力上根本不比“结构类型（structurally-typed）的 Java”更强<a
href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a>，我们指的是一种假设的 Java
方言，具有结构化的结构体（structural
records）以及类型变量的下限和上限。要理解这一点，请考虑以下函数：</p>
<p><span class="math display">\[ \lambda x. \{ L = x - 1; R = \text{if }
x &lt; 0 \text{ then } 0 \text{ else } x \} \]</span></p>
<p>which could be given the following <em>unsimplified</em> type by
MLsub or Simple-sub:</p>
<p>可以通过 MLsub 或 Simple-sub 给出以下 <em>未简化</em> 类型：</p>
<p><span class="math display">\[ \alpha \sqcap \text{int} \to \{ L :
\text{int}; R : \beta \sqcup \text{nat} \sqcup \alpha \} \]</span></p>
<p>or equivalently, after simplification:</p>
<p>或者等价地，在简化后：</p>
<p><span class="math display">\[ \alpha \sqcap \text{int} \to \{ L :
\text{int}; R : \text{nat} \sqcup \alpha \} \]</span></p>
<p>The <span class="math inline">\(\beta\)</span> type variable is
introduced to represent the result type of the <em>if</em> expression.
During type inference, both constraints <span
class="math inline">\(\text{nat} \le \beta\)</span> and <span
class="math inline">\(\alpha \le \beta\)</span> are registered, which is
handled by replacing all occurrences of <span
class="math inline">\(\beta\)</span> in positive positions (there is
only one here) by <span class="math inline">\(\beta \sqcup \text{nat}
\sqcup \alpha\)</span>. In this simple example, the <span
class="math inline">\(\beta\)</span> type variable turns out to be
redundant, and is later removed during simplification.</p>
<p><span class="math inline">\(\beta\)</span> 类型变量被引入以表示
<em>if</em> 表达式的结果类型。在类型推断期间，两个约束 <span
class="math inline">\(\text{nat} \le \beta\)</span> 和 <span
class="math inline">\(\alpha \le \beta\)</span>
被记录，这通过将所有正位置上（这里只有一个）的 <span
class="math inline">\(\beta\)</span> 替换为 <span
class="math inline">\(\beta \sqcup \text{nat} \sqcup \alpha\)</span>
来处理。在这个简单的例子中，<span class="math inline">\(\beta\)</span>
类型变量被证明是多余的，并在简化过程中被移除。</p>
<p>Now, recall that Java allows users to quantify types using type
variables, and also allows bounding these type variables with subtypes
and supertypes.<a href="#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a> The insight is that unions and
intersections, when used at the appropriate polarity, are only a way of
indirectly bounding type variables. For instance, the unsimplified MLsub
type seen above is equivalent to the following Java-esque type, where
type parameters are written between <code>⟨</code> and
<code>⟩</code>:</p>
<p>现在，回想一下 Java
允许用户使用类型变量来量化类型，同时也允许用子类型和超类型来限制这些类型变量。<a
href="#fn16" class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a>
这个见解是，联合和交叉，当在适当的极性下使用时，仅仅是在间接限制类型变量的一种方式。例如，上面未简化的MLsub类型等同于以下Java风格的类型，其中类型参数写在<code>⟨</code>和<code>⟩</code>之间：</p>
<p><span class="math display">\[ \langle \alpha \ extends \ int, \ \beta
\ super \ nat \mid \alpha \rangle(\alpha) \to \{ L : int; R : \beta \}
\]</span></p>
<p>meaning that <span class="math inline">\(\alpha\)</span> should be a
<em>subtype</em> of int and that <span
class="math inline">\(\beta\)</span> should be a <em>supertype</em> of
both nat and <span class="math inline">\(\alpha\)</span>. Moreover, the
simplified type is equivalent to:</p>
<p>这意味着<span
class="math inline">\(\alpha\)</span>应该是int的<em>子类型</em>，而<span
class="math inline">\(\beta\)</span>应该是nat和<span
class="math inline">\(\alpha\)</span>的<em>超类型</em>。此外，简化后的类型等同于：</p>
<p><span class="math display">\[ \langle \alpha \ super \ nat \ extends
\ int \rangle(\alpha) \to \{ L : int; R : \alpha \} \]</span></p>
<p>meaning that <span class="math inline">\(\alpha\)</span> should be a
supertype of nat and also a subtype of int.</p>
<p>意味着 <span class="math inline">\(\alpha\)</span> 应该是 nat
的超类型，同时也是 int 的子类型。</p>
<p>As for MLsub's recursive types, they are expressible via F-bounded
polymorphism, which Java also supports. F-bounded polymorphism allows a
type variable <span class="math inline">\(\alpha\)</span> to be bounded
by a type expression that contains occurrences of <span
class="math inline">\(\alpha\)</span> itself.</p>
<p>至于 MLsub 的递归类型，它们可以通过 F-bounded polymorphism
来表达，Java 也支持这一点。F-bounded polymorphism 允许一个类型变量 <span
class="math inline">\(\alpha\)</span> 受到一个包含 <span
class="math inline">\(\alpha\)</span> 本身的类型表达式的限制。</p>
<p>The fact that type intersections can be used to encode upper bounds
on type variables was originally remarked by Castagna and Xu [2011,
footnote 4]. Naturally, the same goes for type unions and lower bounds
respectively. What we proposed above is, in a sense, the <em>reverse
direction</em> of this translation: stating that <em>polar</em> usages
of unions and intersections can be encoded as lower and upper bounds on
type variables.</p>
<p>类型交集可用于编码类型变量的上界这一事实最初是由 Castagna 和 Xu
[2011, footnote 4]
提出的。自然，类型并集和下界同样适用。我们上面所提的在某种意义上是这种翻译的<em>反向方向</em>：即表明<em>极性</em>使用的并集和交集可以作为类型变量的下界和上界进行编码。</p>
<h2 id="essence-of-mlsub-type-inference">2.5 Essence of MLsub Type
Inference</h2>
<h2 id="mlsub-类型推断的本质">2.5 MLsub 类型推断的本质</h2>
<p>Reading Dolan [2017]; Dolan and Mycroft [2017], one could be led to
think that MLsub is all about:</p>
<p>阅读 Dolan [2017]; Dolan 和 Mycroft [2017]，人们可能会认为 MLsub
全部是关于：</p>
<ul>
<li><p>supporting unions and intersections in the type language, forming
a distributive lattice;</p></li>
<li><p>a new algorithm called biunification as an alternative to
traditional unification;</p></li>
<li><p>separating the syntax of types between positive and negative
types.</p></li>
<li><p>在类型语言中支持并集和交集，形成一个分布格；</p></li>
<li><p>一种名为 biunification
的新算法，作为传统合并的替代方案；</p></li>
<li><p>将类型的语法分为正类型和负类型。</p></li>
</ul>
<p>However, we argue that this is not the most helpful way of
understanding the processes at work in this type inference algorithm;
instead, we argue that the essence of the approach is:</p>
<p>然而，我们认为这并不是理解这种类型推导算法中运行过程的最有帮助的方法；相反，我们认为该方法的本质是：</p>
<ul>
<li><p>making the semantics of types simple enough that all inferred
subtyping constraints can be reduced to constraints on type variables,
which can be recorded efficiently (for instance using mutation, as done
in this paper and in MLsub's actual implementation);</p></li>
<li><p>using intersection, union, and recursive types to express compact
type signatures where type variables are indirectly constrained,
avoiding the need for separate constraint specifications.</p></li>
<li><p>使类型的语义足够简单，以便所有推导出的子类型约束都可以简化为对类型变量的约束，这些约束可以高效记录（例如使用变异，如本文和MLsub的实际实现所做的那样）；</p></li>
<li><p>使用交集、并集和递归类型来表达紧凑的类型签名，其中类型变量受到间接约束，避免了单独约束规范的需要。</p></li>
</ul>
<h1 id="the-simple-sub-type-inference-algorithm">3 THE SIMPLE-SUB TYPE
INFERENCE ALGORITHM</h1>
<h1 id="simple-sub-类型推导算法">3 SIMPLE-SUB 类型推导算法</h1>
<p>We now present Simple-sub. We start with the internal Scala syntax
used in the algorithms (Section 3.1); we then describe the basic
mechanisms of type inference, at first omitting let bindings for
simplicity (Section 3.2); we show how to produce user-facing type
representations from the results of type inference (Section 3.3); we
discuss some insights on recursive types and unroll an example of type
inference (Section 3.4); and we explain how to support let polymorphism
and recursive let bindings (Section 3.5). Finally, we summarize the full
Simple-sub algorithm (Section 3.6).</p>
<p>我们现在介绍 Simple-sub。我们首先介绍算法中使用的内部 Scala 语法（第
3.1 节）；然后描述类型推断的基本机制，最初省略 let 绑定以简化问题（第
3.2 节）；接着展示如何从类型推断的结果生成用户可见的类型表示（第 3.3
节）；我们讨论一些关于递归类型的见解，并演示一个类型推断的例子（第 3.4
节）；最后，我们解释如何支持 let 多态性和递归 let 绑定（第 3.5
节）。最后，我们总结完整的 Simple-sub 算法（第 3.6 节）。</p>
<h2 id="simple-sub-syntax">3.1 Simple-sub Syntax</h2>
<h2 id="simple-sub-语法">3.1 Simple-sub 语法</h2>
<p>3.1.1 <em>Term Syntax.</em> The Scala implementation of the term
syntax is shown in Figure 4. We derive it directly from Figure 1, except
that we add a construct for integer literals.</p>
<p>3.1.1 <em>项语法。</em> Scala 对项语法的实现如图 4 所示。我们直接从图
1 中推导出来，除了我们添加了一个整数字面量的构造。</p>
<p>As mentioned before, there is no need for an if-then-else feature,
since we can just add one as a combinator: our parser actually parses
code of the form "if <span class="math inline">\(e_0\)</span> then <span
class="math inline">\(e_1\)</span> else <span
class="math inline">\(e_2\)</span>" as if it were written</p>
<p>如前所述，实际上不需要 if-then-else
特性，因为我们可以将其作为一个组合子添加：我们的解析器实际上将形式为 "if
<span class="math inline">\(e_0\)</span> then <span
class="math inline">\(e_1\)</span> else <span
class="math inline">\(e_2\)</span>" 的代码解析为它被写成的样子。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="type">Term</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Lit</span> (value: <span class="type">Int</span>)                 <span class="comment">// as in: 27</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Var</span> (name: <span class="type">String</span>)              <span class="comment">// as in: x</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Lam</span> (name: <span class="type">String</span>, rhs: <span class="type">Term</span>)  <span class="comment">// as in: λx. t</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">App</span> (lhs: <span class="type">Term</span>, rhs: <span class="type">Term</span>)     <span class="comment">// as in: s t</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Rcd</span> (fields: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Term</span>)]) <span class="comment">// as in: &#123;a: 0; b: true; ...&#125;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Sel</span> (receiver: <span class="type">Term</span>, fieldName: <span class="type">String</span>) <span class="comment">// as in: t.a</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Let</span> (isRec: <span class="type">Boolean</span>, name: <span class="type">String</span>, rhs: <span class="type">Term</span>, body: <span class="type">Term</span>) &#125;</span><br></pre></td></tr></table></figure>
<p>Fig. 4. Scala syntax for MLsub terms (using the <code>enum</code>¹⁰
keyword for defining algebraic data types).</p>
<p>图 4. Scala 语法用于 MLsub 术语（使用 <code>enum</code>¹⁰
关键字定义代数数据类型）。</p>
<p>“ <span class="math inline">\(\text{if } e_0 e_1 e_2\)</span> ,” and
we perform type checking starting from a context which assigns to the
‘if’ identifier the type <span class="math inline">\(\forall
\alpha\)</span>. <span class="math inline">\(bool \to \alpha \to \alpha
\to \alpha\)</span>.<a href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a></p>
<p>“ <span class="math inline">\(\text{if } e_0 e_1 e_2\)</span>
，”并且我们从一个上下文开始进行类型检查，该上下文将 'if'
标识符分配类型为 <span class="math inline">\(\forall \alpha\)</span>.
<span class="math inline">\(bool \to \alpha \to \alpha \to
\alpha\)</span>.<a href="#fn18" class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="type">SimpleType</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Variable</span> (st: <span class="type">VariableState</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Primitive</span> (name: <span class="type">String</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Function</span> (lhs: <span class="type">SimpleType</span>, rhs: <span class="type">SimpleType</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Record</span> (fields: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">SimpleType</span>)])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="type-syntax.">3.1.2 Type Syntax.</h3>
<h3 id="类型语法">3.1.2 类型语法。</h3>
<p>We start from the realization that union, intersection, top, bottom,
and recursive types are all not really core to the type inference
approach. Therefore, we focus on type variables, basic type constructors
(primitive types), function types, and record types as the cornerstone
of the algorithm. Their Scala syntax is shown above.</p>
<p>我们从意识到联合、交集、上界、下界和递归类型实际上并不是类型推断方法的核心开始。因此，我们将焦点放在类型变量、基本类型构造（原始类型）、函数类型和结构体类型上，作为算法的基石。它们的
Scala 语法如上所示。</p>
<p>The state of a type variable is simply given by all the bounds that
are recorded for it:</p>
<p>类型变量的状态仅由为其记录的所有约束给出：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VariableState</span>(<span class="params">var lowerBounds: <span class="type">List</span>&lt;<span class="type">SimpleType</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">    var upperBounds: <span class="type">List</span>&lt;<span class="type">SimpleType</span>&gt;</span>)</span></span><br></pre></td></tr></table></figure>
<p>Notice that we use mutable variables (<code>var</code> instead of
<code>val</code>) in order to hold the current state of the algorithm —
these lists will be mutated as the algorithm proceeds.</p>
<p>请注意，我们使用可变变量（<code>var</code> 而非
<code>val</code>）来保持算法的当前状态——这些列表将在算法进行过程中被修改。</p>
<p>All we need to do in order to perform type inference now is to find
all subtyping constraints entailed by a given program, and to propagate
these constraints until they reach type variables, which we can
constrain by mutating their recorded bounds.</p>
<p>为了执行类型推断，我们现在需要做的就是找到给定程序所涉及的所有子类型约束，并传播这些约束，直到它们达到类型变量，然后我们可以通过修改其记录的约束来限制它们。</p>
<h2 id="basic-type-inference">3.2 Basic Type Inference</h2>
<h2 id="基本类型推断">3.2 基本类型推断</h2>
<h3 id="typing.">3.2.1 Typing.</h3>
<h3 id="类型推断">3.2.1 类型推断。</h3>
<p>The core function for type inference is <code>typeTerm</code>, which
assigns a type to a given term in some context of type <code>Ctx</code>;
it is complemented by a <code>constrain</code> function to imperatively
constrain one type to be a subtype of another, raising an error if that
is not possible:</p>
<p>类型推断的核心功能是 <code>typeTerm</code>，它在某个类型为
<code>Ctx</code> 的上下文中为给定的术语分配类型；它由一个
<code>constrain</code>
函数补充，该函数用于强制一个类型是另一个类型的子类型，如果不可能，则抛出错误：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">Ctx</span> </span>= <span class="type">Map</span> <span class="type">String</span>, <span class="type">SimpleType</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">typeTerm</span></span>(term: <span class="type">Term</span>)(<span class="keyword">implicit</span> ctx: <span class="type">Ctx</span>): <span class="type">SimpleType</span> = ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">constrain</span></span>(lhs: <span class="type">SimpleType</span>, rhs: <span class="type">SimpleType</span>): <span class="type">Unit</span> = ...</span><br></pre></td></tr></table></figure>
<p>Above, we made the <code>ctx</code> parameter in
<code>typeTerm</code> implicit so it does not have to be passed
explicitly into each recursive call if it does not change.</p>
<p>在上面，我们将 <code>typeTerm</code> 中的 <code>ctx</code>
参数设为隐式的，这样如果它不变，就不必在每个递归调用中显式传入。</p>
<p>We make use of two small helper functions, <code>freshVar</code> and
<code>err</code>, to generate new type variables and raise errors,
respectively:</p>
<p>我们使用两个小辅助函数 <code>freshVar</code> 和
<code>err</code>，分别用于生成新的类型变量和引发错误：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">freshVar</span></span>: <span class="type">Variable</span> =</span><br><span class="line">    <span class="type">Variable</span>(<span class="keyword">new</span> <span class="type">VariableState</span>(<span class="type">Nil</span>, <span class="type">Nil</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">err</span></span>(msg: <span class="type">String</span>): <span class="type">Nothing</span> =</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">Exception</span>(<span class="string">&quot;type error: &quot;</span> + msg)</span><br></pre></td></tr></table></figure>
<p>Remember that <code>VariableState</code> is a class and not a case
class (also called <em>data class</em>). This means that each
<code>VariableState</code> instance, created with <code>new</code>, is
unique and distinct from other instances.</p>
<p>请记住，<code>VariableState</code> 是一个类，不是一个案例类（也称为
<em>data class</em>）。这意味着每个通过 <code>new</code> 创建的
<code>VariableState</code> 实例都是唯一的，与其他实例不同。</p>
<p>Now that we have established the necessary premises, we can start
writing the core of the basic type inference algorithm:</p>
<p>现在我们已经建立了必要的前提，我们可以开始编写基本类型推断算法的核心部分：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">typeTerm</span></span>(term: <span class="type">Term</span>)(<span class="keyword">implicit</span> ctx: <span class="type">Ctx</span>): <span class="type">SimpleType</span> = term <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="comment">// integer literals:</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Lit</span>(n) =&gt; <span class="type">Primitive</span>(<span class="string">&quot;int&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Below, the <code>ctx.getOrElse(k, t)</code> function is used to
access the <code>ctx</code> map at a given key <code>k</code>,
specifying a chunk <code>t</code> to execute in case that key is not
found:</p>
<p>下面，<code>ctx.getOrElse(k, t)</code> 函数用于在给定键
<code>k</code> 的 <code>ctx</code>
映射中访问，指定在未找到该键的情况下执行的代码块 <code>t</code>：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// variable references:</span></span><br><span class="line"><span class="keyword">case</span> <span class="type">Var</span>(name) =&gt; ctx.getOrElse(name, err(<span class="string">&quot;not found: &quot;</span> + name))</span><br><span class="line"></span><br><span class="line"><span class="comment">// record creations:</span></span><br><span class="line"><span class="keyword">case</span> <span class="type">Rcd</span>(fs) =&gt; <span class="type">Record</span>(fs.map &#123; <span class="keyword">case</span> (n, t) =&gt; (n, typeTerm(t)) &#125;)</span><br></pre></td></tr></table></figure>
<p>In order to type a lambda abstraction, we create a fresh variable to
represent the parameter type, and we type the body of the lambda in the
current context extended with a binding for this parameter, where
<code>name -&gt; param</code> is another syntax for the pair
<code>(name, param)</code>:</p>
<p>为了为一个 lambda
抽象指定类型，我们创建一个新的变量来表示参数类型，并在当前上下文中使用该参数的绑定类型化
lambda 的主体，其中 <code>name -&gt; param</code> 是对配对
<code>(name, param)</code> 的另一种语法：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// lambda abstractions:</span></span><br><span class="line"><span class="keyword">case</span> <span class="type">Lam</span>(name, body) =&gt;</span><br><span class="line">  <span class="keyword">val</span> param = freshVar</span><br><span class="line">  <span class="type">Function</span>(param, typeTerm(body)(ctx + (name -&gt; param)))</span><br></pre></td></tr></table></figure>
<p>To type applications, we similarly introduce a fresh variable
standing for the result type of the function that we are applying:</p>
<p>为了分析函数调用的类型，我们同样引入一个新变量，表示我们正在调用的函数的结果类型：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// applications:</span></span><br><span class="line"><span class="keyword">case</span> <span class="type">App</span>(f, a) =&gt;</span><br><span class="line">  <span class="keyword">val</span> res = freshVar</span><br><span class="line">  constrain(typeTerm(f), <span class="type">Function</span>(typeTerm(a), res))</span><br><span class="line">  res</span><br></pre></td></tr></table></figure>
<p>Finally, record accesses result in a constraint that the receiver on
the left-hand side of the selection is a record type with the
appropriate field name:</p>
<p>最后，结构体访问导致了一个约束，要求选择左侧的接收是具有适当字段名称的结构体类型：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// record field selections:</span></span><br><span class="line"><span class="keyword">case</span> <span class="type">Sel</span>(obj, name) =&gt;</span><br><span class="line">  <span class="keyword">val</span> res = freshVar</span><br><span class="line">  constrain(typeTerm(obj), <span class="type">Record</span>((name -&gt; res) :: <span class="type">Nil</span>))</span><br><span class="line">  res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>As one can observe, the basic MLsub type inference algorithm so far
is quite similar to the traditional algorithm W for HM-style type
inference.</p>
<p>如可以观察到的，基本的 MLsub 类型推断算法到目前为止与传统的算法 W 在
HM 风格的类型推断中非常相似。</p>
<h3 id="constraining">3.2.2 Constraining</h3>
<h3 id="约束">3.2.2 约束</h3>
<p>The first thing to diverge from algorithm W is the handling of
constraints.</p>
<p>第一个与算法 W 不同的地方是约束的处理。</p>
<p>First, note that type variable bounds, which are updated using
mutation, may very well begin to form cycles as type inference
progresses. We have to account for this by using a cache parameter
(initially empty) which remembers all the type comparisons that have
been or are being made. This not only prevents us from falling into
infinite recursion, but also avoids repeating identical work (i.e.,
solving some of the sub-constraints more than once), which is important
to avoid making the algorithm exponential in complexity [Pierce 2002,
Chapter 21.10].</p>
<p>首先，请注意，随着类型推断的进行，使用变异更新的类型变量边界很可能开始形成循环。我们必须通过使用一个缓存参数（初始为空）来考虑这一点，该参数记住所有已进行或正在进行的类型比较。这不仅可以防止我们陷入无限递归，还可以避免重复相同的工作（即，对某些子约束的求解进行多次），这对于避免使算法的复杂性变为指数级是很重要的
[Pierce 2002, Chapter 21.10]。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">constrain</span></span>(lhs: <span class="type">SimpleType</span>, rhs: <span class="type">SimpleType</span>)</span><br><span class="line">    (<span class="keyword">implicit</span> cache: <span class="type">MutSet</span>[(<span class="type">SimpleType</span>, <span class="type">SimpleType</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">if</span> (cache.contains(lhs -&gt; rhs)) <span class="keyword">return</span> () <span class="keyword">else</span> cache += rhs -&gt; rhs</span><br></pre></td></tr></table></figure>
<p>The next step is to match each possible pair of basic types which can
be constrained successfully, and propagate the constraints
accordingly:</p>
<p>下一步是匹配每对可以成功约束的基本类型，并相应地传播约束：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">(lhs, rhs) <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> (<span class="type">Primitive</span>(n0), <span class="type">Primitive</span>(n1)) <span class="keyword">if</span> n0 == n1 =&gt;</span><br><span class="line">    () <span class="comment">// nothing to do</span></span><br><span class="line">  <span class="keyword">case</span> (<span class="type">Function</span>(l0, r0), <span class="type">Function</span>(l1, r1)) =&gt;</span><br><span class="line">    constrain(l1, l0); constrain(r0, r1)</span><br><span class="line">  <span class="keyword">case</span> (<span class="type">Record</span>(fs0), <span class="type">Record</span>(fs1)) =&gt;</span><br><span class="line">    fs1 foreach &#123; <span class="keyword">case</span> (n1, t1) =&gt;</span><br><span class="line">      fs0.find(_._1 == n1) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt; err(<span class="string">&quot;missing field: &quot;</span> + n1 + <span class="string">&quot; in &quot;</span> + lhs)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>((_, t0)) =&gt; constrain(t0, t1) &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Function types are constrained according to the usual rules of
contra- and co-variance of parameter and result types (respectively),
and record types according to the usual width and depth subtyping.</p>
<p>Function
类型根据参数和结果类型（分别）的协变和反变的常规规则进行约束，而结构体类型则根据常规的宽度和深度子类型进行约束。</p>
<p>The case for type variables appearing on the left- or right-hand side
is interesting, as this is when we finally mutate the bounds of
variables. Crucially, after adding the corresponding upper or lower
bound to the variable state, we need to iterate<a href="#fn19"
class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>
over the existing opposite bounds of the variable being constrained, in
order to make sure that they become consistent with the new bound:</p>
<p>在左侧或右侧出现的类型变量的情况是有趣的，因为这时我们最终改变变量的边界。至关重要的是，在将相应的上界或下界添加到变量状态后，我们需要遍历<a
href="#fn20" class="footnote-ref" id="fnref20"
role="doc-noteref"><sup>20</sup></a>已存在的与约束变量相对的边界，以确保它们与新的边界保持一致：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> (<span class="type">Variable</span>(lhs), rhs) =&gt;</span><br><span class="line">  lhs.upperBounds = rhs :: lhs.upperBounds</span><br><span class="line">  lhs.lowerBounds foreach(constrain_, rhs))</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> (lhs, <span class="type">Variable</span>(rhs)) =&gt;</span><br><span class="line">  rhs.lowerBounds = lhs :: rhs.lowerBounds</span><br><span class="line">  rhs.upperBounds foreach(constrain(lhs, _))</span><br></pre></td></tr></table></figure>
<p>Note that there is something deeply non-trivial happening here: we
install the new upper bound <code>rhs</code> before recursing into the
<code>lhs.lowerBounds</code>. This turns out to be essential — without
it, recursive constraining calls which would get back to
<code>lhs</code> would miss this new upper bound, failing to constrain
it. Another subtlety is that <em>new bounds</em> may very well appear in
<code>lhs.upperBounds</code> and <code>lhs.lowerBounds</code> while we
are recursing. This subtlety is briefly discussed further in Section
5.3.1.</p>
<p>注意，这里发生了一些深刻的非平凡的事情：我们在递归进入
<code>lhs.lowerBounds</code> 之前安装新的上界
<code>rhs</code>。这被证明是至关重要的——如果没有它，递归约束调用将会返回到
<code>lhs</code>
时会错过这个新的上界，从而无法对其进行约束。另一个微妙之处是，在我们递归期间，<em>新的界限</em>很可能会出现在
<code>lhs.upperBounds</code> 和 <code>lhs.lowerBounds</code>
中。这个微妙之处在第 5.3.1 节中有所简要讨论。</p>
<p>Finally, if all other options have failed, we report an error that
the two types cannot be constrained:</p>
<p>最后，如果所有其他选项都失败了，我们报告一个错误，说明这两种类型无法被约束：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> _ =&gt; err(<span class="string">&quot;cannot constrain &quot;</span> + lhs + <span class="string">&quot; &lt;: &quot;</span> + rhs)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In this subsection, we saw the core of the Simple-sub type inference
algorithm, which distills what we argue is the “simple essence” of
Dolan’s type inference approach. However, we are not quite done yet. We
still need to produce user-readable type representations (next section)
and to support polymorphism and recursion through let bindings (Section
3.5).</p>
<p>在这一小节中，我们看到了简易子类型推断算法的核心，这提炼了我们认为是Dolan类型推断方法的“简单本质”。然而，我们尚未完成。我们仍需生成用户可读的类型表示（下一节）并通过let绑定支持多态和递归（第3.5节）。</p>
<h2 id="user-facing-types-representations">3.3 User-Facing Types
Representations</h2>
<h2 id="面向用户的类型表示">3.3 面向用户的类型表示</h2>
<p><em>Where did union, intersection, top, bottom, and recursive types
go?</em></p>
<p><em>并集、交集、顶、底和递归类型去哪儿了？</em></p>
<p>It turns out these are not really core to the type inference
approach, and are more like emergent properties of type pretty-printing
and simplification. They only come up once we try to display friendly
type expressions to users, after type inference has done the gist of its
job.</p>
<p>事实证明，这些并不是类型推断方法的核心，更像是类型美观打印和简化的涌现属性。它们在我们尝试向用户展示友好的类型表达式时才会出现，在类型推断完成其核心工作之后。</p>
<p>3.3.1 Constraining <em>Type Variables Indirectly</em>. Remember that
we have been constraining type variables, but that type variable
constraints are not part of the syntax that MLsub and Simple-sub are
supposed to output. The “trick” is to indirectly encode these
constraints through the use of union and intersection types (recall the
examples given in Section 2.3.1).</p>
<p>3.3.1
间接约束<em>类型变量</em>。请记住，我们一直在约束类型变量，但类型变量约束并不是MLsub和Simple-sub应该输出的语法的一部分。“技巧”在于通过使用并集和交集类型间接编码这些约束（回忆第2.3.1节中给出的例子）。</p>
<p>3.3.2 <em>Targeted Type Syntax.</em> In order to produce
user-friendly type representations in the tradition of MLsub, we target
the type syntax tree presented in Figure 5.</p>
<p>3.3.2 <em>目标类型语法.</em>
为了生成符合用户友好的类型表示，遵循MLsub的传统，我们的目标是图5中呈现的类型语法树。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="type">Type</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Top</span></span><br><span class="line">  <span class="keyword">case</span> <span class="type">Bot</span></span><br><span class="line">  <span class="keyword">case</span> <span class="type">Union</span> (lhs: <span class="type">Type</span>, rhs: <span class="type">Type</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Inter</span> (lhs: <span class="type">Type</span>, rhs: <span class="type">Type</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">FunctionType</span> (lhs: <span class="type">Type</span>, rhs: <span class="type">Type</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">RecordType</span>   (fields: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Type</span>)])</span><br><span class="line">  <span class="keyword">case</span> <span class="type">RecursiveType</span> (name: <span class="type">String</span>, body: <span class="type">Type</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">TypeVariable</span>  (name: <span class="type">String</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">PrimitiveType</span> (name: <span class="type">String</span>) &#125;</span><br></pre></td></tr></table></figure>
<p>Fig. 5. The type syntax targeted as the end result of type
inference.</p>
<p>图5. 作为类型推断最终结果的目标类型语法。</p>
<p>3.3.3 <em>Type Coalescing Algorithm.</em> In order to produce
immutable <em>Type</em> values from our inferred <em>SimpleType</em>
internal representation, we need to go through a process we refer to as
<em>type coalescing</em>, whose goal is to replace the positive
occurrences of <em>type</em> variables with a union of their lower
bounds, and their negative occurrences with an intersection of their
upper bounds.</p>
<p>3.3.3 <em>类型聚合算法.</em>
为了从我们推断的<em>SimpleType</em>内部表示中生成不可变的<em>Type</em>值，我们需要经历一个我们称之为<em>类型聚合（type
coalescing）</em>的过程，其目标是用其下界的并集替换类型变量的正出现，用其上界的交集替换负出现。</p>
<p>We define a <em>PolarVariable</em> type synonym which associates a
<em>type variable</em> state with a <em>polarity</em>. The algorithm
starts by initializing an empty mutable map called <em>recursive</em>,
whose goal is to remember which <em>type variables</em> refer to
themselves through their bounds, assigning them a fresh type variable
which will be used when constructing the corresponding
<em>RecursiveType</em> value:</p>
<p>我们定义了一个 <em>PolarVariable</em> 类型同义词，它将
<em>类型变量</em> 状态与 <em>极性</em>
关联起来。算法首先初始化一个空的可变映射
<em>recursive</em>，其目的是记住哪些 <em>类型变量</em>
通过它们的边界引用自身，并为它们分配一个新的类型变量，该变量将在构造相应的
<em>RecursiveType</em> 值时使用：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">PolarVariable</span> </span>= (<span class="type">VariableState</span>, <span class="type">Boolean</span>) <span class="comment">// &#x27;true&#x27; means &#x27;positive&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">coalesceType</span></span>(ty: <span class="type">SimpleType</span>): <span class="type">Type</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> recursive: <span class="type">MutMap</span>[<span class="type">PolarVariable</span>, <span class="type">String</span>] = <span class="type">MutMap</span>.empty</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The (VariableState, Boolean) keys of the recursive map include the
polarity in the right-hand side to make sure we produce only
<em>polar</em> recursive types (those whose variables occur with the
same polarity as the types themselves); this turns out to be necessary
for principality [Dolan 2017].</p>
<p>递归映射的 (VariableState, Boolean)
键在右侧包含极性，以确保我们只生成 <em>polar</em>
递归类型（这些类型的变量与类型本身的极性相同）；这被证明对于首要性是必要的
[Dolan 2017]。</p>
<p>Then, we define a worker function go which calls itself recursively
in a straightforward manner, but makes sure to keep track of the type
variables that are currently being coalesced, and to keep track of the
current polarity — whether we are coalescing a positive (polar == true)
or negative (polar == false) type position:</p>
<p>然后，我们定义一个工作函数
go，它以直接的方式递归调用自身，但确保跟踪当前正在聚合的类型变量，以及跟踪当前极性——我们是聚合正类型
(polar == true) 还是负类型 (polar == false) 的位置：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">go</span></span>(ty: <span class="type">SimpleType</span>, polar: <span class="type">Boolean</span>)(inProcess: <span class="type">Set</span>[<span class="type">PolarVariable</span>]): <span class="type">Type</span></span><br><span class="line">    = ty <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Primitive</span>(n) =&gt; <span class="type">PrimitiveType</span>(n)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Function</span>(l, r) =&gt;</span><br><span class="line">        <span class="type">FunctionType</span>(go(l, !polar)(inProcess), go(r, polar)(inProcess))</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Record</span>(fs) =&gt;</span><br><span class="line">        <span class="type">RecordType</span>(fs.map(nt =&gt; nt._1 -&gt; go(nt._2, polar)(inProcess)))</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>The interesting case is the following.<a href="#fn21"
class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>
In the code below, <code>vs.uniqueName</code>, is an attribute defined
in the <code>VariableState</code> class, which holds a name unique to
<code>vs</code>.</p>
<p>有趣的情况如下。<a href="#fn22" class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a>
在下面的代码中，<code>vs.uniqueName</code> 是在
<code>VariableState</code> 类中定义的一个属性，它保存一个对
<code>vs</code> 唯一的名称。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">Variable</span>(vs) =&gt;</span><br><span class="line">    <span class="keyword">val</span> vs_pol = vs -&gt; polar</span><br><span class="line">    <span class="keyword">if</span> (inProcessamilates(vs_pol))</span><br><span class="line">        <span class="type">TypeVariable</span>(recursive.get lub <span class="keyword">else</span> <span class="type">Update</span>(vs_pol, freshVar.uniqueName))</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> bounds = <span class="keyword">if</span> (polar) vs.lowerBounds <span class="keyword">else</span> vs.upperBounds</span><br><span class="line">        <span class="keyword">val</span> boundTypes = bounds.map(go_, polar)(inProcess + vs_pol))</span><br><span class="line">        <span class="keyword">val</span> mrg = <span class="keyword">if</span> (polar) <span class="type">Union</span> <span class="keyword">else</span> <span class="type">Inter</span></span><br><span class="line">        <span class="keyword">val</span> res = boundTypes.foldLeft(<span class="type">TypeVariable</span>(vs.uniqueName))(mrg)</span><br><span class="line">        recursive.get (vs_pol).fold (res) (<span class="type">RecursiveType_</span>, res))</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>We first check whether the variable is already being coalesced. If it
is, we look up the 'recursive' map: if this map already contains an
entry for the variable, we simply return it; otherwise, we create a new
fresh <code>TypeVariable</code> and update the map using
<code>getOrElseUpdate</code>.</p>
<p>我们首先检查变量是否已经被聚合。如果是，我们查找"recursive"映射：如果该映射已经包含该变量的条目，我们直接返回；否则，我们创建一个新的
<code>TypeVariable</code> 并使用 <code>getOrElseUpdate</code>
更新映射。</p>
<p>If we are not coalescing a recursive variable occurrence, we look
into the bounds of the variable. Depending on the current polarity, we
recurse into the lower or upper bounds. Then, if the recursive map now
contains an entry for the variable, it means the variable was recursive.
In this case, we wrap the result in RecursiveType with the variable
found in the map.</p>
<p>如果我们不是在聚合一个递归变量的出现，我们将查看变量的界限。根据当前的极性，我们递归进入下限或上限。然后，如果递归映射现在包含该变量的条目，这意味着该变量是递归的。在这种情况下，我们用在映射中找到的变量包装结果为
<code>RecursiveType</code>。</p>
<p>We conclude the algorithm by calling go on the top-level type ty with
an empty inProcess:</p>
<p>我们通过在顶级类型 ty 上调用 go 并传入一个空的 inProcess
来结束算法：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">go(ty, <span class="literal">true</span>)(<span class="type">Set</span>.empty)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>This algorithm does produce some unnecessary variables (variables
which could be removed to simplify the type expression); we see how to
simplify type representations in Section 4.</p>
<p>该算法确实会产生一些不必要的变量（可以通过去除这些变量来简化类型表达）；我们将在第4节中看到如何简化类型表示。</p>
<h2 id="examples">3.4 Examples</h2>
<h2 id="示例">3.4 示例</h2>
<p>Now is a good time to pause and exemplify some crucial aspects of
Simple-sub.</p>
<p>现在是暂停并举例说明 Simple-sub 的一些关键方面的好时机。</p>
<h3 id="recursive-types.-1">3.4.1 Recursive Types.</h3>
<h3 id="递归类型-1">3.4.1 递归类型。</h3>
<p>The reason for having recursive types in the user-facing type syntax
has now become quite obvious: we need them in order to “tie the knot”
when we are trying to coalesce type variables which appears in the
coalescence of their own bounds.</p>
<p>在用户可见的类型语法中引入递归类型的原因现在变得相当明显：我们需要它们来“打结”，当我们尝试将出现在自身边界的类型变量聚合时。</p>
<p>For instance, consider the possible inferred representation
<code>Function(Variable(s), Variable(t))</code>, where
<code>s = new VariableState(Nil, Nil)</code> and
<code>t = new VariableState(Nil, Function(Variable(s), Variable(t))) :: Nil</code>.
Notice that there is a cycle in the upper bounds of <code>t</code>;
therefore, the coalescing algorithm turns this <code>SimpleType</code>
representation into the user-facing type
<code>FunctionType(TypeVariable("s"), RecursiveType("t", FunctionType(TypeVariable("s"), TypeVariable("t"))))</code>,
which corresponds to <span class="math inline">\(\alpha \rightarrow
(\mu\beta.\alpha \rightarrow \beta)\)</span> (and which will then be
simplified to <span class="math inline">\(\tau \rightarrow
(\mu\alpha.\tau \rightarrow \alpha)\)</span>).</p>
<p>例如，考虑可能推断出的表示
<code>Function(Variable(s), Variable(t))</code>，其中
<code>s = new VariableState(Nil, Nil)</code> 和
<code>t = new VariableState(Nil, Function(Variable(s), Variable(t))) :: Nil</code>。注意
<code>t</code> 的上限中存在一个循环；因此，聚合算法将此
<code>SimpleType</code> 表示转换为用户可见的类型
<code>FunctionType(TypeVariable("s"), RecursiveType("t", FunctionType(TypeVariable("s"), TypeVariable("t"))))</code>，这对应于
<span class="math inline">\(\alpha \rightarrow (\mu\beta.\alpha
\rightarrow \beta)\)</span>（然后将简化为 <span
class="math inline">\(\tau \rightarrow (\mu\alpha.\tau \rightarrow
\alpha)\)</span>）。</p>
<h3 id="example-of-type-inference.">3.4.2 Example of Type
Inference.</h3>
<h3 id="类型推断的示例">3.4.2 类型推断的示例</h3>
<p>To facilitate our understanding of the typing and coalescing
algorithms, we now unroll the execution of a type inference run.
Consider the term twice = <span class="math inline">\(\lambda f. \lambda
x. f(f x)\)</span>, which takes a function <em>f</em> and some
<em>x</em> as parameters, and applies <em>f</em> twice on
<em>x</em>.</p>
<p>为了帮助我们理解类型和聚合算法，我们现在展开一次类型推断的执行过程。考虑项
twice = <span class="math inline">\(\lambda f. \lambda x. f(f
x)\)</span>，它以一个函数 <em>f</em> 和一些 <em>x</em> 作为参数，并在
<em>x</em> 上调用 <em>f</em> 两次。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">typeTerm(λx. λx. f (f x))(empty)</span><br><span class="line">| typeTerm(λx. f (f x))(Map(f ↦ α))  // α fresh</span><br><span class="line">|   typeTerm(f (f x))(Map(f ↦ α, x ↦ β))  // β fresh</span><br><span class="line">|     typeTerm(f)(Map(f ↦ α, x ↦ β)) = α</span><br><span class="line">|     typeTerm(f x)(Map(f ↦ α, x ↦ β))</span><br><span class="line">|       typeTerm(f)(Map(f ↦ α, x ↦ β)) = α</span><br><span class="line">|       typeTerm(x)(Map(f ↦ α, x ↦ β)) = β</span><br><span class="line">|       constrain(α, Function(β, γ))  // γ fresh</span><br><span class="line">|         α.upperBounds = Function(β, γ) :: α.upperBounds</span><br><span class="line">|       = γ</span><br><span class="line">|     constrain(α, Function(γ, δ))  // δ fresh</span><br><span class="line">|       α.upperBounds = Function(γ, δ) :: α.upperBounds</span><br><span class="line">|     = δ</span><br><span class="line">|   = Function(β, δ)</span><br><span class="line">= Function(α, Function(β, δ))</span><br></pre></td></tr></table></figure>
<p>After this process, we end up with two upper bounds on <span
class="math inline">\(\alpha\)</span>, namely
<code>Function(\beta, \gamma)</code> and
<code>Function(\gamma, \delta)</code>. We next see how the type
coalescing algorithm unrolls from this inferred <code>SimpleType</code>
representation. We omit the details of some of the less interesting
sub-executions, and by a slight abuse of notation we use <span
class="math inline">\(\alpha\)</span> to denote <span
class="math inline">\(\alpha.uniqueName\)</span>:</p>
<p>在这个过程中，我们得到两个对 <span
class="math inline">\(\alpha\)</span> 的上界，即
<code>Function(\beta, \gamma)</code> 和
<code>Function(\gamma, \delta)</code>。接下来，我们将看到类型聚合算法如何从这个推断的
<code>SimpleType</code>
表示中展开。我们省略一些不太有趣的子执行的细节，并通过轻微的符号滥用使用
<span class="math inline">\(\alpha\)</span> 来表示 <span
class="math inline">\(\alpha.uniqueName\)</span>：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">coalesceType(function(α, function(β, δ)))</span><br><span class="line">  go(function(α, function(β, δ)), <span class="literal">true</span>)(empty)</span><br><span class="line">    go(α, <span class="literal">false</span>)(empty)</span><br><span class="line">    <span class="keyword">val</span> bounds = function(β, γ) :: function(γ, δ) :: <span class="type">Nil</span></span><br><span class="line">    <span class="keyword">val</span> boundTypes</span><br><span class="line">      go(function(β, γ), <span class="literal">false</span>)(<span class="type">Set</span>(α ↦ <span class="literal">false</span>)) = β → γ</span><br><span class="line">      go(function(γ, δ), <span class="literal">false</span>)(<span class="type">Set</span>(α ↦ <span class="literal">false</span>)) = γ → δ</span><br><span class="line">    = β → γ :: γ → δ :: <span class="type">Nil</span></span><br><span class="line">    = α ∩ (β → γ) ∩ (γ → δ)</span><br><span class="line">  go(function(β, δ), <span class="literal">true</span>)(empty)</span><br><span class="line">    go(β, <span class="literal">false</span>)(empty) = β</span><br><span class="line">    go(δ, <span class="literal">true</span>)(empty) = δ</span><br><span class="line">    = β → δ</span><br><span class="line">    = α ∩ (β → γ) ∩ (γ → δ) → β → δ</span><br><span class="line">    = α ∩ (β → γ) ∩ (γ → δ) → β → δ</span><br></pre></td></tr></table></figure>
<p>Finally, we will see in Section 4 that this type can be compacted to
<span class="math inline">\(\alpha \sqcap (\beta \sqcup \gamma
\rightarrow \gamma \sqcap \delta) \rightarrow \beta \rightarrow
\delta\)</span>, and then simplified to <span
class="math inline">\((\beta \sqcup \gamma \rightarrow \gamma)
\rightarrow \beta \rightarrow \gamma\)</span>, since <span
class="math inline">\(\alpha\)</span> occurs only negatively (thus can
be removed) and <span class="math inline">\(\delta\)</span> and <span
class="math inline">\(\gamma\)</span> co-occur negatively (thus can be
merged into a single variable).</p>
<p>最后，我们将在第4节看到，这种类型可以压缩为 <span
class="math inline">\(\alpha \sqcap (\beta \sqcup \gamma \rightarrow
\gamma \sqcap \delta) \rightarrow \beta \rightarrow
\delta\)</span>，然后简化为 <span class="math inline">\((\beta \sqcup
\gamma \rightarrow \gamma) \rightarrow \beta \rightarrow
\gamma\)</span>，因为 <span class="math inline">\(\alpha\)</span>
仅以负面形式出现（因此可以被移除），而 <span
class="math inline">\(\delta\)</span> 和 <span
class="math inline">\(\gamma\)</span>
在负面形式中共现（因此可以合并为一个变量）。</p>
<h2 id="let-polymorphism-and-recursion">3.5 Let Polymorphism and
Recursion</h2>
<h2 id="let多态性和递归">3.5 Let多态性和递归</h2>
<h3 id="let-polymorphism.">3.5.1 Let Polymorphism.</h3>
<h3 id="let多态性">3.5.1 Let多态性。</h3>
<p>In traditional ML languages, local let bindings may be assigned
polymorphic types. This requires keeping track of generalized <em>typing
schemes</em> which are to be <em>instantiated</em> with fresh variables
on every use, and making sure that we are not generalizing those type
variables which occur in the environment, which would be unsound.</p>
<p>在传统的 ML 语言中，局部 let 绑定可以被赋予多态类型。这需要跟踪广义
<em>类型方案</em>，这些方案将在每次使用时用新变量
<em>实例化</em>，并确保我们不对环境中出现的类型变量进行泛化，这将是不安全的。</p>
<p>One way of determining which type variables to generalize is to scan
the current environment, looking for references to the type variables in
question. However, that is quite inefficient (it adds a linear-time
operation in an important part of the algorithm).</p>
<p>确定哪些类型变量需要泛化的一种方法是扫描当前环境，寻找对相关类型变量的引用。然而，这种方法效率相当低下（它在算法的一个重要部分增加了线性时间操作）。</p>
<p><em>Efficient generalization in ML.</em> A better approach is to use
levels. The idea is that all fresh type variables created inside the
right-hand side of a let binding are first assigned a higher level,
which indicates that they should be generalized. However, the level of a
variable is lowered when the variable “escapes” through a constraint
into the enclosing environment, preventing its future generalization
(see the web article by Kiselyov [2013] for an excellent resource on the
subject).</p>
<p><em>高效的ML泛型。</em>
一种更好的方法是使用级别（levels）。这个想法是，在let绑定的右侧创建的所有新类型变量首先被分配一个更高的级别，这表明它们应该被泛化。然而，当变量通过约束“逃逸”到封闭环境中时，变量的级别会降低，从而防止其未来的泛化（参见Kiselyov
[2013] 的网络文章，这是一个关于该主题的优秀资源）。</p>
<p><em>Simple-sub typing with levels.</em> We can use the same idea to
achieve let polymorphism in Simple-sub, though we have to be a little
more careful, because we do not merely <em>unify</em> type variables as
in ML, but instead we constrain their bounds. Our idea is to make sure
that lower-level type variables never refer to higher-level ones through
their bounds, and to enforce that property by duplicating type
structures as needed, when it would otherwise be violated by the
addition of a bound.</p>
<p><em>带级别的简单子类型。</em>
我们可以使用相同的想法在Simple-sub中实现let多态，尽管我们必须更加小心，因为我们并不仅仅像在ML中那样“合并（Unify）”类型变量，而是约束它们的边界。我们的想法是确保低级别的类型变量通过它们的边界
never
引用高级别的类型变量，并在需要时通过复制类型结构来强制执行该属性，以防止由于添加约束而违反该属性。</p>
<p>We first need to add a <code>lvl</code> field to type variable
states:</p>
<p>我们首先需要向类型变量状态添加一个<code>lvl</code>字段：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VariableState</span>(<span class="params">val level: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">  var lowerBounds: <span class="type">List</span>[<span class="type">SimpleType</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">  var upperBounds: <span class="type">List</span>[<span class="type">SimpleType</span>]</span>)</span></span><br></pre></td></tr></table></figure>
<p>and to update <code>freshVar</code> correspondingly:</p>
<p>并相应地更新 <code>freshVar</code>：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">freshVar</span></span>(<span class="keyword">implicit</span> lvl: <span class="type">Int</span>): <span class="type">Variable</span> =</span><br><span class="line">    <span class="type">Variable</span>(<span class="keyword">new</span> <span class="type">VariableState</span>(lvl, <span class="type">Nil</span>, <span class="type">Nil</span>))</span><br></pre></td></tr></table></figure>
<p>Next, we add an implicit <code>lvl</code> parameter to the
<code>typeTerm</code> function, and we make sure to type the right-hand
sides of let bindings with a higher level than the current one:</p>
<p>接下来，我们在 <code>typeTerm</code> 函数中添加一个隐式的
<code>lvl</code> 参数，并确保让绑定的右侧类型使用比当前高的级别：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">typeTerm</span></span>(trm: <span class="type">Term</span>)(<span class="keyword">implicit</span> ctx: <span class="type">Ctx</span>, lvl: <span class="type">Int</span>): <span class="type">SimpleType</span> = trm <span class="keyword">match</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// non-recursive let bindings:</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Let</span>(<span class="literal">false</span>, nme, rhs, bod) =&gt;</span><br><span class="line">        <span class="keyword">val</span> rhsTy = typeTerm(rhs)(ctx, lvl + <span class="number">1</span>) <span class="comment">// incremented level!</span></span><br><span class="line">        typeTerm(bod)(ctx + (nme =&gt; <span class="type">PolyMorphicType</span>(lvl, rhs_ty)), lvl)</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Notice that in the context used to type the body of the let binding,
we wrap the right-hand side type into a <code>PolymorphicType</code>
wrapper, which is defined at the end of Figure 6. A polymorphic type
wraps a simple type body, but additionally remembers above which level
the type variables that appear in body are to be considered universally
quantified. Its <code>in instances</code> method copies body, replacing
the type variables above level with fresh variables at level
<code>lvl</code> (a task performed by <code>freshenAbove</code>, whose
implementation is too boring to warrant taking space in this paper).</p>
<p>请注意，在用于输入 let 绑定主体的上下文中，我们将右侧的类型包装在
<code>PolymorphicType</code> 包装器中，该包装器在图 6
的末尾定义。多态类型包装一个简单类型主体，但额外记住在主体中出现的类型变量应被视为普遍量化的级别。它的
<code>in instances</code> 方法复制主体，替换级别以上的类型变量为级别
<code>lvl</code> 的新变量（这项任务由 <code>freshenAbove</code>
执行，其实现过于无聊，不值得在本文中占用空间）。</p>
<p>In order to make <code>PolymorphicType</code> and
<code>SimpleType</code> type-compatible, we create a common base trait<a
href="#fn23" class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a> <em>TypeScheme</em>, as shown in
Figure 6. This trait contains two abstract methods: one to instantiate
the type at a given level, and one to compute the level of the type. The
latter is implemented in <code>SimpleType</code> by a field which is
lazily evaluated, to avoid needless recomputation; this field is used to
remember the maximum level of any type variables contained in the
type.</p>
<p>为了使 <code>PolymorphicType</code> 和 <code>SimpleType</code>
类型兼容，我们创建一个共同的基类特 trait<a href="#fn24"
class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a>
<em>TypeScheme</em>，如图 6
所示。该特含有两个抽象方法：一个用于在给定级别实例化类型，一个用于计算类型的级别。后者在
<code>SimpleType</code>
中通过一个懒惰求值的字段实现，以避免不必要的重新计算；该字段用于记住类型中包含的任何类型变量的最大级别。</p>
<p>Finally, we adapt <code>typeTerm</code> to instantiate the types
associated with variable names in <code>ctx</code>:</p>
<p>最后，我们调整 <code>typeTerm</code> 以实例化与 <code>ctx</code>
中变量名相关联的类型：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">Ctx</span> </span>= <span class="type">Map</span>[<span class="type">String</span>, <span class="type">TypeScheme</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">typeTerm</span></span>(trm: <span class="type">Term</span>)(<span class="keyword">implicit</span> ctx: <span class="type">Ctx</span>, lvl: <span class="type">Int</span>): <span class="type">SimpleType</span> = trm <span class="keyword">match</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Var</span>(name) =&gt;</span><br><span class="line">        ctx.getOrElse(name, err(<span class="string">&quot;not found: &quot;</span> + name)).instantiate</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">sealed</span> <span class="class"><span class="keyword">trait</span> <span class="title">TypeScheme</span> </span>&#123;</span><br><span class="line">  <span class="comment">// to be implemented in SimpleType and TypeScheme:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">instantiate</span></span>(<span class="keyword">implicit</span> lvl: <span class="type">Int</span>): <span class="type">SimpleType</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">level</span></span>: <span class="type">Int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="type">SimpleType</span> <span class="keyword">extends</span> <span class="type">TypeScheme</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Variable</span>(s: <span class="type">VariableState</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Primitive</span>(name: <span class="type">String</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Function</span>(lhs: <span class="type">SimpleType</span>, rhs: <span class="type">SimpleType</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Record</span>(fields: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">SimpleType</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment">// the following members are required to implement TypeScheme:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">instantiate</span></span>(<span class="keyword">implicit</span> lvl: <span class="type">Int</span>) = <span class="keyword">this</span></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> level = <span class="keyword">this</span> <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Function</span>(lhs, rhs) =&gt; max(lhs.level, rhs.level)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Record</span>(fields)     =&gt; fields.map(_._2.level).maxOption.getOrElse(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Variable</span>(vs)       =&gt; vs.level</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Primitive</span>(_)       =&gt; <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">PolymorphicType</span>(<span class="params">level: <span class="type">Int</span>, body: <span class="type">SimpleType</span></span>) <span class="keyword">extends</span> <span class="title">TypeScheme</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">instantiate</span></span>(<span class="keyword">implicit</span> lvl: <span class="type">Int</span>) = freshenAbove(body, level)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VariableState</span>(<span class="params">val level: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                    var lowerBounds: <span class="type">List</span>[<span class="type">SimpleType</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">                    var upperBounds: <span class="type">List</span>[<span class="type">SimpleType</span>]</span>)</span></span><br></pre></td></tr></table></figure>
<p><em>Constraining with levels.</em> The next step is to make sure that
variables of higher level do not escape into the bounds of variables of
lower level. We do that by adding guards in the constraining algorithm,
preventing it from happening:</p>
<p><em>使用级别进行约束。</em>
下一步是确保较高级别的变量不会逃逸到较低级别变量的边界中。我们通过在约束算法中添加保护措施来防止这种情况发生：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">constrain</span></span>(lhs: <span class="type">SimpleType</span>, rhs: <span class="type">SimpleType</span>)</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> (<span class="type">Variable</span>(lhs), rhs) <span class="keyword">if</span> rhs.level &lt;= lhs.level =&gt;  <span class="comment">// new guard here</span></span><br><span class="line">        lhs.upperBounds = rhs :: lhs.upperBounds</span><br><span class="line">        lhs.lowerBounds.foreach(constrain(_, rhs))</span><br><span class="line">    <span class="keyword">case</span> (lhs, <span class="type">Variable</span>(rhs)) iflhs.level &lt;= rhs.level =&gt; <span class="comment">// new guard here</span></span><br><span class="line">        rhs.lowerBounds = lhs :: rhs.lowerBounds</span><br><span class="line">        rhs.upperBounds.forEach(constrain(lhs, _))</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extrude</span></span>(ty: <span class="type">SimpleType</span>, pol: <span class="type">Boolean</span>)</span><br><span class="line">    (<span class="keyword">implicit</span> lvl: <span class="type">Int</span>, c: <span class="type">MutMap</span>[<span class="type">PolarVariable</span>, <span class="type">VariableState</span>]): <span class="type">SimpleType</span></span><br><span class="line">    = <span class="keyword">if</span> (ty.level &lt;= lvl) ty <span class="keyword">else</span> ty <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Primitive</span>(_)</span><br><span class="line">            =&gt; ty</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Function</span>(l, r)</span><br><span class="line">            =&gt; <span class="type">Function</span>(extrude(l, !pol), extrude(r, pol))</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Record</span>(fs)</span><br><span class="line">            =&gt; <span class="type">Record</span>(fs.map(nt =&gt; nt._1 -&gt; extrude(nt._2, pol)))</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Variable</span>(vs)</span><br><span class="line">            =&gt; c.getOrElse(vs -&gt; pol, &#123;</span><br><span class="line">                <span class="keyword">val</span> nvs = freshVar</span><br><span class="line">                c += vs -&gt; pol -&gt; nvs</span><br><span class="line">                <span class="keyword">if</span> (pol) &#123;</span><br><span class="line">                    vs.upperBounds ::= nvs</span><br><span class="line">                    nvs.lowerBounds = vs.lowerBounds.map(extrude(_, pol))</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    vs.lowerBounds ::= nvs</span><br><span class="line">                    nvs.upperBounds = vs.upperBounds.map(extrude(_, pol))</span><br><span class="line">                &#125;</span><br><span class="line">                nvs</span><br><span class="line">            &#125;)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>Fig. 7. Type extrusion algorithm.</p>
<p>图 7. 类型挤出算法。</p>
<p>Naturally, we also need to handle the cases where there is a level
violation. In such cases, we make a copy of the problematic type up to
its type variables of wrong level (including their bounds) using the
<code>extrude</code> function, which returns a type at the right level
that mirrors the structure of the original type:</p>
<p>自然，我们也需要处理存在级别违规的情况。在这种情况下，我们使用
<code>extrude</code>
函数复制到其错误级别的类型变量（包括它们的边界）的有问题的类型，该函数返回一个在正确级别的类型，反映了原始类型的结构：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> (lhs @ <span class="type">Variable_</span>, rhs0) =&gt;</span><br><span class="line">    <span class="keyword">val</span> rhs = extrude rhs0, <span class="literal">false</span>)(lhs.level, <span class="type">MutMap</span>.empty)</span><br><span class="line">    constrain (lhs, rhs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> (lhs0, rhs @ <span class="type">Variable_</span>) =&gt;</span><br><span class="line">    vallhs = extrude (lhs0, <span class="literal">true</span>)(rhs.level, <span class="type">MutMap</span>.empty)</span><br><span class="line">    constrain (lhs, rhs)</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>The <code>extrude</code> function is defined in Figure 7. Its goal is
to make a copy of the problematic type such that the copy has the
requested level and soundly <em>approximates</em> the original type. If
a variable <code>vs</code> needs to be copied as part of an extruded
type, two new variables should be created, one for each of vs's bounds
(unless of course the variable occurs strictly positively or strictly
negatively, in which case one of the two bounds can be discarded). This
way, we essentially create a conservative approximation of vs in the
result of the extrusion, and any later instantiation of vs (created at
every point the nested let binding is used) will be able to receive
additional constraints independently, as long as these constraints are
within the extruded approximating bounds of vs.</p>
<p><code>extrude</code> 函数在图 7
中定义。它的目标是复制有问题的类型，使得该副本具有请求的级别并且能够合理地
<em>近似</em> 原始类型。如果需要将变量 <code>vs</code>
作为外延类型的一部分进行复制，则应创建两个新变量，一个用于每个vs的界（当然，除非变量严格正向或严格负向出现，在这种情况下可以丢弃两个边界中的一个）。通过这种方式，我们基本上在挤出的结果中创建了vs的一个保守近似，并且任何后续对vs的实例化（在每次使用嵌套let绑定时创建）都能够独立地接收额外的约束，只要这些约束在vs的挤出近似边界之内。</p>
<p>extrude recursively traverses its argument type tree up to its
subtrees of acceptable levels. When it finds a type variable vs with the
wrong level, it creates a copy nvs of the faulty type variable at the
requested level lv1 and registers the necessary constraints. This works
because nvs has a level lower than vs, satisfying the invariant on
levels. We have to recursively extrude the bound of vs to place it in
the nvs copy, but this bounds may form cycles. To avoid going into an
infinite extrusion loop, we keep a cache c of the variables already
being extruded, along with the polarity of that extrusion. In other
words, extrude copies not only type trees, but also the
potentially-cyclic subgraphs of type variable bounds which are rooted in
these type trees.</p>
<p>extrude
递归遍历其参数类型树直到可接受级别的子树。当它发现一个级别错误的类型变量
vs 时，它在请求的级别 lv1 创建一个故障类型变量 nvs
的副本，并注册必要的约束。这是可行的，因为 nvs 的级别低于
vs，满足级别不变量。我们必须递归地 extrude vs 的边界以将其放置在 nvs
副本中，但这些边界可能会形成循环。为了避免进入无限 extrusion
循环，我们保持一个已经被 extruded 的变量的缓存 c，以及该 extrusion
的极性。换句话说，extrude
不仅复制类型树，还复制这些类型树的类型变量边界的潜在循环子图。</p>
<p><em>Let polymorphism in MLsub.</em> In contrast to the approach
presented here, Dolan uses an equivalent “lambda-lifted” type system,
which associates to let-bound variables entire typing environments, in
the typing context. While this can make for a slicker specification, it
is rather counter-intuitive and thus harder to understand, creates many
useless type variables (which need to be simplified later), and
needlessly duplicates constraints, which causes inefficiencies [Pottier
1998, Chapter 16.2].</p>
<p><em>MLsub 中的 Let 多态性。</em> 与此处提出的方法不同，Dolan
使用了一种等效的“lambda-lifted”类型系统，它将 let
绑定变量与整个类型环境关联，在类型上下文中。虽然这可以使规范更加简洁，但它相当直觉上不易理解，因此更难以把握，产生许多无用的类型变量（稍后需要简化），并不必要地重复约束，这导致效率低下
[Pottier 1998, Chapter 16.2]。</p>
<p>3.5.2 <em>Recursive Let Bindings.</em> Finally, supporting recursive
let bindings is done in the usual way, by typing the right-hand side of
the let binding with, in the context, a name bound to a type variable
which is later checked to be a supertype of the actual right-hand side
type (see Figure 8).</p>
<p>3.5.2 <em>递归 Let 绑定。</em> 最后，支持递归的 let
绑定是通过以通常的方式进行的，即在上下文中使用一个绑定到类型变量的名称对
let
绑定的右侧进行类型检查，该类型变量稍后被检查为实际右侧类型的超类型（见图
8）。</p>
<h2 id="summary">3.6 Summary</h2>
<h2 id="总结">3.6 总结</h2>
<p>We summarize the final typing and constraining algorithms in Figures
8 and 9, respectively.</p>
<p>我们在图 8 和图 9 中分别总结了最终的类型和约束算法。</p>
<p>Overall, Simple-sub looks more like traditional type inference
algorithms than Dolan’s biunification, and it completely eschews the
complexities of bisubstitution and polar types. Yet, as we confirm
experimentally in Section 6, both algorithms produce equivalent results.
This shows that bisubstitution and polar types are not, in fact,
essential to type inference with subtyping and principal types in the
style of MLsub.</p>
<p>总体而言，Simple-sub 更像传统的类型推断算法，而不是 Dolan
的双重合并（biunification），并且完全避免了双重替换和极性类型的复杂性。然而，正如我们在第六节中通过实验确认的，两个算法产生的结果是等价的。这表明，双重替换和极性类型实际上不是在
MLsub 风格中进行带有子类型及主要类型的类型推断所必需的。</p>
<h2 id="simplifying-types">4 SIMPLIFYING TYPES</h2>
<h2 id="简化类型">4 简化类型</h2>
<p>As it is, the algorithm shown in the previous section infers types
which often contain redundancies in their structures, as well as type
variables which could be removed or unified. An important component of
type inference when subtyping is involved is to simplify the types
inferred, so as to make them compact and easy to comprehend [Pottier
1998]. If we did not perform any simplification, the inferred types
would usually grow linearly with the size of the program!</p>
<p>如前所述，前一节中展示的算法推断出的类型通常在结构上包含冗余部分，以及可以删除或合并的类型变量。当涉及子类型时，类型推断的一个重要组成部分是简化推断出的类型，以使其紧凑且易于理解
[Pottier
1998]。如果我们不进行任何简化，推断出的类型通常会随着程序大小的增加而线性增长！</p>
<p>In this section, we explore the design space and tradeoffs of type
simplification (Section 4.1); we recall how MLsub performs
automaton-based simplification (Section 4.2); we explain the ideas
behind Simple-sub’s more basic approach to simplification, which turns
out to be sufficient most of the time — and sometimes better (Section
4.3); and we describe an intermediate representation to facilitate the
application of these ideas (Section 4.4).</p>
<p>在本节中，我们探讨类型简化的设计空间和权衡（第4.1节）；我们回顾MLsub如何执行基于自动机的简化（第4.2节）；我们解释Simple-sub更基本的简化方法背后的想法，这种方法在大多数情况下被证明是足够的——有时甚至更好（第4.3节）；我们描述了一种中间表示，以促进这些想法的应用（第4.4节）。</p>
<h3 id="type-simplification-tradeoffs">4.1 Type Simplification
Tradeoffs</h3>
<h3 id="类型简化的权衡">4.1 类型简化的权衡</h3>
<p>Part of the appeal of algebraic subtyping is that it produces
<em>compact</em> principal types, which are easy to read, unlike
previous approaches to subtype inference. However, this comes at a cost:
it requires making simplifying assumptions about the semantics of types.
These assumptions hold in MLsub, but may not hold in languages with more
advanced features.</p>
<p>代数子类型的吸引力部分在于它产生<em>紧凑</em>的主类型，这些主类型易于阅读，不像以前的子类型推断方法。然而，这是有代价的：它需要对类型的语义做出简化假设。这些假设在MLsub中成立，但在具有更高级特性的语言中可能不成立。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">typeTerm</span></span>(trm: <span class="type">Term</span>)(<span class="keyword">implicit</span> ctx: <span class="type">Ctx</span>, lvl: <span class="type">Int</span>): <span class="type">SimpleType</span> = trm <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Lit</span>(n)     =&gt; <span class="type">Primitive</span>(<span class="string">&quot;int&quot;</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Var</span>(name)  =&gt; ctx.getOrElse(name, err(<span class="string">&quot;not found: &quot;</span> + name)).instantiate</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Rcd</span>(fs)    =&gt; <span class="type">Record</span>(fs.map &#123; <span class="keyword">case</span> (n, t) =&gt; (n, typeTerm(t)) &#125;)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Lam</span>(name, body) =&gt;</span><br><span class="line">    <span class="keyword">val</span> param = freshVar</span><br><span class="line">    <span class="type">Function</span>(param, typeTerm(body)(ctx + (name -&gt; param), lvl))</span><br><span class="line">  <span class="keyword">case</span> <span class="type">App</span>(f, a) =&gt;</span><br><span class="line">    <span class="keyword">val</span> res = freshVar</span><br><span class="line">    constrain(typeTerm(f), <span class="type">Function</span>(typeTerm(a), res))</span><br><span class="line">    res</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Sel</span>(obj, name) =&gt;</span><br><span class="line">    <span class="keyword">val</span> res = freshVar</span><br><span class="line">    constrain(typeTerm(obj), <span class="type">Record</span>((name -&gt; res) :: <span class="type">Nil</span>))</span><br><span class="line">    res</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Let</span>(isrec, nme, rhs, bod) =&gt;</span><br><span class="line">    <span class="keyword">val</span> rhs_ty = <span class="keyword">if</span> (isrec) &#123;</span><br><span class="line">      <span class="keyword">val</span> exp = freshVar(lvl + <span class="number">1</span>)</span><br><span class="line">      <span class="keyword">val</span> inf = typeTerm(rhs)(ctx + (nme -&gt; exp), lvl + <span class="number">1</span>)</span><br><span class="line">      constrain(inf, exp)</span><br><span class="line">      exp</span><br><span class="line">    &#125; <span class="keyword">else</span> typeTerm(rhs)(ctx, lvl + <span class="number">1</span>)</span><br><span class="line">    typeTerm(bod)(ctx + (nme -&gt; <span class="type">PolymorphicType</span>(lvl, rhs_ty)), lvl)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Fig. 8. Full specification of term typing in Simple-sub.</p>
<p>图 8. Simple-sub 中术语类型的完整规格说明。</p>
<p>For instance, MLsub considers the types
<code>(int → int) ∧ (nat → nat)</code> and
<code>int ∪ nat → int ∧ nat</code> to be equivalent, although the latter
intuitively contains strictly <em>less</em> information. This assumption
is sound, because MLsub programs cannot distinguish between the two
types — program which works with one will also work with the other.
However, the equivalence would not hold in a language which, for
example, used intersection types to encode overloading.</p>
<p>例如，MLsub认为类型<code>(int → int) ∧ (nat → nat)</code>和<code>int ∪ nat → int ∧ nat</code>是等价的，尽管后者在直观上包含的信息严格<em>少</em>。这个假设是合理的，因为MLsub程序无法区分这两种类型——处理一种的程序也可以处理另一种。然而，在一种使用交集类型来编码重载的语言中，这种等价关系就不成立了。</p>
<p>As another example, MLsub does not distinguish between the types
<code>&#123; tag : 0; payload : str &#125; ∪ &#123; tag : 1; payload : int &#125;</code> and
<code>&#123; tag : 0 ∪ 1; payload : str ∪ int &#125;</code>, where 0 and 1 denote
singleton literal types (trivial to add to our type system). But in
languages like JavaScript which support flow typing [Pearce 2013;
Tobin-Hochstadt and Felleisen 2010], the former holds more information,
since the different types of payload could be extracted separately by
first matching on the tag.¹⁴</p>
<p>作为另一个例子，MLsub并不区分类型<code>&#123; tag : 0; payload : str &#125; ∪ &#123; tag : 1; payload : int &#125;</code>和<code>&#123; tag : 0 ∪ 1; payload : str ∪ int &#125;</code>，其中0和1表示单元素文字类型（很容易添加到我们的类型系统中）。但在支持流类型的语言如JavaScript中[Pearce
2013; Tobin-Hochstadt and Felleisen
2010]，前者包含更多信息，因为不同类型的负载可以通过首先匹配标签分别提取。<a
href="#fn25" class="footnote-ref" id="fnref25"
role="doc-noteref"><sup>25</sup></a></p>
<p>These simplifying assumptions are not <em>necessary</em> for
principal type inference — they are merely a requirement of MLsub's
simplification and subsumption checking approaches (note that
subsumption checking is outside the scope of this paper). While they are
<em>implied</em> by Dolan's algebraic construction of subtyping, making
them inescapable in his system, these assumptions can actually</p>
<p>这些简化假设对于主类型推断并不是<em>必要</em>的——它们仅仅是MLsub的简化和涵蓋性检查方法的要求（请注意，涵蓋性检查超出了本文的范围）。虽然它们是由Dolan的子类型代数构造<em>隐含</em>的，使得它们在他的系统中不可避免，但实际上这些假设可以</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">constrain</span></span>(lhs: <span class="type">SimpleType</span>, rhs: <span class="type">SimpleType</span>)</span><br><span class="line">  (<span class="keyword">implicit</span> cache: <span class="type">MutSet</span>[(<span class="type">SimpleType</span>,<span class="type">SimpleType</span>)] = <span class="type">MutSet</span>.empty): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (cache.contains(lhs -&gt; rhs)) <span class="keyword">return</span> () <span class="keyword">else</span> cache += lhs -&gt; rhs</span><br><span class="line">  (lhs, rhs) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> (<span class="type">Primitive</span>(n0), <span class="type">Primitive</span>(n1)) <span class="keyword">if</span> n0 != n1 =&gt; ()</span><br><span class="line">    <span class="keyword">case</span> (<span class="type">Function</span>(l0, r0), <span class="type">Function</span>(l1, r1)) =&gt;</span><br><span class="line">      constrain(l1, l0); constrain(r0, r1)</span><br><span class="line">    <span class="keyword">case</span> (<span class="type">Record</span>(fs0), <span class="type">Record</span>(fs1)) =&gt;</span><br><span class="line">      fs1.foreach &#123; <span class="keyword">case</span> (n1, t1) =&gt;</span><br><span class="line">        fs0.find(_._1 == n1) <span class="keyword">match</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt; err(<span class="string">&quot;missing field: &quot;</span> + n1 + <span class="string">&quot; in &quot;</span> + lhs)</span><br><span class="line">          <span class="keyword">case</span> <span class="type">Some</span>(_, t0) =&gt; constrain(t0, t1) &#125;&#125;</span><br><span class="line">    <span class="keyword">case</span> (<span class="type">Variable</span>(lhs), rhs0) <span class="keyword">if</span> rhs.level &lt;= lhs.level =&gt;</span><br><span class="line">      lhs.upperBounds = rhs :: lhs.upperBounds</span><br><span class="line">      lhs.lowerBounds.foreach(constrain(_, rhs))</span><br><span class="line">    <span class="keyword">case</span> (lhs0, <span class="type">Variable</span>(rhs)) <span class="keyword">if</span> lhs.level &lt;= rhs.level =&gt;</span><br><span class="line">      rhs.lowerBounds = lhs :: rhs.lowerBounds</span><br><span class="line">      rhs.upperBounds.foreach(constrain(lhs, _))</span><br><span class="line">    <span class="keyword">case</span> (lhs @ <span class="type">Variable</span>(_), rhs0) =&gt;</span><br><span class="line">      <span class="keyword">val</span> rhs = extrude(rhs0, <span class="literal">false</span>)(lhs.level, <span class="type">MutMap</span>.empty)</span><br><span class="line">      constrain(lhs, rhs)</span><br><span class="line">    <span class="keyword">case</span> (lhs0, rhs @ <span class="type">Variable</span>(_)) =&gt;</span><br><span class="line">      <span class="keyword">val</span> lhs = extrude(lhs0, <span class="literal">true</span>)(rhs.level, <span class="type">MutMap</span>.empty)</span><br><span class="line">      constrain(lhs, rhs)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; err(<span class="string">&quot;cannot constrain &quot;</span> + lhs + <span class="string">&quot; &lt;: &quot;</span> + rhs)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Fig. 9. Full specification of subtype constraining in Simple-sub.</p>
<p>图9. Simple-sub中子类型约束的完整规范。</p>
<p>be separated from the type inference specification — we see a
syntactic interpretation of subtyping in Section 5 which does
<em>not</em> imply them, the understanding being that the system can be
completed with more rules as desired, to achieve the simplification
potential described in this section.</p>
<p>与类型推断规范分开 —
我们在第5节中看到了一种子类型的语法解释，该解释<em>不</em>意味着它们，理解是系统可以根据需要添加更多规则，以实现本节中描述的简化潜力。</p>
<h2 id="type-simplification-in-mlsub">4.2 Type Simplification in
MLsub</h2>
<h2 id="mlsub中的类型简化">4.2 MLsub中的类型简化</h2>
<p>Thanks to the simplifying assumptions described in the previous
subsection, MLsub can represent types as finite-state automata, where
the states are type variables and where the edges, which are labelled,
represent relations between these type variables. There are four sorts
of labels on any edge between two type variables <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>: an “is-a” label indicate that
<span class="math inline">\(\alpha\)</span> is a subtype of <span
class="math inline">\(\beta\)</span>; a “consumes” label indicate that
<span class="math inline">\(\alpha\)</span> is a function which takes
some <span class="math inline">\(\beta\)</span> in parameter; a
“produces” label indicate that <span
class="math inline">\(\alpha\)</span> is a function which returns some
<span class="math inline">\(\beta\)</span> as a result; and finally, a
“contains-L” label indicate that <span
class="math inline">\(\alpha\)</span> is a record which contains a field
named <span class="math inline">\(L\)</span> of type <span
class="math inline">\(\beta\)</span>. The starting state of the
automaton represents the root of the type expression.</p>
<p>由于前一小节中描述的简化假设，MLsub
可以将类型表示为有限状态自动机，其中状态是类型变量，边缘（带标签）表示这些类型变量之间的关系。在任何两个类型变量
<span class="math inline">\(\alpha\)</span> 和 <span
class="math inline">\(\beta\)</span>
之间的边缘上有四种标签：一个“is-a”标签表示 <span
class="math inline">\(\alpha\)</span> 是 <span
class="math inline">\(\beta\)</span> 的子类型；一个“consumes”标签表示
<span class="math inline">\(\alpha\)</span> 是一个以某个 <span
class="math inline">\(\beta\)</span>
为参数的函数；一个“produces”标签表示 <span
class="math inline">\(\alpha\)</span> 是一个返回某个 <span
class="math inline">\(\beta\)</span>
作为结果的函数；最后，一个“contains-L”标签表示 <span
class="math inline">\(\alpha\)</span> 是一个包含名为 <span
class="math inline">\(L\)</span> 的字段类型为 <span
class="math inline">\(\beta\)</span>
的结构体。自动机的起始状态表示类型表达式的根。</p>
<p>This clever representation allows one to simplify types by reusing
well-known existing techniques from the domain of automata theory: type
automata can be made deterministic (“is-a”-labelled</p>
<p>这种巧妙的表示允许通过重用自动机理论领域中的现有技术来简化类型：类型自动机可以被制作成确定性的（“is-a”标签）</p>
<p>edges are seen as <span class="math inline">\(\epsilon\)</span>
edges, so type automata are initially non-deterministic) and then
minimized, to achieve simplification. However, this is a quite heavy and
expensive approach. We found that in practice, a more straightforward
simplification algorithm was often sufficient. We describe such an
algorithm in the rest of this section.</p>
<p>边被视为 <span class="math inline">\(\epsilon\)</span>
边，因此类型自动机最初是非确定性的)
然后经过最小化，以实现简化。然而，这是一种相当繁重和昂贵的方法。我们发现，在实践中，通常更直接的简化算法就足够了。我们将在本节的其余部分描述这样的算法。</p>
<h2 id="type-simplification-in-simple-sub">4.3 Type Simplification in
Simple-sub</h2>
<h2 id="在-simple-sub-中的类型简化">4.3 在 Simple-sub 中的类型简化</h2>
<p>Our simplification approach hinges on two main ideas:
<em>co-occurrence analysis</em> and <em>hash consing</em>.</p>
<p>我们的简化方法依赖于两个主要思想：<em>共现分析</em> 和
<em>哈希一致性</em>。</p>
<p>4.3.1 <em>Co-occurrence Analysis.</em> Co-occurrence analysis looks
at every variable that appears in a type in both positive and negative
positions, and records along which other variables and types it always
occurs. A variable <span class="math inline">\(v\)</span> occurs along a
type <span class="math inline">\(\tau\)</span> if it is part of the same
type union ... <span class="math inline">\(\sqcup v \sqcup\)</span> ...
<span class="math inline">\(\sqcup \tau \sqcup\)</span> ... or part of
the same type intersection ... <span class="math inline">\(\sqcap v
\sqcap\)</span> ... <span class="math inline">\(\sqcap \tau
\sqcap\)</span> ...</p>
<p>4.3.1 <em>共现分析。</em>
共现分析查看在类型中以正面和负面位置出现的每个变量，并记录它与其他变量和类型的共同出现情况。如果一个变量
<span class="math inline">\(v\)</span> 出现在类型 <span
class="math inline">\(\tau\)</span> 旁边，则它是同一类型并的一个部分 ...
<span class="math inline">\(\sqcup v \sqcup\)</span> ... <span
class="math inline">\(\sqcup \tau \sqcup\)</span> ...
或同一类型交集的一个部分 ... <span class="math inline">\(\sqcap v
\sqcap\)</span> ... <span class="math inline">\(\sqcap \tau
\sqcap\)</span> ...</p>
<p>Based on this information, we can perform three kinds of
simplification:</p>
<p>基于这些信息，我们可以进行三种简化：</p>
<p><em>Removal of polar variable.</em> First, we want to remove type
variables which appear only positively (or negatively) in a type
expression. For instance, consider the type inferred for <span
class="math inline">\(\lambda x.x + 1\)</span>, which is currently <span
class="math inline">\(\alpha \sqcap \text{int} \rightarrow
\text{int}\)</span> (because the typing of lambda expressions always
assigns a type variable to the parameter). The variable <span
class="math inline">\(\alpha\)</span> in this type is redundant since it
only occurs in negative position — whichever <span
class="math inline">\(\alpha\)</span> the caller may pick, the function
will still require the argument to be an int, and it will still produce
an int as a result. So we can simply remove <span
class="math inline">\(\alpha\)</span> and obtain the simplified type
<span class="math inline">\(\text{int} \rightarrow
\text{int}\)</span>.</p>
<p><em>去除极性变量。</em>
首先，我们想要去除在类型表达式中仅以正面（或负面）出现的类型变量。例如，考虑函数
<span class="math inline">\(\lambda x.x + 1\)</span>
推断出的类型，目前是 <span class="math inline">\(\alpha \sqcap
\text{int} \rightarrow \text{int}\)</span>（因为 lambda
表达式的类型总是将类型变量分配给参数）。这个类型中的变量 <span
class="math inline">\(\alpha\)</span>
是多余的，因为它只出现在负面位置——无论调用者选择哪个 <span
class="math inline">\(\alpha\)</span>，函数仍然要求参数是
int，并且结果仍然是 int。因此，我们可以简单地去除 <span
class="math inline">\(\alpha\)</span>，得到简化后的类型 <span
class="math inline">\(\text{int} \rightarrow \text{int}\)</span>。</p>
<p>As another example, the type of a function which uses its argument as
an int but never terminates, <span class="math inline">\(\text{int}
\rightarrow \alpha\)</span>, can be simplified to <span
class="math inline">\(\text{int} \rightarrow \perp\)</span>.</p>
<p>作为另一个例子，一个使用其参数作为 int 但永不终止的函数类型 <span
class="math inline">\(\text{int} \rightarrow \alpha\)</span> 可以简化为
<span class="math inline">\(\text{int} \rightarrow \perp\)</span>。</p>
<p><em>Unification of indistinguishable variables.</em> We have
previously mentioned that a type such as <span
class="math inline">\(\text{bool} \rightarrow \alpha \rightarrow \beta
\rightarrow \alpha \sqcup \beta\)</span> (the natural type of
if-then-else) is equivalent to the simpler type <span
class="math inline">\(\text{bool} \rightarrow \alpha \rightarrow
\alpha\)</span>. This is true because the positive occurrences of the
variables <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> are "indistinguishable" — whenever
an <span class="math inline">\(\alpha\)</span> is produced, a <span
class="math inline">\(\beta\)</span> is also produced. Therefore, we
cannot distinguish the two variables, and they can be unified.</p>
<p><em>不可区分变量的合并。</em> 我们之前提到过，类型 <span
class="math inline">\(\text{bool} \rightarrow \alpha \rightarrow \beta
\rightarrow \alpha \sqcup \beta\)</span>（if-then-else
的自然类型）等价于更简单的类型 <span class="math inline">\(\text{bool}
\rightarrow \alpha \rightarrow \alpha\)</span>。这是因为变量 <span
class="math inline">\(\alpha\)</span> 和 <span
class="math inline">\(\beta\)</span>
的正出现是“不可区分”的——每当产生一个 <span
class="math inline">\(\alpha\)</span> 时，<span
class="math inline">\(\beta\)</span>
也会被产生。因此，我们无法区分这两个变量，它们可以被合并。</p>
<p>Based on the result of the co-occurrence analysis, we can unify all
those variables that always occur together either in positive or in
negative positions (or both).</p>
<p>根据共现分析的结果，我们可以合并那些总是一起出现在正位置或负位置（或两者）的所有变量。</p>
<p><em>Flattening of “variable sandwiches”.</em> What we call a
"variable sandwich" is an inferred type variable <span
class="math inline">\(v\)</span> which has a type <span
class="math inline">\(\tau\)</span> both as an upper bound and as a
lower bound, i.e., <span class="math inline">\(v \le \tau\)</span> and
<span class="math inline">\(v \ge \tau\)</span>. This means that <span
class="math inline">\(v\)</span> is equivalent to <span
class="math inline">\(\tau\)</span>. In a coalesced type, this will
transpire as <span class="math inline">\(v\)</span> co-occurring with
<span class="math inline">\(\tau\)</span> both positively and
negatively. So we can use the result of co-occurrence analysis to remove
variables which are sandwiched between two identical bounds. As an
example, we simplify the type <span class="math inline">\(\alpha \sqcap
\text{int} \rightarrow \alpha \sqcup \text{int}\)</span> to just <span
class="math inline">\(\text{int} \rightarrow \text{int}\)</span>.</p>
<p><em>“变量三明治”的扁平化。</em>
我们所称的“变量三明治”是一个推断的类型变量 <span
class="math inline">\(v\)</span>，其类型 <span
class="math inline">\(\tau\)</span> 同时作为上界和下界，即 <span
class="math inline">\(v \le \tau\)</span> 和 <span
class="math inline">\(v \ge \tau\)</span>。这意味着 <span
class="math inline">\(v\)</span> 与 <span
class="math inline">\(\tau\)</span> 等价。在一个聚合的类型中，这将表现为
<span class="math inline">\(v\)</span> 与 <span
class="math inline">\(\tau\)</span>
同时正向和负向共现。因此，我们可以使用共现分析的结果来移除夹在两个相同界限之间的变量。作为一个例子，我们将类型
<span class="math inline">\(\alpha \sqcap \text{int} \rightarrow \alpha
\sqcup \text{int}\)</span> 简化为仅仅 <span
class="math inline">\(\text{int} \rightarrow \text{int}\)</span>。</p>
<p>Conceptually, this idea generalizes polar variable removal, which was
explained above. Indeed, if a variable never occurs positively, it
conceptually occurs both positively and negatively along with the type
<span class="math inline">\(\perp\)</span>, so we can replace that
variable with <span class="math inline">\(\perp\)</span> (i.e., remove
it from all type unions).</p>
<p>在概念上，这个思想推广了极性变量的移除，如上所述。实际上，如果一个变量从未正向出现，那么它在概念上同时与类型
<span class="math inline">\(\perp\)</span>
正向和负向出现，因此我们可以用 <span
class="math inline">\(\perp\)</span>
替换该变量（即，从所有类型的并集中移除它）。</p>
<p>All these transformations are truly simplifications, in the sense
that they yield new types which contain fewer subterms but are still
<em>equivalent</em> to the original types (i.e., the two types subsume
each other). Therefore, these transformations also preserve
principality.</p>
<p>所有这些转换实际上都是简化，从这个意义上说，它们产生了包含较少子项的新类型，但仍然与原始类型<em>等价</em>（即，这两个类型可以互相包含）。因此，这些转换也保留了原始性。</p>
<p>4.3.2 <em>Hash Consing.</em> Simple-sub's other simplification
approach, <em>hash consing</em>, deals with removing duplicated
structures in coalesced type expressions.</p>
<p>4.3.2 <em>Hash Consing.</em> Simple-sub的另一种简化方法<em>hash
consing</em>，处理的是在聚合的类型表达式中移除重复结构的问题。</p>
<p>Consider the following recursive term:</p>
<p>考虑以下递归项：</p>
<p><span class="math display">\[ \text{let } f = \lambda x. \{ L = x ; R
= f x \} \text{ in } f \]</span></p>
<p>The coalesced type inferred for this term would be:</p>
<p>为这个项推断出的聚合类型将是：</p>
<p><span class="math display">\[ \alpha \rightarrow \{ L : \alpha; R :
\mu\beta. \{ L : \alpha; R : \beta \} \} \]</span></p>
<p>Notice that there is an outer record layer that is redundant. We
would like to instead infer:</p>
<p>注意，这里有一个冗余的外部结构体层。我们希望推断出：</p>
<p><span class="math display">\[ \alpha \rightarrow \mu\beta. \{ L :
\alpha; R : \beta \} \]</span></p>
<p>This can be done by performing hash consing on the types being
coalesced, in the <code>coalesceType</code> function: instead of simply
remembering which <em>variables</em> are in the process of being
coalesced, we can remember whole type expressions; when we reach a type
expression which is already being coalesced, we introduce a recursive
type variable in this position, removing the redundant outer layer of
types like the above.</p>
<p>这可以通过在 <code>coalesceType</code>
函数中对正在聚合的类型执行哈希合并来完成：我们可以记住正在聚合的整个类型表达式，而不仅仅是哪个
<em>变量</em>
正在被聚合；当我们遇到一个已经在聚合中的类型表达式时，我们会在这个位置引入一个递归类型变量，从而去除像上述那样冗余的外层类型。</p>
<p>Interestingly, MLsub does not currently perform a comparable
simplification, so Simple-sub infers simpler types in examples like the
one above.</p>
<p>有趣的是，MLsub
当前并不执行类似的简化，因此在像上述示例中，Simple-sub
推导出更简单的类型。</p>
<h2 id="an-intermediate-representation-for-simplification">4.4 An
Intermediate Representation for Simplification</h2>
<h2 id="用于简化的中间表示">4.4 用于简化的中间表示</h2>
<p>The above two approaches do not work very well out of the box. First,
we cannot perform them on non-coalesced types, since co-occurrence
analysis would miss information which only becomes apparent after the
bounds are flattened. For instance, if we inferred a type variable <span
class="math inline">\(\alpha\)</span> with upper bounds <span
class="math inline">\(\tau_0 \rightarrow \tau_1\)</span> and <span
class="math inline">\(\tau_2 \rightarrow \tau_3\)</span>, only after we
flatten these bounds and merge the function types into <span
class="math inline">\(\tau_0 \sqcup \tau_2 \rightarrow \tau_1 \sqcap
\tau_2\)</span> do we notice the co-occurrence of <span
class="math inline">\(\tau_0\)</span>, <span
class="math inline">\(\tau_2\)</span> and <span
class="math inline">\(\tau_1\)</span>, <span
class="math inline">\(\tau_3\)</span>. Second, it is awkward to perform
the normalization steps necessary for this sort of function type merging
on the final coalesced type representation, which is syntactically too
loose (it can represent types which do not correspond to inferred types,
for instance merging unions and intersections).</p>
<p>上述两种方法在实际应用中效果并不理想。首先，我们无法对非聚合类型执行这些操作，因为共现分析会遗漏在边界被扁平化后才显现的信息。例如，如果我们推断出一个类型变量
<span class="math inline">\(\alpha\)</span>，其上界为 <span
class="math inline">\(\tau_0 \rightarrow \tau_1\)</span> 和 <span
class="math inline">\(\tau_2 \rightarrow
\tau_3\)</span>，只有在我们扁平化这些边界并将函数类型合并为 <span
class="math inline">\(\tau_0 \sqcup \tau_2 \rightarrow \tau_1 \sqcap
\tau_3\)</span> 后，我们才会注意到 <span
class="math inline">\(\tau_0\)</span>、<span
class="math inline">\(\tau_2\)</span> 与 <span
class="math inline">\(\tau_1\)</span>、<span
class="math inline">\(\tau_3\)</span>
的共现。其次，在最终的聚合类型表示上执行这种函数类型合并所需的标准化步骤是尴尬的，因为它的语法过于松散（它可以表示与推断类型不对应的类型，例如合并并集和交集）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="keyword">class</span> <span class="title class_">CompactType</span> vars: Set[CTypeVariable],</span><br><span class="line">    prims: Set[PrimType],</span><br><span class="line">    rcd: Option[SortedMap String, CompactType]],</span><br><span class="line">    fun: Option[(CompactType, CompactType)]</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">class</span> <span class="title class_">CompactTypeScheme</span> (cty: CompactType,</span><br><span class="line">    recVars: Map[CTypeVariable, CompactType])</span><br></pre></td></tr></table></figure>
<p>For these reasons, we introduce an intermediate
<code>CompactType</code> representation between <code>SimpleType</code>
and <code>Type</code>, in which to perform simplification more easily.
The <code>CompactType</code> representation, shown above, corresponds to
a normalized representation of types where all the non-recursive
variable bounds are coalesced. The <code>recVars</code> field of
<code>CompactTypeScheme</code> records the bounds of recursive type
variables (which we cannot coalesce, as they are cyclic).</p>
<p>出于这些原因，我们引入了一种介于 <code>SimpleType</code> 和
<code>Type</code> 之间的中间 <code>CompactType</code>
表示，以便更容易地进行简化。上述的 <code>CompactType</code>
表示对应于类型的标准化表示，其中所有非递归变量的界限都进行了聚合。<code>CompactTypeScheme</code>
的 <code>recVars</code>
字段记录了递归类型变量的界限（我们不能聚合它们，因为它们是循环的）。</p>
<p>The <code>compactType</code> function to convert a
<code>SimpleType</code> into a <code>CompactTypeScheme</code> is
straightforward and looks like the <code>coalesceType</code> function
shown earlier. The <code>simplifyType</code> function is slightly more
complicated, as it has to perform a co-occurrence analysis pass followed
by a rewriting pass. Finally, hash consing is done as part of the
<code>coalesceCompactType</code> function. We do not show the
implementations of these functions here for lack of space, but they can
be seen in the code associated with the paper.</p>
<p>将 <code>SimpleType</code> 转换为 <code>CompactTypeScheme</code> 的
<code>compactType</code> 函数很简单，类似于前面显示的
<code>coalesceType</code> 函数。<code>simplifyType</code>
函数稍微复杂一些，因为它需要进行共现分析遍及和重写遍及。最后，哈希一致性作为
<code>coalesceCompactType</code>
函数的一部分完成。由于篇幅限制，我们在此不展示这些函数的实现，但可以在与论文相关的代码中看到它们。</p>
<h2 id="formalization-of-simple-sub">5 FORMALIZATION of SIMPLE-SUB</h2>
<h2 id="simple-sub-的形式化">5 SIMPLE-SUB 的形式化</h2>
<p>So far, we have appealed to an intuitive understanding of subtyping,
eschewing a more explicit characterization. In this section, we make our
intuition more formal by giving a syntactic account of the minimal
subtyping relationship required to make the type inference algorithm of
Section 3 sound and complete. We state the corresponding theorems and
sketch how to carry out their proofs. The complete proofs are outside
the scope of this (already quite long) paper.</p>
<p>到目前为止，我们还是主要从直观上理解子类型，避免了更明确的表述。在这一节中，我们通过提供一个基于语法的的最小子类型关系的形式化表述，使我们的直观理解更加正式，以使第3节的类型推断算法是可靠和完整的（sound
and
complete）。我们陈述相应的定理并概要说明如何进行证明。完整的证明超出了本文（已经介绍了相当长）的范围。</p>
<p><span class="math display">\[
\text{S-REFL}
\quad
\frac{}{\tau \leq \tau}
\]</span></p>
<p><span class="math display">\[
\text{S-TRANS}
\quad
\frac{
  \Sigma \vdash \tau_0 \leq \tau_1 \quad \Sigma \vdash \tau_1 \leq
\tau_2
}{
  \Sigma \vdash \tau_0 \leq \tau_2
}
\]</span></p>
<p><span class="math display">\[
\text{S-WEAKEN}
\quad
\frac{H}{\Sigma \vdash H}
\]</span></p>
<p><span class="math display">\[
\text{S-ASSUM}
\quad
\frac{\Sigma, \triangleright H \vdash H}{\Sigma \vdash H}
\]</span></p>
<p><span class="math display">\[
\text{S-HYP}
\quad
\frac{H \in \Sigma}{\Sigma \vdash H}
\]</span></p>
<p><span class="math display">\[
\text{S-REC}
\quad
\frac{}{\mu\alpha.\,\tau \equiv [\mu\alpha.\,\tau / \alpha]\tau}
\]</span></p>
<p><span class="math display">\[
\text{S-OR}
\quad
\frac{
  \forall i, \exists j,\ \Sigma \vdash \tau_i \leq \tau&#39;_j
}{
  \Sigma \vdash \bigsqcup_i \tau_i \leq \bigsqcup_j \tau&#39;_j
}
\]</span></p>
<p><span class="math display">\[
\text{S-AND}
\quad
\frac{
  \forall i, \exists j,\ \Sigma \vdash \tau_j \leq \tau&#39;_i
}{
  \Sigma \vdash \bigcap_j \tau_j \leq \bigcap_i \tau&#39;_i
}
\]</span></p>
<p><span class="math display">\[
\text{S-FUN}
\quad
\frac{
  \triangleleft\Sigma \vdash \tau_0 \leq \tau_1 \quad
\triangleleft\Sigma \vdash \tau_2 \leq \tau_3
}{
  \Sigma \vdash \tau_1 \to \tau_2 \leq \tau_0 \to \tau_3
}
\]</span></p>
<p><span class="math display">\[
\text{S-RCD}
\quad
\frac{}{
  \{ l_i : t_i \}^i \equiv \bigcap_i \{ l_i : t_i \}
}
\]</span></p>
<p><span class="math display">\[
\text{S-DEPTH}
\quad
\frac{
  \triangleleft\Sigma \vdash \tau_1 \leq \tau_2
}{
  \Sigma \vdash \{ l : \tau_1 \} \leq \{ l : \tau_2 \}
}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp;\triangleleft(\Sigma, H) = \triangleleft\Sigma, H \\
&amp;\triangleleft(\Sigma, \triangleright H) = \triangleleft\Sigma, H \\
&amp;\triangleleft\epsilon = \epsilon
\end{aligned}
\]</span></p>
<p>Fig. 10. Declarative subtyping rules of Simple-sub. These only cover
part of the relationships present in Dolan’s algebraic construction of
types [Dolan 2017]. More subtyping rules can be added to give desirable
properties to the system (such as distributivity of unions,
intersections, and type constructors), but they are not strictly
required for principal type inference. Note that by convention, we
consider that an empty union is ⊥ and an empty intersection is T, so
these rules cover things like int ≤ T.</p>
<p>图10. Simple-sub
的声明性子类型规则。这些仅涵盖了Dolan的类型代数构造中存在的关系的一部分[Dolan
2017]。可以添加更多的子类型规则，以赋予系统所需的特性（例如，并集、交集和类型构造子的分配性），但这些对于主类型推断并不严格必要。请注意，根据约定，我们认为空并集是⊥，空交集是T，因此这些规则涵盖了
int ≤ T 这样的情况。</p>
<p>We restrict ourselves to the non-let-polymorphic version of
Simple-sub for simplicity.<a href="#fn26" class="footnote-ref"
id="fnref26" role="doc-noteref"><sup>26</sup></a></p>
<p>我们仅讨论 Simple-sub 的非 let-多态 版本，以简化问题。<a href="#fn27"
class="footnote-ref" id="fnref27"
role="doc-noteref"><sup>27</sup></a></p>
<p>译者注：这里先不要太在意这里的三角形符号和Σ，后面会详细介绍</p>
<h2 id="a-syntax-first-definition-of-subtyping">5.1 A Syntax-First
Definition of Subtyping</h2>
<h2 id="子类型的语法优先定义">5.1 子类型的语法优先定义</h2>
<p>Figure 10 presents the minimal subtyping rules necessary to perform
sound and complete type inference in Simple-sub. The general subtyping
judgement has the form <span class="math inline">\(Σ \vdash τ_0 ≤
τ_1\)</span> and includes a subtyping context <span
class="math inline">\(Σ\)</span> made of subtyping hypotheses of the
form <span class="math inline">\(τ_2 ≤ τ_3\)</span>, possibly prefixed
with a <span class="math inline">\(▷\)</span> symbol. We use <span
class="math inline">\(Σ \vdash τ_0 ≡ τ_1\)</span> as a shorthand for
<span class="math inline">\(Σ \vdash τ_0 ≤ τ_1 ∧ Σ \vdash τ_1 ≤
τ_0\)</span>. When <span class="math inline">\(Σ\)</span> is empty, we
omit the <span class="math inline">\(Σ \vdash\)</span> and just write
<span class="math inline">\(τ_0 ≤ τ_1\)</span> and <span
class="math inline">\(τ_0 ≡ τ_1\)</span>.</p>
<p>图 10 展示了在 Simple-sub
中执行完善和完整类型推断所需的最小子类型规则。一般的子类型判断形式为
<span class="math inline">\(Σ \vdash τ_0 ≤
τ_1\)</span>，并包含由子类型假设构成的子类型上下文 <span
class="math inline">\(Σ\)</span>，假设的形式为 <span
class="math inline">\(τ_2 ≤ τ_3\)</span>，可能以 <span
class="math inline">\(▷\)</span> 符号为前缀。我们使用 <span
class="math inline">\(Σ \vdash τ_0 ≡ τ_1\)</span> 作为 <span
class="math inline">\(Σ \vdash τ_0 ≤ τ_1 ∧ Σ \vdash τ_1 ≤ τ_0\)</span>
的简写。当 <span class="math inline">\(Σ\)</span> 为空时，我们省略 <span
class="math inline">\(Σ \vdash\)</span>，只写 <span
class="math inline">\(τ_0 ≤ τ_1\)</span> 和 <span
class="math inline">\(τ_0 ≡ τ_1\)</span>。</p>
<p>Note that Figure 10 only presents a subset of all the rules one may
want in an actual system. In particular, type simplification and
subsumption checking (to determine whether one type signature is at
least as general as another) require rules to merge type constructors
like function types, so that for instance the equivalence <span
class="math inline">\((τ_0 → τ_1) ∩ (τ_2 → τ_3) ≡ τ_0 ∪ τ_1 → τ_2 ∩
τ_3\)</span> holds (see the related discussion in Section 4.1). On the
other hand, we do not expect rules like distributivity of unions over
intersections to be actually useful in a pure MLsub-style system, since
unions and intersections are normally kept separate (unions occurring
strictly positively, and intersections strictly negatively); however,
they could come in useful in a generalized system.</p>
<p>请注意，图10仅呈现了在实际系统中可能需要的所有规则的一个子集。特别是，类型简化和子类型检查（以确定一个类型签名是否至少和另一个类型签名一样一般）需要规则来合并类型构造器，如函数类型，因此例如等式
<span class="math inline">\((τ_0 → τ_1) ∩ (τ_2 → τ_3) ≡ τ_0 ∪ τ_1 → τ_2
∩ τ_3\)</span>
成立（参见第4.1节中的相关讨论）。另一方面，我们不希望如交集上的并集的分配律这样的规则在纯MLsub风格的系统中实际上有用，因为并集和交集通常保持分开（并集严格正向出现，交集严格负向出现）；但是，在一个广义系统中，它们可能会有用。</p>
<h3 id="subtyping-recursive-types.">5.1.1 Subtyping Recursive
Types.</h3>
<h3 id="子类型递归类型">5.1.1 子类型递归类型</h3>
<p>A consequence of our syntactic account of subtyping is that we do not
define types as some fixed point over a generative relation, as done in,
e.g., [Dolan 2017; Pierce 2002]. Instead, we have to account for the
fact that we manipulate <em>finite</em> syntactic type trees, in which
recursive types have to be manually unfolded to derive things about
them. This is the purpose of the S-REC rule, which substitutes a
recursive types within itself to expose one layer of its underlying
definition. However, as remarked by Amadio and Cardelli [1993], the
S-REC rule alone is not sufficient to derive valid inequalities like
<span class="math inline">\(μα_0. τ → τ → α_0 ≤ μα_1. τ → α_1\)</span>
because these types, although equivalent, never unfold to the precise
same syntactic representation. This motivates the next paragraph.</p>
<p>使用我们这种子类型的语法描述的一个结果是，我们并不将类型定义为一些生成关系上的不动点，如在MLsub原文[Dolan
2017；Pierce
2002]中所做的那样。相反，我们必须考虑到我们操控的是<em>有限</em>的语法类型树，其中递归类型必须手动展开以推导出关于它们的信息。这就是S-REC规则的目的，它在自身内部替换递归类型，以揭示其基本定义的一层。然而，正如Amadio和Cardelli
[1993]所指出的，单独的S-REC规则不足以推导出有效的不等式，例如<span
class="math inline">\(μα_0. τ → τ → α_0 ≤ μα_1. τ →
α_1\)</span>，因为这些类型虽然是等价的，但从未展开成完全相同的语法表示。这启发了下一段中描述的方法。</p>
<p>译者注：我们看S-Rec规则： <span
class="math inline">\(\mu\alpha.\,\tau \equiv [\mu\alpha.\,\tau /
\alpha]\tau\)</span> 左边是递归类型的定义，表示变量 <span
class="math inline">\(\alpha\)</span> 等价于右边的表达式 <span
class="math inline">\(\tau\)</span> （而 <span
class="math inline">\(\tau\)</span> 通常里面也带着变量 <span
class="math inline">\(\alpha\)</span>
）。这个规则的意义就是，可以把递归类型的右侧的 <span
class="math inline">\(\tau\)</span> 里面的变量 <span
class="math inline">\(\alpha\)</span>
的出现都替换为整个递归类型。例如，对于递归变量 <span
class="math inline">\(μα_1. \text{int} → α_1\)</span> 我们取右侧 <span
class="math inline">\(\text{int} → α_1\)</span> 然后把里面的 <span
class="math inline">\(α_1\)</span> 替换为一开始的整个递归类型，得到
<span class="math inline">\(\text{int} → (μα_1. \text{int} →
α_1)\)</span> 。这就是递归类型展开了一层。</p>
<p>5.1.2 <em>Subtyping Hypotheses.</em> We make use of the environment Σ
to store subtyping hypotheses, to be leveraged later using the S-HYP
rule. We have to be careful not to allow the use of a hypothesis right
after assuming it, which would obviously make the system unsound. In the
specification of their constraint solving algorithm, Hosoya et al.
[2005] use two distinct judgments ⊢ and ⊢' to distinguish from places
where the hypotheses can or cannot be used. We take a different, but
related approach. Our S-Assum subtyping rule resembles the Löb rule
described by Appel et al. [2007], which uses the “later” modality ▷ in
order to delay the applicability of hypotheses — by placing this symbol
in front of the hypothesis being assumed, we prevent its immediate usage
by S-HYP. We eliminate ▷ when passing through a function or record
constructor, using ◁ to remove all ▷ occurrences from the set of
hypotheses, thereby unlocking them for use by S-HYP.</p>
<p>5.1.2 <em>子类型假设。</em> 我们利用环境 Σ
来存储子类型假设，以便稍后通过 S-HYP
规则使用。我们必须小心不要在假设某条件后立即使用该假设的条件，这显然会导致系统的不完善（即任何条件都能够成立）。在他们的约束求解算法的规范中，Hosoya
等人 [2005] 使用两个不同的判断 ⊢ 和 ⊢'
来区分可以使用和不能使用假设的地方。我们采取一种不同但相关的方法。我们的
S-Assum 子类型规则类似于 Appel 等人 [2007] 所描述的 Löb
规则，它使用“later”模态 ▷
来延迟假设的适用性——通过将此符号放在假设前面，我们防止其被 S-HYP
立即使用。我们在通过函数或结构体构造函数时消除 ▷，使用 ◁
从假设集中移除所有 ▷ 出现，从而解锁它们以供 S-HYP 使用。</p>
<p>译者注：这里的假设主要处理递归类型。假设会在函数或者结构体的时候被移除。</p>
<p>These precautions reflect the “guardedness” restrictions used by
Dolan [2017] on recursive types, which prevents usages of α that are not
guarded by → or { ... } in a recursive type <span
class="math inline">\(µα. τ\)</span>. By contrast, our restriction is
not a syntactic one, and contrary to Dolan we do allow types like <span
class="math inline">\(µα. α\)</span> — this type unfolds into itself by
S-REC — and µα. α ∩ α, about which no useful assumptions can be
leveraged, since they never go through a function or record
constructor.</p>
<p>这些预防措施反映了Dolan
[2017]对递归类型使用的“guardedness”限制，这防止了在递归类型µα.
τ中使用未被→或{...}保护的α。相比之下，我们的限制不是一个语法上的限制，与Dolan不同，我们确实允许像
<span class="math inline">\(µα. α\)</span>
这样的类型——这个类型通过S-REC展开成它自己——以及 <span
class="math inline">\(µα. α ∩ α\)</span>
，关于这些类型没有可用的有用假设，因为它们从未经过一层函数或结构体构造器（定义的假设还处于不可用状态）。</p>
<p>译者注：MLsub中介绍了类型的guardedness属性，这是一个语法上的约束，确保递归类型都有唯一的不动点，即无限展开后有唯一的形式。guardedness要求，简单来说就是，要求变量躲在结构体或者函数里面。
<span class="math inline">\(µα. α\)</span>
这种就是不符合guardness的。但是MLsub中也可以处理不符合guardedness要求的变量，通过把不符合要求的部分，即没有躲在结构体或者函数里面的变量（通常是，变量直接通过
<span class="math inline">\(\sqcup\)</span> 或者 <span
class="math inline">\(\sqcap\)</span> 连接）给直接去掉。</p>
<p>5.1.3 <em>Example.</em> As an example, let us try to derive the
following inequality, which states that the type of a function taking
two curried <span class="math inline">\(τ\)</span> arguments an
arbitrary number of times is a <em>special case</em> of the type of a
function taking a single <span class="math inline">\(τ\)</span> argument
an arbitrary number of times:</p>
<p>5.1.3 <em>示例.</em>
作为一个例子，让我们尝试推导以下不等式，它指出一个函数接受两个柯里化
<span class="math inline">\(τ\)</span>
参数任意次数的类型是一个函数接受单个 <span
class="math inline">\(τ\)</span> 参数任意次数的类型的<em>特例</em>：</p>
<p><span class="math display">\[
\mu\alpha_0. \tau \to \tau \to \alpha_0 \le \mu\alpha_1. \tau \to
\alpha_1
\]</span></p>
<p>To facilitate the development, we use the shorthands τ₀ = μα₀. τ → τ
→ α₀; τ₁ = μα₁. τ → α₁; and H = τ₀ ≤ τ₁. We start by deriving that the
respective unfoldings of the recursive types are subtypes; that is, that
τ → τ → τ₀ ≤ τ → τ₁ (1). Note that for conciseness, we omit the
applications of S-WEAKEN in the derivations below:</p>
<p>为了方便构建，我们使用简写 <span class="math inline">\(τ₀ = μα₀. τ →
τ → α₀; τ₁ = μα₁. τ → α₁\)</span> ; 以及 <span class="math inline">\(H =
τ₀ ≤ τ₁\)</span> 。我们开始推导递归类型的相应展开是子类型；也就是说，
<span class="math inline">\(τ → τ → τ₀ ≤ τ → τ₁\)</span> (1)
。请注意，为了简洁，我们在下面的推导中省略了S-WEAKEN的应用：</p>
<p><span class="math display">\[
\text{Fun} \quad
\dfrac{
  \text{Refl} \quad \dfrac{}{H \vdash \tau \leq \tau}
  \quad
  \dfrac{
    \text{Fun}
    \quad
    \dfrac{
      \text{Refl}
      \quad
      \dfrac{}{H \vdash \tau \to \tau_0 \leq \tau \to \tau_1}
      \quad
      \dfrac{(\tau_0 \leq \tau_1) \in H}{H \vdash \tau_0 \leq \tau_1}
      \quad
      \text{Hyp}
    }{
      H \vdash \tau \to \tau_0 \leq \tau \to \tau_1
    }
    \quad
    \dfrac{}{
      H \vdash \tau \to \tau_1 \leq \tau_1
    }
    \quad \text{Rec}
  }{
    H \vdash \tau \to \tau_0 \leq \tau_1
  }
  \quad
  \text{Trans}
}{
  \triangleright H \vdash \tau \to \tau \to \tau_0 \leq \tau \to \tau_1
\quad (1)
}
\]</span></p>
<p>Then, we simply have to fold back the unfolded recursive types, using
<em>REC</em> and <em>TRANS</em>:</p>
<p>然后，我们只需使用 <em>REC</em> 和 <em>TRANS</em>
将展开的递归类型折叠回去：</p>
<p><span class="math display">\[
\text{Assum}
\quad
\dfrac{
  \text{Trans}
  \quad
  \dfrac{
    \text{Trans}
    \quad
    \dfrac{
      \text{Rec} \quad \dfrac{}{\triangleright H \vdash \tau_0 \leq \tau
\to \tau \to \tau_0 \quad (1)}
    }{\triangleright H \vdash \tau_0 \leq \tau \to \tau_1}
    \quad
    \dfrac{}{\triangleright H \vdash \tau \to \tau_1 \leq \tau_1}
    \quad
    \text{Rec}
  }{
    \triangleright H \vdash \tau_0 \leq \tau_1
  }
}{\tau_0 \leq \tau_1}
\]</span></p>
<p>译者注：这里的什么假设相关的，主要是涉及递归类型。其实有点像是数学归纳法，先假设结论成立，然后尝试推理一步，但是这里是要求证明过程，至少应用了一次函数或者结构体。</p>
<p>译者注：我们从错误的结论出发，看看假设相关的定理。比如我们假设
<code>H = int ≤ bool</code> 这明显是错误的。 因此我们有
<code>Σ = &#123;▷(int ≤ bool)&#125;</code>
其中▷表示这个假设还不能用。然后我们应用一下 S-Fun
函数相关的规则，因为它可以移除假设的限制，让它可以被使用，比如尝试证明
<code>τ → int ≤ τ → bool</code> 我们有</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int ≤ bool ∈ ◁Σ</span><br><span class="line">--------------- (S-Hyp)</span><br><span class="line">◁Σ ⊢ int ≤ bool</span><br><span class="line"></span><br><span class="line">⊢ τ ≤ τ, ◁Σ ⊢ int ≤ bool</span><br><span class="line">------------------------- (S-Fun)</span><br><span class="line">Σ ⊢ τ → int ≤ τ → bool</span><br></pre></td></tr></table></figure>
<p>◁运算会去掉所有假设的不可用标记，让我们的假设变得可以使用，因此，我们有
<code>◁Σ ⊢ int ≤ bool</code>（S-Hyp），因此利用它可以推导出
<code>Σ ⊢ τ → int ≤ τ → bool</code>, 其中
<code>Σ = &#123;▷(int ≤ bool)&#125;</code>
。这里▷表示假设还不能用。可以发现，我们的结论带有原来的条件，而且条件还是带有不可用标记，更不是无条件的
<code>⊢ τ → int ≤ τ → bool</code>。</p>
<p>我们需要仔细观察S-Assum，它负责将某个假设从条件中移除。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Σ, ▷H ⊢ H</span><br><span class="line">---------- (S-ASSUM)</span><br><span class="line">    Σ ⊢ H</span><br></pre></td></tr></table></figure>
<p>比如，我们让这里的Σ等于空集，那么下面就是H无条件成立，上面就是只有一条（暂时无法使用的）假设H下证明自身H，那么就可以证明H无条件成立。如果之前，S-Fun的横线下的结论部分改成<code>▷Σ</code>的话，我们就可以用S-Assum得到无条件的成立了。但是，前面所有定理的结论部分都没有▷标记。因此，这里是无法证明
<code>int ≤ bool</code> 是无条件成立的。</p>
<p>仔细观察S-Fun，可以总结：如果尝试从上到下应用，假设依然是不成立的，但是如果</p>
<p>可以发现，只有在假设的情况下证明自身才可以移除条件，变成无条件的成立。什么时候能证明出自身呢？自然是这种递归类型，能够无限创造出外层结构体和函数的情况。</p>
<p>我们再看回原文的例子：我们要证明 <span class="math inline">\(\tau_0
\leq \tau_1\)</span>
只需要证明在它作为不可用假设的时候，它自身成立。根据各自递归类型的定义，我们有
<span class="math inline">\(\tau_0 \leq \tau \to \tau \to
\tau_0\)</span> 和 <span class="math inline">\(\tau \to \tau_1 \leq
\tau_1\)</span> 根据传递性，我们只需要证明能够把中间连起来 <span
class="math inline">\(\tau \to \tau \to \tau_0 \leq \tau \to
\tau_1\)</span>。我们利用S-Func从两边去掉函数的一层的时候，假设就可以从结论到前提，变得可用。</p>
<h2 id="simplified-algorithms-and-mutability">5.2 Simplified Algorithms
and Mutability</h2>
<h2 id="简化算法与可变性">5.2 简化算法与可变性</h2>
<p>For ease of formal reasoning, we use a simpler definition of type
coalescing, shown in Figure 11. In this definition, we refer to
TypeVariable(vs.uniqueName) as <span
class="math inline">\(\alpha_{vs}\)</span>, and we use <span
class="math inline">\(\alpha_{vs}^{+}\)</span> and <span
class="math inline">\(\alpha_{vs}^{-}\)</span> to denote two additional
(distinct) unique names, to be used as positive and negative recursive
occurrence binders — they serve the purpose of
<code>freshVar.uniqueName</code> in the version of type coalescing shown
in Section 3.3. Similarly, it is possible to give a simpler (but less
efficient) definition of the constrain function using immutable data
structures instead of mutable ones, which is easily proven equivalent;
we do not show this simpler version here for lack of space, but assume
its existence.</p>
<p>为了方便形式推理，我们对类型聚合（type
coalescing）采取一种更简单的定义，见图11。在这个定义中，我们将
TypeVariable 即(vs.uniqueName) 称为 <span
class="math inline">\(\alpha_{vs}\)</span>，并用 <span
class="math inline">\(\alpha_{vs}^{+}\)</span> 和 <span
class="math inline">\(\alpha_{vs}^{-}\)</span>
来表示两个额外的（不同的）唯一名字，作为正递归出现绑定器和负递归出现绑定器——它们在类型聚合的版本中起着
<code>freshVar.uniqueName</code>
的作用，如第3.3节所示。类似地，可以使用不可变数据结构而不是可变数据结构给出约束函数的更简单（但效率较低）定义，这很容易证明是等价的；由于篇幅有限，我们在这里不展示这个更简单的版本，但假设它的存在。</p>
<p><span class="math display">\[
\mathbf{E}^{\phi}_{\sigma}[\![\mathrm{Primitive}(n)]\!]\,C = n
\]</span></p>
<p><span class="math display">\[
\mathbf{E}^{\phi}_{\sigma}[\![\mathrm{Function}(s,t)]\!]\,C =
\mathbf{E}^{-\phi}_{\sigma}[\![s]\!]\,C \to
\mathbf{E}^{\phi}_{\sigma}[\![t]\!]\,C
\]</span></p>
<p><span class="math display">\[
\mathbf{E}^{\phi}_{\sigma}[\![\mathrm{Record}(fs)]\!]\,C = {\Large
\mathop ⨅}_{(n,t)\,\in\,fs} \{ n :
\mathbf{E}^{\phi}_{\sigma}[\![t]\!]\,C \}
\]</span></p>
<p><span class="math display">\[
\mathbf{E}^{-}_{\sigma}[\![\mathrm{Variable}(vs)]\!]\,C =
\alpha^{-}_{vs}
\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\text{if
} (vs, -) \in C
\]</span></p>
<p><span class="math display">\[
\mathbf{E}^{-}_{\sigma}[\![\mathrm{Variable}(vs)]\!]\,C =
\mu\alpha^{-}_{vs}.\,\alpha_{vs} \cap {\Large \mathop
⨅}_{u\in\mathrm{ub}^{vs}_{\sigma}} \mathbf{E}^{-}_{\sigma}[\![u]\!]\,(C
\cup \{(vs, -)\}) \quad\quad\text{if } (vs, -) \notin C
\]</span></p>
<p><span class="math display">\[
\mathbf{E}^{+}_{\sigma}[\![\mathrm{Variable}(vs)]\!]\,C =
\alpha^{+}_{vs}
\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\text{if
} (vs, +) \in C
\]</span></p>
<p><span class="math display">\[
\mathbf{E}^{+}_{\sigma}[\![\mathrm{Variable}(vs)]\!]\,C =
\mu\alpha^{+}_{vs}.\,\alpha_{vs} \cup
\bigsqcup_{l\in\mathrm{lb}^{vs}_{\sigma}}
\mathbf{E}^{+}_{\sigma}[\![l]\!]\,(C \cup \{(vs, +)\})
\quad\quad\text{if } (vs, +) \notin C
\]</span></p>
<p>Fig. 11. Type coalescing, where the metavariable φ is either + or −
and ¬(+) = − and ¬(−) = +.</p>
<p>图 11. 类型聚合，其中元变量 φ 是 + 或 −，并且 ¬(+) = − 和 ¬(−) =
+。</p>
<p>The only mutability left in the simplified algorithms is the
mutability of type variable bounds. We refer to these bounds
collectively as <span class="math inline">\(σ\)</span> , which maps each
<code>VariableState</code> instance to its current upper and lower
bounds. We write <span
class="math inline">\(\text{foo}(\text{args})_{\sigma}
\Downarrow_{\sigma&#39;}\)</span> res to denote the execution of some
function foo given bounds <span class="math inline">\(σ\)</span> and
having the effect of producing the new bounds <span
class="math inline">\(σ&#39;\)</span> . We use the shorthand <span
class="math inline">\(\text{lb}^{\text{vs}}_\sigma\)</span> for <span
class="math inline">\(\text{vs.lowerBounds}_\sigma\)</span> and <span
class="math inline">\(\text{ub}^{\text{vs}}_\sigma\)</span> for <span
class="math inline">\(\text{vs.upperBounds}_\sigma\)</span>.</p>
<p>在简化算法中唯一剩下的可变性是类型变量边界的可变性。我们将这些边界统称为
<span class="math inline">\(σ\)</span> ，它将每个
<code>VariableState</code> 实例映射到其当前的上界和下界。我们写 <span
class="math inline">\(\text{foo}(\text{args})_{\sigma}
\Downarrow_{\sigma&#39;}\)</span> res 来表示在给定边界 <span
class="math inline">\(σ\)</span> 的情况下执行某个函数
foo，并产生新的边界 <span class="math inline">\(σ&#39;\)</span>
。我们使用简写 <span
class="math inline">\(\text{lb}^{\text{vs}}_\sigma\)</span> 表示 <span
class="math inline">\(\text{vs.lowerBounds}_\sigma\)</span> ， <span
class="math inline">\(\text{ub}^{\text{vs}}_\sigma\)</span> 表示 <span
class="math inline">\(\text{vs.upperBounds}_\sigma\)</span> 。</p>
<h2 id="soundness-and-completeness">5.3 Soundness and Completeness</h2>
<h2 id="完善性与完整性">5.3 完善性与完整性</h2>
<p>Our theorems of interest are the <em>soundness</em> and
<em>completeness</em> of Simple-sub:</p>
<p>我们关注的定理是 Simple-sub 的<em>完善性</em>和<em>完整性</em>：</p>
<p>THEOREM 1 (Soundness). Simple-sub only yields types which comply with
the declarative type system: if <span
class="math inline">\(\text{typeTerm}(t)(\text{empty})_\emptyset
\Downarrow_\sigma \text{st}\)</span> for some <span
class="math inline">\(\text{st}\)</span> and <span
class="math inline">\(\sigma\)</span>, then there exists a type <span
class="math inline">\(\tau\)</span> such that <span
class="math inline">\(\vdash t : \tau\)</span> and <span
class="math inline">\(\tau \leq^\forall
\mathbf{E}^+_\sigma[\![\text{st}]\!]\)</span>.</p>
<p>定理 1（完善性）。Simple-sub 仅产生与描述性类型系统相符的类型：如果
<span class="math inline">\(\text{typeTerm}(t)(\text{empty})_\emptyset
\Downarrow_\sigma \text{st}\)</span> 对于某些 <span
class="math inline">\(\text{st}\)</span> 和 <span
class="math inline">\(\sigma\)</span> 成立，则存在一个类型 <span
class="math inline">\(\tau\)</span>，使得 <span
class="math inline">\(\vdash t : \tau\)</span> 且 <span
class="math inline">\(\tau \leq^\forall
\mathbf{E}^+_\sigma[\![\text{st}]\!]\)</span> 。</p>
<p>THEOREM 2 (Completeness). Simple-sub always finds principal type
schemes: if <span class="math inline">\(\vdash t : \tau\)</span>, then
<span class="math inline">\(\mathrm{typeTerm}(t)(\mathrm{empty})_0
\Downarrow_\sigma \mathrm{st}\)</span> for some <span
class="math inline">\(\mathrm{st}\)</span> and <span
class="math inline">\(\sigma\)</span>, and <span
class="math inline">\(\mathbf{E}^+_\sigma[\![\mathrm{st}]\!]
\leq^\forall \tau\)</span>.</p>
<p>定理 2（完整性）。Simple-sub 始终找到主类型方案：如果 <span
class="math inline">\(\vdash t : \tau\)</span>，则存在某些 <span
class="math inline">\(\mathrm{st}\)</span> 和 <span
class="math inline">\(\sigma\)</span> ，使得 <span
class="math inline">\(\mathrm{typeTerm}(t)(\mathrm{empty})_0
\Downarrow_\sigma \mathrm{st}\)</span> ，以及 <span
class="math inline">\(\mathbf{E}^+_\sigma[\![\mathrm{st}]\!]
\leq^\forall \tau\)</span> 。</p>
<h3 id="soundness.">5.3.1 Soundness.</h3>
<h3 id="完善性">5.3.1 完善性</h3>
<p>As usual, proving the theorem requires proving a more general
lemma.</p>
<p>与往常一样，证明该定理需要证明一个更一般的引理。</p>
<p>We use <em>unifying type coalescing</em> (Figure 12) — a variant of
type coalescing which allows proving the soundness lemmas more easily.
The crucial property of unifying coalescing is that it instantiates each
type variable <span class="math inline">\(\alpha_{vs}\)</span> in a way
that makes the positive coalescing of vs a subtype of its negative
coalescing, as long as all lower bounds of vs are subtypes of all its
upper bounds — i.e., its bounds are <em>consistent</em>. We also denote
by <span class="math inline">\(\vdash_{\text{cons}}\sigma\)</span> the
fact that the bounds of all variables in <span
class="math inline">\(σ\)</span> are consistent.</p>
<p>我们使用 <em>unifying type coalescing</em>（图12）——
一种类型聚合的变体，允许更容易地证明完善性引理。合并聚合的关键性质是，它以一种方式实例化每个类型变量
<span class="math inline">\(\alpha_{vs}\)</span>，使得 vs
的正聚合是其负聚合的子类型，只要 vs 的所有下界都是其所有上界的子类型 ——
即，它的界限是 <em>一致</em> 的。我们还用 <span
class="math inline">\(\vdash_{\text{cons}}\sigma\)</span> 表示 <span
class="math inline">\(σ\)</span> 中所有变量的界限是一致的事实。</p>
<p><strong>Lemma 1 (Soundness — General).</strong> Assuming <span
class="math inline">\(\vdash_{\text{cons}} \sigma\)</span> and <span
class="math inline">\(\text{typeTerm}(t)(\text{ctx})_\sigma
\Downarrow_{\sigma&#39;} \text{st}\)</span>, then <span
class="math inline">\(\vdash_{\text{cons}} \sigma&#39;\)</span> and
<span
class="math inline">\(\mathcal{E}^-_{\sigma&#39;}[\![\text{ctx}]\!]
\vdash t : \mathcal{E}^-_{\sigma&#39;}[\![\text{st}]\!]\)</span>.</p>
<p><strong>引理1（完善性 — 一般地）</strong>。 假设 <span
class="math inline">\(\vdash_{\text{cons}} \sigma\)</span> 且 <span
class="math inline">\(\text{typeTerm}(t)(\text{ctx})_\sigma
\Downarrow_{\sigma&#39;} \text{st}\)</span>，则 <span
class="math inline">\(\vdash_{\text{cons}} \sigma&#39;\)</span> 且 <span
class="math inline">\(\mathcal{E}^-_{\sigma&#39;}[\![\text{ctx}]\!]
\vdash t : \mathcal{E}^-_{\sigma&#39;}[\![\text{st}]\!]\)</span></p>
<p>The proof is by induction on the executions of typeTerm, assuming
that typeTerm terminates successfully. In the process, we need a number
of auxiliary lemmas, most of which we do not show here. The core of the
proof actually resides in the proof of <em>sound constraining</em>
(Lemma 2).</p>
<p>证明的过程是通过对 typeTerm 应用归纳法，假设 typeTerm
成功终止。在此过程中，我们需要几个辅助引理，其中大部分在这里不展示。证明的核心实际上在于
<em>sound constraining</em> 的证明（引理2）。</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{E}_\sigma^-[\mathrm{Variable}(vs)]\,C &amp;= \mu\alpha_{vs}^-.
{\Large \mathop ⨅}_{u \in \mathrm{ub}^{vs}_\sigma}
\mathcal{E}_\sigma^-[\![u]\!]\,(C \cup \{(vs, -)\}) &amp; \text{if }
(vs, -) \notin C \\
\mathcal{E}_\sigma^+[\mathrm{Variable}(vs)]\,C &amp;= \mu\alpha_{vs}^+.
\mathcal{E}_\sigma^-[\mathrm{Variable}(vs)]\,C \cup \bigsqcup_{l \in
\mathrm{lb}_\sigma^{vs}} \mathcal{E}_\sigma^+[\![l]\!]\,(C \cup \{(vs,
+)\}) &amp; \text{if } (vs, +) \notin C
\end{aligned}
\]</span></p>
<p>Fig. 12. Unifying type coalescing. All other cases are exactly like
in Figure 11, and are omitted.</p>
<p>图12. 合并类型聚合。其他所有情况与图11完全相同，故省略。</p>
<p><strong>Lemma 2 (Soundness of Constraining).</strong> <em>When it
succeeds, constraining in consistent bounds ensures that the bounds
remain consistent and the coalescing of the constrained types become
subtypes: if <span class="math inline">\(\vdash_{\text{cons}}
\sigma\)</span> and constrain(st₀, st₁)ₐ <span
class="math inline">\(\Downarrow\)</span> <em>σ'</em> (), then <span
class="math inline">\(\vdash_{\text{cons}} \sigma&#39;\)</span> and
<span class="math inline">\(\mathcal{E}_{\sigma&#39;}^-[st₀] \le
\mathcal{E}_{\sigma&#39;}^+[st₁]\)</span>.</em></p>
<p><strong>引理2（约束的完善性）。</strong>
<em>当成功时，在一致的界限内进行约束确保界限保持一致，且被约束类型的聚合变为子类型：如果
<span class="math inline">\(\vdash_{\text{cons}} \sigma\)</span> 且
constrain(st₀, st₁)ₐ <span class="math inline">\(\Downarrow\)</span>
<em>σ'</em> ()，那么 <span class="math inline">\(\vdash_{\text{cons}}
\sigma&#39;\)</span> 且 <span
class="math inline">\(\mathcal{E}_{\sigma&#39;}^-[st₀] \le
\mathcal{E}_{\sigma&#39;}^+[st₁]\)</span>.</em></p>
<p>This is proven by induction on executions of the constraining calls.
We actually need a stronger induction hypothesis, which relates the
subtyping context <span class="math inline">\(\Sigma\)</span> with the
constraining cache, talks precisely about the bounds introduced by each
call, and states that existing subtyping relations between coalesced
types are not altered by further constraining calls. The <em>Variable
cases</em> are quite subtle; when we insert the new bound into the
variable’s state, we temporarily break the consistency of the variable’s
bounds, but we restore it as an effect of the following recursive calls
to propagate the bound. To apply the induction on these recursive calls,
we need to loosen the “consistent bounds” premise of the hypothesis,
making an exception for those variables which appear as part of the
current constraining cache, thus allowing the calls to happen in
partially-broken bounds.</p>
<p>这通过对约束调用执行的归纳证明。我们实际上需要一个更强的归纳假设，它将子类型上下文
<span class="math inline">\(\Sigma\)</span>
与约束缓存相关联，准确地讨论每个调用引入的界限，并声明已聚合类型之间的现有子类型关系不受进一步约束调用的影响。<em>变量情况</em>非常微妙；当我们将新界限插入变量的状态时，我们暂时打破了变量界限的一致性，但我们会在后续递归调用中恢复它，以传播该界限。为了对这些递归调用应用归纳，我们需要放宽假设中的“一致界限”前提，对那些作为当前约束缓存一部分出现的变量作出例外，从而允许在部分破坏的界限中进行调用。</p>
<h3 id="completeness.">5.3.2 Completeness.</h3>
<h3 id="完整性">5.3.2 完整性。</h3>
<p>Completeness is proven through the following more general lemma:</p>
<p>完整性通过以下更一般的引理证明：</p>
<p><strong>Lemma 3 (Completeness — GENERAL).</strong> *Assuming <span
class="math inline">\(\Gamma \vdash t : \tau\)</span>, then for all
<span class="math inline">\(ctx\)</span>, <span
class="math inline">\(\sigma\)</span>, and type-variable substitution
<span class="math inline">\(\rho\)</span>, if <span
class="math inline">\(\rho(E_\sigma^-[ctx]) \equiv \Gamma\)</span> then
typeTerm(t)(ctx)ₐ <span class="math inline">\(\Downarrow\)</span> _σ'_st
for some st and <span class="math inline">\(\sigma&#39;\)</span>, and
there exists a substitution <span
class="math inline">\(\rho&#39;\)</span> such that <span
class="math inline">\(\rho&#39;(E_{\sigma&#39;}^-[ctx]) \equiv
\Gamma\)</span> and <span
class="math inline">\(\rho&#39;(E_{\sigma&#39;}^+[st]) \le
\tau\)</span>.*</p>
<p><strong>引理 3 (完备性 — 一般地).</strong> *假设 <span
class="math inline">\(\Gamma \vdash t : \tau\)</span>，则对于所有 <span
class="math inline">\(ctx\)</span>、<span
class="math inline">\(\sigma\)</span> 和类型变量替换 <span
class="math inline">\(\rho\)</span>，如果 <span
class="math inline">\(\rho(E_\sigma^-[ctx]) \equiv \Gamma\)</span>，则
typeTerm(t)(ctx)ₐ <span class="math inline">\(\Downarrow\)</span> _σ'_st
对某些 st 和 <span class="math inline">\(\sigma&#39;\)</span>
成立，并且存在一个替换 <span class="math inline">\(\rho&#39;\)</span>
使得 <span class="math inline">\(\rho&#39;(E_{\sigma&#39;}^-[ctx])
\equiv \Gamma\)</span> 且 <span
class="math inline">\(\rho&#39;(E_{\sigma&#39;}^+[st]) \le
\tau\)</span>。*</p>
<p>Remark that “there exists a <span
class="math inline">\(\rho&#39;\)</span> such that <span
class="math inline">\(\rho&#39;(\tau_0) \le \tau_1\)</span>” is
equivalent to “<span class="math inline">\(\tau_0 \le^\forall
\tau_1\)</span>” by definition of the subsumption relation <span
class="math inline">\(\le^\forall\)</span>. Again, the core of the proof
resides in lemmas about constraining.</p>
<p>注意，“存在一个 <span class="math inline">\(\rho&#39;\)</span> 使得
<span class="math inline">\(\rho&#39;(\tau_0) \le
\tau_1\)</span>”根据子类关系 <span
class="math inline">\(\le^\forall\)</span> 的定义等价于“<span
class="math inline">\(\tau_0 \le^\forall
\tau_1\)</span>”。再次强调，证明的核心在于关于约束的引理。</p>
<p><strong>Lemma 4 (Termination of Constraining).</strong> *For all st₀,
st₁, and <span class="math inline">\(\sigma\)</span>, either
constrain(st₀, st₁)ₐ hits an err(...) case and fails, or there exists a
<span class="math inline">\(\sigma&#39;\)</span> such that
constrain(st₀, st₁)ₐ <span class="math inline">\(\Downarrow\)</span>
_<span class="math inline">\(\sigma&#39;\)</span>().*</p>
<p><strong>引理 4 (约束的终止).</strong> *对于所有 st₀、st₁ 和 <span
class="math inline">\(\sigma\)</span>，要么 constrain(st₀, st₁)ₐ 命中
err(...) 情况并失败，要么存在一个 <span
class="math inline">\(\sigma&#39;\)</span> 使得 constrain(st₀, st₁)ₐ
<span class="math inline">\(\Downarrow\)</span> _<span
class="math inline">\(\sigma&#39;\)</span>()。*</p>
<p><strong>Lemma 5 (Completeness of Constraining).</strong>
*Constraining succeeds on types whose coalesced forms are subtypes, and
it does not alter existing subtyping relationships: for all st₀, st₁,
<span class="math inline">\(\rho\)</span>, and <span
class="math inline">\(\sigma\)</span>, if <span
class="math inline">\(\rho(E_\sigma^-[st₀]) \le
E_\sigma^+[st₁]\)</span>, then constrain(st₀, st₁)ₐ <span
class="math inline">\(\Downarrow\)</span> _<span
class="math inline">\(\sigma&#39;\)</span>() for some <span
class="math inline">\(\sigma&#39;\)</span> - i.e., constraining does not
yield an error — and for all st₂, st₃, <span
class="math inline">\(\sigma&#39;\)</span> such that constrain(st₂,
st₃)ₐ <span class="math inline">\(\Downarrow _\sigma&#39;\)</span>(),
then <span class="math inline">\(\rho(E_{\sigma&#39;}^-[st₀]) \le
E_{\sigma&#39;}^+[st₁]\)</span>.*</p>
<p><strong>引理 5 (约束的完整性)。</strong>
*限制在其聚合形式为子类型的类型上成功，并且不会改变现有的子类型关系：对于所有的
st₀, st₁, <span class="math inline">\(\rho\)</span>, 和 <span
class="math inline">\(\sigma\)</span>，如果 <span
class="math inline">\(\rho(E_\sigma^-[st₀]) \le
E_\sigma^+[st₁]\)</span>，则 constrain(st₀, st₁)ₐ <span
class="math inline">\(\Downarrow\)</span> _<span
class="math inline">\(\sigma&#39;\)</span>() 对某个 <span
class="math inline">\(\sigma&#39;\)</span> 成立 — 即，限制不会产生错误 —
并且对于所有的 st₂, st₃, <span
class="math inline">\(\sigma&#39;\)</span>，如果 constrain(st₂, st₃)ₐ
<span class="math inline">\(\Downarrow _\sigma&#39;\)</span>()，则 <span
class="math inline">\(\rho(E_{\sigma&#39;}^-[st₀]) \le
E_{\sigma&#39;}^+[st₁]\)</span>.*</p>
<p>We prove Lemmas 3 and 5 by induction on typing and subtyping
derivations, respectively. The rule S-TRANS causes some trouble: in case
the subtyping derivation used it, we get premises which refer to
derivations on which we cannot apply the induction, because they do not
correspond to recursive constrain calls. S-TRANS can be removed from the
system and proven from the other rules only in an empty subtyping
context; indeed, <span class="math inline">\(\Sigma\)</span> could in
principle include transitivity-breaking hypotheses, such as <span
class="math inline">\((\top \le \bot) \in \Sigma\)</span>. But the
subtyping context, which will mirror the constraining cache, will not be
empty in the actual inductive proof of (a stronger version of) Lemma 5.
The solution is to show that no transitivity-breaking assumptions are
ever introduced in the subtyping context during successful constraining,
and that the input subtyping relation can always be derived without
using S-TRANS; we do this by strengthening the induction hypothesis
accordingly.</p>
<p>我们通过对类型和子类型推导的归纳法证明引理 3 和引理 5。规则 S-TRANS
造成了一些麻烦：如果子类型推导使用了它，我们得到的前提引用了无法应用归纳法的推导，因为它们不对应于递归约束调用。S-TRANS
可以在空的子类型上下文中从系统中删除，并且仅通过其他规则证明；实际上，<span
class="math inline">\(\Sigma\)</span>
原则上可以包含破坏传递性的假设，例如 <span class="math inline">\((\top
\le \bot) \in \Sigma\)</span>。但是，子类型上下文将在引理
5（更强版本）实际归纳证明中反映约束缓存，因此不会为空。解决方案是证明在成功约束过程中，子类型上下文中从未引入破坏传递性的假设，并且输入子类型关系总是可以在不使用
S-TRANS 的情况下推导出来；我们通过相应地加强归纳假设来做到这一点。</p>
<h2 id="experimental-evaluation">6 EXPERIMENTAL EVALUATION</h2>
<h2 id="实验评估">6 实验评估</h2>
<p>To evaluate the strengths of both the Simple-sub and MLsub
implementations, we ran them on 1,313,832 randomly-generated expressions
of varying sizes, of which 515,509 turned out to be well-typed and
798,321 turned out to be ill-typed.</p>
<p>为了评估 Simple-sub 和 MLsub 实现的优劣，我们在 1,313,832
个随机生成的不同大小的表达式上进行了测试，其中 515,509
个被证明是良类型的，798,321 个被证明是错误类型的。</p>
<p><em>Subsumption checking.</em> MLsub provides a <em>subsumption
checker</em>, whose goal is to determine if one inferred signature is at
least as general as another (i.e., it tests for <span
class="math inline">\(\le^\forall\)</span>). We used MLsub’s subsumption
checker to verify that both algorithms produced equivalent result,
checking that mutual subsumption held between the two inferred type
expressions.</p>
<p><em>subsumption检查。</em> MLsub 提供了一个 <em>subsumption
checker</em>，其目标是确定一个推断的签名是否至少与另一个一样一般（即，它测试
<span class="math inline">\(\le^\forall\)</span>）。我们使用 MLsub
的归纳检查器来验证两个算法产生的结果是相同的，检查两个推断类型表达式之间的互归纳是否成立。</p>
<p><em>Generated expressions.</em> We considered random expressions
making use of integer literals, lambdas, applications, record creations,
field selections, recursive let bindings, and non-recursive let
bindings. We used at most five different variable names and at most
three different field names per expression. We stochastically generated
well-scoped expressions without shadowing, using a depth-first search
with an exponential decrease in probability of recursing into non-leaf
subexpression. This generated 1,313,832 expressions of sizes ranging
from 1 to 23, the majority (about a million) being in the 10–15 range.
The code used for generating and testing these expressions can be found
online in the <em>mlsub-compare</em> branch of the repository, as well
as in the archived artifact of this paper.</p>
<p><em>生成的表达式。</em>
我们考虑了随机表达式，使用整数字面量、lambda、函数调用、结构体创建、字段选择、递归
let 绑定以及非递归 let
绑定。每个表达式中我们最多使用五个不同的变量名和三个不同的字段名。我们随机生成了无变量遮蔽的良作用域表达式，使用深度优先搜索，并在递归到非叶子子表达式的概率上以指数方式递减。如此生成的表达式总计
1,313,832 个，大小范围从 1 到 23，大多数（约一百万个）在 10–15
范围内。用于生成和测试这些表达式的代码可以在在线的
<em>mlsub-compare</em>
仓库分支中找到，也可以在本文的档案工件中找到。</p>
<p><em>Bugs found in MLsub.</em> We found several bugs in MLsub: a
variable shadowing bug — the expression
<code>let rec x = (let y = x in (fun x -&gt; y)) in x</code> gets
assigned the wrong type <code>a -&gt; a</code> because of the shadowing
of let-bounds variable <code>x</code>;<a href="#fn28"
class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a> a
type comparison bug due to a typo (which had already been fixed in
another branch of the project); and a simplification bug, giving (for
instance) to the record expression
<code>&#123;u = 0; v = &#123;w = &#123;w = 0&#125;&#125;&#125;</code> the wrong type
<code>&#123;u : int, v : (rec a = &#123;w : a&#125;)&#125;</code>. Because of the latter
bug, to carry out the tests successfully, we had to disable MLsub’s
simplifier (but the Simple-sub simplifier was still enabled).</p>
<p><em>在MLsub中发现的错误。</em>
我们在MLsub中发现了几个错误：一个变量遮蔽错误——表达式
<code>let rec x = (let y = x in (fun x -&gt; y)) in x</code> 由于遮蔽了
let-bound 变量 <code>x</code> 而被赋予了错误的类型
<code>a -&gt; a</code>；<a href="#fn29" class="footnote-ref"
id="fnref29" role="doc-noteref"><sup>29</sup></a> 一个由于 TYPO
引起的类型比较错误（该错误已经在项目的另一个分支中修复）；以及一个简化错误，使得（例如）结构体表达式
<code>&#123;u = 0; v = &#123;w = &#123;w = 0&#125;&#125;&#125;</code> 被赋予了错误的类型
<code>&#123;u : int, v : (rec a = &#123;w : a&#125;)&#125;</code>。由于后一个错误，为了成功进行测试，我们不得不禁用
MLsub 的简化器（但 Simple-sub 的简化器仍然启用）。</p>
<p><em>Summary.</em> We were able to make sure that Simple-sub and MLsub
agreed on type inference for more than a million randomly-generated
expressions. Systematic testing turned out to be a surprisingly useful
tool for detecting small mistakes which would have otherwise gone
unnoticed.</p>
<p><em>总结。</em> 我们能够确保 Simple-sub 和 MLsub
在超过一百万个随机生成的表达式上的类型推断一致。系统化测试被证明是一个令人惊讶的有效工具，用于检测那些否则会被忽视的小错误。</p>
<h1 id="conclusions-and-future-work">7 CONCLUSIONS AND FUTURE WORK</h1>
<h1 id="结论与未来工作">7 结论与未来工作</h1>
<p>Algebraic subtyping and its realization in MLsub demonstrated a very
promising new technique for inferring compact principal types in the
presence of implicit subtyping. In this paper, we presented a simpler
foundational view of MLsub’s type system, which does not require notions
of bisubstitution or polar types, and slightly departs from the focus on
<em>algebra first</em>. This new understanding lead us to more
approachable type inference specification and implementation. We showed
the design of Simple-sub, which achieves principal type inference and
reasonable simplification in just 500 lines of code, to serve as an
inspiration to future type systems and programming languages
designers.</p>
<p>代数子类型及其在MLsub中的实现展示了一种在隐式子类型存在时推导紧凑主类型的新技术，前景非常可观。本文提出了一个更简单的MLsub类型系统的基础视角，该视角不需要双替代或极性类型的概念，并且在一定程度上偏离了<em>代数优先</em>的重点。这一新理解使我们能够制定更易于接近的类型推导规范和实现。我们展示了Simple-sub的设计，它在仅500行代码内实现了主类型推导和合理简化，以此启发未来的类型系统和编程语言设计者。</p>
<p>There is still much to be explored among the possibilities offered by
algebraic subtyping, and by the new Simple-sub algorithm in particular.
Polymorphic variants, a very useful language feature [Garrigue 1998],
are the dual of polymorphic record types. A simple form of polymorphic
variants (i.e., without default match cases and without nested patterns)
can be handled in our system in <em>exactly</em> the same way as we have
shown for records. Both variants and records can also be extended easily
to support row variable for extensibility, yielding a powerful system;
moreover, such a system would still be simple and natural to use thanks
to subtyping, which usefully complements row polymorphism [Pottier 1998,
Chapter 14.7]. Finally, we have been prototyping extensions for more
advanced features which also benefit from subtyping, such as first-class
polymorphism.</p>
<p>仍有许多可能性等待我们去探索，特别是代数子类型和新的 Simple-sub
算法。多态变体，这是一个非常有用的语言特性 [Garrigue
1998]，是多态结构体类型的对偶。我们系统中可以以 <em>完全</em>
相同的方式处理多态变体的简单形式（即，没有默认匹配案例和嵌套模式），就像我们展示的结构体一样。变体和结构体也可以很容易地扩展以支持行变量，从而实现可扩展性，产生一个强大的系统；此外，得益于子类型，这样的系统仍然会简单自然，且实用地补充了行多态性
[Pottier 1998, Chapter
14.7]。最后，我们一直在为更高级特性原型开发扩展，这些特性也受益于子类型，例如一等公民多态性。</p>
<h1 id="acknowledgments">8 ACKNOWLEDGMENTS</h1>
<h1 id="致谢">8 致谢</h1>
<p>I would like to thank Stephen Dolan and Alan Mycroft for their
responsiveness and help in testing MLsub, and for their feedback on the
paper; Paolo G. Giarrusso for his insightful suggestions; the paper’s
shepherd Tom Schrijvers; and the anonymous reviewers for their useful
comments.</p>
<p>我想感谢 Stephen Dolan 和 Alan Mycroft 对 MLsub
测试的响应和帮助，以及他们对论文的反馈；感谢 Paolo G. Giarrusso
的深刻建议；感谢论文的指导 Tom
Schrijvers；感谢匿名评审对其有用评论的贡献。</p>
<h1 id="references">REFERENCES</h1>
<h1 id="参考文献">参考文献</h1>
<p>Roberto M. Amadio and Luca Cardelli. 1993. Subtyping Recursive Types.
<em>ACM Trans. Program. Lang. Syst.</em> 15, 4 (Sept. 1993), 575–631.
https://doi.org/10.1145/155183.155231</p>
<p>Nada Amin, Samuel Grütter, Martin Odersky, Tiark Rompf, and Sandro
Stucki. 2016. <em>The Essence of Dependent Object Types</em>. Springer
International Publishing, Cham, 249–272.
https://doi.org/10.1007/978-3-319-30936-1_14</p>
<p>Andrew W. Appel, Paul-André Melliès, Christopher D. Richards, and
Jérôme Vouillon. 2007. A Very Modal Model of a Modern, Major, General
Type System. In <em>Proceedings of the 34th Annual ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages</em> (Nice, France)
(POPL ’07). Association for Computing Machinery, New York, NY, USA,
109–122. https://doi.org/10.1145/1190216.1190235</p>
<p>Giuseppe Castagna, Tommaso Petrucciani, and Kim Nguyen. 2016.
Set-theoretic types for polymorphic variants. In <em>Proceedings of the
21st ACM SIGPLAN International Conference on Functional Programming
(ICFP 2016)</em>. Association for Computing Machinery, Nara, Japan,
378–391. https://doi.org/10.1145/2951913.2951928</p>
<p>Giuseppe Castagna and Zhiwu Xu. 2011. Set-Theoretic Foundation of
Parametric Polymorphism and Subtyping. (2011), 94–106.
https://doi.org/10.1145/2034773.2034788</p>
<p>Nathanaël Courant. 2018. Safely typing algebraic effects (Gagallium
Blog). http://gallium.inria.fr/blog/safely-typing-algebraic-effects/.
Accessed: 2020-06-30.</p>
<p>Luis Damas and Robin Milner. 1982. Principal type-schemes for
functional programs. In <em>Proceedings of the 9th ACM SIGPLAN-SIGACT
symposium on Principles of programming languages (POPL ’82)</em>.
Association for Computing Machinery, Albuquerque, New Mexico, 207–212.
https://doi.org/10.1145/582153.582176</p>
<p>Stephen Dolan. 2017. <em>Algebraic subtyping</em>. Ph.D.
Dissertation.</p>
<p>Stephen Dolan and Alan Mycroft. 2017. Polymorphism, subtyping, and
type inference in MLsub. <em>ACM SIGPLAN Notices</em> 52, 1 (Jan. 2017),
60–72. https://doi.org/10.1145/3093333.3099882</p>
<p>Joshua Dunfield and Neelakantan R. Krishnaswami. 2013. Complete and
Easy Bidirectional Typechecking for Higher-Rank Polymorphism.
<em>SIGPLAN Not.</em> 48, 9 (Sept. 2013), 429–442.
https://doi.org/10.1145/2544174.2500582</p>
<p>Tim Freeman and Frank Pfenning. 1991. Refinement types for ML. In
<em>Proceedings of the ACM SIGPLAN 1991 conference on Programming
language design and implementation</em>. 268–277.</p>
<p>Alain Frisch, Giuseppe Castagna, and Véronique Benzaken. 2008.
Semantic Subtyping: Dealing Set-Theoretically with Function, Union,
Intersection, and Negation Types. <em>J. ACM</em> 55, 4, Article 19
(Sept. 2008), 64 pages. https://doi.org/10.1145/1391289.1391293</p>
<p>Jacques Garrigue. 1998. Programming with polymorphic variants. In
<em>ML Workshop</em>, Vol. 13. Baltimore, 7.</p>
<p>Roger Hindley. 1969. The Principal Type-Scheme of an Object in
Combinatory Logic. <em>Trans. Amer. Math. Soc.</em> 146 (1969), 29–60.
https://doi.org/10.2307/1995158 Publisher: American Mathematical
Society.</p>
<p>Haruo Hosoya, Jérôme Vouillon, and Benjamin C. Pierce. 2005. Regular
Expression Types for XML. <em>ACM Trans. Program. Lang. Syst.</em> 27, 1
(Jan. 2005), 46–90. https://doi.org/10.1145/1053468.1053470</p>
<p>DeLesley S. Hutchins. 2010. Pure Subtype Systems. In <em>Proceedings
of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages</em> (Madrid, Spain) (POPL ’10). Association for
Computing Machinery, New York, NY, USA, 287–298.
https://doi.org/10.1145/1706299.1706334</p>
<p>Oleg Kiselyov. 2013. Efficient generalization with levels (Okmij
Blog). http://okmij.org/ftp/ML/generalization.html#levels. Accessed:
2020-06-30.</p>
<p>Robin Milner. 1978. A theory of type polymorphism in programming.
<em>J. Comput. System Sci.</em> 17, 3 (Dec. 1978), 348–375.
https://doi.org/10.1016/0022-0000(78)90014-4</p>
<p>Martin Odersky and Konstantin Läufer. 1996. Putting Type Annotations
to Work. In <em>Proceedings of the 23rd ACM SIGPLAN-SIGACT Symposium on
Principles of Programming Languages</em> (St. Petersburg Beach, Florida,
USA) (POPL ’96). Association for Computing Machinery, New York, NY, USA,
54–67. https://doi.org/10.1145/237721.237729</p>
<p>David J. Pearce. 2013. Sound and Complete Flow Typing with Unions,
Intersections and Negations. In <em>Verification, Model Checking, and
Abstract Interpretation (Lecture Notes in Computer Science)</em>,
Roberto Giacobazzi, Josh Berdine, and Isabella Mastroeni (Eds.).
Springer, Berlin, Heidelberg, 335–354.
https://doi.org/10.1007/978-3-642-35873-9_21</p>
<p>Benjamin C. Pierce. 2002. <em>Types and programming languages</em>.
MIT press.</p>
<p>François Pottier. 1998. <em>Type Inference in the Presence of
Subtyping: from Theory to Practice</em>. Research Report RR-3483. INRIA.
https://hal.inria.fr/inria-00073205</p>
<p>Patrick M. Rondon, Ming Kawaguci, and Ranjit Jhala. 2008. Liquid
Types. In <em>Proceedings of the 29th ACM SIGPLAN Conference on
Programming Language Design and Implementation</em> (Tucson, AZ, USA)
(PLDI ’08). Association for Computing Machinery, New York, NY, USA,
159–169. https://doi.org/10.1145/1375581.1375602</p>
<p>Andreas Rossberg. 2015. 1ML – Core and Modules United (F-Ing
First-Class Modules). In <em>Proceedings of the 20th ACM SIGPLAN
International Conference on Functional Programming</em> (Vancouver, BC,
Canada) (ICFP 2015). Association for Computing Machinery, New York, NY,
USA, 35–47. https://doi.org/10.1145/2784731.2784738</p>
<p>John Rushby, Sam Owre, and Natarajan Shankar. 1998. Subtypes for
Specifications: Predicate Subtyping in PVS. <em>IEEE Trans. Softw.
Eng.</em> 24, 9 (Sept. 1998), 709–720.
https://doi.org/10.1109/32.713327</p>
<p>Sam Tobin-Hochstadt and Matthias Felleisen. 2010. Logical Types for
Untyped Languages. <em>SIGPLAN Not.</em> 45, 9 (Sept. 2010), 117–128.
https://doi.org/10.1145/1932681.1863561</p>
<p>Niki Vazou, Eric L. Seidel, Ranjit Jhala, Dimitrios Vytiniotis, and
Simon Peyton-Jones. 2014. Refinement Types for Haskell. In
<em>Proceedings of the 19th ACM SIGPLAN International Conference on
Functional Programming</em> (Gothenburg, Sweden) (ICFP '14). Association
for Computing Machinery, New York, NY, USA, 269–282.
https://doi.org/10.1145/2628136.2628161</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>¹OCaml has been quite conservative with such
principality-breaking features, notable exceptions being GADTs and
overloaded record fields, but Haskell has been adopting them more
liberally in order to increase expressiveness.</p>
<p>OCaml 在这些打破原则的特性上一直相对保守，显著的例外是 GADTs
和多重结构体字段，但 Haskell 在这方面的采用更为宽松，以增强表达能力。<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>¹OCaml has been quite conservative with such
principality-breaking features, notable exceptions being GADTs and
overloaded record fields, but Haskell has been adopting them more
liberally in order to increase expressiveness.</p>
<p>OCaml 在这些打破原则的特性上一直相对保守，显著的例外是 GADTs
和多重结构体字段，但 Haskell 在这方面的采用更为宽松，以增强表达能力。<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>For instance, OCaml uses row types to make object types
and polymorphic variants more flexible, avoiding the need for explicit
coercions, somewhat similarly to implicit subtyping [Pottier 1998]; and
Haskell can use type classes to emulate subtyping, as exemplified by the
<em>lens</em> and <em>optics</em> libraries, which are both designed
around a subtyping analogy.</p>
<p>例如，OCaml
使用行类型使对象类型和多态变体更灵活，避免了显式强制转换的需求，这在某种程度上类似于隐式子类型
[Pottier 1998]；而 Haskell 可以使用类型类来模拟子类型，如 <em>lens</em>
和 <em>optics</em> 库所示，这两个库都是围绕子类型类比设计的。<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>For instance, OCaml uses row types to make object types
and polymorphic variants more flexible, avoiding the need for explicit
coercions, somewhat similarly to implicit subtyping [Pottier 1998]; and
Haskell can use type classes to emulate subtyping, as exemplified by the
<em>lens</em> and <em>optics</em> libraries, which are both designed
around a subtyping analogy.</p>
<p>例如，OCaml
使用行类型使对象类型和多态变体更灵活，避免了显式强制转换的需求，这在某种程度上类似于隐式子类型
[Pottier 1998]；而 Haskell 可以使用类型类来模拟子类型，如 <em>lens</em>
和 <em>optics</em> 库所示，这两个库都是围绕子类型类比设计的。<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Operationally speaking, Simple-sub has many similarities
to the graph-based implementation of MLsub, though the two algorithms
are still quite different — in particular, MLsub separates positive
nodes from negative nodes in its constraint graph (while there is no
such separation in Simple-sub), and MLsub generates many more type
variables than Simple-sub.</p>
<p>从操作的角度来看，Simple-sub 与 MLsub
的图形实现有许多相似之处，尽管这两种算法仍然相当不同——尤其是，MLsub
在其约束图中将正节点与负节点分开（而 Simple-sub 没有这种分离），并且
MLsub 生成的类型变量比 Simple-sub 多得多。<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Operationally speaking, Simple-sub has many similarities
to the graph-based implementation of MLsub, though the two algorithms
are still quite different — in particular, MLsub separates positive
nodes from negative nodes in its constraint graph (while there is no
such separation in Simple-sub), and MLsub generates many more type
variables than Simple-sub.</p>
<p>从操作的角度来看，Simple-sub 与 MLsub
的图形实现有许多相似之处，尽管这两种算法仍然相当不同——尤其是，MLsub
在其约束图中将正节点与负节点分开（而 Simple-sub 没有这种分离），并且
MLsub 生成的类型变量比 Simple-sub 多得多。<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>We have some doubts that the extensibility property of
algebraic subtyping is as useful as advertised by its author, besides
its simplifying consequences. First, practical programming languages
already have extensible type systems by design, since they allow
user-defined data types, and the subtyping paradoxes which arise from
closed-world formal calculi do not typically arise or cause troubles in
these settings. Second, extending the core type semantics of a
programming language happens exceedingly rarely, and thus is probably
not a scenario worth optimizing for, when designing a type system.</p>
<p>我们对于代数子类型的可扩展性属性是否如其作者所宣传的那样有用，除了它的简化结果之外，存在一些疑问。首先，实际的编程语言设计上已经具有可扩展的类型系统，因为它们允许用户定义数据类型，而来自封闭世界形式演算的子类型悖论通常不会在这些环境中出现或造成问题。其次，扩展编程语言的核心类型语义的情况极为罕见，因此在设计类型系统时，这种情况可能并不值得优化。<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>We have some doubts that the extensibility property of
algebraic subtyping is as useful as advertised by its author, besides
its simplifying consequences. First, practical programming languages
already have extensible type systems by design, since they allow
user-defined data types, and the subtyping paradoxes which arise from
closed-world formal calculi do not typically arise or cause troubles in
these settings. Second, extending the core type semantics of a
programming language happens exceedingly rarely, and thus is probably
not a scenario worth optimizing for, when designing a type system.</p>
<p>我们对于代数子类型的可扩展性属性是否如其作者所宣传的那样有用，除了它的简化结果之外，存在一些疑问。首先，实际的编程语言设计上已经具有可扩展的类型系统，因为它们允许用户定义数据类型，而来自封闭世界形式演算的子类型悖论通常不会在这些环境中出现或造成问题。其次，扩展编程语言的核心类型语义的情况极为罕见，因此在设计类型系统时，这种情况可能并不值得优化。<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Interestingly, the OCaml compiler supports recursive
types, but it only allows them as part of object types by default,
because they can otherwise lead to surprises — in some cases inferring
recursive types instead of reporting obvious errors. In a practical
language based on MLsub, it would be possible to have similar
restrictions on the inference of recursive types.</p>
<p>有趣的是，OCaml
编译器支持递归类型，但默认情况下只允许它们作为对象类型的一部分，因为它们可能导致意外情况——在某些情况下推断出递归类型，而不是报告明显的错误。在基于
MLsub 的实际语言中，可以对递归类型的推断施加类似的限制。<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Interestingly, the OCaml compiler supports recursive
types, but it only allows them as part of object types by default,
because they can otherwise lead to surprises — in some cases inferring
recursive types instead of reporting obvious errors. In a practical
language based on MLsub, it would be possible to have similar
restrictions on the inference of recursive types.</p>
<p>有趣的是，OCaml
编译器支持递归类型，但默认情况下只允许它们作为对象类型的一部分，因为它们可能导致意外情况——在某些情况下推断出递归类型，而不是报告明显的错误。在基于
MLsub 的实际语言中，可以对递归类型的推断施加类似的限制。<a
href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>⁶In that sense, <code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code> is similar to
<span class="math inline">\(\tau\)</span>, although MLsub does not
consider these two types to be equivalent.</p>
<p>从这个意义上说，<code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code> 类似于 <span
class="math inline">\(\tau\)</span>，尽管 MLsub
不认为这两种类型是等价的。<a href="#fnref11" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>⁶In that sense, <code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code> is similar to
<span class="math inline">\(\tau\)</span>, although MLsub does not
consider these two types to be equivalent.</p>
<p>从这个意义上说，<code>int</code> <span
class="math inline">\(\sqcup\)</span> <code>string</code> 类似于 <span
class="math inline">\(\tau\)</span>，尽管 MLsub
不认为这两种类型是等价的。<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>⁷Note that several features of Java go well beyond what
can be expressed in MLsub (such as polymorphic methods and generic class
hierarchies), so MLsub really is <em>strictly less</em> expressive than
our hypothetical structurally-typed Java.</p>
<p>请注意，Java的几个特性远远超出了MLsub所能表达的范畴（例如，多态方法和泛型类层次结构），因此MLsub确实是比我们假设的结构化类型Java<em>严格少</em>的表达能力。<a
href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>⁷Note that several features of Java go well beyond what
can be expressed in MLsub (such as polymorphic methods and generic class
hierarchies), so MLsub really is <em>strictly less</em> expressive than
our hypothetical structurally-typed Java.</p>
<p>请注意，Java的几个特性远远超出了MLsub所能表达的范畴（例如，多态方法和泛型类层次结构），因此MLsub确实是比我们假设的结构化类型Java<em>严格少</em>的表达能力。<a
href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>⁸In fact, in real Java, lower-bound specifications are
inexplicably only supported for <em>wildcard</em> type arguments – an
apparent oversight. For more details on type bounds in Java, see
https://docs.oracle.comjavase/tutorial/java/generics/bounded.html and
https://docs.oracle.comjavase/tutorial/java/generics/lowerBounded.html.</p>
<p>实际上，在真实的Java中，下界规范 inexplicably
仅支持<em>通配符</em>类型参数——这显然是一个疏漏。有关Java中类型边界的更多详细信息，请参见
https://docs.oracle.comjavase/tutorial/java/generics/bounded.html 和
https://docs.oracle.comjavase/tutorial/java/generics/lowerBounded.html。<a
href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>⁸In fact, in real Java, lower-bound specifications are
inexplicably only supported for <em>wildcard</em> type arguments – an
apparent oversight. For more details on type bounds in Java, see
https://docs.oracle.comjavase/tutorial/java/generics/bounded.html and
https://docs.oracle.comjavase/tutorial/java/generics/lowerBounded.html.</p>
<p>实际上，在真实的Java中，下界规范 inexplicably
仅支持<em>通配符</em>类型参数——这显然是一个疏漏。有关Java中类型边界的更多详细信息，请参见
https://docs.oracle.comjavase/tutorial/java/generics/bounded.html 和
https://docs.oracle.comjavase/tutorial/java/generics/lowerBounded.html。<a
href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>⁹As explained by Dolan and Mycroft [2017], this type is
just as general as the more natural <span class="math inline">\(\forall
\alpha, \beta\)</span>. <span class="math inline">\(bool \to \alpha \to
\beta \to \alpha \sqcup \beta\)</span>.</p>
<p>正如 Dolan 和 Mycroft [2017] 所解释的，这种类型与更自然的 <span
class="math inline">\(\forall \alpha, \beta\)</span> 一样一般。 <span
class="math inline">\(bool \to \alpha \to \beta \to \alpha \sqcup
\beta\)</span>。<a href="#fnref17" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>⁹As explained by Dolan and Mycroft [2017], this type is
just as general as the more natural <span class="math inline">\(\forall
\alpha, \beta\)</span>. <span class="math inline">\(bool \to \alpha \to
\beta \to \alpha \sqcup \beta\)</span>.</p>
<p>正如 Dolan 和 Mycroft [2017] 所解释的，这种类型与更自然的 <span
class="math inline">\(\forall \alpha, \beta\)</span> 一样一般。 <span
class="math inline">\(bool \to \alpha \to \beta \to \alpha \sqcup
\beta\)</span>。<a href="#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>¹¹Scala syntax (<code>foo(a,_,c)</code>) is a shorthand
for the lambda abstraction (<code>x =&gt; foo(a, x, c)</code>).</p>
<p>Scala 语法 (<code>foo(a,_,c)</code>) 是对 lambda 抽象
(<code>x =&gt; foo(a, x, c)</code>) 的一种简写。<a href="#fnref19"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>¹¹Scala syntax (<code>foo(a,_,c)</code>) is a shorthand
for the lambda abstraction (<code>x =&gt; foo(a, x, c)</code>).</p>
<p>Scala 语法 (<code>foo(a,_,c)</code>) 是对 lambda 抽象
(<code>x =&gt; foo(a, x, c)</code>) 的一种简写。<a href="#fnref20"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>¹²In Scala, <code>opt.fold(t)(f)</code> folds the
<code>opt</code> option by applying a function <code>f</code> on the
contained value, or by evaluating a default <code>thunk t</code> if the
option is empty. The <code>map.getOrElseUpdate(k, t)</code> method of
<code>MutMap</code> looks up a key <code>k</code> in <code>map</code>;
if the key is not found, it evaluates the <code>thunk t</code> and
update <code>map</code> with the value; otherwise, it returns the value
associated with the key.</p>
<p>在 Scala 中，<code>opt.fold(t)(f)</code> 通过对包含的值调用函数
<code>f</code> 来折叠 <code>opt</code> 选项，如果选项为空，则评估默认的
<code>thunk t</code>。 <code>MutMap</code> 的
<code>map.getOrElseUpdate(k, t)</code> 方法在 <code>map</code>
中查找一个键 <code>k</code>；如果未找到该键，则评估 <code>thunk t</code>
并用该值更新 <code>map</code>；否则，返回与该键关联的值。<a
href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p>¹²In Scala, <code>opt.fold(t)(f)</code> folds the
<code>opt</code> option by applying a function <code>f</code> on the
contained value, or by evaluating a default <code>thunk t</code> if the
option is empty. The <code>map.getOrElseUpdate(k, t)</code> method of
<code>MutMap</code> looks up a key <code>k</code> in <code>map</code>;
if the key is not found, it evaluates the <code>thunk t</code> and
update <code>map</code> with the value; otherwise, it returns the value
associated with the key.</p>
<p>在 Scala 中，<code>opt.fold(t)(f)</code> 通过对包含的值调用函数
<code>f</code> 来折叠 <code>opt</code> 选项，如果选项为空，则评估默认的
<code>thunk t</code>。 <code>MutMap</code> 的
<code>map.getOrElseUpdate(k, t)</code> 方法在 <code>map</code>
中查找一个键 <code>k</code>；如果未找到该键，则评估 <code>thunk t</code>
并用该值更新 <code>map</code>；否则，返回与该键关联的值。<a
href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p>¹³In Scala, a <em>sealed trait</em> is like an
<em>interface</em> which can only be implemented by types defined in the
same file.</p>
<p>在Scala中，<em>sealed trait</em>
类似于只能由同一文件中定义的类型实现的 <em>interface</em>。<a
href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p>¹³In Scala, a <em>sealed trait</em> is like an
<em>interface</em> which can only be implemented by types defined in the
same file.</p>
<p>在Scala中，<em>sealed trait</em>
类似于只能由同一文件中定义的类型实现的 <em>interface</em>。<a
href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p>¹⁴Some approaches achieve complete type inference in
the face of this more advanced form of reasoning [Castagna et al. 2016],
but they typically lack the principal type property (they generate a set
of possible types instead of a single, most-general type), and they
naturally do not enable the same level of simplification.</p>
<p>一些方法在面对这种更高级的推理形式时实现了完整的类型推断 [Castagna et
al.
2016]，但它们通常缺乏主类型属性（它们生成一组可能的类型而不是单个最通用的类型），而且它们自然不支持相同程度的简化。<a
href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p>¹⁵Our implementation of let polymorphism can be proven
correct separately, by showing it has the same effect as duplicating the
let-bound definition at each of its use sites (which is the semantics of
let polymorphism [Damas and Milner 1982]).</p>
<p>¹⁵我们对let多态性的实现可以单独证明是正确的，方法是显示它在每个使用地点的效果与复制let绑定定义相同（这就是let多态性的语义[Damas和Milner
1982]）。<a href="#fnref26" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p>¹⁵Our implementation of let polymorphism can be proven
correct separately, by showing it has the same effect as duplicating the
let-bound definition at each of its use sites (which is the semantics of
let polymorphism [Damas and Milner 1982]).</p>
<p>¹⁵我们对let多态性的实现可以单独证明是正确的，方法是显示它在每个使用地点的效果与复制let绑定定义相同（这就是let多态性的语义[Damas和Milner
1982]）。<a href="#fnref27" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p>¹⁶We found this because, in an earlier testing attempt,
we generated expressions which contained shadowing.</p>
<p>¹⁶我们发现这一点是因为，在早期的测试尝试中，我们生成了包含遮蔽的表达式。<a
href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p>¹⁶We found this because, in an earlier testing attempt,
we generated expressions which contained shadowing.</p>
<p>¹⁶我们发现这一点是因为，在早期的测试尝试中，我们生成了包含遮蔽的表达式。<a
href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>StaticAnalysis</tag>
        <tag>Decompile</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解投资中的凯利公式</title>
    <url>/2025/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%8A%95%E8%B5%84%E4%B8%AD%E7%9A%84%E5%87%AF%E5%88%A9%E5%85%AC%E5%BC%8F/</url>
    <content><![CDATA[<p>凯利公式在投资上的应用</p>
<span id="more"></span>
<h2 id="总结">总结</h2>
<ul>
<li>数学期望只能决定是否存在赚的可能性。而风险的分散程度才是决定下注比例的关键</li>
<li><strong>对数期望的计算</strong>：考虑下注比例时，需要根据不同场景下的回报情况<span
class="math inline">\(r\)</span>，计算函数<span
class="math inline">\(\log (1+rx)\)</span>关于概率的加权平均。
<ul>
<li>只要存在风险，就不能无限制地使用杠杆投入</li>
<li><strong>买彩票场景</strong>：对于小概率赚大钱的买彩票场景，只能用很少部分的本金投入</li>
<li><strong>借钱场景</strong>：对于大概率赚小钱的借钱场景，必须要警惕风险的估计是否准确，且也不能投入太大比例</li>
<li><strong>分散风险</strong>：存在多个独立的投资机会时，应当分散风险。</li>
</ul></li>
</ul>
<p>使用蒙特卡洛模拟法，暴力遍历所有的比例组合可能性，看看哪个更好的在线工具：</p>
<p><a
href="https://wjk.moe/monte-carlo-invest/">https://wjk.moe/monte-carlo-invest/</a></p>
<h2 id="前言">前言</h2>
<p>在和概率相关的游戏中，我们常常会直接看数学期望，然而，只看期望的话，难道意味着期望为正的赌局我们就直接all
in，期望为负的赌局就完全不参与吗？比如<a
href="https://www.bilibili.com/video/BV1QLHnzEEzp">这个视频</a>中，明明是期望为正的赌局，all
in策略却在99%的情况下最后输到根本不剩多少？</p>
<p>同样的道理在德州扑克中也会出现。合适的下注比例非常重要，<a
href="https://www.bilibili.com/video/BV1h9ySBiE49">下注尺度错误会直接损失EV</a>。</p>
<p>而数学期望只能决定是否存在赚的可能性。考虑这样一种抽奖场景，你必须投入你所有本金，1%的概率赚200倍，99%的概率全亏。即使你知道你总体期望是赚的，但是你依然有99%的可能性倾家荡产。而在剩下1%的情况又有着过多的钱。我想大多数人都不会去参与这个游戏。</p>
<p>核心的道理是，中位数非常重要。可以想象成，在平行世界里，有很多个你在投资后有着不一样的结果，怎么让平行世界里的大多数的你（至少一半，即中位数）都能最终富起来。</p>
<p>深刻理解凯利公式是投资的基础。更为客观的投资，投资尺寸应该考虑的是当前投资策略，看作一个多次重复的赌局时，如何最大化中位数的增长。</p>
<h3 id="凯利公式的推导">凯利公式的推导</h3>
<p>在赌博或投资中，假设每次投注比例为<span
class="math inline">\(f\)</span>（<span class="math inline">\(0 \leq f
\leq 1\)</span>），初始财富为<span
class="math inline">\(W_0\)</span>。每次赌博的获胜概率为<span
class="math inline">\(p\)</span>，失败概率为<span
class="math inline">\(q = 1 - p\)</span>，获胜时的赔率为<span
class="math inline">\(b\)</span>（即获胜时财富变为<span
class="math inline">\(1 + fb\)</span>，失败时损失全部投入，财富变为<span
class="math inline">\(1 - f\)</span>）。经过<span
class="math inline">\(n\)</span>次独立赌博后，财富<span
class="math inline">\(W_n\)</span>为：</p>
<p><span class="math display">\[
W_n = W_0 \cdot (1 + fb)^S \cdot (1 - f)^F
\]</span></p>
<p>其中<span class="math inline">\(S\)</span>是获胜次数，<span
class="math inline">\(F\)</span>是失败次数，且<span
class="math inline">\(n = S + F\)</span>。</p>
<h3 id="中位数财富与几何平均增长率">中位数财富与几何平均增长率</h3>
<p>从长期的角度，所有财富都是指数增长的。因此，我们尝试从对数的视角去看我们的财富增长情况。</p>
<p>从财富表达式可得：</p>
<p><span class="math display">\[
\log W_n = \log W_0 + S \log(1 + fb) + F \log(1 - f)
\]</span></p>
<p>如果重复次数足够多，<span class="math inline">\(S = np\)</span>,<span
class="math inline">\(F = nq\)</span></p>
<!-- 由于对数变换，$\log W_n$近似服从正态分布。 -->
<p><span class="math display">\[
\log W_n = \log W_0 + n \left[ p \log(1 + fb) + q \log(1 - f) \right]
\]</span></p>
<p>因此，最大化<span class="math inline">\(\mathbb{E}[\log
W_n]\)</span>等价于最大化那个<span
class="math inline">\(n\)</span>的系数，即以下函数：</p>
<p><span class="math display">\[
G(f) = p \log(1 + fb) + q \log(1 - f)
\]</span></p>
<p>这里<span
class="math inline">\(G(f)\)</span>就是每期赌博的期望对数回报，即几何平均增长率。将它关于<span
class="math inline">\(f\)</span>求导</p>
<p>为了找到使几何平均增长率 <span class="math display">\[
G(f) = p \log(1 + fb) + q \log(1 - f)
\]</span></p>
<h3 id="求导得到最大值">求导得到最大值</h3>
<p>重要的是对数的视角，有了公式之后，我们只需要求导找出极值点即可了。下面是枯燥的计算过程，可以跳过。总之最后计算出了凯利公式</p>
<p>最大的最优投注比例<span
class="math inline">\(f^*\)</span>，我们对<span
class="math inline">\(G(f)\)</span>关于<span
class="math inline">\(f\)</span>求导，并令导数为零。</p>
<p>首先计算导数：</p>
<p><span class="math display">\[
\frac{dG}{df} = p \cdot \frac{b}{1 + fb} + q \cdot \frac{-1}{1 - f}
= \frac{pb}{1 + fb} - \frac{q}{1 - f}
\]</span></p>
<p>令导数为零，求极值点：</p>
<p><span class="math display">\[
\frac{pb}{1 + fb} - \frac{q}{1 - f} = 0
\]</span></p>
<p>移项得：</p>
<p><span class="math display">\[
\frac{pb}{1 + fb} = \frac{q}{1 - f}
\]</span></p>
<p>交叉相乘：</p>
<p><span class="math display">\[
pb(1 - f) = q(1 + fb)
\]</span></p>
<p>展开两边：</p>
<p><span class="math display">\[
pb - pbf = q + qfb
\]</span></p>
<p>整理含<span class="math inline">\(f\)</span>的项：</p>
<p><span class="math display">\[
pb - q = f(pb + qb) = f b (p + q)
\]</span></p>
<p>由于<span class="math inline">\(p + q = 1\)</span>，有：</p>
<p><span class="math display">\[
pb - q = f b
\]</span></p>
<p>解出<span class="math inline">\(f\)</span>：</p>
<p><span class="math display">\[
f^* = \frac{pb - q}{b}
\]</span></p>
<p>这就是<a
href="https://zh.wikipedia.org/wiki/%E5%87%B1%E5%88%A9%E5%85%AC%E5%BC%8F"><strong>凯利公式</strong></a>（Kelly
Criterion）的标准形式。</p>
<h3
id="真正的核心多次重复视角下的对数期望">真正的核心：多次重复视角下的对数期望</h3>
<p>假如我们有一个投资机会，它未来的回报率<span
class="math inline">\(f\)</span>有多种可能。这里我们假设有三种情况，可能性分别是<span
class="math inline">\(p_1, p_2,
p_3\)</span>，加起来等于1，同时三种情况下的回报率是<span
class="math inline">\(r_1, r_2, r_3\)</span>。</p>
<p>这里回报率<span
class="math inline">\(r\)</span>的定义是，比如，回报率是0.1表示赚了投入的10%，回报率是-0.1表示亏了投入的10%。</p>
<p>打算投入产品的比例是<span class="math inline">\(x &gt;=
0\)</span>，如果<span class="math inline">\(x &gt;
1\)</span>则表示加杠杆了。单次进行投资，我们投资后的钱就是 本金乘以<span
class="math inline">\(1+rx\)</span>。</p>
<p>我们反复进行投资，最终的回报是</p>
<p><span class="math display">\[
W_n = W_0 \cdot {(1 + r_1x)}^{S_1} \cdot {(1 + r_2x)}^{S_2} \cdot {(1 +
r_3x)}^{S_3}
\]</span></p>
<p>其中，几个<span
class="math inline">\(S\)</span>表示几种情况出现的次数。如果次数足够多，那么几种情况出现的次数会和概率成比例，分别等于n乘以对应的概率。</p>
<p><span class="math display">\[
W_n = W_0 \cdot {(1 + r_1x)}^{n \cdot p_1} \cdot {(1 + r_2x)}^{n \cdot
p_2} \cdot {(1 + r_3x)}^{n \cdot p_3}
\]</span></p>
<p>接下来我们求对数：</p>
<p><span class="math display">\[
\log W_n = \log W_0 + n \cdot p_1 \log (1+r_1x) + n \cdot p_2 \log
(1+r_2x) + n \cdot p_3 \log (1+r_3x)
\]</span></p>
<p>我们关注关于n的系数，因此关注：</p>
<p><span class="math display">\[
p_1 \log (1+r_1x) + p_2 \log (1+r_2x) + p_3 \log (1+r_3x)
\]</span></p>
<p>这个就是最核心，最需要深入理解的式子。以后投资时，可以列出这个函数，然后去在线画一下函数图像，比如用<a
href="https://www.geogebra.org/classic">GeoGebra</a>。</p>
<h3 id="深入理解对数期望">深入理解对数期望</h3>
<p><span class="math display">\[
p_1 \log (1+r_1x) + p_2 \log (1+r_2x) + p_3 \log (1+r_3x)
\]</span></p>
<p>直观上看，首先是概率加权，给出现可能性更大的情况更大的权重，这个比较好理解。</p>
<p>其次，回报率会按照下面的函数处理：</p>
<p><span class="math display">\[
f(x) = log(1+rx)
\]</span></p>
<p>我们按照那个视频里的经典场景，投一枚硬币，0.5概率赚本金的0.8，0.5概率亏损一半本金。</p>
<p>对于赚的情况，系数r是大于零的，这里是0.5，此时对应的函数<span
class="math inline">\(\log(1+0.8x)\)</span>图像如下：</p>
<p><img src="logx-positive.png" /></p>
<p>函数随着x一直增长，这意味着，如果没有损失本金的情况，那么自然应该无限加杠杆，加的越多赚的越多。</p>
<p>对于亏的情况，系数<span
class="math inline">\(r=-0.5\)</span>，此时函数<span
class="math inline">\(\log(1-0.5x)\)</span>图像如下：</p>
<p><img src="logx-negative.png" /></p>
<p>这个函数图像可以看作是<span class="math inline">\(\log
x\)</span>的翻转平移。</p>
<p>首先我们可以观察到，随着x的增长，函数指数级地向下掉。即使和上面增长的函数图像叠加，上面log级别的增长怎么也不可能比得过这里指数级的下跌。这意味着，只要存在风险，就不能无限制加杠杆，否则会极大放大归零风险。特别是当<span
class="math inline">\(x=2\)</span>，加两倍杠杆的时候，正好让自己可以一次归零。</p>
<p>然后我们将两个函数相加，函数<span class="math inline">\(\log(1+0.8x)
+ \log(1-0.5x)\)</span>的图像如下：</p>
<p><img src="logexpect1.png" /></p>
<p>（严格来说，两个函数都要乘以概率0.5，但是函数图像的趋势类似）</p>
<p>可以看到，正好在0.375的时候达到最高点，和凯利公式的结果一致。投入本金的37.5%是最优解。</p>
<p>同时，我们如果在游戏中没有优势，即赢的时候也只能赚一半的本金，那么就有函数图像<span
class="math inline">\(\log(1+0.5x) + \log(1-0.5x)\)</span>，如下：</p>
<p><img src="logexpect2.png" /></p>
<p>可以看到，无论怎么投入，大多数人的本金都是减少的。</p>
<p>总的来说，因为投资总是有赚钱的情况和不赚钱的情况，因此一般都是这样的两个图像叠加。关键在于是否有大于零的情况，以及极值点对应的投入是多少。</p>
<h3 id="判断赚钱的机会">判断赚钱的机会</h3>
<p>还是这个式子，但是这次我们观察在零点处的斜率，看看我们投入很少的本金，是不是能赚到钱。</p>
<p><span class="math display">\[
p_1 \log (1+r_1x) + p_2 \log (1+r_2x) + p_3 \log (1+r_3x)
\]</span></p>
<p>求导后可得</p>
<p><span class="math display">\[
f&#39;(x) = \frac{p_1 r_1}{1 + r_1 x} + \frac{p_2 r_2}{1 + r_2 x} +
\frac{p_3 r_3}{1 + r_3 x}
\]</span></p>
<p>取<span class="math inline">\(x = 0\)</span></p>
<p><span class="math display">\[
f&#39;(0) = p_1 r_1 + p_2 r_2 + p_3 r_3
\]</span></p>
<p>这个其实就是数学期望了。不同的概率下，损失和盈利加权平均。所以期望还是有用的，但是具体的投入比例和期望无关，而是和结果的离散程度有关。</p>
<h3 id="场景买彩票">场景：买彩票</h3>
<p>比如我们考虑买彩票的场景。当然，因为彩票的总体期望是负的，所以怎么算都是赚不了钱的。因此我们看看期望为正的彩票场景：有1%的概率赚200倍，99%概率损失全部本金。</p>
<p>期望：<span class="math inline">\(0.01*200+0.99*-1 =
1.01\)</span></p>
<p>此时的函数是<span class="math inline">\(0.01\log(1+200x) +
0.99\log(1-x)\)</span></p>
<p><img src="logexpect3.png" /></p>
<p>此时只能投入很少量的本金！而期望是几乎翻倍！期望为正只能判断是否能赚，而决定投入比例的是结果的离散程度。</p>
<h3 id="场景借钱">场景：借钱</h3>
<p>假如你要存银行（也算是借钱给银行了），在99%的可能性下会还你的本金加5%利息，在1%的可能性下世界末日，银行倒闭。</p>
<p>期望：<span class="math inline">\(0.99*0.05 - 0.01 * -1=0.0295 &gt;
0\)</span></p>
<p>函数：<span class="math inline">\(0.99\log(1+0.05x) +
0.01\log(1-x)\)</span></p>
<p><img src="logexpect4.png" /></p>
<p>可以看出，还是可以投入大部分钱的，至少大概80%左右。</p>
<p>需要警惕的是，你是否低估了不还钱的风险，比如借给网上认识的网友。只需要将不还钱的可能性增加到5%，就可以抵消利息带来的正期望。</p>
<p>此时期望：<span class="math inline">\(0.97*0.05 + 0.03*-1 =
-0.0025\)</span></p>
<p>如果不还钱的可能性只增加到4%，虽然还是有的赚，但是应该借的比例也依然急剧下降</p>
<p>此时函数：<span class="math inline">\(0.96\log(1+0.05x) +
0.04\log(1-x)\)</span></p>
<p><img src="logexpect5.png" /></p>
<p>可以看到该借的百分比少于30%了。</p>
<p>此时，你的网友说，你借给银行期望也才0.0295，我给你提高利率，让你最终的期望更高，这下可以借给我了吧</p>
<p>利率被提高到了8%，此时期望是<span class="math inline">\(0.96*0.08 +
0.04*-1 = 0.0368\)</span>。然而，此时的函数<span
class="math inline">\(0.96\log(1+0.08x) +
0.04\log(1-x)\)</span>图像是：</p>
<p><img src="logexpect6.png" /></p>
<p>此时应该借的比例依然略小于二分之一。</p>
<h3 id="分散风险">分散风险</h3>
<p>如果有多个独立的赌局，同时分散在他们上，有助于减少风险。</p>
<p>比如最开始的投硬币赚0.8亏0.5的场景，如果钱被等量分散在两个独立赌局，那么其实就变成了四种情况：</p>
<ul>
<li>0.25的概率两边都赚，赚0.8的投入本金</li>
<li>0.5的概率一赚一亏，赚0.15的投入本金</li>
<li>0.25的情况两边都亏，亏0.5的投入本金</li>
</ul>
<p>可以明显看出，严重亏损的概率明显减少。这也使得单次可以投入的本金变多了。</p>
<p>函数是<span class="math inline">\(0.25 \log (1+0.8x) + 0.5 \log
(1+0.15x) + 0.25 \log (1-0.5x)\)</span></p>
<p>当然，前提是风险真正分散了。如果你在A股市场买不同股票，其实背后有很大一块共同的大盘风险。真正分散则需要配置黄金ETF，豆粕ETF等真正风险独立的产品，或者做空等量的指数对冲大盘风险。</p>
<p><img src="logexpect7.png" /></p>
<p>最优投资比例几乎是原来0.375的两倍，即0.75左右。</p>
<h3 id="更复杂的情况">更复杂的情况</h3>
<p>当然，如果同时有着不同的投资机会，那么自然可能会在两个机会上分散，但是有着不同的投资比例。此时可以使用蒙特卡洛模拟法，暴力遍历所有的比例组合可能性，看看哪个更好。</p>
<p>在线工具：</p>
<p><a
href="https://wjk.moe/monte-carlo-invest/">https://wjk.moe/monte-carlo-invest/</a></p>
<p>此外，后续还可以进一步引入夏普比率，通过折算的年化去考虑资金占用的时间太长造成的影响。</p>
<h3 id="函数的构造">函数的构造</h3>
<p>网页中可以加入基于概率的构造方式，而不是仅基于JavaScript函数。当我们只考虑一个产品时，可以创建一个这样的表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">你期望有_p1_%的概率，投入该产品的本金会赚/亏_r1_%</span><br><span class="line">你期望有_p2_%的概率，投入该产品的本金会赚/亏_r2_%</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>然后对于这个市场的预测，可以构建出一个函数，避免了蒙特卡洛采样时，反复调用随机函数导致的开销。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">f = p1 log(1 + r1 * x) + p2 log(1 + r2 * x) </span><br></pre></td></tr></table></figure>
<p>然后直接通过采样的方式画出函数图像。</p>
<p>对于多产品的情况，我们先考虑两个产品，可能存在同时影响两个产品的大盘风险，剩下的则是两个产品独立的情况。可以考虑直接叠加大盘风险。首先增加一个大盘预测表，然后每个产品增加一个大盘风险系数。最终的概率等于自己的函数和大盘的函数的加权和。</p>
<p>UI组织成有向无环图的形式，每个叶子节点都是具体的产品。首先最顶上是大盘风险概率表。然后有一个带风险系数权重的边指向具体的产品概率表。对于多层次的形式，就是中间连接细分板块的风险。</p>
<p>风险可以选择分一块概率出来，或者叠加，但是两者没有本质区别？分概率出来也是函数加起来，叠加也是函数加起来。不对，叠加不是函数加起来，而是假如，每当你买了一部分这个产品，就会同时被迫增送了一定量的大盘产品，增送部分可能赚也可能亏，和原产品独立分布。最终概率需要两个产品的概率正交一下。正交出来其实是稀释风险的，不能简单的按分概率的方式算。</p>
<p>正交的话，也还是带权重的边？那就按权重算，权重用来缩放指数涨跌的收益比例。可以细分板块，但，是不是不太能板块交叉？大盘下面两个小板块再交叉会怎么样？得看是否大盘的影响是仅通过小板块传导，还是说会额外单独也受到大盘影响。</p>
<p>两个板块交错的时候，就直接正交？假如某个公司营收正好美股A股各一半，比如FoF。那么就是直接正交。根据进来的权重。</p>
<p>最后，每个节点出自己的概率分布？还是说对每个叶子节点产品，给一个分配比例作为变量，最终得到一个多维函数，然后里面再找极值点。</p>
<p>如何求所有极值点：即对于<code>f = p1 log(1 + r1 * x) + p2 log(1 + r2 * x) ... + p1 log(1 + r1 * y) + p2 log(1 + r2 * y) + ...</code>
这种形式的函数，可能存在若干维度自变量，分布表示为x,y,z...，如何求所有的极值点？是不是平滑的，能不能通过什么梯度下降的方式。</p>
<p>好像函数是平滑的，求偏导会怎么样？其他的变量相关的很多都会是常数项，就相当于单个函数求偏导。最终可能是反比例函数相关。首先检查是否至少有一个正和负的收益比例，然后就直接梯度下降。</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Investing</tag>
      </tags>
  </entry>
  <entry>
    <title>旧显卡在2026年的AI-LLM生存指南</title>
    <url>/2026/%E6%97%A7%E6%98%BE%E5%8D%A1%E5%9C%A82026%E5%B9%B4%E7%9A%84AI-LLM%E7%94%9F%E5%AD%98%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p>旧显卡在2026年的AI-LLM生存指南</p>
<span id="more"></span>
<h2 id="老显卡的问题">老显卡的问题</h2>
<p>我之前买的是NVidia GForce 2080ti显卡 Turing
架构。最直接的当然是Cuda的兼容等级太低。直接的痛点则是FlashAttention完全不支持，不支持BFloat16
BF16。现在各种模型基本都是FlashAttention和BF16了。</p>
<p>但是其实还是有出路的。首先放弃vLLM，各种新模型从来没有在vLLM上跑起来过。</p>
<h2 id="出路1-ollama">出路1 Ollama</h2>
<p>能用Ollama跑的就不要用别的跑。旧显卡还是ollama好用。主流模型都支持。</p>
<p><strong>核心痛点：Chat Template</strong></p>
<p>如果发现有新模型，只支持vLLM，可以先尝试转到Ollama。使用Ollama的Modelfile，直接下载模型，写一个FROM，然后执行<code>ollama create</code>命令。</p>
<p>如果报错：“不支持的架构”，则接下来应该尝试使用llama.cpp的转换脚本，转成gguf文件后再用Ollama的Modelfile的方式导入。此时，你可能发现模型的性能完全不对劲。此时应该检查template的问题了！</p>
<p>对话模版的作用是插入一些特殊的token。比如下面的是<a
href="https://huggingface.co/tencent/HY-MT1.5-7B/blob/main/chat_template.jinja">混元翻译模型的模版</a>
(注：经过了手动格式化)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% set ns = namespace(has_head=true) %&#125;</span><br><span class="line">&#123;% set loop_messages = messages %&#125;</span><br><span class="line">&#123;% for message in loop_messages %&#125;</span><br><span class="line">    &#123;% set content = message[&#x27;content&#x27;] %&#125;</span><br><span class="line">    &#123;% if loop.index0 == 0 %&#125;</span><br><span class="line">        &#123;% if content == &#x27;&#x27; %&#125;</span><br><span class="line">            &#123;% set ns.has_head = false %&#125;</span><br><span class="line">            &#123;% elif message[&#x27;role&#x27;] == &#x27;system&#x27; %&#125;</span><br><span class="line">            &#123;% set content = &#x27;&lt;|startoftext|&gt;&#x27; + content + &#x27;&lt;|extra_4|&gt;&#x27; %&#125;</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">    &#123;% if message[&#x27;role&#x27;] == &#x27;user&#x27; %&#125;</span><br><span class="line">        &#123;% if loop.index0 == 1 and ns.has_head %&#125;</span><br><span class="line">            &#123;% set content = content + &#x27;&lt;|extra_0|&gt;&#x27; %&#125;</span><br><span class="line">        &#123;% else %&#125;</span><br><span class="line">            &#123;% set content = &#x27;&lt;|startoftext|&gt;&#x27; + content + &#x27;&lt;|extra_0|&gt;&#x27; %&#125;</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">    &#123;% elif message[&#x27;role&#x27;] == &#x27;assistant&#x27; %&#125;</span><br><span class="line">        &#123;% set content = content + &#x27;&lt;|eos|&gt;&#x27; %&#125;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">    &#123;&#123; content &#125;&#125;</span><br><span class="line">&#123;% endfor %&#125;</span><br></pre></td></tr></table></figure>
<p>它会在system message插入特殊token
<code>&lt;|extra_4|&gt;</code>，这种特殊的东西我们看不懂，但是模型之前学过，看得懂，而且可能对性能有影响。其他特殊token可以阅读<a
href="https://medium.com/@khalandar.mokula/understanding-eos-token-and-pad-token-in-model-generate-config-huggingface-transformers-fef6845ed92a">这个文章</a>学习eos_token和pad_token。</p>
<p>各种框架通常采用的是基于jinja的对话模版，转换为GGUF格式，里面存的也是jinja模板。但是<strong>在导入ollama的时候，模版就丢了！！</strong>因为其他框架一般都是jinja的模版，ollama用的是golang模板！</p>
<p><a
href="https://docs.ollama.com/modelfile#message">官网对模版的介绍</a>不全，先看<a
href="https://github.com/ollama/ollama/blob/31085d5e53811bedc53a9cb2afdea45554749d01/docs/template.mdx">这里</a>，现在一般用Messages模板，</p>
<p>简单看了下代码，总之有下面的元素可用。必须用到"Messages"。其他的可能是legacy旧版本的语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">return t.Template.Execute(w, map[string]any&#123;</span><br><span class="line">    &quot;System&quot;:     system,</span><br><span class="line">    &quot;Messages&quot;:   convertMessagesForTemplate(messages),</span><br><span class="line">    &quot;Tools&quot;:      convertToolsForTemplate(v.Tools),</span><br><span class="line">    &quot;Response&quot;:   &quot;&quot;,</span><br><span class="line">    &quot;Think&quot;:      v.Think,</span><br><span class="line">    &quot;ThinkLevel&quot;: v.ThinkLevel,</span><br><span class="line">    &quot;IsThinkSet&quot;: v.IsThinkSet,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="出路2-memoryefficient-attention">出路2 MemoryEfficient
Attention</h2>
<p>就算ollama不能跑，我们也可以直接用huggingface
的transformers包跑模型。大部分情况和ollama一样，是可以直接跑的，少部分情况会发现<strong>内存随着输入长度的增加而暴涨</strong>。此时可能是因为没有启用Memory
Efficient Attention。</p>
<p>通常新款显卡都用的是FlashAttention，它也很节约内存，但是我们老款显卡一般都用不了这个。因此往往会用MemoryEfficient
Attention。因为往往显存大小是瓶颈。普通的直接算Attention，输入长一点可能直接需要的显存比模型还大了。</p>
<p>这一点在支持图片的多模态模型上尤其明显。Qwen-VL系列，一方面使用了Grouped
Query Attention GQA，导致可能底层pytorch不会调用MemoryEfficient
Attention后端。因为Query的张量大小和Key，Value不相等。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UserWarning: For dense input, both fused kernels require query, key and value to have the same num_heads. Query.sizes(): [1, 32, 11861, 128], Key sizes(): [1, 8, 11861, 128], Value sizes(): [1, 8, 11861, 128] instead.</span><br></pre></td></tr></table></figure>
<p>Grouped Query
Attention的原理是多个Query头共享一个Key和Value，但是MemoryEfficient
Attention后端不支持这种情况，导致调用了其他底层后端，消耗过多显存。然而，只需要<strong>把Key和Value直接多复制几份</strong>，使其大小和Query一致，就可以继续用MemoryEfficient
Attention后端了！不会出现内存暴涨的问题。</p>
<p>解决方案：<a
href="https://gist.github.com/am009/be749ce4b6133a2208366205e9d9728b"><strong>更新transformers库里的实现</strong></a>
可以解决这一问题。基本上只有 MemoryEfficient
Attention能用了，其他的占显存太多。最终跑下来速度也不会特别慢，除非输入特别长（或者前面有一张特别清晰的图片）。</p>
<p>另外注意，Qwen系列模型，输入图片的时候最好<strong>长和宽都是28像素的倍数</strong>，不然可能坐标有问题。因为分词器是按照28*28字节划分token的。</p>
<h2
id="让基于python脚本的llm-api也可以超时自动卸载模型节约显存">让基于Python脚本的LLM
API也可以超时自动卸载模型，节约显存</h2>
<p>之前搜了半天怎么写逻辑，在不用的时候卸载模型节约显存，结果发现怎么都卸载不干净。</p>
<p>总结：直接区分进程，在要用的时候才启动相关进程。</p>
<p>使用这个<a
href="https://gist.github.com/am009/78989aa6597245c9444b9253e920ff64"><strong>通用的脚本</strong></a>，它多监听一个端口，将流量转发到另外一个端口。但是如果长时间没有连接，就会启动停止进程的命令，停止占显存的API
Server脚本。如果又进来了新的连接，会自动启动那个API
Server，然后等待启动后转发流量过去。实现了类似Ollama的效果。</p>
<ul>
<li>推荐挂到systemd中成为系统服务，实现开机自动启动，毕竟基本不占什么资源。</li>
<li>如果是Docker程序，则启动和停止命令只需要设置为docker start docker
stop</li>
<li>如果是本地程序，推荐挂载为systemd服务，启动停止命令设置为systemctl
start stop。这个就不用设置开机启动了。</li>
</ul>
<h2 id="总结">总结</h2>
<ul>
<li>老显卡还可以再继续用。</li>
<li>话说，BFloat说不定真的只应该是存储类型？具体运算的时候每一层拿出来再转float32算是不是也完全可以？</li>
</ul>
<h2 id="附录1-jinja模板转ollama的golang模板的提示词">附录1
Jinja模板转Ollama的Golang模板的提示词</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">你需要为某模型的chat_template（使用的jinja模板）生成对应的，使用golang模板语法的模版，下面是golang模板的教程</span><br><span class="line"></span><br><span class="line">## Adding templates to your model</span><br><span class="line"></span><br><span class="line">By default, models imported into Ollama have a default template of `&#123;&#123; .Prompt &#125;&#125;`, i.e. user inputs are sent verbatim to the LLM. This is appropriate for text or code completion models but lacks essential markers for chat or instruction models.</span><br><span class="line"></span><br><span class="line">Omitting a template in these models puts the responsibility of correctly templating input onto the user. Adding a template allows users to easily get the best results from the model.</span><br><span class="line"></span><br><span class="line">To add templates in your model, you&#x27;ll need to add a `TEMPLATE` command to the Modelfile. Here&#x27;s an example using Meta&#x27;s Llama 3.</span><br><span class="line"></span><br><span class="line">```dockerfile</span><br><span class="line">FROM llama3.2</span><br><span class="line"></span><br><span class="line">TEMPLATE &quot;&quot;&quot;&#123;&#123;- if .System &#125;&#125;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;</span><br><span class="line"></span><br><span class="line">&#123;&#123; .System &#125;&#125;&lt;|eot_id|&gt;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- range .Messages &#125;&#125;&lt;|start_header_id|&gt;&#123;&#123; .Role &#125;&#125;&lt;|end_header_id|&gt;</span><br><span class="line"></span><br><span class="line">&#123;&#123; .Content &#125;&#125;&lt;|eot_id|&gt;</span><br><span class="line">&#123;&#123;- end &#125;&#125;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">## Variables</span><br><span class="line"></span><br><span class="line">`System` (string): system prompt</span><br><span class="line"></span><br><span class="line">`Prompt` (string): user prompt</span><br><span class="line"></span><br><span class="line">`Response` (string): assistant response</span><br><span class="line"></span><br><span class="line">`Suffix` (string): text inserted after the assistant&#x27;s response</span><br><span class="line"></span><br><span class="line">`Messages` (list): list of messages</span><br><span class="line"></span><br><span class="line">`Messages[].Role` (string): role which can be one of `system`, `user`, `assistant`, or `tool`</span><br><span class="line"></span><br><span class="line">`Messages[].Content` (string): message content</span><br><span class="line"></span><br><span class="line">`Messages[].ToolCalls` (list): list of tools the model wants to call</span><br><span class="line"></span><br><span class="line">`Messages[].ToolCalls[].Function` (object): function to call</span><br><span class="line"></span><br><span class="line">`Messages[].ToolCalls[].Function.Name` (string): function name</span><br><span class="line"></span><br><span class="line">`Messages[].ToolCalls[].Function.Arguments` (map): mapping of argument name to argument value</span><br><span class="line"></span><br><span class="line">`Tools` (list): list of tools the model can access</span><br><span class="line"></span><br><span class="line">`Tools[].Type` (string): schema type. `type` is always `function`</span><br><span class="line"></span><br><span class="line">`Tools[].Function` (object): function definition</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Name` (string): function name</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Description` (string): function description</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Parameters` (object): function parameters</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Parameters.Type` (string): schema type. `type` is always `object`</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Parameters.Required` (list): list of required properties</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Parameters.Properties` (map): mapping of property name to property definition</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Parameters.Properties[].Type` (string): property type</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Parameters.Properties[].Description` (string): property description</span><br><span class="line"></span><br><span class="line">`Tools[].Function.Parameters.Properties[].Enum` (list): list of valid values</span><br><span class="line"></span><br><span class="line">## Tips and Best Practices</span><br><span class="line"></span><br><span class="line">Keep the following tips and best practices in mind when working with Go templates:</span><br><span class="line"></span><br><span class="line">- **Be mindful of dot**: Control flow structures like `range` and `with` changes the value `.`</span><br><span class="line">- **Out-of-scope variables**: Use `$.` to reference variables not currently in scope, starting from the root</span><br><span class="line">- **Whitespace control**: Use `-` to trim leading (`&#123;&#123;-`) and trailing (`-&#125;&#125;`) whitespace</span><br><span class="line"></span><br><span class="line">样例：原始模版：</span><br><span class="line">```</span><br><span class="line">&#123;% if messages[0][&#x27;role&#x27;] == &#x27;system&#x27; %&#125;</span><br><span class="line">  &#123;% set loop_messages = messages[1:] %&#125;</span><br><span class="line">  &#123;% set system_message = messages[0][&#x27;content&#x27;] %&#125;</span><br><span class="line">  &lt;｜hy_begin▁of▁sentence｜&gt;&#123;&#123; system_message &#125;&#125;&lt;｜hy_place▁holder▁no▁3｜&gt;</span><br><span class="line">&#123;% else %&#125;</span><br><span class="line">  &#123;% set loop_messages = messages %&#125;</span><br><span class="line">  &lt;｜hy_begin▁of▁sentence｜&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br><span class="line">&#123;% for message in loop_messages %&#125;</span><br><span class="line">  &#123;% if message[&#x27;role&#x27;] == &#x27;user&#x27; %&#125;</span><br><span class="line">    &lt;｜hy_User｜&gt;&#123;&#123; message[&#x27;content&#x27;] &#125;&#125;</span><br><span class="line">  &#123;% elif message[&#x27;role&#x27;] == &#x27;assistant&#x27; %&#125;</span><br><span class="line">    &lt;｜hy_Assistant｜&gt;&#123;&#123; message[&#x27;content&#x27;] &#125;&#125;&lt;｜hy_place▁holder▁no▁2｜&gt;</span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line">&#123;% endfor %&#125;</span><br><span class="line">&#123;% if add_generation_prompt %&#125;</span><br><span class="line">  &lt;｜hy_Assistant｜&gt;</span><br><span class="line">&#123;% else %&#125;</span><br><span class="line">  &lt;｜hy_place▁holder▁no▁8｜&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br><span class="line">```</span><br><span class="line">上面的样例jinja模板，正确的转换结果是：</span><br><span class="line">```</span><br><span class="line">&lt;｜hy_begin▁of▁sentence｜&gt;</span><br><span class="line">&#123;&#123;- if .System &#125;&#125;&#123;&#123; .System &#125;&#125;&lt;｜hy_place▁holder▁no▁3｜&gt;&#123;&#123; end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- range $i, $_ := .Messages &#125;&#125;</span><br><span class="line">&#123;&#123;- $last := eq (len (slice $.Messages $i)) 1 -&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- if eq .Role &quot;user&quot; -&#125;&#125;</span><br><span class="line">&lt;｜hy_User｜&gt;&#123;&#123; .Content &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- if eq .Role &quot;assistant&quot; -&#125;&#125;</span><br><span class="line">&lt;｜hy_Assistant｜&gt;&#123;&#123; .Content &#125;&#125;&lt;｜hy_place▁holder▁no▁2｜&gt;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- if and $last (ne .Role &quot;assistant&quot;) -&#125;&#125;</span><br><span class="line">&lt;｜hy_Assistant｜&gt;</span><br><span class="line">&#123;&#123;- else -&#125;&#125;</span><br><span class="line">&lt;｜hy_place▁holder▁no▁8｜&gt;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- end -&#125;&#125;</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">对于下面的模板内容，</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">&#123;% set ns = namespace(has_head=true) %&#125;</span><br><span class="line">&#123;% set loop_messages = messages %&#125;</span><br><span class="line">&#123;% for message in loop_messages %&#125;</span><br><span class="line">    &#123;% set content = message[&#x27;content&#x27;] %&#125;</span><br><span class="line">    &#123;% if loop.index0 == 0 %&#125;</span><br><span class="line">        &#123;% if content == &#x27;&#x27; %&#125;</span><br><span class="line">            &#123;% set ns.has_head = false %&#125;</span><br><span class="line">            &#123;% elif message[&#x27;role&#x27;] == &#x27;system&#x27; %&#125;</span><br><span class="line">            &#123;% set content = &#x27;&lt;|startoftext|&gt;&#x27; + content + &#x27;&lt;|extra_4|&gt;&#x27; %&#125;</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">    &#123;% if message[&#x27;role&#x27;] == &#x27;user&#x27; %&#125;</span><br><span class="line">        &#123;% if loop.index0 == 1 and ns.has_head %&#125;</span><br><span class="line">            &#123;% set content = content + &#x27;&lt;|extra_0|&gt;&#x27; %&#125;</span><br><span class="line">        &#123;% else %&#125;</span><br><span class="line">            &#123;% set content = &#x27;&lt;|startoftext|&gt;&#x27; + content + &#x27;&lt;|extra_0|&gt;&#x27; %&#125;</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">    &#123;% elif message[&#x27;role&#x27;] == &#x27;assistant&#x27; %&#125;</span><br><span class="line">        &#123;% set content = content + &#x27;&lt;|eos|&gt;&#x27; %&#125;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">    &#123;&#123; content &#125;&#125;</span><br><span class="line">&#123;% endfor %&#125;</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">转换后的Golang模板结果是什么？认真思考</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>盘点开源Fuzzer的策略-LibAFL-AFL++-Honggfuzz</title>
    <url>/2026/%E7%9B%98%E7%82%B9%E5%BC%80%E6%BA%90Fuzzer%E7%9A%84%E7%AD%96%E7%95%A5-LibAFL-AFL++-Honggfuzz/</url>
    <content><![CDATA[<p>盘点开源Fuzzer的策略-LibAFL-AFL++-Honggfuzz</p>
<span id="more"></span>
<h2 id="种子调度策略">种子调度策略</h2>
<p><strong>Honggfuzz</strong></p>
<p>在December 21st,
2025，Honggfuzz更新了新的调度函数<code>power_calculateEnergy</code>，这次在种子调度方面直接涵盖了大量的因素</p>
<ul>
<li>Phase-aware energy:
在探索节点，倾向于小于256的种子，给1.5倍分数</li>
<li>Novelty:
根据种子覆盖到的新的边的数量，给指数级增益，最大乘以<code>2**8</code>。随着时间递减，每隔10分钟递减一级</li>
<li>Density：根据coverage情况，优先fuzz 总coverage更高的种子。</li>
<li>Speed：优先速度更快的种子</li>
<li>Fertility：优先生成更多子种子的种子。</li>
<li>Freshness：优先新来的种子，60s内给4倍，5分钟内2倍，60分钟开外给0.5倍</li>
<li>Size：更小的种子</li>
<li>Stack depth：倾向于栈深度更深的种子。</li>
<li>Execution path
diversity：有unique执行路径的种子，如果pathHash不为空。</li>
<li>CMP progress：绕过更多比较运算的种子。</li>
<li>Rare edge bonus：覆盖了其他种子没有覆盖的边</li>
<li>Depth：倾向于派生深度低的种子。</li>
<li>Stagnation：当最近60秒都没有覆盖新的边的时候，倾向于coverage更高的种子。</li>
<li>Entropy：计算输入的熵，惩罚总体看起来更随机的种子。</li>
<li>timedout：如果超时了，除以2**5。</li>
</ul>
<p><strong>AFL++</strong></p>
<p>AFL采用了<a
href="https://zh.wikipedia.org/wiki/%E5%88%A5%E5%90%8D%E6%96%B9%E6%B3%95">别名方法</a>，实现了快速的O(1)采样。但是每次来了新种子需要重新更新别名表。</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>类型系统与编程语言</title>
    <url>/2025/%E7%B1%BB%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[<p>类型系统与编程语言，《Types and Programming
Languages》TAPL的阅读笔记。</p>
<span id="more"></span>
<h3 id="小专题c和java和ml之间的关系">小专题：C和Java和ML之间的关系</h3>
<p>当你发现，简单编程语言，一只手就能数过来的语句种类，加上各种语法糖，居然表达能力就等价于我们常用的C、Java等语言了</p>
<p>盘点C语言的语句： 1. 赋值语句 1. 取地址 1. 解引用加载 1. 解引用存储
1. 内存分配 1. 函数调用</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>StaticAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title>二进制代码的多态类型推断Retypd</title>
    <url>/2025/%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BB%A3%E7%A0%81%E7%9A%84%E5%A4%9A%E6%80%81%E7%B1%BB%E5%9E%8B%E6%8E%A8%E6%96%ADRetypd/</url>
    <content><![CDATA[<p>钻研了两年半《<a href="https://arxiv.org/abs/1603.05495">Polymorphic
Type Inference for Machine
Code</a>》论文。看完本文后还有任何相关的问题可以问我。</p>
<p>跨函数的类型传播算法，可以将库函数的类型传递到代码内部。即使没有库函数识别时，也可以识别处函数内的结构体信息。</p>
<span id="more"></span>
<p><strong>资源</strong></p>
<p><a href="https://github.com/GrammaTech/retypd">retypd</a>
是一个非常高级的反编译类型恢复算法，技术领先程度足以超出其他论文好几年。有一篇<a
href="https://github.com/GrammaTech/retypd/blob/master/reference/paper.pdf">论文</a>:
《<a href="https://arxiv.org/abs/1603.05495">Polymorphic Type Inference
for Machine Code</a>》</p>
<p>资源：</p>
<ul>
<li>优先看<a
href="https://github.com/GrammaTech/retypd/blob/master/reference/type-recovery.rst">这个介绍</a>。</li>
<li>这个<a
href="https://github.com/GrammaTech/retypd/blob/master/reference/presentation_slides.pdf">PPT</a>比论文容易懂很多</li>
</ul>
<h2 id="qa">Q&amp;A</h2>
<h3
id="为什么retypd要有自顶向下分析">为什么Retypd要有自顶向下分析？</h3>
<p>在初始自底向上（bottom-up）阶段后，自顶向下收集函数的调用者传入的所有类型，并生成最具体类型重新作为参数类型传播到函数中。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">linkedBuf</span> &#123;</span></span><br><span class="line">  <span class="type">char</span> buf[<span class="number">50</span>]; <span class="class"><span class="keyword">struct</span> <span class="title">linkedBuf</span>* <span class="title">next</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> linkedBuf* </span><br><span class="line"><span class="title function_">getEnd</span><span class="params">(<span class="keyword">struct</span> linkedBuf* L)</span> &#123;</span><br><span class="line">  <span class="keyword">while</span>(L-&gt;next) &#123; L = L-&gt;next; &#125; <span class="keyword">return</span> L;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">printBuf</span><span class="params">(<span class="keyword">struct</span> linkedBuf* L)</span> &#123;</span><br><span class="line">  <span class="built_in">puts</span>(L-&gt;buf);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">linkedBuf</span> <span class="title">B1</span> =</span> &#123;&#125;;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">linkedBuf</span> *<span class="title">E</span> =</span> getEnd(&amp;B1);</span><br><span class="line">  printBuf(E); <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>printBuf函数，参数可以理解为<code>linkedBuf*</code>，也可以理解为<code>char*</code>。<code>char*</code>是更通用的，<code>linkedBuf*</code>是更具体的。如果所有的caller调用printBuf的时候传的都是<code>linkedBuf*</code>，那么参数可以是它，但是只要有任何caller传了<code>char*</code>，类型就只能是<code>char*</code>了。top_down再来一遍，就是从caller到callee，可以分析每个函数被调用的时候传的参数的情况，比如上面例子里的，是不是没有人传<code>char*</code></p>
<h3
id="区分不同指针之间的类型区分load和store类型">区分不同指针之间的类型（区分load和store类型）</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">爷爷 *q;</span><br><span class="line">曾孙 *p;</span><br><span class="line"></span><br><span class="line">q = p;</span><br><span class="line"></span><br><span class="line">爸爸 x;</span><br><span class="line">孙子 y;</span><br><span class="line"></span><br><span class="line">*q = x;</span><br><span class="line">y = *p;</span><br></pre></td></tr></table></figure>
<p>子类型关系：
曾孙-&gt;孙子-&gt;儿子-&gt;爸爸-&gt;爷爷。子类型指向父类型。</p>
<p>问题：类型推理是可以推理出x &lt;=
y的。但是这里x的类型是爸爸，y的类型是孙子，明显出现了矛盾。问题出在哪里呢？</p>
<p>其实就是C++类型系统的问题，C++允许构造出这种情况，把不合法的类型操作弄成了合法的，说明它的类型系统捕捉不到这种不合法的赋值。（但是至少没有把合法的东西弄成不合法的，不然就影响正常编程了）。</p>
<p>意思是，如果是用retypd作为C++的类型系统（即C++也区分load和store类型），那么在这三句话就已经报错了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">爷爷 *q;</span><br><span class="line">曾孙 *p;</span><br><span class="line"></span><br><span class="line">q = p;</span><br></pre></td></tr></table></figure>
<p>如果把爷爷和曾孙类型换过来，肯定也是有问题的。（难道说retypd只允许完全相等的指针类型才能赋值吗？也不是，这个后面在解释）我们先说明为什么会报错。</p>
<p>我们这样看，首先假设有一个赋值语句<code>q = p</code>。首先可以证明，如果只是简单用<code>某个类型*</code>表示的话，一定会有矛盾。其次，retypd提出了一种全新的子类型方式，使得<code>*p</code>和<code>*q</code>之间不一定是谁是谁的子类型，而是根据用作load还是用作store，给出这样的两个关系：<code>q.store -&gt; p.store</code>
<code>p.load -&gt; q.load</code>。</p>
<p><strong>不区分load/store一定有矛盾</strong>：假设q的类型是<code>Q*</code>，p的类型是<code>P*</code>。那么可以证明，无论Q是P的子类型（协变），还是P是Q的子类型（逆变），都会产生矛盾。</p>
<ul>
<li><p>情况1：P是Q的子类型，我们这里假设，Q是爷爷类型，P是曾孙类型。此时。下面的程序使得爸爸类型被赋值给了孙子类型，所以有矛盾。
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">爷爷 *q;</span><br><span class="line">孙子 *p;</span><br><span class="line"></span><br><span class="line">q = p;</span><br><span class="line"></span><br><span class="line">爸爸 x;</span><br><span class="line">孙子 y;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 往父类指针里面存一个中间类。</span></span><br><span class="line">*q = x;</span><br><span class="line"><span class="comment">// 然后用子类指针取出来，赋值给子类。</span></span><br><span class="line">y = *p;</span><br><span class="line"><span class="comment">// 最终爸爸类型被赋值给了孙子类型。出现类型问题。</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>情况2：Q是P的子类型。 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">孙子* q;</span><br><span class="line">爷爷* p;</span><br><span class="line"></span><br><span class="line">q = p; <span class="comment">// 这里父类指针赋值给了子类指针，明显有问题？</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 直接往p里存父类，然后从q取出来</span></span><br><span class="line">爸爸 x;</span><br><span class="line">孙子 y;</span><br><span class="line">*p = x;</span><br><span class="line">y = *q</span><br><span class="line"></span><br></pre></td></tr></table></figure></p></li>
</ul>
<p>那么retypd到底允许什么类型之间可以有赋值关系呢？</p>
<p><strong>retypd怎么解决的</strong>
可以复习一下函数的子类型关系。结合一下函数的子类型关系，以及getter/setter模式，就可以得到retypd下的指针类型的子类型要求。</p>
<p><strong>函数的子类型关系</strong>
这里其实就是PL领域里常规的要求了，在网上其他的PL基础知识介绍里面说不定有更容易懂的例子。函数的子类型定义是说，如果在调用A函数的时候，我一定能用B函数替换，那么B函数更厉害，所以B函数是子类型。</p>
<p>首先从类比的角度，把函数比作干活的人。有两个工人，工人A一定要钻石镐才能干活，工人B只要有镐子就能干活。这里B能替代A，所以B是A的子类型。这里钻石镐是镐子的一个子集，所以钻石镐是镐子的一个子类型。总结：其他不变的条件下。函数的参数向父类型转变（对参数要求没那么高了），那么函数自身向子类型方向转变。参数变成父类型，函数反而变成子类型，这种反向关系称为逆变。然后我们看返回值。假设还是有两个工人，当前的工作要求是，挖出价值大于20的矿。工人A恰好满足条件。工人B会挖出价值大于10的矿。工人C只会挖出价值大于30的矿。这里明显工人C可以替代工人A，而工人B则无法满足要求。由于价值大于30的矿是价值大于20的矿的子类型，所以我们这里返回值向子类型方向转变之后，变成的新函数可以替代原来的函数。这里返回值变成子类型，函数也变成子类型，转换方向相同，称为协变。</p>
<p>我们沿用之前<code>q = p</code>的例子，但是这一次把它看作一个有getter和setter函数的类。</p>
<p>那么retypd就不会和C++一样，给一个单一的xx*这样的指针类型了，而是会分为load和store类型，这里用getter和setter表示。对于赋值语句<code>q = p</code>，retypd给出了这样的要求：<code>q.store -&gt; p.store</code>（q的setter参数类型是p的setter参数类型的子类型）
<code>p.load -&gt; q.load</code>（p的getter返回值类型是q的getter返回值类型的子类型）。我们先构造出一个满足这个要求的类型，然后拿上面那两个例子来看看会不会出错。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">p</span> &#123; 爸爸 <span class="built_in">get</span>(); <span class="function"><span class="type">void</span> <span class="title">set</span><span class="params">(孙子)</span></span>; &#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">q</span> &#123; 爷爷 <span class="built_in">get</span>(); <span class="function"><span class="type">void</span> <span class="title">set</span><span class="params">(曾孙)</span></span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 赋值语句来自前提条件</span></span><br><span class="line">q = p;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 首先我们尝试往父类型q里面存一个中间类。然后从子类里面取出来？</span></span><br><span class="line">q.<span class="built_in">set</span>(孙子) <span class="comment">// 类型错误了，不能设置</span></span><br></pre></td></tr></table></figure>
<p>最后回顾一下，这个C++它指针只有一种类型。然后retypd里面它的指针存和取是不同的类型。就比如说这里，指针
q
的存和取是两个不同的类型的时候，如果C++也想模仿，但是给p和q只能各写一个类型出来，写哪个好像都会造成问题。既不能说Q是P的子类型，也不能说P是Q的子类型。</p>
<h2 id="开发与使用">开发与使用</h2>
<p>如何使用当前开源的代码呢？代码是一个python模块。当前开源的两个相关的使用代码有：<a
href="https://github.com/GrammaTech/retypd-ghidra-plugin">retypd-ghidra-plugin</a>和<a
href="https://github.com/GrammaTech/gtirb-ddisasm-retypd">gtirb-ddisasm-retypd</a>。</p>
<p>首先分析<a
href="https://github.com/GrammaTech/retypd-ghidra-plugin">retypd-ghidra-plugin</a>是如何使用retypd的。内部代码主要分为ghidra插件的java代码，和封装模块，<a
href="https://github.com/GrammaTech/retypd-ghidra-plugin/tree/master/ghidra_retypd_provider">ghidra_retypd_provider</a>。Java代码部分通过Ghidra提供的API，从Ghidra的反编译器的IR中提取出相关的类型约束，提取为json文件。然后调用python封装模块读取并求解，结果也表示为json文件。然后Ghidra插件部分的java代码读取结果，并设置相应的类型。（注，无论是上次分析lua虚拟机，还是这次分析<code>/bin/ls</code>，花的时间特别久，半小时往上）</p>
<p>输入ghidra_retypd_provider的样例json约束文件如下。可以观察到，每个函数的约束单独分开，同时还包含一个call
graph部分。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;language&quot;</span><span class="punctuation">:</span> <span class="string">&quot;x86/little/64/default&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;constraints&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;FUN_00109d00&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;v_7456 ⊑ v_7780&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_997 ⊑ int64&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_1441 ⊑ FUN_00109b50.in_13&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_4504 ⊑ v_1242.store.σ8@0&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_6777 ⊑ FUN_00109b50.in_5&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;bool ⊑ v_542&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_2301 ⊑ null&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_7379.load.σ8@0*[nobound] ⊑ v_1441&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_4396 ⊑ v_1671.store.σ8@0*[nobound]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_1188.load.σ8@0 ⊑ v_1191&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;v_1671.load.σ8@0*[nobound] ⊑ v_1720&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;FUN_00110e10&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="attr">&quot;callgraph&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;FUN_00109d00&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;FUN_001158c0&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;FUN_00115920&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;FUN_00109b50&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;FUN_00115b30&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;FUN_00110e10&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;strcmp&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;strlen&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;FUN_001158c0&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;getgrnam&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;strcpy&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    ...</span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>输出ghidra_retypd_provider的样例json结果文件如下。可以观察到，包含两种类型的结果，分别是结构体和函数。结构体包含内部的成员及类型。函数块描述了函数的各个参数的类型。在<a
href="https://github.com/am009/retypd-ghidra-plugin/blob/e4f587a2560148f0d0ebbdb2f26fc9977587661f/ghidra_retypd_provider/type_serialization.py#L51">这里</a>的自定义encoder中定义了转json的函数。</p>
<p>这一点其实很奇怪，似乎该插件关注的核心是函数参数类型。这里<a
href="https://github.com/am009/retypd-ghidra-plugin/blob/7c2547574cd86100e02793ae2c8c0cc8f88c3990/GhidraRetypd/src/main/java/ghidraretypd/RetypdTypes.java#L272">后续解析和类型设置</a>也说明了这一点。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;struct&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;struct_545&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;field_0&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;char1_t*&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;offset&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;field_1&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;char1_t[4]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;offset&quot;</span><span class="punctuation">:</span> <span class="number">168</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;function&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;function_260&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;params&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;char1_t[4]&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ret&quot;</span><span class="punctuation">:</span> <span class="string">&quot;char1_t[0]&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  ...</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>接着我们看ghidra_retypd_provider内部是如何调用retypd的。</p>
<ul>
<li><p>使用<code>SchemaParser.parse_constraint</code>解析每个约束项（<code>SubtypeConstraint</code>），它保存子类型关系左右两边的变量（<code>DerivedTypeVariable</code>）。每个函数的约束项放到一个集合里，再按函数名字放到map里，然后构建<code>Program</code>：
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">program = Program(</span><br><span class="line">    CLattice(),</span><br><span class="line">    &#123;&#125;,</span><br><span class="line">    parsed_constraints,</span><br><span class="line">    callgraph,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>这里<code>parsed_constraints</code>就是准备好的那个map。callgraph都不用动，就是<code>Dict[str, List[str]]</code>。前两个参数分别是<code>types: Lattice[DerivedTypeVariable]</code>和<code>global_vars: Iterable[MaybeVar]</code>。</p></li>
<li><p>使用Solver去求解约束： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">config = SolverConfig(top_down_propagation=<span class="literal">True</span>)</span><br><span class="line">solver = Solver(program, config, verbose=LogLevel.DEBUG)</span><br><span class="line">_, sketches = solver()</span><br></pre></td></tr></table></figure></p>
<p>查看solver的<code>__call__</code>方法，可以发现返回类型是<code>Dict[DerivedTypeVariable, ConstraintSet]</code>和<code>Dict[DerivedTypeVariable, Sketch]</code>。</p></li>
<li><p>传入<code>CTypeGenerator</code>，得到最终的类型结果。
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gen = CTypeGenerator(</span><br><span class="line">    sketches,</span><br><span class="line">    CLattice(),</span><br><span class="line">    CLatticeCTypes(),</span><br><span class="line">    int_size,</span><br><span class="line">    pointer_size,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">list</span>(gen().values())</span><br></pre></td></tr></table></figure></p>
<p><code>CTypeGenerator</code>的<code>__call__</code>方法的返回类型是<code>Dict[DerivedTypeVariable, CType]</code>。</p></li>
</ul>
<p>根据<a
href="https://github.com/GrammaTech/retypd/blob/e2c2adac5b123aa68b573192519f0d01e365527d/src/parser.py#L111">这里</a>，每个规则大致就是<code>var1 ⊑ var2</code>或者<code>var1 &lt;= var2</code>，然后两边的变量就是DerivedTypeVariable类型的。因此，上面结果里返回的map其实就能够用来查每个变量的类型。</p>
<p><strong>S-Pointer and S-Field⊕/⊖</strong>
通过搜索代码，可以得知，至少在<a
href="https://github.com/GrammaTech/retypd-ghidra-plugin">retypd-ghidra-plugin</a>和<a
href="https://github.com/GrammaTech/gtirb-ddisasm-retypd">gtirb-ddisasm-retypd</a>中是没有和这个相关的规则的生成的。</p>
<h4 id="retypd-ghidra-插件">retypd ghidra 插件</h4>
<p>在我的<a
href="https://github.com/am009/retypd-ghidra-plugin">fork</a>仓库里可以直接下载到构建好的插件，修改版Ghidra，以及docker镜像。同时提供了给retypd的样例输入和输出。（其实docker容器可以通过挂载x11
socks的方式运行图形界面程序）</p>
<p>通过修改
GhidraRetypd.zip中的extension.properties，可以绕过ghidra插件安装时的版本检查</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">version=<span class="number">10.2</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<p>安装Ghidra插件：</p>
<ol type="1">
<li>打开 Ghidra 软件，点击 "File" 菜单，选择 "Install Extensions"
选项。</li>
<li>在弹出的 "Install Extensions" 窗口中，点击 "Browse"
按钮选择你要安装的扩展程序。</li>
<li>选中你要安装的扩展程序文件（通常是一个 zip 压缩文件），然后点击
"Open" 按钮。</li>
<li>点击 "OK" 按钮开始安装扩展程序。在安装过程中，Ghidra
软件会自动解压缩扩展程序文件，并将它们安装到正确的目录中。</li>
<li>安装完成后，重启 Ghidra。</li>
</ol>
<h2 id="算法详解">算法详解</h2>
<ul>
<li>首先阅读<a
href="http://www.lsv.fr/~schwoon/enseignement/verification/ws1112/c3.pdf">这个PPT</a>和这个论文《<a
href="https://arxiv.org/pdf/1405.5593">Saturation algorithms for
model-checking pushdown systems</a>》，学会B¨uchi发现，
Caucal提出的这个saturation算法。</li>
<li>然后阅读论文，学习其中基于saturation算法改进的部分。</li>
</ul>
<h3 id="自动机基础-saturation-algorithms">自动机基础 Saturation
algorithms</h3>
<p>资料：</p>
<ul>
<li>《<a
href="http://www.lsv.fr/~schwoon/enseignement/verification/ws1112/c3.pdf">Pushdown
systems</a>》了解下推自动机</li>
<li>《<a href="https://arxiv.org/abs/1405.5593">Saturation algorithms
for model-checking pushdown systems</a>》了解Saturation
algorithms相关的背景概念。</li>
</ul>
<p>有两个重要结论：</p>
<ul>
<li>下推系统可达的栈内容形成了一个正则语言，因此可以表示为有限状态自动机。但是最初提出的算法是指数级的。后面有人提出了多项式级的算法，核心思想就是引入一个saturation
process，转换被逐渐地加入有限自动机。（这个结论没有被retypd使用）</li>
<li>下推系统定义了配置（状态加栈字符串）之间的转换关系，可以多项式时间内构建一个带输出的有限状态自动机（transducer）识别这些转换关系。（retypd使用的结论）</li>
</ul>
<p><strong>有限自动机</strong></p>
<ul>
<li><span class="math inline">\(\Sigma\)</span> 是自动机的字符集。<span
class="math inline">\(\Sigma^{*}\)</span> 是字符串的集合。 <span
class="math inline">\(\Gamma^{\leq n}\)</span>
是长度最多为n的字符串集合。</li>
<li>一个在字符集 <span class="math inline">\(\Sigma\)</span> 上的自动机
<span class="math inline">\(\mathcal{A}\)</span> 是一个元组： <span
class="math inline">\((\mathbb{S},\mathcal{I},\mathcal{F},\delta)\)</span>
分别代表有限的状态集合，初始状态集合，最终状态集合，转换规则集合 <span
class="math inline">\(\delta \subseteq \mathbb{S} \times \Sigma \times
\mathbb{S}\)</span> 表示从一个状态遇到一个字符，转换到另外一个状态。
<ul>
<li>有时会把字符集写进来 <span
class="math inline">\((\mathbb{S},\Sigma,\mathcal{I},\mathcal{F},\delta)\)</span>
变成五元组</li>
</ul></li>
<li><span class="math inline">\(s
\overset{a}{\underset{\mathcal{A}}{\longrightarrow}} t\)</span>
表示自动机 <span class="math inline">\(\mathcal{A}\)</span>
有这样一个转换 <span class="math inline">\((s,a,t)\)</span></li>
<li><span class="math inline">\(s
\overset{w}{\underset{\mathcal{A}}{\Longrightarrow}} t\)</span>
表示自动机读入字符串w之后可以转换到t。</li>
</ul>
<h4 id="下推系统-pushdown-system-与-p-自动机">下推系统 pushdown system
与 P-自动机</h4>
<p><strong>和下推自动机的区别</strong>：pushdown
system是自动机的简化版本。当我们用PDS建模程序的时候，有时不太关注读入和识别字符，而是关注栈状态的转移。</p>
<p>和自动机的区别在于没有识别字符串这种概念。自动机一般只能用来识别字符串，有初始态，终止态，遇到某个字符的时候触发转换规则。这里的下推系统则不是识别字符串的，即转换规则里不需要读入字符，直接改变状态和栈内容。这里下推系统直接主要关注栈上的内容字符串。</p>
<p>一个下推系统是四元组 <span
class="math inline">\((Q,\Gamma,\bot,\Delta)\)</span></p>
<ul>
<li><span class="math inline">\(Q\)</span> 是有限的控制状态的集合</li>
<li><span class="math inline">\(\Gamma\)</span> 是有限的栈字符集</li>
<li><span class="math inline">\(\bot \in \Gamma\)</span>
是一个特殊的底部栈字符</li>
<li><span class="math inline">\(\Delta \subseteq (Q \times \Gamma)
\times (Q \times \Gamma^{\leq 2})\)</span>
是转换的集合。表示在一个状态从栈上弹出一个字符，转换到另外一个状态并压入一个字符串。</li>
<li>Configuration表示系统状态，是 当前状态 <span
class="math inline">\(\in Q\)</span> 和 当前栈字符串 <span
class="math inline">\(\in \Gamma^{*}\)</span> 的二元组。</li>
<li>不考虑弹出超过栈底的情况。所以有时会引入特殊底部栈字符，然后要求规则不会把这个符号弹出来。</li>
</ul>
<p><strong>Pushdown system （PDS）可以用来分析程序</strong></p>
<ul>
<li>程序表示
<ul>
<li>状态Q保存程序的全局变量</li>
<li>栈反映程序执行的调用栈</li>
<li>栈上字符编码程序局部变量：比如编码为 当前program counter 和
局部变量的二元组。</li>
</ul></li>
<li>一些例子
<ul>
<li>状态 <span class="math inline">\(pAw\)</span>, 这里 <span
class="math inline">\(p\)</span> 表示状态，代表全局变量， <span
class="math inline">\(Aw\)</span> 表示栈。其中 <span
class="math inline">\(A\)</span>
表示当前的PC和局部变量，w表示调用栈中，被“暂停”执行的程序状态，包括返回地址和局部变量情况。</li>
<li>状态转换 <span class="math inline">\(pA \rightarrow qB\)</span>
表示执行一个普通语句。
<ul>
<li>全局变量可能发生修改，从 <span class="math inline">\(p\)</span> 变成
<span class="math inline">\(q\)</span> ，</li>
<li>栈深度不变，但是从A变成B，表示当前PC和局部变量发生了变化。</li>
</ul></li>
<li>状态转换 <span class="math inline">\(pA \rightarrow qBC\)</span>
表示函数调用
<ul>
<li>栈深度增加了，B里面包含了返回地址以及调用者的局部变量状态。现在压入了被调用者的栈。</li>
</ul></li>
<li><span class="math inline">\(pA \rightarrow q\epsilon\)</span>
表示函数返回
<ul>
<li>栈上弹出了一个字符，表示弹出了一个调用栈。</li>
</ul></li>
</ul></li>
</ul>
<p><strong>PDS的可达性问题</strong></p>
<p>给定一个PDS和两个configuration <span
class="math inline">\(c,c&#39;\)</span>，是否能从 <span
class="math inline">\(c\)</span> 走到 <span
class="math inline">\(c&#39;\)</span> 状态？</p>
<p><span class="math display">\[
\{ w \in \Gamma^{*} \mid  \exists q \in Q, (q_{0},\bot) \Rightarrow
(q,w) \}
\]</span></p>
<p>即求出这样一个集合，从起始状态 <span
class="math inline">\((q_{0},\bot)\)</span> 出发能推导到的所有状态 <span
class="math inline">\((q,w)\)</span> (这里状态 <span
class="math inline">\(q \in Q\)</span>
任意)，其中字符串w组成的集合。</p>
<p><strong>一个非常重要的结论是，这里可达的字符串集合形成了正则语言。</strong>
这意味着函数调用时的状态转换可以用一个有限状态自动机表示。</p>
<p><strong>PDS的configuration的正则性：</strong></p>
<ul>
<li><strong>背景</strong>：众所周知，能被确定有限状态自动机识别的语言是正则（regular）语言。而说到语言，我们会想到根据语法生成的规则，最后推导出很多可以被接受的字符串，但是语言本质也就是一种无限的字符串的集合。
<ul>
<li>如果是有限的话，直接对每个字符串用or连接就完全匹配了。所以一般讨论的都是无限的字符串集合。</li>
</ul></li>
<li><strong>定义1</strong>：如果某个配置集合 <span
class="math inline">\(C\)</span> 是正则的，那么对任意的状态 <span
class="math inline">\(p \in Q\)</span>
（即不管状态），在这个配置集合里面的所有字符串w构成的集合， <span
class="math inline">\(\{ w \in \Gamma^{*} \mid (p,w) \in C\}\)</span>
是正则的。即栈状态构成正则语言。
<ul>
<li>简单来说，不管state，如果栈上字符的集合构成正则的语言，则这个configuration集合是正则的。</li>
</ul></li>
<li><strong>定理1，初始状态可达的配置集合的正则性</strong>：
<ul>
<li>定义：初始配置：任意状态，但是栈为空（仅有 <span
class="math inline">\(\bot\)</span> 符号）的配置</li>
<li>任意pushdown system，从初始配置出发，可达的配置是正则的。</li>
</ul></li>
<li><strong>定理2：后推闭包的正则性</strong>：给定一个正则配置集合C，基于自动机规则任意后推形成的闭包集合也是正则的。
<ul>
<li>写作：<span class="math inline">\(Post^*_{P}(C) = \{ c&#39;  \mid
\exists c \in C, c \underset{P}{\Longrightarrow} c&#39; \}\)</span>
从任意的C中配置开始，在自动机P下能推导出c'，则c'属于集合。</li>
<li>这一定理能从定理1推出：构建一个新自动机P'，增加很多新的state，使得当前配置集合都是初始配置。这里定理里的后推可得到的配置集合其实就是可达的配置集合。</li>
</ul></li>
<li><strong>倒推闭包的正则性</strong>：正则集合的倒推集合，即另外一个配置集合Pre<em>(C)，能够推理得到当前集合C。当前集合是正则的，则Pre</em>(C)也是正则的。
<ul>
<li><strong>原因</strong>：有时候想要基于程序的错误状态，倒退前面的可达状态。</li>
<li><strong>证明</strong>：思想是，构建新的自动机P'，规则和P是反着来的。
<ul>
<li>如果P有个规则是 <span class="math inline">\(qA \rightarrow
p\)</span> 即弹出了字符A。我们P'增加反着来，压入字符A的规则 <span
class="math inline">\(pX \rightarrow
qAX\)</span>。即对于任意字符X，都允许压入AX。</li>
<li>如果P有个规则是 <span class="math inline">\(qA \rightarrow
pBC\)</span> 弹出A压入BC。则我们需要增加两个规则。
<ul>
<li><span class="math inline">\(pB \rightarrow r_{(C,q,A)}\)</span></li>
<li><span class="math inline">\(r_{(C,q,A)} C  \rightarrow  q
A\)</span></li>
<li>直接插入规则的问题在于，下推自动机左边一般只能匹配一个栈顶字符，右边则可以为空，也可以压入两个字符。这里我们需要考虑同时按顺序存在BC字符的情况。</li>
<li>借助中间状态 <span class="math inline">\(r_{(C,q,A)}\)</span>
我们</li>
</ul></li>
<li><strong>一致性</strong>：如果在P中有两个状态可以互推，当且仅当我们P'中这两个状态可以反着互推。而且P'满足上面定理的要求，然后应用上面正推的定理，成功证明反推定理。</li>
</ul></li>
</ul></li>
</ul>
<!-- 但是实际构建出来可能存在很多初始状态不可达的序列。例如如果有规则 $A.load \sqsubseteq B$ 我们增加初始状态的转换，使得初始状态可达 (A/B, $\bot$) 的配置。但是规则并不允许 $(A, \bot) \rightarrow (A, .load)$ ，否则存在子类型关系 $A \sqsubseteq A.load$。也因此，这里构建的自动机没有用在retypd中。 -->
<p><strong>PDS对应的自动机</strong></p>
<p>有一个PDS <span class="math inline">\(\mathcal{P}=(P, \Gamma,
\Delta)\)</span>，我们对应有一个有限自动机 <span
class="math inline">\(\mathcal{A}=(Q, \Gamma, P, T, F)\)</span></p>
<ul>
<li>PDS的栈字符集 <span class="math inline">\(\Gamma\)</span>
被用作有限自动机的字符集。PDS栈字符原本用来表示局部变量和PC。</li>
<li>PDS的控制状态（表示全局变量），被用作有限自动机的初始状态。</li>
<li>我们称，有限自动机接受配置 <span class="math inline">\(pw\)</span>
，如果自动机从状态p开始，接受字符串w之后能停止在终结态。而且对应每个PDS都能构造出这样的自动机。
<ul>
<li>直观上理解：对任意的state（代表了程序的全局变量状态），此时可能的栈情况是什么样的？这些所有可能的栈情况可以用一个有限自动机来表达。</li>
<li>上面提到，不考虑状态，单把栈上字符串拿出来，形成的也是正则语言。这里其实表达的是一个意思。每个configuration的状态作为初始状态，然后存在一个P-有限自动机匹配栈上的内容，其实就是说明了栈上形成的是正则语言。</li>
</ul></li>
</ul>
<p>本质上我们关注的是操作序列。操作序列是一个函数，描述了所有可能的初始栈和操作后的栈之间的关系。一个栈就是对应一个变量加一系列标签，就是派生变量。所以描述的是派生变量之间的关系。</p>
<p><strong>操作序列的概念类比</strong>。你就想象有一个人在流水线上，拿着这个操作序列的纸条去操作一个存了方块的栈。比如说纸条是
pop蓝色，push红色。那么我们给一个栈，里面方块按自顶向下顺序是（蓝，黄），传入流水线，里面的人根据指示拿出一个蓝色的方块，放入一个红色的方块，然后把栈传出来，得到新的栈（红，黄）。这里这个人就看作一个函数，进入流水线时的栈状态（蓝，黄）就是定义域，出来流水线的栈状态就是值域。我们这里关注的是内部的操作，而不局限于具体的某一个输入输出。还有操作失败的情况：如果输入的栈顶上不是蓝色，但是里面的人要按照指示先拿出蓝色方块，那么我们说这个输入的栈序列不被这个操作序列接受。</p>
<p>有几种值得注意的情况： - <strong>push B, pop
A的无法操作序列</strong>：比如纸条里面的序列有这样连续的两个操作，push蓝色然后pop红色，可以想象push之后顶上就是蓝色的方块，所以不可能从顶上拿出一个红色的方块。此时没有任何输入的栈能够满足操作的要求，我们称这个操作序列是non-productive的。
- <strong>pop A, push
A的无操作序列</strong>：比如纸条里面的序列有这样连续的两个操作，push蓝色然后pop蓝色，可以想象push再pop之后等于啥也没干，因此如果发现了这种情况，可以直接把这两个操作组合抵消掉。</p>
<p>定理：所有可能的输入栈是无限的。证明过程：纸条上的操作序列是确定的，因此，总有一个访问的最大深度，此时不会操作到更深的栈里面的东西，因此更深的栈里面无论放什么都是符合输入要求的。</p>
<p>更进一步，我们可以把纸条上的序列内容拓展为一个自动机，描述一个序列的正则集合。里面的工人可以根据自动机的定义，操作的同时变更自动机的状态，然后根据当前状态看接下来允许的操作是什么。操作完成后看是否在终结态，判断是否能停止操作栈并输出。</p>
<p>子类型关系一个核心的部分就是，比如A和B有子类型关系，那么两个加上相同标签（比如都访问相同offset的成员）之后，还是有子类型关系。栈的操作的特点是，可能只会操作某个最大深度向上的顶部的东西。这个时候，一个操作序列就可以只把顶部的有子类型关系的变量换掉，然后栈底下的东西不动，这里栈底下的东西就是这里子类型关系前面相同的标签。</p>
<p>比如A和B有子类型关系，有一个pop A，push
B的序列被自动机接受。这个操作序列可以对什么样的栈就行操作呢？当然是顶部有A的栈，不然pop不了这个东西。后面的push操作会压入一个B。</p>
<p><strong>Pre(S)的Saturation Algorithm</strong></p>
<ul>
<li>相关符号总结
<ul>
<li><span class="math inline">\(\Delta\)</span>: pushdown
system的下推规则</li>
<li><span class="math inline">\(\delta\)</span>:
P-自动机的状态推理规则。后面会不断增加规则，构成一个递增的规则序列。</li>
<li><span class="math inline">\(Q\)</span>: pushdown
system的状态集合，也是P-自动机的初始状态</li>
<li><span class="math inline">\(\mathcal{F}\)</span>:
P-自动机的终止状态集合</li>
<li><span class="math inline">\(\mathcal{A}\)</span>:
P-自动机。包括状态集合 <span class="math inline">\(\mathbb{S}\)</span>,
初始状态 <span class="math inline">\(Q\)</span>, 推理规则 <span
class="math inline">\(\delta\)</span> 和终止状态 <span
class="math inline">\(\mathcal{F}\)</span>。</li>
<li><span class="math inline">\(\mathcal{L}(\mathcal{A})\)</span>:
表示A接受的语言。</li>
<li><span class="math inline">\(\mathcal{B}\)</span>:
需要构建的新自动机，接受 <span class="math inline">\(Pre^{*}_P
(\mathcal{L}(\mathcal{A}))\)</span></li>
</ul></li>
<li>Saturation Algorithm算法
<ul>
<li><p>前提：已知一个下推系统 <span
class="math inline">\(P=(Q,\Gamma,\bot,\Delta)\)</span>
,和对应的P-自动机 <span
class="math inline">\(\mathcal{A}=(\mathbb{S},Q,\delta,\mathcal{F})\)</span></p></li>
<li><p>目标：构建出一个新的自动机 <span
class="math inline">\(\mathcal{B}\)</span> 接受语言 <span
class="math inline">\(Pre^{*}_P
(\mathcal{L}(\mathcal{A}))\)</span></p></li>
<li><p>过程：构建一个自动机的序列 <span
class="math inline">\((\mathcal{A}_{i})_{i \in [0,N]}\)</span></p>
<ul>
<li>其中其他部分都是相同的，状态数量是相同的，只有转换规则 <span
class="math inline">\(\delta_i\)</span> 不同。</li>
<li>保证转换规则只会增加新的规则： <span class="math inline">\(i \in
[0,N-1]\)</span>, <span class="math inline">\(\delta_{i} \subseteq
\delta_{i+1}\)</span></li>
<li>最后转换规则会收敛，达到不动点： <span
class="math inline">\(\delta_{i+1}=\delta_{i}\)</span></li>
<li>每次至少增加一个规则，因此程序最多走 <span
class="math inline">\(|Q|^{2} |\Gamma|\)</span> 步
<ul>
<li>作为一个有限状态自动机，这里只对Q状态增加边，每两个状态之间最多
<span class="math inline">\(|\Gamma|\)</span> 个规则。</li>
</ul></li>
</ul></li>
<li><p>算法：如果有一个规则 <span class="math inline">\(pA \rightarrow
qw\)</span> ，同时现在的P-自动机存在一个路径 <span
class="math inline">\(q
\overset{w}{\underset{\mathcal{A}_{i}}{\Longrightarrow}} s\)</span>
我们给P-自动机增加一个新的转换规则 <span class="math inline">\(p
\xrightarrow[]{A} s\)</span></p>
<figure>
<img src="saturation.drawio.png" alt="saturaion" />
<figcaption aria-hidden="true">saturaion</figcaption>
</figure>
<p><code>p Au -&gt; q wu</code>。原有自动机为黑色部分，u代表未知任意字符串，即代表的是路径，内部省略了具体的其他节点。意味着从状态为q栈为空的状态，能够接受一个字符串wu。</p>
<p>然后我们新增了这样一条规则，使得状态为p，字符串为Au也被接受了。</p>
<p>规则的构建使得，某个下推系统的前驱规则的节点被覆盖到了。而最后目的自动机
<span class="math inline">\(\mathcal{B}\)</span>
由于达到了不动点，因此关于下推系统P的前驱规则封闭。</p></li>
<li><p>证明过程的不变量：在这个自动机转换规则的序列中，存在一些始终为真的条件。如果自动机存在转换规则
<span class="math inline">\(p \xrightarrow[]{A} s\)</span>
，那么以下两个性质始终满足满足。</p>
<ul>
<li>如果状态s属于下推系统P的状态：在下推系统P中存在规则 <span
class="math inline">\(pA \overset{}{\underset{P}{\Longrightarrow}}
s\)</span>。这是一个弹出栈字符的规则。</li>
<li>如果状态s属于其他状态，即不属于下推系统P的状态：对于任何从状态s出发能被接受的字符串u，配置
<span class="math inline">\((p,Au)\)</span> 属于 <span
class="math inline">\(Pre^{*}_P (\mathcal{L}(\mathcal{A}))\)</span></li>
<li>从这个不变关系，可以推出， <span
class="math inline">\(\mathcal{L}(\mathcal{A}_i) \subseteq Pre^{*}_P
(\mathcal{L}(\mathcal{A}))\)</span> ，即每个A的语言都是我们目标的子集。
特别地， <span class="math inline">\(\mathcal{L}(\mathcal{B}) \subseteq
Pre^{*}_P (\mathcal{L}(\mathcal{A}))\)</span>
最终迭代的不动点也是这样。</li>
</ul></li>
<li><p>最小关系：我们如果只关注状态在Q中（下推系统的状态）的部分，那么关系只在
<span class="math inline">\((Q \times \{\varepsilon\}) \times (Q \times
\Gamma)\)</span> 上被添加 1. 左边都是初始状态; 2.
转换规则都是接受了一个字符。 这里增加的关系可以被看作是一个最小关系
<span class="math inline">\(\mathcal{R}\)</span></p>
<ul>
<li><span class="math inline">\(pA \; \mathcal{R} \; q\)</span>
如果存在规则 <span class="math inline">\(pA \rightarrow q\)</span></li>
<li><span class="math inline">\(pA \; \mathcal{R} \; q\)</span> 如果
<span class="math inline">\(rB \; \mathcal{R} \; q\)</span> 并且 <span
class="math inline">\(pA \rightarrow rB\)</span> 在规则中。
<ul>
<li>这里关系 <span class="math inline">\(\mathcal{R}\)</span>
似乎会对每个带栈字符的状态创建一个无字符的对应状态？比如这里为 <span
class="math inline">\(rB\)</span> 引入中间状态</li>
</ul></li>
<li><span class="math inline">\(pA \; \mathcal{R} \; q\)</span>
如果存在规则 <span class="math inline">\(pA \rightarrow
rBC\)</span>，并且存在状态 <span class="math inline">\(s\in
Q\)</span>，关系 <span class="math inline">\(rB \; \mathcal{R} \;
s\)</span> 和 <span class="math inline">\(sC \; \mathcal{R} \;
q\)</span>
<ul>
<li>这里 <span class="math inline">\(q\)</span> 仿佛直接代表了 <span
class="math inline">\(rBC\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p><strong>和retypd的PDS对应</strong>：我们构建的PDS表达的是子类型之间的转换关系，某个配置如果可达，表示这种dtv的存在。</p>
<ul>
<li>首先，我们构建一个自动机识别当前所有存在的变量。
<ul>
<li>初始状态是所有顶层变量，栈为空的变量。</li>
<li>终止状态是所有存在的变量。
<ul>
<li>如果顶层变量存在，则它也是终止状态。</li>
<li>如果某个dtv存在，我们构造从顶层变量到它的连续的push边，表示从顶层变量走过来要识别这些栈字符，然后把它设置为终止态。</li>
</ul></li>
</ul></li>
<li>然后我们使用saturation算法计算post*。</li>
</ul>
<p>得到的自动机描述所有可达的配置集合，即描述所有可能存在的dtv，进一步得到每个变量所有可能存在的标签语言，即sketches。</p>
<h4 id="描述派生可达关系的-transducer">描述派生（可达）关系的
Transducer</h4>
<p>基础概念：</p>
<ul>
<li><p>Finite State Transducer 其实就是带有输出的有限状态自动机（finite
state automaton）。简单来说自动机的边上标记了(push/pop,
字符)的pair，表示一个操作。想象自动机有一个栈，栈里放了一个待转换的字符串，自动机先走过一些弹出字符的边，弹出栈顶对应字符，然后再走一些压入字符的边，压入字符到栈顶，这样就完成了栈顶，甚至整个字符串的替换。此时把栈拿出来就是输出的字符串。</p></li>
<li><p>派生关系 <span
class="math inline">\(Deriv_{P}\)</span>：描述任意两个字符串之间的关系：
<span class="math inline">\(Deriv_{P} =\{ (u,v) \in \Gamma^{*} \mid
(q_{0},u) \overset{}{\underset{P}{\Longrightarrow}} (q_{f},v)
\}.\)</span></p>
<ul>
<li><span class="math inline">\(Deriv_{P} \subseteq \Gamma^{*} \times
\Gamma^{*}\)</span> 。是字符串之间的关系。</li>
</ul></li>
<li><p>操作：<span class="math inline">\(A_{+}\)</span>
表示压入单个符号的操作 push A（<span class="math inline">\(A \in
\Gamma\)</span> 是字符）。 <span class="math inline">\(A_{-}\)</span>
同理。</p>
<ul>
<li>操作集合 <span class="math inline">\(\Gamma_{+}=\{ A_{+} \mid A \in
\Gamma\}\)</span> push操作的集合， <span
class="math inline">\(\Gamma_{-}\)</span> 同理。 <span
class="math inline">\(\overline{\Gamma}=\Gamma_{+} \cup
\Gamma_{-}\)</span> 表示两个的并集。</li>
<li>操作序列： <span class="math inline">\(\alpha=\alpha_{1} \ldots
\alpha_{n} \in \overline{\Gamma}^{*}\)</span> 表示一系列操作。
<ul>
<li>例如， <span class="math inline">\(pA \rightarrow qBC\)</span>
的操作序列是 <span class="math inline">\(A_{-}C_{+}B_{+}\)</span></li>
</ul></li>
<li>操作转换关系： <span class="math inline">\(u
\overset{\alpha}{\underset{}{\leadsto}} v\)</span> 表示栈状态 <span
class="math inline">\(u \in \Gamma^{*}\)</span> 在操作 <span
class="math inline">\(\alpha\)</span> 下变成了栈状态 <span
class="math inline">\(v\)</span>。</li>
<li>non-productive序列：无法被应用的栈序列，常常是这种 <span
class="math inline">\(B_{+} C_{-}\)</span>
先push再pop一个不同符号的序列，刚压入B，怎么可能栈顶弹出C呢？
<ul>
<li>就像下面对比图先走橙色边再走蓝色边一样。</li>
</ul></li>
</ul></li>
<li><p>对比自动机和transducer</p>
<figure>
<img src="saturation3.drawio.png" alt="对比自动机和transducer" />
<figcaption aria-hidden="true">对比自动机和transducer</figcaption>
</figure>
<p>注意到几点：1.
Transducer的边可以看作双向的，如果有个pop过去的边，则也可以push回去。而且这里pop边和P-自动机的边对应。2.
从非确定性自动机NFA角度看，transducer 1 和transducer 2是等价的。3.
这里可以看到，transducer的状态可以和PDS配置是一个一对多的关系。</p></li>
<li><p>行为集合 <span class="math inline">\(Behaviour_{P}\)</span>
表示下推系统P，不管是否non-productive，可能走出的所有栈操作序列的集合。</p>
<ul>
<li>即我现在只需要管状态转换，不需要管栈操作的应用。</li>
<li>即画出上面的转换图，然后随便沿着边走</li>
</ul></li>
<li><p><span class="math inline">\(Behaviour_{P}\)</span> 和 <span
class="math inline">\(Deriv_{P}\)</span>
的关系：对于任何在行为集合的操作序列， <span
class="math inline">\(\alpha \in Behaviour_{P}\)</span> ，
两个字符串属于派生关系集合 <span class="math inline">\((u,v) \in
Deriv_{P}\)</span> 当且仅当 这两个字符串存在操作关系 <span
class="math inline">\(u \overset{\alpha}{\underset{}{\leadsto}}
v\)</span> 。</p>
<ul>
<li>然而这个定义不太行，因为 (1) <span
class="math inline">\(Behaviour_{P}\)</span> 有很多不合法的序列。(2)
存在刚push就pop的冗余序列，如 <span class="math inline">\(A_{-} B_{+}
A_{+} A_{-} C_{+} C_{-}=A_{-} B_{+}\)</span> 。</li>
</ul></li>
<li><p>简化关系 <span class="math inline">\(\mapsto\)</span>
：表示一个栈操作序列被简化为另外一个栈操作序列。消除了上面的这种刚push就pop的冗余行为</p>
<ul>
<li>例如 <span class="math inline">\(B_{-}A_{+}A_{-}C_{+} \mapsto
B_{-}C_{+}\)</span></li>
</ul></li>
<li><p>操作序列集合在简化操作下维持正则性：如果一个操作序列集合R内的每个操作都被
<span class="math inline">\(\mapsto\)</span> 简化，那么新的集合 <span
class="math inline">\(Red(R) = \{ Red(\alpha)  \mid \alpha \in R
\}\)</span> 也是正则的</p></li>
<li><p>操作序列自动机的简化算法： <span
class="math inline">\(Red(R)\)</span> 能在 <span
class="math inline">\(\mathcal{O}(|\mathcal{A}|^{3})\)</span>
的复杂度构建出来。</p></li>
<li><p>简化并移除non-productive序列的操作集合 <span
class="math inline">\(RP_{P}\)</span></p>
<ul>
<li>移除non-productive序列：简化后很容易识别，直接扫描找先push再pop的序列。因为如果push的字符和pop的字符不同则不合法，相同则说明化简没有结束。</li>
<li>性质：可以推出里面的序列必然只会先pop再push。</li>
</ul></li>
<li><p>最终的结论：</p>
<ul>
<li><span class="math inline">\(Deriv_{P}\)</span> 的关系 <span
class="math inline">\((w_{1},w_{2})\)</span> 对应到transducer
必然是，找出两个串的公共后缀，然后先pop w1的前缀，然后push
w2的前缀。</li>
<li><span class="math inline">\(Deriv_{P}\)</span> 对应的 Transducer
可以在多项式时间内被构建出来。</li>
</ul></li>
</ul>
<p>核心在于，将状态转换改为了一个push pop栈的序列。即，如果有一个 <span
class="math inline">\(pA \rightarrow rw\)</span>
规则，那么我们这里构建一个序列：pop A，push
...(构成w的几个字符)。表示栈上的变化关系。</p>
<p>然后使用饱和（Saturation）算法。这里需要每条边上的操作只能压入或者弹出单个字符。即找到两个路径上能化简的状态，然后直接连过去，标上化简后的操作序列。</p>
<p>这里的饱和（Saturation）算法才是后面retypd使用的。</p>
<h3 id="retypd-基础符号">retypd 基础符号</h3>
<p><strong>使用的符号</strong></p>
<ul>
<li><span class="math inline">\(\mathcal{V}\)</span>: 类型变量的集合
<ul>
<li>在这个集合里包含一系列类型常量，作为一种符号描述。这些类型常量可能形成一个lattice，但是我们不解释它们。</li>
</ul></li>
<li><span class="math inline">\(\Sigma\)</span>: 字段标签 field
label。不一定是有限的。主要的符号如下：
<ul>
<li><span class="math inline">\(\mathsf{.in}_L\)</span>
函数在位置L的输入</li>
<li><span class="math inline">\(\mathsf{.out}_L\)</span>
函数在L位置的输出</li>
<li><span class="math inline">\(\mathsf{.load}\)</span> 可读的指针</li>
<li><span class="math inline">\(\mathsf{.store}\)</span> 可写的指针</li>
<li><span class="math inline">\(.\sigma\mathsf{N@k}\)</span>
在偏移k处有一个N bit的成员。</li>
</ul></li>
<li>函数 <span class="math inline">\(\langle \cdot \rangle : \Sigma \to
\{ \oplus, \ominus \}\)</span>: 从结构体label映射到 <span
class="math inline">\(\{ \oplus, \ominus \}\)</span>
表示variance，协变和逆变属性</li>
<li>派生的类型变量 derived type variable (定义3.1)：形为 <span
class="math inline">\(\alpha w\)</span> ，其中类型变量 <span
class="math inline">\(\alpha \in \mathcal{V}\)</span> and 字段标签 <span
class="math inline">\(w \in \Sigma^*\)</span>.</li>
<li>标签 <span class="math inline">\(\ell\)</span> 的variance
(定义3.2)，指的是前面的类型变量的类型如果发生变化时，带标签的派生类型变量的variance的变化方向。
<span class="math inline">\(\alpha.\ell\)</span> 和 <span
class="math inline">\(\beta.\ell\)</span> 中，如果 <span
class="math inline">\(\alpha\)</span> 是 <span
class="math inline">\(\beta\)</span> 的子类型。</li>
<li>约束 <span class="math inline">\(c\)</span>
(定义3.3)有两种形式。约束的集合用 <span
class="math inline">\(\mathcal{C}\)</span> 表示
<ul>
<li>存在形式: (派生)类型变量X存在</li>
<li>子类型形式：(派生)类型变量X是Y的子类型。</li>
<li>约束的推导 <span class="math inline">\(\mathcal{C} \vdash c\)</span>
表示约束能从原约束集合中，由那些规则派生出来。</li>
<li>约束中的自由变量定义 <span class="math inline">\(\exists \tau .
\mathcal{C}\)</span> 表示，存在变量 <span
class="math inline">\(\tau\)</span> 满足了约束集合。</li>
</ul></li>
<li>Type Scheme类型方案，表示一个泛型的函数。 <span
class="math inline">\(\forall{\overline{\alpha}}.{\mathcal{C}}\Rightarrow{\beta}\)</span>
表示在约束C的条件下，带有模板变量集合 <span
class="math inline">\(\overline{\alpha}\)</span> 的泛型类型 <span
class="math inline">\(\beta\)</span>
<ul>
<li>仅增加约束： <span class="math inline">\(\forall \tau . C
\Rightarrow \tau\)</span> 表示仅对类型 <span
class="math inline">\(\tau\)</span> 增加约束。
<ul>
<li>例如 <span class="math inline">\(\forall \tau .
(\tau.\mathsf{in}.\mathsf{load}.\sigma\mathsf{32@4} \sqsubseteq
\tau.\mathsf{out}) \Rightarrow \tau\)</span>
表示函数返回了参数在4字节offset位置的成员。</li>
</ul></li>
<li>和约束的关系：基本是对应的。可以想象为我们主要关注约束，任何类型方案都可以理解为，声明一些通配符变量，然后定义一些约束。例如
<span class="math inline">\(\forall \alpha . (\exists \tau .
\mathcal{C}) \Rightarrow \alpha\)</span>
。通过引入新的类型变量，可以让最右侧总是等于单个变量。如果能把约束里每个类型变量解出来，那么这个泛型也很容易得到。</li>
<li>和sketch的关系。通过inferShapes算法将约束求解为变量映射到sketch的树/自动机结构。</li>
</ul></li>
</ul>
<p><strong>常见术语</strong></p>
<ul>
<li>pushdown system: 在基本的自动机的基础上，额外增加了一个栈结构。</li>
<li>non-structural subtyping:
即子类型关系不一定非要结构完全相同（在structural
subtyping中只能叶子节点不同）。尤其是在有结构体和对象这种情况。见<a
href="https://web.cs.ucla.edu/~palsberg/paper/fac97.pdf">"Type Inference
with Non-structural Subtyping"</a></li>
</ul>
<p><strong>规则生成</strong></p>
<ul>
<li>复制操作：x :=
y，此时保守地认为，有可能是子类型赋值给了父类型变量：Y ⊑ X。
<ul>
<li>由复制操作带来的数据流，类型方向是父类型。子类型赋值给了父类型。</li>
</ul></li>
<li>指针加载：x := *p，生成：P.load.σ32@0 ⊑ X 。</li>
<li>指针赋值：*q := y，生成 Y ⊑ Q.store.σ32@0 。</li>
<li>函数调用：如果有调用y := f(x)，生成 X ⊑ F.in 和 F.out ⊑ Y 。</li>
<li>icmp：两值进行比较的时候：1 bool类型是结果的子类型。2
两个被比较的值直接，随便生成一个子类型关系？</li>
</ul>
<p><strong>规约规则</strong></p>
<ul>
<li><strong>T-Left</strong>/<strong>T-Right</strong>/<strong>T-Prefix</strong>:
如果存在约束 <span class="math inline">\(\alpha \sqsubseteq
\beta\)</span> ，则 <span class="math inline">\(\alpha\)</span> 和 <span
class="math inline">\(\beta\)</span> 存在。如果存在一个带field
label的派生变量，则原始变量存在。
<ul>
<li>这意味着在算法中我们在访问约束时会创建对应变量节点。</li>
</ul></li>
<li><strong>T-InheritL</strong> / <strong>T-InheritR</strong>:
子类型能安全代换父类型。父类型如果能带一个field
label，则子类型带有相同的field label的派生变量也存在。</li>
<li><strong>S-Refl</strong>: 反射性，自己是自己的子类型。</li>
<li><strong>S-Field<span class="math inline">\(_\oplus\)</span></strong>
/ <strong>S-Field<span class="math inline">\(_\ominus\)</span></strong>:
如果field label的variance是协变 <span
class="math inline">\(\oplus\)</span>，则原变量子类型关系在带上标签后保持。否则反过来。</li>
<li><strong>S-Pointer</strong>: 指针存入的类型是取出的子类型。</li>
</ul>
<p><strong>sketches</strong>
约束的求解结果被表示为sketches。每个value关联上一个sketch，包含该value的所有能力，即能否被store，能否访问指定的偏移。同时sketch还包含一个可自定义的lattice，用来传播类似于typedef这种类型。</p>
<p>我们分析的不是具体的程序中的变量，而是他们的类型和类型之间的关系。因为复杂的约束关系，我们会把类型再设为一个类型变量，称为DataTypeVariable，DTV。</p>
<p><strong>什么是Sketches</strong>：一个派生类型变量DTV，可能有各种各样的能力，比如可以在offset为4的地方load出一个四字节的值
（<code>.load.σ32@4</code>）。首先可以遍历所有的约束关系，比如<code>v_4504 ⊑ v_1242.store.σ8@0</code>，对每个关系单独看两边的变量，然后看比如<code>v_1242</code>是否被直接这样取过offset，然后把这些操作收集起来。但是这样还不够，因为可能因为约束的存在，其他变量能做的操作，它因为约束，应该也能做。这些都求解出来，得到的数据结构就是一个Sketch。</p>
<p>一个Sketch才是真正直接代表一个具体的类型。是一个树状的类型结构。这个树的边上标记了field
label，节点上标记了类型lattice上的元素。</p>
<p><strong>基于程序操作的约束生成</strong></p>
<ul>
<li>变量复制/赋值：要么两边类型相同，要么根据安全代换原则，子类型被赋值为父类型。</li>
<li>指针读取：增加field label。
<ul>
<li>指针的读和写能力分开考虑。子类型方面特殊处理。</li>
</ul></li>
<li>函数调用：参数父类型，返回值子类型。
<ul>
<li>单独的类型变量规则是structural的，即子类型和父类型的能力必须一致。但是在函数调用时，可以遗忘一些能力。</li>
</ul></li>
</ul>
<h2 id="规约算法概述section-5">规约算法：概述（Section 5）</h2>
<h3 id="约束的简化">约束的简化</h3>
<p><strong>类型，以及函数的类型到底应该怎么表示？</strong></p>
<ul>
<li>格表示的类型：对于单个固定大小的基本类型，可以使用lattice结构以及一个偏序关系表示类型。子类型为格上的偏序关系</li>
<li>对于复杂的具有能力的类型，比如访问某个偏移字段的能力，加载出值的能力，则类似结构体的子类型关系，子类型允许具有更多能力，安全代换父类型。</li>
<li>函数的类型则涉及到泛型的类型方案的表示 <span
class="math inline">\(\forall{\overline{\alpha}}.\,{C}\!\Rightarrow\!{\tau}\)</span>
。为函数的输入和输出类型创建类型变量，然后得到一个变量的最小约束集合表示这个函数的类型。
<ul>
<li>例如通用的恒等函数，直接将参数返回，表示为，对任意的类型X，返回值的类型也是X。对应我们的表示可能是
<span class="math inline">\(F.in \sqsubseteq F.out\)</span></li>
</ul></li>
<li>PDS = （未化简，或者简化后的）约束 = 类型方案 type scheme</li>
</ul>
<p><strong>我们为什么要简化约束？</strong>
为了减少无用的自由变量，降低约束集的增长率。令 <span
class="math inline">\(\mathcal{C}\)</span>
表示由抽象解释生成的过程的约束集，并且 <span
class="math inline">\(\overline{\alpha}\)</span> 是 <span
class="math inline">\(\mathcal{C}\)</span>
中的自由类型变量集。我们其实已经可以使用 <span
class="math inline">\(\forall{\overline{\alpha}}.\,{\mathcal{C}}\!\Rightarrow\!{\tau}\)</span>
作为过程类型方案中的约束集，因为合法调用 <span
class="math inline">\(f\)</span> 时使用的输入和输出类型显然是满足 <span
class="math inline">\(\mathcal{C}\)</span> 的。</p>
<p>然而，实际上我们不能直接使用这个约束集，因为这会导致在嵌套过程中产生很多无用的自由变量，并且约束集的增长率很高。如果一个函数没有调用其他函数，则确实约束集就自己。但是当函数调用别人，其他函数又调用更其他的函数，此时每次为一个函数推理类型时，就会牵涉进来所有这些涉及的函数的约束。因此化简约束是非常有必要的（TODO，是否可以根据约束的性质，判断它是否需要牵涉进来？）。</p>
<p>这个简化算法的输入是，从一个函数的推断得到的一个类型方案 <span
class="math inline">\(\forall{\overline{\alpha}}.\,{C}\!\Rightarrow\!{\tau}\)</span>
（包括自由类型变量，约束，和泛型），并创建一个较小的约束集 <span
class="math inline">\(\mathcal{C}&#39;\)</span>，使得任何由 <span
class="math inline">\(\mathcal{C}\)</span> 对 <span
class="math inline">\(\tau\)</span> 的约束也被 <span
class="math inline">\(\mathcal{C}&#39;\)</span> 所蕴含。</p>
<p>相反，我们寻求生成一个<strong>简化的约束集</strong> <span
class="math inline">\(\mathcal{C}&#39;\)</span>，使得如果 <span
class="math inline">\(c\)</span> 是一个“有趣”的约束，并且 <span
class="math inline">\(\mathcal{C} \;\vdash\; c\)</span>，那么 <span
class="math inline">\(\mathcal{C}&#39; \;\vdash\; c\)</span>
也同样成立。但什么让一个约束变得有趣呢？</p>
<ul>
<li>能力约束，表示某个dtv有某个field label</li>
<li>递归类型约束： <span class="math inline">\(\tau.u {\;\sqsubseteq\;}
\tau.v\)</span></li>
<li>涉及常量类型的约束： <span class="math inline">\(\tau.u
{\;\sqsubseteq\;} \overline{\kappa}\)</span> 或者 <span
class="math inline">\(\overline{\kappa} {\;\sqsubseteq\;}
\tau.u\)</span> 其中 <span
class="math inline">\(\overline{\kappa}\)</span> 是类型常量.</li>
</ul>
<h3 id="roadmap">Roadmap</h3>
<ol type="1">
<li>（A.）收集文字格式的初始约束，构建初始图。插入外部函数已知的参数类型。</li>
<li>（F.1）约束简化算法。简化后的约束就是type
schemes。这里对每个强连通分量后序遍历进行处理，处理完的分量内的type
schemes保存下来，等待实例化。
<ol type="1">
<li>基于约束集合构建初始图。子类型关系增加标记为1的边。对标签增加和减少的关系，增加对应push/pop的边。
<ol type="1">
<li>比如对于dtv <code>F.in_a.load.off_4_size_8</code> 构建一系列图节点
<code>F -&gt; F.in_a -&gt; ... -&gt; F.in_a.load.off_4_size_8</code>。</li>
<li>对于约束关系两边的dtv，连接边（边上标记1）。</li>
</ol></li>
<li>运行Saturation算法，将 <code>push α -&gt; 1 -&gt; pop α</code>
这种边序列增加shortcut边。应用S-Pointer的实例化规则</li>
</ol></li>
</ol>
<ul>
<li>Step 3: Identify the “externally-visible” type variables and
constants; call that set E.</li>
<li>Step 4: Use Tarjan’s path-expression algorithm to describe all paths
that start and end in E but only travel through E c.</li>
<li>Step 5: Intersect the path expressions with the language (recall
<em>)*(forget </em>)*.</li>
<li>Step 6: Interpret the resulting language as a regular set of subtype
constraints. (“forgets” on the right, “recalls” on the left)</li>
</ul>
<ol start="3" type="1">
<li>（F.2）构建sketches（为每个类型变量，比如函数类型）（自底向上遍历call
graph的顺序），同时细化具体类型。</li>
<li>（4.3）最后转换sketches到C类型。</li>
</ol>
<p>类型恢复本质上是三层分析的叠加：</p>
<ul>
<li>指针和数字类型的区分。</li>
<li>指针能力分析。</li>
<li>自定义的typedef常量类型传播。</li>
</ul>
<p>本质上，retypd在前两者里用的是快速的steensgaard的指针分析，在最后这层的分析上用的是Anderson的指针分析算法。</p>
<p>retypd为什么不直接采用steensgaard的类型恢复？因为常量用不了，merge了直接变成父类型，基本无法传播自定义的typedef类型。。</p>
<p>对于每个SCC看作按需分析。每个SCC能够简化算法计算出对应的summary。</p>
<h3
id="无约束的下推系统-unconstrained-pushdown-systems">无约束的下推系统
Unconstrained Pushdown Systems</h3>
<p><strong>无约束的含义</strong>：TODO。可能是表示没有限制栈符号和转换规则的有限性？</p>
<p>核心思路： 下推系统 <span
class="math inline">\(\mathcal{P}_\mathcal{C}\)</span>
的转换序列，可以直接对应上基于约束集合 <span
class="math inline">\(\mathcal{C}\)</span>
上的子类型推导判断的推导树。</p>
<p>定义：一个<strong>无约束下推系统</strong>是由三个部分组成的元组 <span
class="math inline">\(\mathcal{P} = (\mathcal{V}, \Sigma,
\Delta)\)</span>，其中 <span class="math inline">\(\mathcal{V}\)</span>
是<strong>控制位置</strong>的集合，<span
class="math inline">\(\Sigma\)</span>
是<strong>栈符号</strong>的集合，而 <span
class="math inline">\(\Delta\)</span> 是包含在 <span
class="math inline">\((\mathcal{V} \times \Sigma^*)^2\)</span>
内的（可能无限）<strong>转换规则</strong>的集合。转换规则表示为 <span
class="math inline">\(\langle X; u \rangle \hookrightarrow \langle
Y;v\rangle\)</span>，其中 <span class="math inline">\(X,Y \in
\mathcal{V}\)</span> 且 <span class="math inline">\(u,v \in
\Sigma^*\)</span>。我们定义<strong>配置</strong>的集合为 <span
class="math inline">\(\mathcal{V} \times \Sigma^*\)</span>。在配置 <span
class="math inline">\((p,w)\)</span> 中，<span
class="math inline">\(p\)</span> 称为<strong>控制状态</strong>，<span
class="math inline">\(w\)</span> 称为<strong>栈状态</strong>。</p>
<p>注意到，我们既不要求栈符号的集合也不要求转换规则的集合是有限的。这种自由度是为了模拟推导规则
S-Pointer， 正如图3的推导规则 S-Pointer
所示，它对应于一个无限的转换规则集。</p>
<p><strong>为什么要用下推系统？</strong>
下推系统能很好地反映类型关系关于能力的传递关系，反映在下推系统上就是后缀子串的关系。</p>
<ul>
<li>转换关系定义：一个无约束的下推系统 <span
class="math inline">\(\mathcal{P}\)</span>
确定了一个<strong>转换关系</strong> <span
class="math inline">\(\longrightarrow\)</span> 在配置集合上： <span
class="math inline">\((X,w) \longrightarrow (Y,w&#39;)\)</span>
如果存在一个后缀 <span class="math inline">\(s\)</span> 和一个规则 <span
class="math inline">\(\langle {X}; {u} \rangle \hookrightarrow   \langle
{Y}; {v} \rangle\)</span>，使得 <span class="math inline">\(w =
us\)</span> 和 <span class="math inline">\(w&#39; = vs\)</span>。<span
class="math inline">\(\longrightarrow\)</span> 的传递闭包表示为 <span
class="math inline">\(\stackrel{*}{\longrightarrow}\)</span>。
<ul>
<li>这里的公共后缀s，就可以想象为类型的能力。比如各种偏移里的字段。然后前缀类型变量，比如两个结构体类型，如果符合子类型关系，则对应的访问相同的字段得到的类型变量，则也存在子类型关系。</li>
</ul></li>
</ul>
<p>有了这个定义，我们可以陈述我们简化算法背后的主要定理。这里一个类型对应一个
<span class="math inline">\((\mathcal{V} \cup \Sigma)^*\)</span>
字符串。</p>
<p>设 <span class="math inline">\(\mathcal{C}\)</span>
是一个约束集合，<span class="math inline">\(\mathcal{V}\)</span>
是一组基类型变量集合。定义
在类型变量和标签集合构成的两个字符串之间的关系 <span
class="math inline">\((\mathcal{V} \cup \Sigma)^* \times (\mathcal{V}
\cup \Sigma)^*\)</span> 的一个子集 <span
class="math inline">\(S_\mathcal{C}\)</span>， 通过 <span
class="math inline">\((Xu, Yv) \in S_\mathcal{C}\)</span> 当且仅当 <span
class="math inline">\(\mathcal{C} \;\vdash\; X.u {\;\sqsubseteq\;}
Y.v\)</span>。 那么 <span class="math inline">\(S_\mathcal{C}\)</span>
是一个正则集合，并且可以在 <span
class="math inline">\(O(|\mathcal{C}|^3)\)</span> 时间内构造一个识别
<span class="math inline">\(S_\mathcal{C}\)</span> 的自动机 <span
class="math inline">\(Q\)</span>。</p>
<!-- TODO -->
<p>证明：基本思想是将每个 <span class="math inline">\(X.u
{\;\sqsubseteq\;} Y.v \in \mathcal{C}\)</span> 作为下推系统 <span
class="math inline">\(\mathcal{P}\)</span> 中的一个转换规则 <span
class="math inline">\(\langle {X}; {u} \rangle \hookrightarrow \langle
{Y}; {v} \rangle\)</span>。 此外，我们为每个 <span
class="math inline">\(X \in \mathcal{V}\)</span> 添加控制状态 <span
class="math inline">\({Start}, {End}\)</span> 及其转换 <span
class="math inline">\(\langle {Start}; {X} \rangle \hookrightarrow
\langle {X}; {\varepsilon} \rangle\)</span> 和 <span
class="math inline">\(\langle {X}; {\varepsilon} \rangle \hookrightarrow
\langle ; {X} \rangle\)</span>。
目前，假设所有标签都是协变的，并且忽略规则 S-Pointer。 通过构造，<span
class="math inline">\(({Start}, Xu) \stackrel{*}{\longrightarrow}
({End}, Yv)\)</span> 在 <span class="math inline">\(\mathcal{P}\)</span>
中当且仅当 <span class="math inline">\(\mathcal{C} \;\vdash\; X.u
{\;\sqsubseteq\;} Y.v\)</span>。 Büchi [27]
保证，对于任何标准（非无约束）下推系统中的两个控制状态 <span
class="math inline">\(A\)</span> 和 <span
class="math inline">\(B\)</span>， 所有满足 <span
class="math inline">\((A, u) \stackrel{*}{\longrightarrow} (B,
v)\)</span> 的 <span class="math inline">\((u,v)\)</span>
对组成的集合是一个正则语言； Caucal [8]
给出了一个构造识别这种语言的自动机的饱和算法。</p>
<p>在完整的证明中，我们增加了两个创新之处：首先，我们通过将variance数据编码到控制状态和转换规则中，支持逆变堆栈符号。
第二个创新之处涉及到 S-Pointer
规则；这个规则是有问题的，因为自然的编码将导致无限多的转换规则。 我们将
Caucal 的构造扩展为在饱和过程中懒惰实例化所有必要的 S-Pointer 应用。
详情见 Appendix D。</p>
<p>由于 <span class="math inline">\(\mathcal{C}\)</span>
通常涉及到无限多的约束， 这个定理特别有用：它告诉我们由 <span
class="math inline">\(\mathcal{C}\)</span>
引发的完整约束集合可以通过自动机 <span class="math inline">\(Q\)</span>
的有限编码来实现。 对约束闭包的进一步操作，如有效的最小化，可以在 <span
class="math inline">\(Q\)</span> 上进行。通过限制与 <span
class="math inline">\({Start}\)</span> 和 <span
class="math inline">\({End}\)</span> 的转换，使用相同的算法
消去类型变量，生成所需的约束简化。</p>
<p><strong>推理的整体复杂性</strong></p>
<p>用于执行约束集简化类型方案构造的饱和算法，
在最坏情况下，是关于简化子类型约束数量的三次方。由于一些著名的指针分析方法也具有三次方复杂度（如
Andersen [4]）， 因此很自然地会怀疑 Retypd
的“无需指向”分析是否真的比基于指向分析数据的类型推理系统提供优势。</p>
<p>为了理解 Retypd 的效率所在，首先考虑 <span
class="math inline">\(O(n^3)\)</span> 中的 <span
class="math inline">\(n\)</span>。 Retypd
的核心饱和算法在子类型约束的数量上是三次方的；由于机器代码指令的简单性，每条指令大约会产生一个子类型约束。
此外，Retypd 在每个独立的过程中应用约束简化以消除该过程局部的类型变量，
从而得到只涉及过程形参、全局变量和类型常量的约束集。在实践中，这些简化的约束集很小。</p>
<p>由于每个过程的约束集是独立简化的，因此三次方的 <span
class="math inline">\(n^3\)</span>
因子由最大过程大小控制，而不是整个二进制文件的大小。 相比之下，像
Andersen
这样的源代码指向分析通常与指针变量的总数呈三次方，并且根据用于上下文敏感性的调用字符串深度呈</p>
<h2 id="算法细节">算法细节</h2>
<h3 id="约束简化算法appendix-d">约束简化算法（Appendix D）</h3>
<p><strong>基础符号</strong></p>
<ul>
<li><span class="math inline">\(\amalg\)</span>
表示集合的不交并。表示某个集合可以分割为不同的组成部分。
<ul>
<li><span class="math inline">\(\mathcal{V} = \mathcal{V}_i \amalg
\mathcal{V}_u\)</span>
表示类型变量集合被分割为interesting和uninteresting两部分。</li>
</ul></li>
<li>一个证明是elementary的，如果证明的结论的子类型关系里没有uninteresting的变量，且证明过程中，uninteresting变量都只在内部。
<ul>
<li><span class="math inline">\(\mathcal{C}
{\;\vdash\;}^{\mathcal{V}_i}_\text{elem} X.u {\;\sqsubseteq\;}
Y.v\)</span> 表示约束集合 <span
class="math inline">\(\mathcal{C}\)</span>
上能够推理出这样一个子类型约束。其中类型变量都定义在 <span
class="math inline">\({\mathcal{V}_i}\)</span>
上，并且这样的关系是elementary的。</li>
</ul></li>
</ul>
<p><strong>自动机</strong></p>
<p>对应关系：</p>
<ul>
<li>一个类型（sketch）就是一个有限状态自动机。
<ul>
<li>本来用树就够了，但是递归类型会导致无限长的树。根据子树的有限性，用自动机处理递归的情况。典型的例子是复杂的递归结构体类型。</li>
</ul></li>
<li>下推自动机工作的过程就是我们类型推理的过程
<ul>
<li>当前状态表示基础的类型变量。</li>
<li>栈状态表示标签，比如<code>.load</code>，field访问</li>
<li>自动机配置：状态+栈状态。表示一个派生变量。</li>
<li>状态转换规则：子类型关系。
<ul>
<li>比如，随便写一个规则 <span
class="math inline">\(a.\sigma\mathsf{N@k} \sqsubseteq b.load\)</span>
表示可以从状态为 <span class="math inline">\(a\)</span> 栈内容为 <span
class="math inline">\(\sigma\mathsf{N@k}\)</span> 的配置转换到 状态为
<span class="math inline">\(b\)</span> 栈内容为 <span
class="math inline">\(load\)</span> 的配置。</li>
</ul></li>
<li>可达性：派生的子类型关系。
<ul>
<li>然后，如果 <span class="math inline">\(b.load\)</span> 又是 <span
class="math inline">\(c\)</span>
的子类型，两个规则合起来，在自动机上，状态 <span
class="math inline">\(a.\sigma\mathsf{N@k}\)</span> 到 <span
class="math inline">\(c\)</span>
也是可达的（走了两步）。因此也具有子类型关系。 <span
class="math inline">\(a.\sigma\mathsf{N@k} \sqsubseteq c\)</span>。</li>
</ul></li>
</ul></li>
</ul>
<h3 id="transducer-与其构建">Transducer 与其构建</h3>
<ul>
<li>Transducer可以表示下推自动机的所有的推断关系！任意两个dtv字符串之间的子类型关系！</li>
<li>Transducer和类型推断的对应关系。</li>
</ul>
<p>重要概念：</p>
<ul>
<li><p><span class="math inline">\(\mathcal{P}_\mathcal{C}\)</span>
表示我们这里构建的pushdown system。包含三部分 <span
class="math inline">\((\widetilde{\mathcal{V}}, \widetilde{\Sigma},
\Delta)\)</span></p>
<ul>
<li>状态集合： <span class="math inline">\(\widetilde{\mathcal{V}} =
\left(\mathsf{lhs}(\mathcal{V}_i) \amalg \mathsf{rhs}(\mathcal{V}_i)
\amalg \mathcal{V}_u\right) \times \{ \oplus, \ominus \} \cup \{
{Start}, {End} \}\)</span>
<ul>
<li>额外增加的两个特殊状态 start 和 end</li>
<li>带有variance标签的状态，包括三部分
<ul>
<li>带有L或R标签的interesting变量</li>
<li>uninteresting变量</li>
</ul></li>
</ul></li>
<li>栈字符集： <span class="math inline">\(\widetilde{\Sigma} = \Sigma
\cup \{ v^\oplus ~|~ v \in \mathcal{V}_i \} \cup \{ v^\ominus ~|~ v \in
\mathcal{V}_i \}\)</span>
<ul>
<li>包含普通的field label</li>
<li>带有variance标记的有趣变量。TODO这表示什么意思</li>
</ul></li>
<li>转换规则包括四部分 <span class="math inline">\(\Delta =
\Delta_\mathcal{C} \amalg \Delta_\mathsf{ptr} \amalg
\Delta_\mathsf{start} \amalg \Delta_\mathsf{end}\)</span>
<ul>
<li><span class="math inline">\(\Delta_\mathcal{C}\)</span>
现有的规则，经过rule函数转换后的结果</li>
<li><span class="math inline">\(\Delta_\mathsf{ptr}\)</span>
PTR规则，经过rule函数转换后的结果</li>
<li><span class="math inline">\(\Delta_\mathsf{start} = \left\{\langle
{Start}; {v^\oplus} \rangle \hookrightarrow \langle
{v^\oplus_\mathsf{L}}; {\varepsilon} \rangle~|~v \in \mathcal{V}_i
\right\} \cup \left\{\langle {Start}; {v^\ominus} \rangle
\hookrightarrow \langle {v^\ominus_\mathsf{L}}; {\varepsilon}
\rangle~|~v \in \mathcal{V}_i \right\}\)</span>
<ul>
<li>表示start状态可以把栈上的唯一变量标签转换为当前状态，栈为空</li>
</ul></li>
<li><span class="math inline">\(\Delta_\mathsf{end} = \left\{\langle
{v^\oplus_\mathsf{R}}; {\varepsilon} \rangle \hookrightarrow \langle
{End}; {v^\oplus} \rangle~|~v \in \mathcal{V}_i \right\} \cup
\left\{\langle {v^\ominus_\mathsf{R}}; {\varepsilon} \rangle
\hookrightarrow \langle {End}; {v^\ominus} \rangle~|~v \in \mathcal{V}_i
\right\}\)</span>
<ul>
<li>表示当前状态为某个变量，栈为空的时候，可以转换到End状态，把变量放到标签。</li>
</ul></li>
</ul></li>
</ul></li>
<li><p><span
class="math inline">\(\mathsf{Deriv}_{\mathcal{P_C}}\)</span> 表示 <span
class="math inline">\(\mathcal{P}_\mathcal{C}\)</span>
上派生得到的约束</p></li>
<li><p><span class="math inline">\(\mathsf{Deriv}_{\mathcal{P_C}}&#39; =
\left\{ (X.u, Y.v) ~|~ (X^{\langle u \rangle}u, Y^{\langle v \rangle}
v)\in \mathsf{Deriv}_{\mathcal{P_C}}\right\}\)</span></p>
<ul>
<li>表示 <span class="math inline">\(\mathcal{P}_\mathcal{C}\)</span>
上删去variance标签得到的约束。</li>
</ul></li>
<li><p>rule辅助函数，对普通的规则，生成我们内部使用的，带variance标签的规则形式</p>
<ul>
<li><span class="math inline">\(\mathsf{rule}^\oplus(p.u \sqsubseteq
q.v) = \langle {\mathsf{lhs}(p)^{\langle u \rangle}}; {u} \rangle
\hookrightarrow \langle {\mathsf{rhs}(q)^{\langle v \rangle}}; {v}
\rangle \\\)</span>
<ul>
<li>首先观察到分别给左边和后边的有趣的基本类型变量，通过lhs和rhs函数带上了L/R标记</li>
<li>其次将field label的variance标签标记到了类型变量上</li>
</ul></li>
<li><span class="math inline">\(\mathsf{rule}^\ominus(p.u \sqsubseteq
q.v) = \langle {\mathsf{lhs}(p)^{\ominus \cdot \langle u \rangle}}; {u}
\rangle \hookrightarrow \langle {\mathsf{rhs}(q)^{\ominus \cdot \langle
v \rangle}}; {v} \rangle \\\)</span>
<ul>
<li>这里的点运算符就是variance的叠加运算。</li>
<li>TODO：这里的规则有什么实际的含义吗？</li>
</ul></li>
<li><span class="math inline">\(\mathsf{rules}(c) = \{
\mathsf{rule}^\oplus(c),~ \mathsf{rule}^\ominus(c)\}\)</span>
<ul>
<li>表示对每个约束生成两种类型的约束，带有不同的variance标记。</li>
</ul></li>
</ul></li>
<li><p>状态上的variance标签的作用：控制状态上的 <span
class="math inline">\(\{ \oplus, \ominus \}\)</span>
上标用于追踪栈状态的当前variance，这使得我们能够区分在协变和逆变位置使用公理的情况。</p></li>
<li><p>标签 操作 lhs 和 rhs 的作用：用于防止推导中使用来自 <span
class="math inline">\(\mathcal{V}_i\)</span> 的变量，防止 <span
class="math inline">\(\mathcal{P}_\mathcal{C}\)</span>
接受代表非基本证明的推导。</p>
<ul>
<li>例如，我们写一个递归的无限约束 <span class="math inline">\(var.load
\sqsubseteq var\)</span>，推导为 <span
class="math inline">\(var.load.load \sqsubseteq var.load \sqsubseteq
var\)</span> ，在增加标签之后就变成了 <span
class="math inline">\(var_{L}.load \sqsubseteq var_{R}\)</span>
从而不会被递归推导。</li>
</ul></li>
</ul>
<p>基于Transducer的约束简化算法包含四个步骤：</p>
<ul>
<li>构建初始图
<ul>
<li>生成的约束可以直接看作PDS，这里的初始图表示未化简的transducer。</li>
</ul></li>
<li>Saturation。</li>
<li>Tarjan's PathExpression 算法</li>
<li>转换回约束</li>
</ul>
<p><strong>Saturation算法</strong></p>
<p>实际算法直接构建对应的，在边上标记有push/pop序列的自动机，即Transducer。然后在上面执行saturation算法。</p>
<ol type="1">
<li>基于约束集合构建初始图。子类型关系增加标记为1的边。对标签增加和减少的关系，增加对应push/pop的边。
<ol type="1">
<li>规则左边存在的变量，标记pop边，右边的变量标记push边。</li>
<li>状态标记代表剩余的可读字符串，所以push之后反而变少，pop反而变多。</li>
</ol></li>
<li>运行Saturation算法，
<ol type="1">
<li>维护Reaching Push Set集合 <span class="math inline">\(R(x)\)</span>
<ol type="1">
<li>初始的时候，遍历所有边，如果存在一个 <code>push l</code> 的边从 x 到
y 的边，则 <span class="math inline">\(R(y) \leftarrow R(y) \cup
{(l,x)}\)</span> 从 x 节点 push l 可以来到 y 。即，只关注push边。</li>
<li>循环开始时，假如有子类型关系边 <span class="math inline">\((x, y,
1)\)</span> ，则 <span class="math inline">\(R(y) \leftarrow R(y) \cup
R(x)\)</span> 父类型更新子类型的可达关系。</li>
</ol></li>
<li>（循环内）Saturation规则：将 <code>push α -&gt; 1 -&gt; pop a</code>
这种边序列增加shortcut边。即，如果存在边 <span class="math inline">\((x,
y, pop\;l)\)</span> 且 x 的到达集合 <span
class="math inline">\(R(x)\)</span> 内有一个对应标签的到达关系 <span
class="math inline">\((l,z)\)</span> 则给增加子类型关系边 <span
class="math inline">\((z, y, 1)\)</span>。</li>
<li>同时考虑S-Pointer规则：如果有一个 <span
class="math inline">\((.store, z) \in R(x)\)</span>，想象边从 z 到
x，上面标记push store。此时找到x的逆 variance 节点 <span
class="math inline">\(x^-\)</span>，然后给 <span
class="math inline">\(R(x^-)\)</span> 增加 <span
class="math inline">\((.load, z)\)</span>
<ol type="1">
<li>直接应用： <span class="math inline">\((.load,\;x.store) \in
R(\overline{x})\)</span>
不是最典型的例子。往往会结合之前新增的子类型边。</li>
<li>可以想象 <span class="math inline">\(x\)</span> 到 <span
class="math inline">\(x^-\)</span> 额外增加了pop store和push load边。
<img src="s-ptr-example.drawio.png" /></li>
<li>应用时最好 <span class="math inline">\(\overline{x}\)</span>
也存在在图上。</li>
</ol></li>
</ol></li>
</ol>
<p>实际实现时，saturation算法被包含在Transducer的构建中。Transducer的构建在两个地方发挥作用：</p>
<ul>
<li>约束的简化。</li>
<li>给sketch标记lattice元素时用来查询。</li>
</ul>
<p><strong>Tarjan’s path-expression algorithm</strong> 来自论文 《Fast
Algorithms for Solving Path Problems》（see also this <a
href="https://github.com/johspaeth/PathExpression">Github repo</a>）。
在一个有向图中，求解一个源点到其他任意点的可能的路径构成的正则表达式。</p>
<p>在Saturation算法后，首先找到感兴趣的变量集合 <span
class="math inline">\(\mathcal{\epsilon}\)</span>
然后找出所有开始并结束于 <span
class="math inline">\(\mathcal{\epsilon}\)</span> 但是不经过 <span
class="math inline">\(\mathcal{\epsilon}\)</span> 的路径表达式。然后和
<span class="math inline">\((recall\;\_)^*(forget \;\_)^*\)</span>
求交集（recall就是pop，forget就是push）。正则表达式也可以看作自动机，因此这里得到了一个新的自动机。</p>
<p>将自动机翻译为一系列子类型约束：首先将源点和目的点的基础类型变量，作为子类型关系变量的两侧。如果路径上遇到了forget标记，则在右侧增加label。遇到了recall，对应的label增加到左侧。如果存在通配关系，引入新的类型变量，表示为递归的约束。</p>
<p><strong>将Transducer转换回约束（D.3 TypeScheme）</strong>
这里的算法D.3并不是直接被用。而是主要反映一个性质。上述 transducer
在构建时，我们理解为有一个隐藏的栈，会从状态push进去。这里仅仅是构建了一个完全对应的PDS，把这个栈显式地表示出来。</p>
<p>算法具体实现的时候，则是在前一步就找出从有趣变量到有趣变量的路径，然后直接把路径写成约束。</p>
<p><strong>性质</strong>：最终得到的自动机Q有以下性质：</p>
<ul>
<li>将 pop l 看作读取输入 l，push l 看作写出字符 l，1
看作空转换（ε）。则这个Transducer描述了PDS所有可能的派生关系，即所有可能的子类型关系。</li>
<li>如果在Q下，字符 Xu 能转换为
Yv，当且仅当X和Y是感兴趣变量，且存在一个基础的派生关系 <span
class="math inline">\(\mathcal{C} \vdash X.u \sqsubseteq Y.v\)</span>
。</li>
</ul>
<h3 id="sketches-构成的格">Sketches 构成的格</h3>
<ul>
<li>sketch
<ul>
<li>定义1：sketch是一个带有标记的regular tree。</li>
<li>定义2：sketch可以被看作两个函数
<ul>
<li>前缀闭合的语言： <span class="math inline">\(\mathcal{L}(S)
\subseteq \Sigma^*\)</span></li>
<li>从语言上的单词映射到lattice标记的函数 <span
class="math inline">\(\nu : S \to \Lambda\)</span> ，例如 <span
class="math inline">\(\nu_S(w)\)</span>。</li>
</ul></li>
<li>定义3：通过折叠sketch子树，sketch可以表示为一个有限状态自动机，每个状态标注了一个lattice元素
<span class="math inline">\(\Lambda\)</span> 。
<ul>
<li>这个自动机的每个状态都是接受态。因为语言是前缀闭合的。</li>
</ul></li>
<li>sketch的格结构。偏序关系写作 <span class="math inline">\(X
\trianglelefteq Y\)</span>
<ul>
<li>为sketch的树结构定义了 <span class="math inline">\(\sqcup\)</span>
和 <span class="math inline">\(\sqcap\)</span>
运算：在语言上分别是交和并。对应节点不变，或者根据variance在节点标记的格上做交或者并。</li>
</ul></li>
</ul></li>
</ul>
<p>一个在变量集合V上的约束集合C的解，是一个变量到sketch的映射，满足：</p>
<ul>
<li>如果是类型常量，则路径为空，lattice标记为常量</li>
<li>如果约束能推出 <span class="math inline">\(X.v\)</span>
存在，则v属于语言 <span class="math inline">\(v \in
\mathcal{L}(X)\)</span></li>
<li>如果有子类型关系 <span class="math inline">\(\mathcal{C} \vdash X.u
\sqsubseteq Y.v\)</span>
<ul>
<li>对应的节点上的lattice标记也有偏序关系</li>
<li>对应的子树之间有sketch的偏序关系 <span class="math inline">\(u^{-1}
S_X \trianglelefteq v^{-1} S_Y\)</span></li>
</ul></li>
</ul>
<p>sketch
和约束的对应关系很好。任何约束集合都能被一个sketch表示，只要没有证明出lattice标记上不可能的关系。</p>
<p><strong>从约束构建sketches (E.1 InferShapes)</strong></p>
<p>将子类型关系理解为等价关系。</p>
<ol type="1">
<li>为每个变量，以及前缀隐含的变量存在，创建节点。</li>
<li>构建图，边上标记field label的增加关系。</li>
<li>划分等价关系：
<ol type="1">
<li>如果有子类型关系，则属于一个等价类。
<ol type="1">
<li>如果因为子类型关系在没有函数调用时是结构化的，即形状上一致，父子类型可拥有的field
label一致，因此这里的父子关系划分的等价类内部，只要有一个变量能有某个label，则类内每个变量都能有这个label。</li>
</ol></li>
<li>等价类内两个变量，访问相同的标签得到的变量，（有子类型关系）也在同一个等价类内。
<ol type="1">
<li>这个地方有点像Steensgaard的线性指针分析算法。</li>
</ol></li>
<li>等价类内两个变量，一个访问load标签，一个访问store标签，得到的新变量也属于同一个等价类。</li>
</ol></li>
<li>计算每个等价类的形状，就是等价类内每个变量的sketch的形状。</li>
</ol>
<p>算法中实际实现时使用的步骤</p>
<ol type="1">
<li>Substitute</li>
</ol>
<p><strong>标记lattice元素 (F.2 Solve)</strong></p>
<p>具体sketch上每个节点标什么lattice元素，借助了前面的transducer。关注所有的类型常量，然后看这个类型常量和哪些dtv有子类型关系，有则更新对应的lattice标记。根据子类型或父类型，取交或者并。</p>
<figure>
<img src="sketch-lattice-annotation.png"
alt="sketch-lattice-annotation" />
<figcaption aria-hidden="true">sketch-lattice-annotation</figcaption>
</figure>
<h3 id="tarjan-path-expression">Tarjan Path Expression</h3>
<p>基础符号</p>
<ul>
<li><span class="math inline">\(\epsilon(P(a,b))\)</span>
从源点a到目标点b的路径表达式P(a,b)，所表达的所有路径的集合。</li>
<li><span class="math inline">\(\Lambda\)</span>
表示空路径，源点和目的点为同一点时，为空路径。</li>
</ul>
<p>定义</p>
<h3 id="qa-1">Q&amp;A</h3>
<p>Q1. <strong>为什么实现的时候，那边先infer
shapes然后才简化约束？那能不能直接不简化约束了，既然我本来就想要内部的变量</strong></p>
<p>确实不应该这样？简化约束应当是最早的一步，然后才是type
scheme。但是这并不代表简化约束是没有意义的。因为如果其他地方如果调用了这边的函数，会实例化约束。简化了还是有好处的。</p>
<p>从我的其他角度：</p>
<ul>
<li>先infer
shapes可以获取到小的内部变量的类型，不然后面这些变量被简化没了。</li>
<li>sketches可以作为函数的简化版约束，用在增量运算。关联Q3</li>
</ul>
<p>Q2. <strong>为什么算法要后序遍历SCC？起到什么作用？</strong></p>
<p>TODO</p>
<p>Q3.
给定一个SCC内所有函数的已经简化完的约束。开始分析另一个调用了已分析函数的SCC，是否会对之前函数的分析结果产生影响？？</p>
<p>直观上看，函数就是函数本身，type
schemes也就是一个函数到约束集合的映射，所以外部调用不会对函数类型有影响。细化到最具体的类型是后面考虑的事情。</p>
<p>如何证明？类型从形状和lattice两方面考虑。类型关系在函数调用的时候允许丢失一些能力（non-structural
subtyping）。</p>
<p>Q4. 为什么只有函数调用的时候是non-structural subtyping?</p>
<p>可能一般以函数为单位做抽象？一般不会出现：函数内部一小块代码突然被看作更泛化的代码。</p>
<p>Q5. 如何将Sketch转换为普通类型？</p>
<p>从根节点出发，为所有可达路径构建path expression。？</p>
<p>Q6. 全局变量怎么处理？</p>
<ol type="1">
<li>全局变量被认为是参数和返回值的拓展？在分析时作为一个interesting的变量，从而在简化约束得到type
scheme的时候，能够得到它和其他类型变量之间的关系？如果其他函数也用了同样的全局变量，就可以对接上。</li>
<li>全局变量可以看作一个无参函数？函数的type
scheme是最简化的约束，假设存在任何调用者，也不因caller的调用而变化。这个角度考虑，如果看作一个无参函数，任何全局变量的类型都是一个无约束的自由类型变量。真正发挥作用的时候，仅仅是后面的附录G里面，根据使用细化类型的时候才真正产生类型。这个是不是就是retypd代码里的top
down propagation？TODO
<ol type="1">
<li>比如存在全局变量g，以及getter函数get_g和setter函数set_g。简化约束过程中，不推断G的类型。最后结束时根据使用会给G赋值一个最精确的类型。如果使用是通过get_g和set_g，则get_g因为使用获得的类型，能否从g顺着传播到set_g？</li>
</ol></li>
</ol>
<p>Q7. 约束的实例化是怎么做的？</p>
<ul>
<li>在简化约束，求每个函数的type scheme时：
<ul>
<li>如果涉及的函数调用在SCC外，则根据调用点的不同，总是创建额外的实例。例如identity函数，函数内调用多次是不同的类型。</li>
<li>如果涉及的函数在SCC内。则不复制任何实例。TODO是这样吗？调研一下summary
based analysis是如何处理递归和调用环的情况的。</li>
</ul></li>
</ul>
<p>另外，这说明提取约束时需要显式体现函数调用。可能可以为每个函数调用的约束增加一个调用地址标识。</p>
<p>Q8.
为什么要标记L和R？为什么构图时仅对左边的增加forget边，右边的变量仅增加recall边？能否证明，不标记L和R，仅仅限制路径探索不能再经过interesting的变量，即可得到相同的约束？如果不能，则得到的约束是否能用？</p>
<p>区分L/R以及仅对左边的增加forget边，右边的变量仅增加recall边，可以使得我们关注的变量不会存在于推导树内部。</p>
<p>推理关系和 proof tree
之间有对应关系。区分L和R的区别在于是否把L的变量当R的变量，从而递归推进了子类型关系。回忆elementary
proof的定义，能否保证得到的约束关系的推导树，都没有感兴趣的变量在函数内部？</p>
<p>能否给出一个例子，使得某个saturation推导使得感兴趣的变量在推导树中间。</p>
<p>为了给出这样一个例子，首先回忆，为什么要简化类型约束。关键在于，是否任何原约束集合能推导出的关系，我们给出的简化的约束集合也能推导出来？</p>
<p>没有任何field
label的<code>F.in</code>不能出现在该函数的子类型关系的子类型一方。同样，对应的<code>F.out</code>不能出现在子类型关系的父类型一方。</p>
<p>另外，如果一个变量仅出现在子类型关系左边（contra-variant时仅出现在右边）。不会出现反过来的情况，因此即使加上了这样的边也不会被用到。定理：如果有临时变量t，仅出现在子类型关系左边，证明不会有额外的边指向t，因此即使有边从t指向end，也不会被用到。证明：有边指向t有两种情况。第一种：构建图的时候有边指向。这种情况需要t在子类型关系右边，所以不成立。第二种，saturation时增加了边指向。根据saturation规则，仅有某个节点已经被某个pop边指向的时候，这个节点才会可能获得新增的1边。因为t没有其他边指向它，所以不成立。</p>
<p>Q9. 单个SCC内如何处理多态的类型关系？以及non-structural
subtyping?</p>
<p>可以假设，能形成SCC的变量，不太可能有多态的类型关系，所以，就按照非多态的角度考虑？</p>
<p>TODO？这一块和full-context-sensitive的分析之间有点关系？</p>
<p>Q10. 为什么算法，在单个函数内关于指令是指令数的三次方的复杂度？</p>
<p>我们关注那个SCC的循环：生成约束的低于三次方。然后是对于每函数，这里还不是指令，不太算一个N。内部transducer函数构图，saturate，pathexpr算法。文章说saturate是主要的复杂度来源。</p>
<p>其实这里SCC构图之后，对每个普通的函数，已经可以做一些简单的优化了？比如一个base
var没有其他的节点，然后仅有一个successor和predecessor，则可以消除。怎么有点像基本块的。</p>
<p>或者我可以把所有感兴趣的变量都区分L/R，先saturate一次，然后每次分析把图复制一份，merge其他的非感兴趣的图。</p>
<p>Q11. 函数内的类型分析算法是怎么做的？</p>
<p>首先，假如你已经有了被调函数的type schemes，type
lattice，而且所有变量都是需要的，不需要简化。那么可以构建图，然后假设完全是non-structural
subtyping，直接推导sketches。为了标记lattice，则需要构建transducer推导然后标记相关元素。</p>
<p>Q12. 加减法约束对约束化简有什么影响？</p>
<p>TODO</p>
<h3 id="图算法基础">图算法基础</h3>
<p>回顾之前的算法，我们先构建transducer图表示所有可能的子类型关系，然后饱和算法，再与productive语言相交。然后我们选择一系列感兴趣的变量，计算对应的路径表达式，然后再转换回约束。</p>
<p>为了将带有标记的图转换回约束，有两个相关的算法：</p>
<ol type="1">
<li>将有限状态自动机转换为正则表达式的算法。
我们构建图的时候其实是有起始态和结束态的。把它看作一个自动机，然后即可求解出对应的正则表达式。
<ol type="1">
<li>对每个结束状态，从它开始，利用一系列规则归纳，归纳过程中允许边上直接标记为正则表达式，最后起始态和结束态会相邻。此时删除其他状态，并总结出对应的正则表达式。</li>
<li>最后将得到的多个正则表达式并起来。得到最终的表达式。</li>
</ol></li>
<li>（Tarjan's path
expression算法）给定有向图，和图上的某个源点，求出源点到图上任意一个其他点之间的可达路径，所构成的表达式。</li>
<li>两个算法之间的关联：path expression算法会构建path
sequence，缓存了子图的结果。而上面的表达式算法则没有这样做，因此path
expression算法效率更高一些。（TODO 对吗？）</li>
</ol>
<h4 id="tarjans-path-expression算法">Tarjan's path expression算法</h4>
<ul>
<li>"Fast Algorithms for Solving Path Problems"</li>
<li>"A Unified Approach to Path Problems"</li>
</ul>
<p><strong>定义：</strong> 给定有向图 <span class="math inline">\(G=(V,
E)\)</span> ，对于单源点 s 的路径表达式（path
expression）问题是，对于任何顶点v，求解出一个无歧义的路径表达式 <span
class="math inline">\(P(s,v)\)</span> 使得 它所表达的路径 <span
class="math inline">\(\sigma(P(s,v))\)</span>
包含了所有的从s到v的路径。</p>
<p>注：</p>
<ul>
<li>这里指的表达式就是由路径构成的正则表达式，包括<span
class="math inline">\(\cup\)</span>, <span
class="math inline">\(*\)</span>, <span
class="math inline">\(\;\cdot\;\)</span>(连接) 等特殊符号。</li>
<li>该问题还存在变种：single-sink，all-pairs</li>
</ul>
<p><strong>路径序列（Path Sequence）：</strong>
一个有向图G的路径序列是一个序列 <span
class="math inline">\((P_1,v_1,w_1),
(P_2,v_2,w_2),...,(P_l,v_l,w_l)\)</span> ，满足以下条件：</p>
<ol type="1">
<li>对于 <span class="math inline">\(1 \le i \le l\)</span> ， <span
class="math inline">\(P_l\)</span> 是一个无歧义的路径表达式，具有类型
<span class="math inline">\((v_i, w_i)\)</span> (即该表达式表示从 <span
class="math inline">\(v_i\)</span> 到 <span
class="math inline">\(w_i\)</span> 的路径)</li>
<li>（空路径）对于 <span class="math inline">\(1 \le i \le l\)</span>
，如果 <span class="math inline">\(v_i = w_i\)</span>，则空路径 <span
class="math inline">\(\Lambda \in \sigma(P_i)\)</span></li>
<li>（非空路径）对于任何非空的路径p，存在一个唯一的下标序列 <span
class="math inline">\(1 \le i_1 \le i_2 \le ... \le i_k \le l\)</span>
并且存在一个唯一的p的划分（不会划分出非空序列） <span
class="math inline">\(p=p_1,p_2,...,p_k\)</span> 使得 <span
class="math inline">\(p_j \in \sigma(P_{i_j})\)</span> 对于 <span
class="math inline">\(1 \le j \le k\)</span>。</li>
</ol>
<p><strong>如何理解非空路径条件？</strong> 图可以被分区为 <span
class="math inline">\(l\)</span>
部分，且每个分区都按顺序有个编号。然后每条路径都可以被这些部分切分，但是可能不经过部分分区。这里经过了k个分区，编号依次是
<span class="math inline">\(i_1,...,i_k\)</span>。让 <span
class="math inline">\(j\)</span> 从1遍历到 <span
class="math inline">\(k\)</span> ，每个分区内的路径 <span
class="math inline">\(p_j\)</span>
是属于对应分区的路径表达式能够表达的所有路径集合 <span
class="math inline">\(\sigma(P_{i_j})\)</span>。</p>
<p><strong>如何理解路径序列？</strong>
任何图上的路径需要被分解为路径序列。</p>
<ul>
<li>比如我们可以构造一个路径序列，从图上任意点到任意点，则每个路径能直接找到对应。此时路径序列的顺序不重要。</li>
<li>对于有向无环图，每个边可以单独成为一个路径序列，因为这个边是连接这两个节点的唯一必经路径。每个路径可以直接分解为每条边，然后对应到路径序列中。。</li>
<li>对于强连通分量这种复杂情况，实在不行我们可以为里面任意两个点构建路径序列。如果有路径经过了强连通分量内部，如果能直接找到对应，则此时分量内部路径序列的顺序不重要。</li>
</ul>
<p><strong>Solve算法</strong>：给定一个路径序列，我们可以使用下面的传播算法解决单源点的路径表达式问题。</p>
<ul>
<li>初始化：设置 <span class="math inline">\(P(s,s) = \Lambda\)</span>
，同时对每个不为s的顶点，初始化 <span class="math inline">\(P(s,v) =
\emptyset\)</span></li>
<li>循环：让i从1到 <span class="math inline">\(l\)</span> （有 <span
class="math inline">\(l\)</span> 个顶点）
<ul>
<li>如果 路径序列 <span class="math inline">\((P_i,v_i,w_i)\)</span>
中的 <span class="math inline">\(v_i = w_i\)</span> ， <span
class="math inline">\(P(s, v_i):= [P(s,v_i)\;\cdot\;P_i]\)</span></li>
<li>如果 <span class="math inline">\(v_i \ne w_i\)</span> ，<span
class="math inline">\(P(s,w_i) =
[P(s,w_i)\cup[P(s,v_i)\;\cdot\;P_i]]\)</span></li>
</ul></li>
</ul>
<p>（这个算法基本上就是把路径连接起来。另外意味着我们需要按拓扑排序给节点一个编号）</p>
<p><strong>路径表达式简化算法（方括号）</strong>：</p>
<ul>
<li>如果路径表达式 R 具有形式 <span class="math inline">\(R_1 \cup
R_2\)</span> 则，
<ul>
<li>如果任意一边为空集合，则直接简化为另外一边</li>
</ul></li>
<li>如果路径表达式具有形式 <span
class="math inline">\(R_1\;\cdot\;R_2\)</span> 则
<ul>
<li>如果任意一边是空集，则直接返回空集</li>
<li>如果任意一边是空路径，则直接简化为另外一边</li>
</ul></li>
<li>如果路径表达式具有形式 <span class="math inline">\(R_1^*\)</span>
<ul>
<li>如果 <span class="math inline">\(R_1\)</span>
是空集或者空路径，则直接返回空路径</li>
</ul></li>
<li>否则原样返回</li>
</ul>
<p><strong>使用Solve函数解决路径问题</strong></p>
<ul>
<li>对于单源点路径表达式问题（single-source path
expression），我们构建Path Sequence然后调用Solve一次</li>
<li>对于所有节点对的路径表达式问题（all-pairs path
expression），我们构建Path
Sequence然后把每个点作为源点，调用Solve。</li>
<li>对于单目的点的路径表达式问题（single-sink path
expression），我们构建一个边都是反向的图，然后转换为单源点的路径表达式问题。</li>
</ul>
<p><strong>Eliminate算法：</strong> 我们可以对任意的图构建路径序列。</p>
<ul>
<li>初始化：
<ul>
<li><span class="math inline">\(P(v, w):=\varnothing\)</span>
任意两个顶点间都初始化为空集合</li>
<li>然后对每个边 <span class="math inline">\(e \in E\)</span> ，
让路径表达式包含当前边 <span class="math inline">\(P(h(e),
t(e)):=[P(h(e), t(e)) \cup e]\)</span></li>
</ul></li>
<li>求解的主循环：
<ul>
<li>让v遍历每个节点序号1到n
<ul>
<li><span class="math inline">\(P(v, v)=\left[P(\nu,
v)^*\right]\)</span></li>
<li>遍历每个 <span class="math inline">\(u \gt v\)</span> ，如果 <span
class="math inline">\(P(u, v) \neq \varnothing\)</span>
<ul>
<li><span class="math inline">\(P(u, v):=[P(u, v) \cdot P(v,
v)]\)</span></li>
<li>遍历每个 <span class="math inline">\(w \gt v\)</span> ，如果 <span
class="math inline">\(P(v, w) \neq \varnothing\)</span>
<ul>
<li><span class="math inline">\(P(u, w):=[P(u, w) \cup[P(u, v) \cdot
P(v, w)]]\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>比如，如果一个有向无环图，按照拓扑排序编号，则 <span
class="math inline">\(u \gt v\)</span> 时， <span
class="math inline">\(P(u, v)\)</span>
必然为空，导致该算法无法进入循环，什么也做不了。但是实际上，初始化过程中，就已经完成了path
sequence的构建了。因为有向无环图的路径序列就是每个边单独构成的序列。</p>
<p><strong>Eliminate结果的顺序</strong>：Eliminate算法计算得到的结果，需要按照正确的顺序排列才能形成路径序列：</p>
<p>Theorem 4. Let <span class="math inline">\(P(u, w)\)</span> for <span
class="math inline">\(u, w \in V\)</span> be the path expressions
computed by ELIMINATE. Then the following sequence is a path sequence:
the elements of <span class="math inline">\(\{(P(u, w), u, w) \mid P(u,
w) \notin\{\varnothing, \Lambda\} \; and \; u \leq w\}\)</span> in
increasing order on <span class="math inline">\(u\)</span>, followed by
the elements of <span class="math inline">\(\{(P(u, w), u, w) \mid P(u,
w)=\varnothing \; and \; u&gt;w\}\)</span> in decreasing order on <span
class="math inline">\(u\)</span>.</p>
<p><strong>问题的分解</strong>：
为了提升Eliminate算法的效率，有两种方法，他们都对图进行分解。首先可以将图按强连通分量SCC分解。</p>
<p><strong>有向无环图的路径序列：</strong>
首先将节点按照拓扑排序编号，可以直接得到集合 <span
class="math inline">\(\{(e, h(e),t(e))|e\in E\}\)</span>
将这个集合中的点按照 <span class="math inline">\(h(e)\)</span>
升序排序，可以直接得到路径序列。</p>
<p><strong>拓展到任意有向图：</strong>
对于有向图G，首先将图中的强连通分离凝结成单个点表示，则可以得到有向无环图，这些节点
<span class="math inline">\(G_1,G_2,...,G_k\)</span>
表示图G中的一个子图，编号按照拓扑排序。假设这些子图的路径表达式是 <span
class="math inline">\(X_1,...,X_k\)</span> ，设 <span
class="math inline">\(Y_l\)</span> 是序列 <span
class="math inline">\(\{e,h(e),t(e)|h(e) \in G_l \; and \; t(e) \notin
G_l\}\)</span> 任意排序（注意到 <span class="math inline">\(Y_k\)</span>
为空）。则 <span
class="math inline">\(X_1,Y_1,X_2,Y_2,...,X_{k-1},Y_{k-1},X_k\)</span>是G的一个路径序列。</p>
<h2 id="与其他算法的关系">与其他算法的关系</h2>
<h3 id="retypd与现有指针分析的关系">Retypd与现有指针分析的关系</h3>
<h4 id="steensgaard-线性时间-指针分析">Steensgaard 线性时间
指针分析</h4>
<p>相关资料：</p>
<ol type="1">
<li><a
href="https://homepages.dcc.ufmg.br/~fernando/classes/dcc888/ementa/slides/PointerAnalysis.pdf">DCC888
编译器静态分析课 Pointer Analysis</a></li>
<li><a
href="https://xiongyingfei.github.io/SA/2017/10_control_flow_analysis.pdf">北京大学
软件分析 熊英飞</a></li>
</ol>
<h4 id="与-anderson-指针分析的关系">与 Anderson 指针分析的关系</h4>
<p>对应retypd论文中Constraint generation一节。</p>
<p>对于语句 q = &amp;x，如何生成约束？有两种方式</p>
<ul>
<li>x是q加载后的子类型（提前假设q会被load）： 生成
<code>x &lt;= q.load.off0@N</code></li>
<li>q存入值是x的子类型（提前假设q会被store）：生成
<code>q.store.off0@N &lt;= x</code></li>
</ul>
<p>需要考虑的问题是，立刻生成这两个约束，和维护一个指针分析，根据指针分析的结果生成这些约束。这两种方式是否有区别。</p>
<ul>
<li>假如提前生成了这个约束，是否会产生什么额外的影响？
<ul>
<li>直观来说，额外生成的 q.load.off0@N q.store.off0@N
还能有谁指向吗？</li>
</ul></li>
<li>如果Steensgaard指针分析能推断出指向关系，假如不产生指针分析的约束，原有类型系统是否依然能推断出来类型关系。</li>
</ul>
<p>证明：</p>
<p>分每种语句考虑(TODO 证明 offset和load/store可以绑定/合并)</p>
<ul>
<li><strong>语句1</strong>：对于 x = &amp;O1，对应
<code>O1 &lt;= x.load</code> 和 <code>x.store &lt;= O1</code>
我们把指向关系定义为这两个关系的组合。</li>
<li><strong>语句2</strong>：对于 y = x (x &lt;=
y)，在retypd下有如下图结构：</li>
</ul>
<figure>
<img src="assignment-retypd.drawio.png"
alt="assignment constraint graph" />
<figcaption aria-hidden="true">assignment constraint graph</figcaption>
</figure>
<p>在指针分析中有如下约束： pts(x) <span
class="math inline">\(\subseteq\)</span> pts(y) 我们尝试证明：</p>
<ul>
<li>对于任何x可能指向的对象，y也会指向它。
<ul>
<li>1 已知 O1 &lt;= x.load ，证明 O1 &lt;= y.load：证：由 x.load &lt;=
y.load 显然 O1 &lt;= x.load &lt;= y.load</li>
<li>2 已知 x.store &lt;= O1 ，证明 y.store &lt;= O1：证：由y.store &lt;=
x.store 显然 y.store &lt;= x.store &lt;= O1</li>
</ul></li>
</ul>
<p>能否证明充要条件？如果存在 <code>O1 &lt;= x.load</code> 和
<code>x.store &lt;= O1</code> 则必然在Anderson指针分析中有 O1 <span
class="math inline">\(\in\)</span> pts(x)</p>
<p>则我们可以证明，retypd是一种基于anderson指针分析的类型推断算法。</p>
<figure>
<img src="Anderson-pointer-algo.png"
alt="Pointer analysis constraints" />
<figcaption aria-hidden="true">Pointer analysis constraints</figcaption>
</figure>
<p><strong>语句3</strong>：对于a = *b，有 b.load &lt;= a</p>
<ul>
<li>方式1 提前生成约束：
由归纳法，如果之前的其他语句都能够维持和指针分析等效的分析关系，当前语句依然能维持关系，则关系继续维持。
<ul>
<li>提前生成约束会额外生成约束： 对于任何 O <span
class="math inline">\(\in\)</span> pts(b) 有 b.store &lt;= O
似乎影响不大？</li>
</ul></li>
<li>方式2 根据指针分析生成约束：对于任何 v <span
class="math inline">\(\in\)</span> pts(b) ，生成/之前有 v &lt;=
b.load。因此有 v &lt;= b.load &lt;= a。对应 v <span
class="math inline">\(\subseteq\)</span> a</li>
</ul>
<p><strong>语句4</strong>：对于*a = b，有 b &lt;= a.store</p>
<ul>
<li><p>根据指针分析生成约束：对于任何 v <span
class="math inline">\(\in\)</span> pts(a) ，之前有 a.store &lt;=
v。所以有 b &lt;= a.store &lt;= v。对应 b <span
class="math inline">\(\subseteq\)</span> v</p></li>
<li><p>saturation算法和Anderson指针分析算法求解时的异同。</p></li>
<li><p>retypd如果没有区分指针的load和store，是否依然和anderson指针分析一致？</p>
<ul>
<li>不行，明显上面的证明是和load和store性质有很大关系的。</li>
</ul></li>
</ul>
<p><strong>问题</strong>：offset和load/store可以绑定/合并?</p>
<p><strong>证明</strong>：首先.in
和.out只能在最外层。因此没有什么能够介入load/store中间。其次，每次load和store必然有offset和size。我们讨论某个变量的load和store的时候，本质上在讨论所有可能的offset和size之间的关系/对应的结构体类型。</p>
<p><strong>结构体域敏感的指针分析</strong></p>
<p>《Efficient Field-Sensitive Pointer Analysis for
C》中提出了几种新的操作</p>
<h2 id="实现---约束生成">实现 - 约束生成</h2>
<p><strong>基本运算</strong></p>
<p>根据指令的依赖关系，自底向上处理指令，插入到指令到约束集合的集合。生成约束变量。</p>
<ul>
<li>指针相关
<ul>
<li>存地址运算：由上面的证明，直接假设它之后会被load/store，生成两条约束。</li>
</ul></li>
<li>变量赋值/数据流传递：对应子类型关系。</li>
<li>加法和减法约束
<ul>
<li>函数内是双向数据流分析，但是要和Summary-based
analysis结合，无法求解的约束存到summary里尝试化简。</li>
</ul></li>
<li>比较运算
<ul>
<li>如果不是指针大小的整数比较，则判定为数字比较或者浮点数比较(应该吧？)</li>
<li>如果是指针大小的比较。
<ul>
<li>变量和常量比较
<ul>
<li>如果常量落在指针可能存在的区间里，则它即有可能是数字也可能是指针</li>
<li>指针类型和数字类型不会混合比较，即使出现了常量数字，则说明该数字为指针类型。</li>
</ul></li>
<li>变量和变量比较
<ul>
<li>同上</li>
</ul></li>
</ul></li>
</ul></li>
<li>整数转换
<ul>
<li>Truncate: 同时适用于有符号和无符号数。无法看出符号。Shl同理</li>
<li>ZExt: 如果是在32位/64位之间的转换，就当普通赋值。否则就都是数字</li>
<li>SExt: 全当做数字。</li>
</ul></li>
<li>比特操作
<ul>
<li>And
Or如果有常量，常量得符合一定要求才能认为可能是保留指针类型的指针运算。否则认为两端非指针。</li>
<li>And Or如果有常量，可以直接认为为保留类型的一元运算符</li>
</ul></li>
</ul>
<p><strong>加减法约束</strong></p>
<p>加减法约束的计算问题，其实是一个双向数据流分析问题。对应关系如下：</p>
<ul>
<li>数据流流动关系，即SSA上的def-use关系，对应约束生成时的子类型关系，都是一种边。</li>
<li>指针类型关于子类型关系双向传递，子类型关系可以看作是数据流分析的边，加减法看作带有运算的基本块。然后基于worklist算法，递归应用约束，直到迭代到不动点。。</li>
<li>子类型关系。</li>
</ul>
<p>因为本来就有基于类型的alias
analysis。所以涉及指针的时候，类型分析和指针分析和别名分析真的有联系。</p>
<ul>
<li>指针分析是别名分析的更精确版本。别名分析可以看作指针分析的应用。</li>
<li>类型分析需要随着指针指向去传播。</li>
<li>类型分析涉及指针时，不需要考虑流敏感性，上下文敏感性。</li>
</ul>
<h2 id="其他">其他</h2>
<p><strong>SSA的静态分析和传统静态分析</strong></p>
<ul>
<li>SSA的静态分析是在 SSA Edge ，即def-use
chain上进行，遇到Phi指令merge结果。。</li>
<li>传统静态分析在CFG上进行，遇到控制流合并时merge结果。</li>
</ul>
<p><strong>静态分析之间的分层依赖</strong></p>
<p>静态分析直接可能有依赖关系。比如指针和数字类型区分就被retypd类型恢复依赖，retypd进一步恢复指针的具体类型。</p>
<p>静态分析之间，是依赖关系还是更复杂的的关系。在于是否上层依赖的分析结果会反哺下层分析的结果。比如这里retypd如果恢复了更详细的具体类型，比如两个指针指向的结构体成员之间的复杂关系，那么这两个就有关系。。</p>
<p>问题：基于Steensgaard的线性时间指针分析算法的合并存储图，和retypd的sketches
等价图分析指针和数字类型，达到的精度是否相同？</p>
<p>答：应该是相同的。retypd的等价图构建后就等价是Steensgaard的存储关系图。</p>
<p>但是在跨函数分析框架下，这些具体分析都是一样地需要专门看待。。</p>
]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>StaticAnalysis</tag>
        <tag>Decompile</tag>
      </tags>
  </entry>
</search>
